2023-12-13 18:53:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-12-13 18:53:34 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 90184, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 55, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoint_adam_90184', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=90184, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_adam_90184', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='lstm_wiseman_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.01]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.01]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-12-13 18:53:34 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2023-12-13 18:53:34 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2023-12-13 18:53:34 | INFO | fairseq_cli.train | LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 256, padding_idx=1)
    (lstm): LSTM(256, 256)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 256, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(512, 256)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=256, out_features=256, bias=False)
      (output_proj): Linear(in_features=512, out_features=256, bias=False)
    )
  )
)
2023-12-13 18:53:34 | INFO | fairseq_cli.train | task: TranslationTask
2023-12-13 18:53:34 | INFO | fairseq_cli.train | model: LSTMModel
2023-12-13 18:53:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-12-13 18:53:34 | INFO | fairseq_cli.train | num. shared model params: 5,474,304 (num. trained: 5,474,304)
2023-12-13 18:53:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-12-13 18:53:34 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2023-12-13 18:53:34 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2023-12-13 18:53:34 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2023-12-13 18:53:36 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias
2023-12-13 18:53:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 18:53:36 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.392 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-12-13 18:53:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 18:53:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-12-13 18:53:36 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-12-13 18:53:36 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoint_adam_90184/checkpoint_last.pt
2023-12-13 18:53:36 | INFO | fairseq.trainer | No existing checkpoint found checkpoint_adam_90184/checkpoint_last.pt
2023-12-13 18:53:36 | INFO | fairseq.trainer | loading train data for epoch 1
2023-12-13 18:53:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2023-12-13 18:53:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2023-12-13 18:53:36 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2023-12-13 18:53:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:53:36 | INFO | fairseq.trainer | begin training epoch 1
2023-12-13 18:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:53:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-12-13 18:53:42 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "11.635", "nll_loss": "11.461", "ppl": "2818.87", "wps": "64700.1", "ups": "18.15", "wpb": "3559.3", "bsz": "142.3", "num_updates": "100", "lr": "0.00025", "gnorm": "0.546", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "6"}
2023-12-13 18:53:47 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "9.921", "nll_loss": "9.433", "ppl": "691.23", "wps": "64104.4", "ups": "18.25", "wpb": "3512.4", "bsz": "143.6", "num_updates": "200", "lr": "0.0005", "gnorm": "0.761", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "11"}
2023-12-13 18:53:53 | INFO | train_inner | {"epoch": 1, "update": 0.273, "loss": "9.677", "nll_loss": "9.16", "ppl": "572.2", "wps": "69108.5", "ups": "19.29", "wpb": "3582.6", "bsz": "139.1", "num_updates": "300", "lr": "0.00075", "gnorm": "0.732", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "17"}
2023-12-13 18:53:57 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "9.297", "nll_loss": "8.732", "ppl": "425.34", "wps": "74896.2", "ups": "20.94", "wpb": "3577.3", "bsz": "156.6", "num_updates": "400", "lr": "0.001", "gnorm": "0.648", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "21"}
2023-12-13 18:54:03 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "8.902", "nll_loss": "8.271", "ppl": "308.99", "wps": "68626.8", "ups": "18.74", "wpb": "3661.1", "bsz": "137.1", "num_updates": "500", "lr": "0.00125", "gnorm": "0.556", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "27"}
2023-12-13 18:54:08 | INFO | train_inner | {"epoch": 1, "update": 0.545, "loss": "8.475", "nll_loss": "7.77", "ppl": "218.3", "wps": "71821.8", "ups": "19.91", "wpb": "3607.4", "bsz": "150.6", "num_updates": "600", "lr": "0.0015", "gnorm": "0.51", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "32"}
2023-12-13 18:54:13 | INFO | train_inner | {"epoch": 1, "update": 0.636, "loss": "8.275", "nll_loss": "7.536", "ppl": "185.6", "wps": "66046.6", "ups": "18.68", "wpb": "3535.5", "bsz": "135.8", "num_updates": "700", "lr": "0.00175", "gnorm": "0.47", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "37"}
2023-12-13 18:54:19 | INFO | train_inner | {"epoch": 1, "update": 0.727, "loss": "7.955", "nll_loss": "7.163", "ppl": "143.29", "wps": "61907.2", "ups": "17.48", "wpb": "3541.8", "bsz": "144", "num_updates": "800", "lr": "0.002", "gnorm": "0.529", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "43"}
2023-12-13 18:54:24 | INFO | train_inner | {"epoch": 1, "update": 0.818, "loss": "7.553", "nll_loss": "6.696", "ppl": "103.65", "wps": "72796.2", "ups": "20.06", "wpb": "3629.8", "bsz": "149.7", "num_updates": "900", "lr": "0.00225", "gnorm": "0.457", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "48"}
2023-12-13 18:54:29 | INFO | train_inner | {"epoch": 1, "update": 0.908, "loss": "7.3", "nll_loss": "6.398", "ppl": "84.34", "wps": "67188.2", "ups": "18.78", "wpb": "3576.9", "bsz": "143", "num_updates": "1000", "lr": "0.0025", "gnorm": "0.483", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "53"}
2023-12-13 18:54:34 | INFO | train_inner | {"epoch": 1, "update": 0.999, "loss": "6.908", "nll_loss": "5.937", "ppl": "61.27", "wps": "75624.9", "ups": "20.82", "wpb": "3632.5", "bsz": "153", "num_updates": "1100", "lr": "0.00275", "gnorm": "0.43", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "58"}
2023-12-13 18:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:54:36 | INFO | valid | {"epoch": 1, "valid_loss": "6.653", "valid_nll_loss": "5.644", "valid_ppl": "49.99", "valid_wps": "130840", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "1101"}
2023-12-13 18:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1101 updates
2023-12-13 18:54:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint1.pt
2023-12-13 18:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint1.pt
2023-12-13 18:54:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint1.pt (epoch 1 @ 1101 updates, score 6.653) (writing took 2.3065755274146795 seconds)
2023-12-13 18:54:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-12-13 18:54:38 | INFO | train | {"epoch": 1, "train_loss": "8.71", "train_nll_loss": "8.042", "train_ppl": "263.52", "train_wps": "64058.7", "train_ups": "17.87", "train_wpb": "3583.7", "train_bsz": "145", "train_num_updates": "1101", "train_lr": "0.0027525", "train_gnorm": "0.556", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "62"}
2023-12-13 18:54:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:54:38 | INFO | fairseq.trainer | begin training epoch 2
2023-12-13 18:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:54:43 | INFO | train_inner | {"epoch": 2, "update": 1.09, "loss": "6.597", "nll_loss": "5.569", "ppl": "47.49", "wps": "38481.8", "ups": "10.68", "wpb": "3601.8", "bsz": "152.1", "num_updates": "1200", "lr": "0.003", "gnorm": "0.434", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "67"}
2023-12-13 18:54:48 | INFO | train_inner | {"epoch": 2, "update": 1.181, "loss": "6.401", "nll_loss": "5.334", "ppl": "40.34", "wps": "74177.3", "ups": "20.58", "wpb": "3604.3", "bsz": "152.6", "num_updates": "1300", "lr": "0.00325", "gnorm": "0.434", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "72"}
2023-12-13 18:54:53 | INFO | train_inner | {"epoch": 2, "update": 1.271, "loss": "6.203", "nll_loss": "5.1", "ppl": "34.29", "wps": "78670.6", "ups": "21.84", "wpb": "3602.9", "bsz": "151.6", "num_updates": "1400", "lr": "0.0035", "gnorm": "0.406", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "77"}
2023-12-13 18:54:58 | INFO | train_inner | {"epoch": 2, "update": 1.362, "loss": "6.177", "nll_loss": "5.065", "ppl": "33.47", "wps": "66736.4", "ups": "18.65", "wpb": "3579.2", "bsz": "129.7", "num_updates": "1500", "lr": "0.00375", "gnorm": "0.39", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "82"}
2023-12-13 18:55:03 | INFO | train_inner | {"epoch": 2, "update": 1.453, "loss": "6.011", "nll_loss": "4.867", "ppl": "29.18", "wps": "66288.6", "ups": "18.53", "wpb": "3578.1", "bsz": "151", "num_updates": "1600", "lr": "0.004", "gnorm": "0.425", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "88"}
2023-12-13 18:55:09 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "5.939", "nll_loss": "4.782", "ppl": "27.52", "wps": "64802.3", "ups": "18.09", "wpb": "3583", "bsz": "143.2", "num_updates": "1700", "lr": "0.00425", "gnorm": "0.378", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "93"}
2023-12-13 18:55:15 | INFO | train_inner | {"epoch": 2, "update": 1.634, "loss": "5.816", "nll_loss": "4.641", "ppl": "24.94", "wps": "61659.7", "ups": "17.39", "wpb": "3545.7", "bsz": "143.4", "num_updates": "1800", "lr": "0.0045", "gnorm": "0.366", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "99"}
2023-12-13 18:55:20 | INFO | train_inner | {"epoch": 2, "update": 1.725, "loss": "5.749", "nll_loss": "4.564", "ppl": "23.65", "wps": "68060.1", "ups": "19.07", "wpb": "3569.2", "bsz": "144.4", "num_updates": "1900", "lr": "0.00475", "gnorm": "0.349", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "104"}
2023-12-13 18:55:26 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "5.757", "nll_loss": "4.568", "ppl": "23.72", "wps": "63133.3", "ups": "17.8", "wpb": "3546.4", "bsz": "128.6", "num_updates": "2000", "lr": "0.005", "gnorm": "0.357", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "110"}
2023-12-13 18:55:31 | INFO | train_inner | {"epoch": 2, "update": 1.907, "loss": "5.703", "nll_loss": "4.506", "ppl": "22.72", "wps": "69768.3", "ups": "19.19", "wpb": "3635.7", "bsz": "134.7", "num_updates": "2100", "lr": "0.00525", "gnorm": "0.35", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "115"}
2023-12-13 18:55:35 | INFO | train_inner | {"epoch": 2, "update": 1.997, "loss": "5.459", "nll_loss": "4.224", "ppl": "18.69", "wps": "79345.8", "ups": "22.05", "wpb": "3598.6", "bsz": "168.7", "num_updates": "2200", "lr": "0.0055", "gnorm": "0.329", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "119"}
2023-12-13 18:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:55:37 | INFO | valid | {"epoch": 2, "valid_loss": "5.355", "valid_nll_loss": "4.15", "valid_ppl": "17.75", "valid_wps": "134617", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "2203", "valid_best_loss": "5.355"}
2023-12-13 18:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2203 updates
2023-12-13 18:55:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint2.pt
2023-12-13 18:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint2.pt
2023-12-13 18:55:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint2.pt (epoch 2 @ 2203 updates, score 5.355) (writing took 2.7336434554308653 seconds)
2023-12-13 18:55:40 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-12-13 18:55:40 | INFO | train | {"epoch": 2, "train_loss": "5.982", "train_nll_loss": "4.837", "train_ppl": "28.59", "train_wps": "64097.8", "train_ups": "17.89", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "2203", "train_lr": "0.0055075", "train_gnorm": "0.383", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "124"}
2023-12-13 18:55:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:55:40 | INFO | fairseq.trainer | begin training epoch 3
2023-12-13 18:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:55:44 | INFO | train_inner | {"epoch": 3, "update": 2.088, "loss": "5.338", "nll_loss": "4.081", "ppl": "16.92", "wps": "40438.1", "ups": "11.33", "wpb": "3569.1", "bsz": "163.8", "num_updates": "2300", "lr": "0.00575", "gnorm": "0.311", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "128"}
2023-12-13 18:55:50 | INFO | train_inner | {"epoch": 3, "update": 2.179, "loss": "5.498", "nll_loss": "4.261", "ppl": "19.17", "wps": "63894.9", "ups": "18.09", "wpb": "3531.7", "bsz": "137", "num_updates": "2400", "lr": "0.006", "gnorm": "0.332", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "134"}
2023-12-13 18:55:55 | INFO | train_inner | {"epoch": 3, "update": 2.27, "loss": "5.494", "nll_loss": "4.258", "ppl": "19.14", "wps": "63701.2", "ups": "17.69", "wpb": "3600.8", "bsz": "139.2", "num_updates": "2500", "lr": "0.00625", "gnorm": "0.323", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "139"}
2023-12-13 18:56:01 | INFO | train_inner | {"epoch": 3, "update": 2.36, "loss": "5.442", "nll_loss": "4.197", "ppl": "18.34", "wps": "65606.4", "ups": "18.44", "wpb": "3558.2", "bsz": "147.7", "num_updates": "2600", "lr": "0.0065", "gnorm": "0.306", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "145"}
2023-12-13 18:56:06 | INFO | train_inner | {"epoch": 3, "update": 2.451, "loss": "5.44", "nll_loss": "4.194", "ppl": "18.3", "wps": "65184.6", "ups": "18.5", "wpb": "3522.7", "bsz": "143", "num_updates": "2700", "lr": "0.00675", "gnorm": "0.301", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "150"}
2023-12-13 18:56:11 | INFO | train_inner | {"epoch": 3, "update": 2.542, "loss": "5.376", "nll_loss": "4.12", "ppl": "17.39", "wps": "76398.3", "ups": "20.77", "wpb": "3679.1", "bsz": "152.2", "num_updates": "2800", "lr": "0.007", "gnorm": "0.299", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "155"}
2023-12-13 18:56:16 | INFO | train_inner | {"epoch": 3, "update": 2.632, "loss": "5.367", "nll_loss": "4.107", "ppl": "17.24", "wps": "70714.1", "ups": "19.58", "wpb": "3612.4", "bsz": "147.4", "num_updates": "2900", "lr": "0.00725", "gnorm": "0.287", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "160"}
2023-12-13 18:56:22 | INFO | train_inner | {"epoch": 3, "update": 2.723, "loss": "5.476", "nll_loss": "4.229", "ppl": "18.75", "wps": "61049.7", "ups": "17.28", "wpb": "3533", "bsz": "124.2", "num_updates": "3000", "lr": "0.0075", "gnorm": "0.306", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "166"}
2023-12-13 18:56:27 | INFO | train_inner | {"epoch": 3, "update": 2.814, "loss": "5.44", "nll_loss": "4.188", "ppl": "18.23", "wps": "64352.8", "ups": "18.08", "wpb": "3560.3", "bsz": "130.7", "num_updates": "3100", "lr": "0.00775", "gnorm": "0.294", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "172"}
2023-12-13 18:56:32 | INFO | train_inner | {"epoch": 3, "update": 2.905, "loss": "5.288", "nll_loss": "4.012", "ppl": "16.14", "wps": "76779.6", "ups": "21.14", "wpb": "3632", "bsz": "160.1", "num_updates": "3200", "lr": "0.008", "gnorm": "0.282", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "176"}
2023-12-13 18:56:37 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "5.341", "nll_loss": "4.072", "ppl": "16.82", "wps": "74394.1", "ups": "20.74", "wpb": "3587.6", "bsz": "153.7", "num_updates": "3300", "lr": "0.00825", "gnorm": "0.289", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "181"}
2023-12-13 18:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:56:39 | INFO | valid | {"epoch": 3, "valid_loss": "5.16", "valid_nll_loss": "3.878", "valid_ppl": "14.7", "valid_wps": "125521", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "3305", "valid_best_loss": "5.16"}
2023-12-13 18:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3305 updates
2023-12-13 18:56:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint3.pt
2023-12-13 18:56:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint3.pt
2023-12-13 18:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint3.pt (epoch 3 @ 3305 updates, score 5.16) (writing took 2.509326236322522 seconds)
2023-12-13 18:56:41 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-12-13 18:56:41 | INFO | train | {"epoch": 3, "train_loss": "5.407", "train_nll_loss": "4.154", "train_ppl": "17.8", "train_wps": "64162.5", "train_ups": "17.9", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "3305", "train_lr": "0.0082625", "train_gnorm": "0.302", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "185"}
2023-12-13 18:56:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:56:41 | INFO | fairseq.trainer | begin training epoch 4
2023-12-13 18:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:56:46 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "5.171", "nll_loss": "3.873", "ppl": "14.66", "wps": "40530.1", "ups": "11.18", "wpb": "3624.8", "bsz": "156.2", "num_updates": "3400", "lr": "0.0085", "gnorm": "0.279", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "190"}
2023-12-13 18:56:52 | INFO | train_inner | {"epoch": 4, "update": 3.177, "loss": "5.3", "nll_loss": "4.012", "ppl": "16.13", "wps": "62833.3", "ups": "17.59", "wpb": "3572.1", "bsz": "139.6", "num_updates": "3500", "lr": "0.00875", "gnorm": "0.299", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "196"}
2023-12-13 18:56:57 | INFO | train_inner | {"epoch": 4, "update": 3.268, "loss": "5.313", "nll_loss": "4.03", "ppl": "16.34", "wps": "68058.7", "ups": "18.97", "wpb": "3588.6", "bsz": "143.8", "num_updates": "3600", "lr": "0.009", "gnorm": "0.291", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "201"}
2023-12-13 18:57:02 | INFO | train_inner | {"epoch": 4, "update": 3.358, "loss": "5.367", "nll_loss": "4.092", "ppl": "17.05", "wps": "65540.8", "ups": "18.45", "wpb": "3552.3", "bsz": "135", "num_updates": "3700", "lr": "0.00925", "gnorm": "0.292", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "206"}
2023-12-13 18:57:08 | INFO | train_inner | {"epoch": 4, "update": 3.449, "loss": "5.385", "nll_loss": "4.11", "ppl": "17.26", "wps": "61393.5", "ups": "17.34", "wpb": "3539.8", "bsz": "137.8", "num_updates": "3800", "lr": "0.0095", "gnorm": "0.306", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "212"}
2023-12-13 18:57:13 | INFO | train_inner | {"epoch": 4, "update": 3.54, "loss": "5.371", "nll_loss": "4.094", "ppl": "17.07", "wps": "71342.7", "ups": "19.97", "wpb": "3572.7", "bsz": "144.7", "num_updates": "3900", "lr": "0.00975", "gnorm": "0.296", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "217"}
2023-12-13 18:57:18 | INFO | train_inner | {"epoch": 4, "update": 3.631, "loss": "5.384", "nll_loss": "4.104", "ppl": "17.19", "wps": "69177.1", "ups": "19.2", "wpb": "3602.9", "bsz": "144.5", "num_updates": "4000", "lr": "0.01", "gnorm": "0.307", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "222"}
2023-12-13 18:57:23 | INFO | train_inner | {"epoch": 4, "update": 3.721, "loss": "5.315", "nll_loss": "4.029", "ppl": "16.33", "wps": "70776.4", "ups": "19.83", "wpb": "3569.1", "bsz": "156.8", "num_updates": "4100", "lr": "0.0098773", "gnorm": "0.285", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "227"}
2023-12-13 18:57:29 | INFO | train_inner | {"epoch": 4, "update": 3.812, "loss": "5.33", "nll_loss": "4.045", "ppl": "16.51", "wps": "68693.8", "ups": "19.09", "wpb": "3598.7", "bsz": "151.1", "num_updates": "4200", "lr": "0.009759", "gnorm": "0.294", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "233"}
2023-12-13 18:57:33 | INFO | train_inner | {"epoch": 4, "update": 3.903, "loss": "5.296", "nll_loss": "4.006", "ppl": "16.07", "wps": "76903.9", "ups": "21.12", "wpb": "3641", "bsz": "146.4", "num_updates": "4300", "lr": "0.00964486", "gnorm": "0.276", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "237"}
2023-12-13 18:57:38 | INFO | train_inner | {"epoch": 4, "update": 3.994, "loss": "5.364", "nll_loss": "4.084", "ppl": "16.96", "wps": "75413.2", "ups": "21.11", "wpb": "3571.9", "bsz": "140.9", "num_updates": "4400", "lr": "0.00953463", "gnorm": "0.296", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "242"}
2023-12-13 18:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:57:40 | INFO | valid | {"epoch": 4, "valid_loss": "5.087", "valid_nll_loss": "3.801", "valid_ppl": "13.94", "valid_wps": "133583", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "4407", "valid_best_loss": "5.087"}
2023-12-13 18:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4407 updates
2023-12-13 18:57:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint4.pt
2023-12-13 18:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint4.pt
2023-12-13 18:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint4.pt (epoch 4 @ 4407 updates, score 5.087) (writing took 2.5258933752775192 seconds)
2023-12-13 18:57:42 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-12-13 18:57:42 | INFO | train | {"epoch": 4, "train_loss": "5.325", "train_nll_loss": "4.042", "train_ppl": "16.47", "train_wps": "64657.2", "train_ups": "18.04", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "4407", "train_lr": "0.00952705", "train_gnorm": "0.293", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "246"}
2023-12-13 18:57:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:57:42 | INFO | fairseq.trainer | begin training epoch 5
2023-12-13 18:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:57:47 | INFO | train_inner | {"epoch": 5, "update": 4.084, "loss": "5.085", "nll_loss": "3.761", "ppl": "13.56", "wps": "38146.2", "ups": "10.83", "wpb": "3522.3", "bsz": "170.6", "num_updates": "4500", "lr": "0.00942809", "gnorm": "0.274", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "251"}
2023-12-13 18:57:53 | INFO | train_inner | {"epoch": 5, "update": 4.175, "loss": "5.258", "nll_loss": "3.958", "ppl": "15.54", "wps": "64433.7", "ups": "17.94", "wpb": "3591.5", "bsz": "129.2", "num_updates": "4600", "lr": "0.00932505", "gnorm": "0.294", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "257"}
2023-12-13 18:57:58 | INFO | train_inner | {"epoch": 5, "update": 4.266, "loss": "5.182", "nll_loss": "3.874", "ppl": "14.66", "wps": "72185", "ups": "20.17", "wpb": "3578.9", "bsz": "136.3", "num_updates": "4700", "lr": "0.00922531", "gnorm": "0.282", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "262"}
2023-12-13 18:58:03 | INFO | train_inner | {"epoch": 5, "update": 4.357, "loss": "5.245", "nll_loss": "3.946", "ppl": "15.41", "wps": "65079.1", "ups": "18.23", "wpb": "3569.7", "bsz": "134.2", "num_updates": "4800", "lr": "0.00912871", "gnorm": "0.289", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "267"}
2023-12-13 18:58:09 | INFO | train_inner | {"epoch": 5, "update": 4.447, "loss": "5.177", "nll_loss": "3.866", "ppl": "14.58", "wps": "63548.2", "ups": "17.77", "wpb": "3575.8", "bsz": "145.3", "num_updates": "4900", "lr": "0.00903508", "gnorm": "0.282", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "273"}
2023-12-13 18:58:14 | INFO | train_inner | {"epoch": 5, "update": 4.538, "loss": "5.172", "nll_loss": "3.863", "ppl": "14.55", "wps": "67427.2", "ups": "19.05", "wpb": "3539.4", "bsz": "144.3", "num_updates": "5000", "lr": "0.00894427", "gnorm": "0.273", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "278"}
2023-12-13 18:58:20 | INFO | train_inner | {"epoch": 5, "update": 4.629, "loss": "5.134", "nll_loss": "3.823", "ppl": "14.16", "wps": "66376.3", "ups": "18.47", "wpb": "3593.2", "bsz": "152.7", "num_updates": "5100", "lr": "0.00885615", "gnorm": "0.282", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "284"}
2023-12-13 18:58:25 | INFO | train_inner | {"epoch": 5, "update": 4.72, "loss": "5.159", "nll_loss": "3.854", "ppl": "14.46", "wps": "70395.5", "ups": "19.42", "wpb": "3625.1", "bsz": "144.2", "num_updates": "5200", "lr": "0.00877058", "gnorm": "0.267", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "289"}
2023-12-13 18:58:30 | INFO | train_inner | {"epoch": 5, "update": 4.81, "loss": "5.181", "nll_loss": "3.877", "ppl": "14.7", "wps": "70146.5", "ups": "19.65", "wpb": "3569.4", "bsz": "143.1", "num_updates": "5300", "lr": "0.00868744", "gnorm": "0.288", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "294"}
2023-12-13 18:58:34 | INFO | train_inner | {"epoch": 5, "update": 4.901, "loss": "4.996", "nll_loss": "3.669", "ppl": "12.72", "wps": "80131.5", "ups": "21.79", "wpb": "3677", "bsz": "168.7", "num_updates": "5400", "lr": "0.00860663", "gnorm": "0.257", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "299"}
2023-12-13 18:58:40 | INFO | train_inner | {"epoch": 5, "update": 4.992, "loss": "5.17", "nll_loss": "3.867", "ppl": "14.59", "wps": "67829.4", "ups": "18.9", "wpb": "3589.6", "bsz": "135.7", "num_updates": "5500", "lr": "0.00852803", "gnorm": "0.279", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "304"}
2023-12-13 18:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:58:42 | INFO | valid | {"epoch": 5, "valid_loss": "4.879", "valid_nll_loss": "3.569", "valid_ppl": "11.87", "valid_wps": "133285", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "5509", "valid_best_loss": "4.879"}
2023-12-13 18:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5509 updates
2023-12-13 18:58:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint5.pt
2023-12-13 18:58:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint5.pt
2023-12-13 18:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint5.pt (epoch 5 @ 5509 updates, score 4.879) (writing took 2.6189212799072266 seconds)
2023-12-13 18:58:44 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-12-13 18:58:44 | INFO | train | {"epoch": 5, "train_loss": "5.16", "train_nll_loss": "3.851", "train_ppl": "14.43", "train_wps": "63710.4", "train_ups": "17.78", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "5509", "train_lr": "0.00852106", "train_gnorm": "0.279", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "308"}
2023-12-13 18:58:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:58:44 | INFO | fairseq.trainer | begin training epoch 6
2023-12-13 18:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:58:49 | INFO | train_inner | {"epoch": 6, "update": 5.083, "loss": "4.981", "nll_loss": "3.644", "ppl": "12.5", "wps": "37088.9", "ups": "10.39", "wpb": "3571.3", "bsz": "135.6", "num_updates": "5600", "lr": "0.00845154", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "313"}
2023-12-13 18:58:54 | INFO | train_inner | {"epoch": 6, "update": 5.173, "loss": "5", "nll_loss": "3.67", "ppl": "12.72", "wps": "75073.6", "ups": "21.34", "wpb": "3517.4", "bsz": "149.2", "num_updates": "5700", "lr": "0.00837708", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "318"}
2023-12-13 18:58:59 | INFO | train_inner | {"epoch": 6, "update": 5.264, "loss": "5.041", "nll_loss": "3.716", "ppl": "13.14", "wps": "67882.9", "ups": "19.14", "wpb": "3546.1", "bsz": "141.2", "num_updates": "5800", "lr": "0.00830455", "gnorm": "0.263", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "323"}
2023-12-13 18:59:04 | INFO | train_inner | {"epoch": 6, "update": 5.355, "loss": "4.985", "nll_loss": "3.65", "ppl": "12.56", "wps": "69132", "ups": "19.14", "wpb": "3612", "bsz": "147.5", "num_updates": "5900", "lr": "0.00823387", "gnorm": "0.268", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "329"}
2023-12-13 18:59:09 | INFO | train_inner | {"epoch": 6, "update": 5.446, "loss": "5.014", "nll_loss": "3.689", "ppl": "12.9", "wps": "71760.7", "ups": "20.03", "wpb": "3581.8", "bsz": "139.1", "num_updates": "6000", "lr": "0.00816497", "gnorm": "0.269", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "334"}
2023-12-13 18:59:15 | INFO | train_inner | {"epoch": 6, "update": 5.536, "loss": "4.994", "nll_loss": "3.664", "ppl": "12.68", "wps": "66092.8", "ups": "18.33", "wpb": "3606.7", "bsz": "136.4", "num_updates": "6100", "lr": "0.00809776", "gnorm": "0.261", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "339"}
2023-12-13 18:59:20 | INFO | train_inner | {"epoch": 6, "update": 5.627, "loss": "4.972", "nll_loss": "3.639", "ppl": "12.45", "wps": "70076.2", "ups": "19.69", "wpb": "3559.8", "bsz": "151", "num_updates": "6200", "lr": "0.00803219", "gnorm": "0.271", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "344"}
2023-12-13 18:59:25 | INFO | train_inner | {"epoch": 6, "update": 5.718, "loss": "4.97", "nll_loss": "3.638", "ppl": "12.45", "wps": "68979", "ups": "19.33", "wpb": "3568.3", "bsz": "146.6", "num_updates": "6300", "lr": "0.00796819", "gnorm": "0.27", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "349"}
2023-12-13 18:59:30 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "4.963", "nll_loss": "3.629", "ppl": "12.38", "wps": "70281.3", "ups": "19.37", "wpb": "3627.9", "bsz": "151.7", "num_updates": "6400", "lr": "0.00790569", "gnorm": "0.264", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "354"}
2023-12-13 18:59:35 | INFO | train_inner | {"epoch": 6, "update": 5.899, "loss": "4.921", "nll_loss": "3.587", "ppl": "12.02", "wps": "81807.7", "ups": "22.44", "wpb": "3646.3", "bsz": "158.4", "num_updates": "6500", "lr": "0.00784465", "gnorm": "0.248", "loss_scale": "64", "train_wall": "4", "gb_free": "39", "wall": "359"}
2023-12-13 18:59:40 | INFO | train_inner | {"epoch": 6, "update": 5.99, "loss": "5.056", "nll_loss": "3.738", "ppl": "13.34", "wps": "62296.8", "ups": "17.59", "wpb": "3542.2", "bsz": "132.5", "num_updates": "6600", "lr": "0.00778499", "gnorm": "0.273", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "365"}
2023-12-13 18:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:59:42 | INFO | valid | {"epoch": 6, "valid_loss": "4.82", "valid_nll_loss": "3.496", "valid_ppl": "11.28", "valid_wps": "134671", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "6611", "valid_best_loss": "4.82"}
2023-12-13 18:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6611 updates
2023-12-13 18:59:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint6.pt
2023-12-13 18:59:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint6.pt
2023-12-13 18:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint6.pt (epoch 6 @ 6611 updates, score 4.82) (writing took 2.4616378266364336 seconds)
2023-12-13 18:59:45 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-12-13 18:59:45 | INFO | train | {"epoch": 6, "train_loss": "4.987", "train_nll_loss": "3.656", "train_ppl": "12.61", "train_wps": "65305.9", "train_ups": "18.22", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "6611", "train_lr": "0.00777851", "train_gnorm": "0.264", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "369"}
2023-12-13 18:59:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:59:45 | INFO | fairseq.trainer | begin training epoch 7
2023-12-13 18:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:59:50 | INFO | train_inner | {"epoch": 7, "update": 6.081, "loss": "4.817", "nll_loss": "3.459", "ppl": "11", "wps": "38810.4", "ups": "10.76", "wpb": "3606.7", "bsz": "149.8", "num_updates": "6700", "lr": "0.00772667", "gnorm": "0.266", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "374"}
2023-12-13 18:59:55 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "4.854", "nll_loss": "3.501", "ppl": "11.33", "wps": "67735.8", "ups": "18.75", "wpb": "3613.2", "bsz": "144.3", "num_updates": "6800", "lr": "0.00766965", "gnorm": "0.261", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "379"}
2023-12-13 19:00:00 | INFO | train_inner | {"epoch": 7, "update": 6.262, "loss": "4.857", "nll_loss": "3.508", "ppl": "11.38", "wps": "66527.1", "ups": "18.45", "wpb": "3606.6", "bsz": "156.2", "num_updates": "6900", "lr": "0.00761387", "gnorm": "0.266", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "385"}
2023-12-13 19:00:06 | INFO | train_inner | {"epoch": 7, "update": 6.353, "loss": "4.903", "nll_loss": "3.561", "ppl": "11.8", "wps": "65607.4", "ups": "18.44", "wpb": "3558", "bsz": "136.2", "num_updates": "7000", "lr": "0.00755929", "gnorm": "0.254", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "390"}
2023-12-13 19:00:11 | INFO | train_inner | {"epoch": 7, "update": 6.444, "loss": "4.913", "nll_loss": "3.572", "ppl": "11.89", "wps": "66558", "ups": "18.87", "wpb": "3526.6", "bsz": "132.5", "num_updates": "7100", "lr": "0.00750587", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "395"}
2023-12-13 19:00:16 | INFO | train_inner | {"epoch": 7, "update": 6.534, "loss": "4.837", "nll_loss": "3.486", "ppl": "11.2", "wps": "77210.2", "ups": "21.42", "wpb": "3604", "bsz": "153.9", "num_updates": "7200", "lr": "0.00745356", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "400"}
2023-12-13 19:00:21 | INFO | train_inner | {"epoch": 7, "update": 6.625, "loss": "4.87", "nll_loss": "3.525", "ppl": "11.51", "wps": "65844.2", "ups": "18.51", "wpb": "3556.5", "bsz": "148.8", "num_updates": "7300", "lr": "0.00740233", "gnorm": "0.265", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "405"}
2023-12-13 19:00:27 | INFO | train_inner | {"epoch": 7, "update": 6.716, "loss": "4.953", "nll_loss": "3.621", "ppl": "12.3", "wps": "65587.4", "ups": "18.24", "wpb": "3596.3", "bsz": "128.2", "num_updates": "7400", "lr": "0.00735215", "gnorm": "0.274", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "411"}
2023-12-13 19:00:31 | INFO | train_inner | {"epoch": 7, "update": 6.807, "loss": "4.82", "nll_loss": "3.473", "ppl": "11.11", "wps": "81792.8", "ups": "22.85", "wpb": "3579.6", "bsz": "160.8", "num_updates": "7500", "lr": "0.00730297", "gnorm": "0.244", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "415"}
2023-12-13 19:00:36 | INFO | train_inner | {"epoch": 7, "update": 6.897, "loss": "4.839", "nll_loss": "3.494", "ppl": "11.26", "wps": "77118", "ups": "21.2", "wpb": "3637.3", "bsz": "151.4", "num_updates": "7600", "lr": "0.00725476", "gnorm": "0.25", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "420"}
2023-12-13 19:00:41 | INFO | train_inner | {"epoch": 7, "update": 6.988, "loss": "4.864", "nll_loss": "3.522", "ppl": "11.49", "wps": "67077.5", "ups": "18.76", "wpb": "3575.7", "bsz": "150.8", "num_updates": "7700", "lr": "0.0072075", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "425"}
2023-12-13 19:00:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:00:43 | INFO | valid | {"epoch": 7, "valid_loss": "4.733", "valid_nll_loss": "3.397", "valid_ppl": "10.53", "valid_wps": "135116", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "7713", "valid_best_loss": "4.733"}
2023-12-13 19:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7713 updates
2023-12-13 19:00:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint7.pt
2023-12-13 19:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint7.pt
2023-12-13 19:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint7.pt (epoch 7 @ 7713 updates, score 4.733) (writing took 5.969559362158179 seconds)
2023-12-13 19:00:49 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-12-13 19:00:49 | INFO | train | {"epoch": 7, "train_loss": "4.868", "train_nll_loss": "3.523", "train_ppl": "11.49", "train_wps": "61021.2", "train_ups": "17.03", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "7713", "train_lr": "0.00720142", "train_gnorm": "0.26", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "434"}
2023-12-13 19:00:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:00:49 | INFO | fairseq.trainer | begin training epoch 8
2023-12-13 19:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:00:54 | INFO | train_inner | {"epoch": 8, "update": 7.079, "loss": "4.728", "nll_loss": "3.361", "ppl": "10.27", "wps": "28103.4", "ups": "7.84", "wpb": "3582.6", "bsz": "148.1", "num_updates": "7800", "lr": "0.00716115", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "438"}
2023-12-13 19:01:00 | INFO | train_inner | {"epoch": 8, "update": 7.17, "loss": "4.745", "nll_loss": "3.378", "ppl": "10.39", "wps": "63939.5", "ups": "17.88", "wpb": "3576.8", "bsz": "143.3", "num_updates": "7900", "lr": "0.00711568", "gnorm": "0.256", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "444"}
2023-12-13 19:01:05 | INFO | train_inner | {"epoch": 8, "update": 7.26, "loss": "4.774", "nll_loss": "3.415", "ppl": "10.66", "wps": "61308.8", "ups": "17.49", "wpb": "3505.9", "bsz": "142.2", "num_updates": "8000", "lr": "0.00707107", "gnorm": "0.261", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "449"}
2023-12-13 19:01:10 | INFO | train_inner | {"epoch": 8, "update": 7.351, "loss": "4.808", "nll_loss": "3.456", "ppl": "10.97", "wps": "71395.5", "ups": "19.83", "wpb": "3601", "bsz": "138.9", "num_updates": "8100", "lr": "0.00702728", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "454"}
2023-12-13 19:01:16 | INFO | train_inner | {"epoch": 8, "update": 7.442, "loss": "4.803", "nll_loss": "3.449", "ppl": "10.92", "wps": "65746.1", "ups": "18.32", "wpb": "3588.8", "bsz": "141", "num_updates": "8200", "lr": "0.0069843", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "460"}
2023-12-13 19:01:21 | INFO | train_inner | {"epoch": 8, "update": 7.533, "loss": "4.732", "nll_loss": "3.369", "ppl": "10.33", "wps": "75099.4", "ups": "20.71", "wpb": "3626.2", "bsz": "153.3", "num_updates": "8300", "lr": "0.0069421", "gnorm": "0.257", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "465"}
2023-12-13 19:01:26 | INFO | train_inner | {"epoch": 8, "update": 7.623, "loss": "4.765", "nll_loss": "3.409", "ppl": "10.62", "wps": "68653.4", "ups": "19.08", "wpb": "3597.6", "bsz": "150.5", "num_updates": "8400", "lr": "0.00690066", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "470"}
2023-12-13 19:01:31 | INFO | train_inner | {"epoch": 8, "update": 7.714, "loss": "4.769", "nll_loss": "3.415", "ppl": "10.66", "wps": "70289.1", "ups": "19.79", "wpb": "3551.3", "bsz": "148.9", "num_updates": "8500", "lr": "0.00685994", "gnorm": "0.246", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "475"}
2023-12-13 19:01:36 | INFO | train_inner | {"epoch": 8, "update": 7.805, "loss": "4.813", "nll_loss": "3.466", "ppl": "11.05", "wps": "65955.2", "ups": "18.45", "wpb": "3574.8", "bsz": "137", "num_updates": "8600", "lr": "0.00681994", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "480"}
2023-12-13 19:01:41 | INFO | train_inner | {"epoch": 8, "update": 7.896, "loss": "4.795", "nll_loss": "3.444", "ppl": "10.88", "wps": "75306.7", "ups": "20.84", "wpb": "3614.2", "bsz": "144.9", "num_updates": "8700", "lr": "0.00678064", "gnorm": "0.255", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "485"}
2023-12-13 19:01:46 | INFO | train_inner | {"epoch": 8, "update": 7.986, "loss": "4.783", "nll_loss": "3.432", "ppl": "10.79", "wps": "68569.4", "ups": "19.16", "wpb": "3579.1", "bsz": "148.1", "num_updates": "8800", "lr": "0.006742", "gnorm": "0.25", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "490"}
2023-12-13 19:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:01:48 | INFO | valid | {"epoch": 8, "valid_loss": "4.656", "valid_nll_loss": "3.309", "valid_ppl": "9.91", "valid_wps": "135852", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "8815", "valid_best_loss": "4.656"}
2023-12-13 19:01:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8815 updates
2023-12-13 19:01:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint8.pt
2023-12-13 19:01:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint8.pt
2023-12-13 19:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint8.pt (epoch 8 @ 8815 updates, score 4.656) (writing took 4.247701061889529 seconds)
2023-12-13 19:01:53 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-12-13 19:01:53 | INFO | train | {"epoch": 8, "train_loss": "4.772", "train_nll_loss": "3.416", "train_ppl": "10.67", "train_wps": "62403.4", "train_ups": "17.41", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "8815", "train_lr": "0.00673626", "train_gnorm": "0.253", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "497"}
2023-12-13 19:01:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:01:53 | INFO | fairseq.trainer | begin training epoch 9
2023-12-13 19:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:01:57 | INFO | train_inner | {"epoch": 9, "update": 8.077, "loss": "4.671", "nll_loss": "3.299", "ppl": "9.84", "wps": "33198.9", "ups": "9.13", "wpb": "3634.9", "bsz": "145.4", "num_updates": "8900", "lr": "0.00670402", "gnorm": "0.248", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "501"}
2023-12-13 19:02:02 | INFO | train_inner | {"epoch": 9, "update": 8.168, "loss": "4.617", "nll_loss": "3.234", "ppl": "9.41", "wps": "71402.4", "ups": "19.78", "wpb": "3610", "bsz": "147.5", "num_updates": "9000", "lr": "0.00666667", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "506"}
2023-12-13 19:02:08 | INFO | train_inner | {"epoch": 9, "update": 8.259, "loss": "4.672", "nll_loss": "3.299", "ppl": "9.84", "wps": "69746.2", "ups": "19.14", "wpb": "3644.3", "bsz": "147.4", "num_updates": "9100", "lr": "0.00662994", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "512"}
2023-12-13 19:02:13 | INFO | train_inner | {"epoch": 9, "update": 8.349, "loss": "4.671", "nll_loss": "3.298", "ppl": "9.84", "wps": "64187.7", "ups": "18.19", "wpb": "3529.2", "bsz": "157.6", "num_updates": "9200", "lr": "0.0065938", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "517"}
2023-12-13 19:02:18 | INFO | train_inner | {"epoch": 9, "update": 8.44, "loss": "4.75", "nll_loss": "3.394", "ppl": "10.51", "wps": "66935.4", "ups": "18.79", "wpb": "3563", "bsz": "130.6", "num_updates": "9300", "lr": "0.00655826", "gnorm": "0.249", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "523"}
2023-12-13 19:02:23 | INFO | train_inner | {"epoch": 9, "update": 8.531, "loss": "4.664", "nll_loss": "3.292", "ppl": "9.8", "wps": "72215", "ups": "19.95", "wpb": "3619.5", "bsz": "150.3", "num_updates": "9400", "lr": "0.00652328", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "528"}
2023-12-13 19:02:29 | INFO | train_inner | {"epoch": 9, "update": 8.622, "loss": "4.786", "nll_loss": "3.434", "ppl": "10.81", "wps": "65383.4", "ups": "18.57", "wpb": "3520.5", "bsz": "131.6", "num_updates": "9500", "lr": "0.00648886", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "533"}
2023-12-13 19:02:34 | INFO | train_inner | {"epoch": 9, "update": 8.712, "loss": "4.689", "nll_loss": "3.324", "ppl": "10.01", "wps": "72445.9", "ups": "20.08", "wpb": "3608.5", "bsz": "155.9", "num_updates": "9600", "lr": "0.00645497", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "538"}
2023-12-13 19:02:39 | INFO | train_inner | {"epoch": 9, "update": 8.803, "loss": "4.699", "nll_loss": "3.335", "ppl": "10.09", "wps": "74219.5", "ups": "20.58", "wpb": "3606.5", "bsz": "142.2", "num_updates": "9700", "lr": "0.00642161", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "543"}
2023-12-13 19:02:44 | INFO | train_inner | {"epoch": 9, "update": 8.894, "loss": "4.73", "nll_loss": "3.371", "ppl": "10.34", "wps": "63778", "ups": "18.23", "wpb": "3497.9", "bsz": "144.1", "num_updates": "9800", "lr": "0.00638877", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "548"}
2023-12-13 19:02:49 | INFO | train_inner | {"epoch": 9, "update": 8.985, "loss": "4.724", "nll_loss": "3.367", "ppl": "10.32", "wps": "73397.4", "ups": "20.39", "wpb": "3600.1", "bsz": "144.9", "num_updates": "9900", "lr": "0.00635642", "gnorm": "0.24", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "553"}
2023-12-13 19:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:02:51 | INFO | valid | {"epoch": 9, "valid_loss": "4.621", "valid_nll_loss": "3.303", "valid_ppl": "9.87", "valid_wps": "133745", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "9917", "valid_best_loss": "4.621"}
2023-12-13 19:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9917 updates
2023-12-13 19:02:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint9.pt
2023-12-13 19:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint9.pt
2023-12-13 19:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint9.pt (epoch 9 @ 9917 updates, score 4.621) (writing took 3.5993156637996435 seconds)
2023-12-13 19:02:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-12-13 19:02:55 | INFO | train | {"epoch": 9, "train_loss": "4.695", "train_nll_loss": "3.329", "train_ppl": "10.05", "train_wps": "63362.3", "train_ups": "17.68", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "9917", "train_lr": "0.00635097", "train_gnorm": "0.249", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "559"}
2023-12-13 19:02:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:02:55 | INFO | fairseq.trainer | begin training epoch 10
2023-12-13 19:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:03:00 | INFO | train_inner | {"epoch": 10, "update": 9.075, "loss": "4.651", "nll_loss": "3.278", "ppl": "9.7", "wps": "33109.3", "ups": "9.26", "wpb": "3577.4", "bsz": "130.9", "num_updates": "10000", "lr": "0.00632456", "gnorm": "0.245", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "564"}
2023-12-13 19:03:05 | INFO | train_inner | {"epoch": 10, "update": 9.166, "loss": "4.562", "nll_loss": "3.175", "ppl": "9.03", "wps": "70854.5", "ups": "19.64", "wpb": "3608.1", "bsz": "152.3", "num_updates": "10100", "lr": "0.00629317", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "569"}
2023-12-13 19:03:10 | INFO | train_inner | {"epoch": 10, "update": 9.257, "loss": "4.584", "nll_loss": "3.199", "ppl": "9.18", "wps": "70714.5", "ups": "19.4", "wpb": "3644.8", "bsz": "145", "num_updates": "10200", "lr": "0.00626224", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "574"}
2023-12-13 19:03:16 | INFO | train_inner | {"epoch": 10, "update": 9.348, "loss": "4.648", "nll_loss": "3.272", "ppl": "9.66", "wps": "65146", "ups": "18.2", "wpb": "3579.9", "bsz": "138.5", "num_updates": "10300", "lr": "0.00623177", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "580"}
2023-12-13 19:03:20 | INFO | train_inner | {"epoch": 10, "update": 9.438, "loss": "4.615", "nll_loss": "3.238", "ppl": "9.43", "wps": "76444", "ups": "21.19", "wpb": "3608.1", "bsz": "152.8", "num_updates": "10400", "lr": "0.00620174", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "584"}
2023-12-13 19:03:25 | INFO | train_inner | {"epoch": 10, "update": 9.529, "loss": "4.521", "nll_loss": "3.13", "ppl": "8.75", "wps": "78158.7", "ups": "21.69", "wpb": "3602.7", "bsz": "172.6", "num_updates": "10500", "lr": "0.00617213", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "589"}
2023-12-13 19:03:30 | INFO | train_inner | {"epoch": 10, "update": 9.62, "loss": "4.641", "nll_loss": "3.27", "ppl": "9.65", "wps": "65192.4", "ups": "18.89", "wpb": "3450.3", "bsz": "150.9", "num_updates": "10600", "lr": "0.00614295", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "594"}
2023-12-13 19:03:36 | INFO | train_inner | {"epoch": 10, "update": 9.711, "loss": "4.739", "nll_loss": "3.38", "ppl": "10.41", "wps": "65313.6", "ups": "18.23", "wpb": "3582.1", "bsz": "125", "num_updates": "10700", "lr": "0.00611418", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "600"}
2023-12-13 19:03:41 | INFO | train_inner | {"epoch": 10, "update": 9.801, "loss": "4.677", "nll_loss": "3.313", "ppl": "9.94", "wps": "68047.3", "ups": "19.15", "wpb": "3554.2", "bsz": "142.9", "num_updates": "10800", "lr": "0.00608581", "gnorm": "0.243", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "605"}
2023-12-13 19:03:46 | INFO | train_inner | {"epoch": 10, "update": 9.892, "loss": "4.635", "nll_loss": "3.265", "ppl": "9.61", "wps": "75351.5", "ups": "20.61", "wpb": "3656.7", "bsz": "150.1", "num_updates": "10900", "lr": "0.00605783", "gnorm": "0.24", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "610"}
2023-12-13 19:03:51 | INFO | train_inner | {"epoch": 10, "update": 9.983, "loss": "4.688", "nll_loss": "3.325", "ppl": "10.02", "wps": "64316.4", "ups": "18.16", "wpb": "3541.8", "bsz": "137.5", "num_updates": "11000", "lr": "0.00603023", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "615"}
2023-12-13 19:03:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:03:54 | INFO | valid | {"epoch": 10, "valid_loss": "4.582", "valid_nll_loss": "3.245", "valid_ppl": "9.48", "valid_wps": "135530", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "11019", "valid_best_loss": "4.582"}
2023-12-13 19:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11019 updates
2023-12-13 19:03:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint10.pt
2023-12-13 19:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint10.pt
2023-12-13 19:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint10.pt (epoch 10 @ 11019 updates, score 4.582) (writing took 3.600413680076599 seconds)
2023-12-13 19:03:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-12-13 19:03:57 | INFO | train | {"epoch": 10, "train_loss": "4.632", "train_nll_loss": "3.258", "train_ppl": "9.57", "train_wps": "63566.3", "train_ups": "17.74", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "11019", "train_lr": "0.00602503", "train_gnorm": "0.245", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "621"}
2023-12-13 19:03:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:03:57 | INFO | fairseq.trainer | begin training epoch 11
2023-12-13 19:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:04:02 | INFO | train_inner | {"epoch": 11, "update": 10.074, "loss": "4.511", "nll_loss": "3.119", "ppl": "8.68", "wps": "34261.3", "ups": "9.56", "wpb": "3585.3", "bsz": "152.2", "num_updates": "11100", "lr": "0.006003", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "626"}
2023-12-13 19:04:07 | INFO | train_inner | {"epoch": 11, "update": 10.164, "loss": "4.541", "nll_loss": "3.151", "ppl": "8.88", "wps": "63333.3", "ups": "17.47", "wpb": "3624.3", "bsz": "137.5", "num_updates": "11200", "lr": "0.00597614", "gnorm": "0.232", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "632"}
2023-12-13 19:04:13 | INFO | train_inner | {"epoch": 11, "update": 10.255, "loss": "4.523", "nll_loss": "3.134", "ppl": "8.78", "wps": "69755.5", "ups": "19.62", "wpb": "3555.1", "bsz": "154.2", "num_updates": "11300", "lr": "0.00594964", "gnorm": "0.236", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "637"}
2023-12-13 19:04:18 | INFO | train_inner | {"epoch": 11, "update": 10.346, "loss": "4.577", "nll_loss": "3.193", "ppl": "9.15", "wps": "71525.8", "ups": "19.85", "wpb": "3604", "bsz": "147", "num_updates": "11400", "lr": "0.00592349", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "642"}
2023-12-13 19:04:23 | INFO | train_inner | {"epoch": 11, "update": 10.436, "loss": "4.585", "nll_loss": "3.206", "ppl": "9.23", "wps": "72048.6", "ups": "20.1", "wpb": "3584.8", "bsz": "145.6", "num_updates": "11500", "lr": "0.00589768", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "647"}
2023-12-13 19:04:28 | INFO | train_inner | {"epoch": 11, "update": 10.527, "loss": "4.616", "nll_loss": "3.242", "ppl": "9.46", "wps": "67247.6", "ups": "18.8", "wpb": "3576.1", "bsz": "137", "num_updates": "11600", "lr": "0.0058722", "gnorm": "0.243", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "652"}
2023-12-13 19:04:33 | INFO | train_inner | {"epoch": 11, "update": 10.618, "loss": "4.577", "nll_loss": "3.196", "ppl": "9.16", "wps": "69979.3", "ups": "19.51", "wpb": "3587.4", "bsz": "148.5", "num_updates": "11700", "lr": "0.00584705", "gnorm": "0.243", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "657"}
2023-12-13 19:04:38 | INFO | train_inner | {"epoch": 11, "update": 10.709, "loss": "4.562", "nll_loss": "3.18", "ppl": "9.07", "wps": "67197.3", "ups": "18.91", "wpb": "3554.1", "bsz": "152.2", "num_updates": "11800", "lr": "0.00582223", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "662"}
2023-12-13 19:04:43 | INFO | train_inner | {"epoch": 11, "update": 10.799, "loss": "4.604", "nll_loss": "3.23", "ppl": "9.38", "wps": "70187.6", "ups": "19.78", "wpb": "3548", "bsz": "150.7", "num_updates": "11900", "lr": "0.00579771", "gnorm": "0.247", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "667"}
2023-12-13 19:04:49 | INFO | train_inner | {"epoch": 11, "update": 10.89, "loss": "4.625", "nll_loss": "3.254", "ppl": "9.54", "wps": "67880.4", "ups": "19.08", "wpb": "3558.2", "bsz": "139.9", "num_updates": "12000", "lr": "0.0057735", "gnorm": "0.249", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "673"}
2023-12-13 19:04:54 | INFO | train_inner | {"epoch": 11, "update": 10.981, "loss": "4.61", "nll_loss": "3.236", "ppl": "9.43", "wps": "68535.9", "ups": "18.68", "wpb": "3669", "bsz": "139.2", "num_updates": "12100", "lr": "0.0057496", "gnorm": "0.236", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "678"}
2023-12-13 19:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:04:57 | INFO | valid | {"epoch": 11, "valid_loss": "4.584", "valid_nll_loss": "3.247", "valid_ppl": "9.49", "valid_wps": "132689", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "12121", "valid_best_loss": "4.582"}
2023-12-13 19:04:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12121 updates
2023-12-13 19:04:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint11.pt
2023-12-13 19:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint11.pt
2023-12-13 19:05:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint11.pt (epoch 11 @ 12121 updates, score 4.584) (writing took 14.758596053346992 seconds)
2023-12-13 19:05:12 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-12-13 19:05:12 | INFO | train | {"epoch": 11, "train_loss": "4.575", "train_nll_loss": "3.195", "train_ppl": "9.15", "train_wps": "52842.6", "train_ups": "14.75", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "12121", "train_lr": "0.00574461", "train_gnorm": "0.242", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "696"}
2023-12-13 19:05:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:05:12 | INFO | fairseq.trainer | begin training epoch 12
2023-12-13 19:05:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:05:16 | INFO | train_inner | {"epoch": 12, "update": 11.072, "loss": "4.492", "nll_loss": "3.099", "ppl": "8.57", "wps": "16569", "ups": "4.61", "wpb": "3592.9", "bsz": "150.8", "num_updates": "12200", "lr": "0.00572598", "gnorm": "0.24", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "700"}
2023-12-13 19:05:22 | INFO | train_inner | {"epoch": 12, "update": 11.162, "loss": "4.538", "nll_loss": "3.148", "ppl": "8.86", "wps": "62478", "ups": "17.78", "wpb": "3514", "bsz": "130.4", "num_updates": "12300", "lr": "0.00570266", "gnorm": "0.239", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "706"}
2023-12-13 19:05:27 | INFO | train_inner | {"epoch": 12, "update": 11.253, "loss": "4.466", "nll_loss": "3.068", "ppl": "8.39", "wps": "73656.6", "ups": "20.66", "wpb": "3565.3", "bsz": "149.4", "num_updates": "12400", "lr": "0.00567962", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "711"}
2023-12-13 19:05:32 | INFO | train_inner | {"epoch": 12, "update": 11.344, "loss": "4.542", "nll_loss": "3.154", "ppl": "8.9", "wps": "66546.7", "ups": "18.86", "wpb": "3528.9", "bsz": "138.2", "num_updates": "12500", "lr": "0.00565685", "gnorm": "0.246", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "716"}
2023-12-13 19:05:37 | INFO | train_inner | {"epoch": 12, "update": 11.435, "loss": "4.529", "nll_loss": "3.141", "ppl": "8.82", "wps": "72241.3", "ups": "20.19", "wpb": "3577.7", "bsz": "146.4", "num_updates": "12600", "lr": "0.00563436", "gnorm": "0.232", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "721"}
2023-12-13 19:05:41 | INFO | train_inner | {"epoch": 12, "update": 11.525, "loss": "4.497", "nll_loss": "3.107", "ppl": "8.62", "wps": "77460.5", "ups": "21.27", "wpb": "3642.2", "bsz": "151.8", "num_updates": "12700", "lr": "0.00561214", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "726"}
2023-12-13 19:05:47 | INFO | train_inner | {"epoch": 12, "update": 11.616, "loss": "4.587", "nll_loss": "3.209", "ppl": "9.25", "wps": "67639", "ups": "18.73", "wpb": "3612", "bsz": "131.1", "num_updates": "12800", "lr": "0.00559017", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "731"}
2023-12-13 19:05:53 | INFO | train_inner | {"epoch": 12, "update": 11.707, "loss": "4.617", "nll_loss": "3.243", "ppl": "9.47", "wps": "61438.1", "ups": "17.49", "wpb": "3513.7", "bsz": "132", "num_updates": "12900", "lr": "0.00556846", "gnorm": "0.259", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "737"}
2023-12-13 19:05:57 | INFO | train_inner | {"epoch": 12, "update": 11.798, "loss": "4.451", "nll_loss": "3.054", "ppl": "8.3", "wps": "78632.3", "ups": "21.4", "wpb": "3675.1", "bsz": "179.3", "num_updates": "13000", "lr": "0.005547", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "741"}
2023-12-13 19:06:02 | INFO | train_inner | {"epoch": 12, "update": 11.888, "loss": "4.514", "nll_loss": "3.129", "ppl": "8.75", "wps": "75879.6", "ups": "20.99", "wpb": "3615.1", "bsz": "151.8", "num_updates": "13100", "lr": "0.00552579", "gnorm": "0.229", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "746"}
2023-12-13 19:06:08 | INFO | train_inner | {"epoch": 12, "update": 11.979, "loss": "4.608", "nll_loss": "3.235", "ppl": "9.41", "wps": "63498.2", "ups": "17.88", "wpb": "3550.6", "bsz": "138.2", "num_updates": "13200", "lr": "0.00550482", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "752"}
2023-12-13 19:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:06:10 | INFO | valid | {"epoch": 12, "valid_loss": "4.522", "valid_nll_loss": "3.174", "valid_ppl": "9.02", "valid_wps": "130213", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "13223", "valid_best_loss": "4.522"}
2023-12-13 19:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13223 updates
2023-12-13 19:06:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint12.pt
2023-12-13 19:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint12.pt
2023-12-13 19:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint12.pt (epoch 12 @ 13223 updates, score 4.522) (writing took 3.9281496107578278 seconds)
2023-12-13 19:06:14 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-12-13 19:06:14 | INFO | train | {"epoch": 12, "train_loss": "4.529", "train_nll_loss": "3.142", "train_ppl": "8.83", "train_wps": "63479.7", "train_ups": "17.71", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "13223", "train_lr": "0.00550003", "train_gnorm": "0.24", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "758"}
2023-12-13 19:06:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:06:14 | INFO | fairseq.trainer | begin training epoch 13
2023-12-13 19:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:06:18 | INFO | train_inner | {"epoch": 13, "update": 12.07, "loss": "4.403", "nll_loss": "2.998", "ppl": "7.99", "wps": "33872.2", "ups": "9.43", "wpb": "3591.8", "bsz": "153.6", "num_updates": "13300", "lr": "0.00548408", "gnorm": "0.231", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "762"}
2023-12-13 19:06:24 | INFO | train_inner | {"epoch": 13, "update": 12.161, "loss": "4.473", "nll_loss": "3.076", "ppl": "8.43", "wps": "62681.5", "ups": "17.56", "wpb": "3568.6", "bsz": "141.8", "num_updates": "13400", "lr": "0.00546358", "gnorm": "0.237", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "768"}
2023-12-13 19:06:29 | INFO | train_inner | {"epoch": 13, "update": 12.251, "loss": "4.511", "nll_loss": "3.12", "ppl": "8.69", "wps": "67094.6", "ups": "18.7", "wpb": "3587.3", "bsz": "137.4", "num_updates": "13500", "lr": "0.00544331", "gnorm": "0.243", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "773"}
2023-12-13 19:06:35 | INFO | train_inner | {"epoch": 13, "update": 12.342, "loss": "4.472", "nll_loss": "3.074", "ppl": "8.42", "wps": "64143.3", "ups": "17.88", "wpb": "3587.4", "bsz": "136.8", "num_updates": "13600", "lr": "0.00542326", "gnorm": "0.241", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "779"}
2023-12-13 19:06:40 | INFO | train_inner | {"epoch": 13, "update": 12.433, "loss": "4.481", "nll_loss": "3.091", "ppl": "8.52", "wps": "74469.6", "ups": "20.71", "wpb": "3596.5", "bsz": "154.2", "num_updates": "13700", "lr": "0.00540343", "gnorm": "0.228", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "784"}
2023-12-13 19:06:45 | INFO | train_inner | {"epoch": 13, "update": 12.524, "loss": "4.523", "nll_loss": "3.136", "ppl": "8.79", "wps": "66201.3", "ups": "18.66", "wpb": "3548.3", "bsz": "149.1", "num_updates": "13800", "lr": "0.00538382", "gnorm": "0.25", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "789"}
2023-12-13 19:06:50 | INFO | train_inner | {"epoch": 13, "update": 12.614, "loss": "4.54", "nll_loss": "3.155", "ppl": "8.91", "wps": "65242.8", "ups": "18.13", "wpb": "3598.8", "bsz": "132", "num_updates": "13900", "lr": "0.00536442", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "795"}
2023-12-13 19:06:55 | INFO | train_inner | {"epoch": 13, "update": 12.705, "loss": "4.516", "nll_loss": "3.129", "ppl": "8.75", "wps": "72022.3", "ups": "20.03", "wpb": "3595.5", "bsz": "137.8", "num_updates": "14000", "lr": "0.00534522", "gnorm": "0.232", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "800"}
2023-12-13 19:07:00 | INFO | train_inner | {"epoch": 13, "update": 12.796, "loss": "4.491", "nll_loss": "3.103", "ppl": "8.59", "wps": "74072.1", "ups": "20.76", "wpb": "3568.7", "bsz": "155.8", "num_updates": "14100", "lr": "0.00532624", "gnorm": "0.24", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "804"}
2023-12-13 19:07:05 | INFO | train_inner | {"epoch": 13, "update": 12.887, "loss": "4.463", "nll_loss": "3.07", "ppl": "8.4", "wps": "74147.1", "ups": "20.67", "wpb": "3586.5", "bsz": "155.3", "num_updates": "14200", "lr": "0.00530745", "gnorm": "0.247", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "809"}
2023-12-13 19:07:10 | INFO | train_inner | {"epoch": 13, "update": 12.977, "loss": "4.479", "nll_loss": "3.09", "ppl": "8.52", "wps": "71376.9", "ups": "19.73", "wpb": "3618.3", "bsz": "147", "num_updates": "14300", "lr": "0.00528886", "gnorm": "0.229", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "814"}
2023-12-13 19:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:07:13 | INFO | valid | {"epoch": 13, "valid_loss": "4.518", "valid_nll_loss": "3.154", "valid_ppl": "8.9", "valid_wps": "129320", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "14325", "valid_best_loss": "4.518"}
2023-12-13 19:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14325 updates
2023-12-13 19:07:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint13.pt
2023-12-13 19:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint13.pt
2023-12-13 19:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint13.pt (epoch 13 @ 14325 updates, score 4.518) (writing took 2.7487969379872084 seconds)
2023-12-13 19:07:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-12-13 19:07:16 | INFO | train | {"epoch": 13, "train_loss": "4.487", "train_nll_loss": "3.095", "train_ppl": "8.54", "train_wps": "63966.4", "train_ups": "17.85", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "14325", "train_lr": "0.00528424", "train_gnorm": "0.238", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "820"}
2023-12-13 19:07:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:07:16 | INFO | fairseq.trainer | begin training epoch 14
2023-12-13 19:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:07:20 | INFO | train_inner | {"epoch": 14, "update": 13.068, "loss": "4.428", "nll_loss": "3.025", "ppl": "8.14", "wps": "37186.9", "ups": "10.5", "wpb": "3542.5", "bsz": "137.7", "num_updates": "14400", "lr": "0.00527046", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "824"}
2023-12-13 19:07:25 | INFO | train_inner | {"epoch": 14, "update": 13.159, "loss": "4.399", "nll_loss": "2.99", "ppl": "7.95", "wps": "65910.4", "ups": "18.67", "wpb": "3531.2", "bsz": "129.8", "num_updates": "14500", "lr": "0.00525226", "gnorm": "0.232", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "829"}
2023-12-13 19:07:30 | INFO | train_inner | {"epoch": 14, "update": 13.25, "loss": "4.442", "nll_loss": "3.041", "ppl": "8.23", "wps": "70216.7", "ups": "19.77", "wpb": "3551.3", "bsz": "138.6", "num_updates": "14600", "lr": "0.00523424", "gnorm": "0.236", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "834"}
2023-12-13 19:07:35 | INFO | train_inner | {"epoch": 14, "update": 13.34, "loss": "4.406", "nll_loss": "3.005", "ppl": "8.03", "wps": "82777.6", "ups": "22.64", "wpb": "3655.9", "bsz": "163.7", "num_updates": "14700", "lr": "0.00521641", "gnorm": "0.241", "loss_scale": "64", "train_wall": "4", "gb_free": "39", "wall": "839"}
2023-12-13 19:07:40 | INFO | train_inner | {"epoch": 14, "update": 13.431, "loss": "4.46", "nll_loss": "3.064", "ppl": "8.36", "wps": "69193.8", "ups": "19.17", "wpb": "3609.3", "bsz": "138.9", "num_updates": "14800", "lr": "0.00519875", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "844"}
2023-12-13 19:07:45 | INFO | train_inner | {"epoch": 14, "update": 13.522, "loss": "4.425", "nll_loss": "3.023", "ppl": "8.13", "wps": "71126.1", "ups": "19.63", "wpb": "3622.9", "bsz": "151.1", "num_updates": "14900", "lr": "0.00518128", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "849"}
2023-12-13 19:07:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-13 19:07:50 | INFO | train_inner | {"epoch": 14, "update": 13.613, "loss": "4.437", "nll_loss": "3.04", "ppl": "8.23", "wps": "67830.1", "ups": "19.01", "wpb": "3567.3", "bsz": "151.5", "num_updates": "15000", "lr": "0.00516398", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "854"}
2023-12-13 19:07:56 | INFO | train_inner | {"epoch": 14, "update": 13.704, "loss": "4.515", "nll_loss": "3.129", "ppl": "8.75", "wps": "67077.9", "ups": "18.61", "wpb": "3603.8", "bsz": "142", "num_updates": "15100", "lr": "0.00514685", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "860"}
2023-12-13 19:08:01 | INFO | train_inner | {"epoch": 14, "update": 13.795, "loss": "4.536", "nll_loss": "3.154", "ppl": "8.9", "wps": "60449.6", "ups": "17.13", "wpb": "3528.9", "bsz": "139.9", "num_updates": "15200", "lr": "0.00512989", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "865"}
2023-12-13 19:08:06 | INFO | train_inner | {"epoch": 14, "update": 13.886, "loss": "4.495", "nll_loss": "3.108", "ppl": "8.62", "wps": "69121.6", "ups": "19.52", "wpb": "3541.1", "bsz": "140.6", "num_updates": "15300", "lr": "0.0051131", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "871"}
2023-12-13 19:08:11 | INFO | train_inner | {"epoch": 14, "update": 13.976, "loss": "4.458", "nll_loss": "3.067", "ppl": "8.38", "wps": "72914.3", "ups": "20.09", "wpb": "3629.8", "bsz": "158.8", "num_updates": "15400", "lr": "0.00509647", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "876"}
2023-12-13 19:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:08:14 | INFO | valid | {"epoch": 14, "valid_loss": "4.483", "valid_nll_loss": "3.127", "valid_ppl": "8.73", "valid_wps": "134715", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "15426", "valid_best_loss": "4.483"}
2023-12-13 19:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15426 updates
2023-12-13 19:08:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint14.pt
2023-12-13 19:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint14.pt
2023-12-13 19:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint14.pt (epoch 14 @ 15426 updates, score 4.483) (writing took 2.7921685576438904 seconds)
2023-12-13 19:08:17 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-12-13 19:08:17 | INFO | train | {"epoch": 14, "train_loss": "4.451", "train_nll_loss": "3.055", "train_ppl": "8.31", "train_wps": "64695.1", "train_ups": "18.05", "train_wpb": "3584.3", "train_bsz": "145.5", "train_num_updates": "15426", "train_lr": "0.00509218", "train_gnorm": "0.242", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "881"}
2023-12-13 19:08:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:08:17 | INFO | fairseq.trainer | begin training epoch 15
2023-12-13 19:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:08:20 | INFO | train_inner | {"epoch": 15, "update": 14.067, "loss": "4.322", "nll_loss": "2.906", "ppl": "7.5", "wps": "40570", "ups": "11.14", "wpb": "3641.3", "bsz": "157.4", "num_updates": "15500", "lr": "0.00508001", "gnorm": "0.218", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "885"}
2023-12-13 19:08:26 | INFO | train_inner | {"epoch": 15, "update": 14.158, "loss": "4.366", "nll_loss": "2.954", "ppl": "7.75", "wps": "71800.5", "ups": "19.68", "wpb": "3649.2", "bsz": "142.4", "num_updates": "15600", "lr": "0.0050637", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "890"}
2023-12-13 19:08:30 | INFO | train_inner | {"epoch": 15, "update": 14.249, "loss": "4.378", "nll_loss": "2.971", "ppl": "7.84", "wps": "74649.5", "ups": "20.91", "wpb": "3569.4", "bsz": "152.3", "num_updates": "15700", "lr": "0.00504754", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "894"}
2023-12-13 19:08:35 | INFO | train_inner | {"epoch": 15, "update": 14.339, "loss": "4.392", "nll_loss": "2.986", "ppl": "7.92", "wps": "67818.1", "ups": "19.23", "wpb": "3526", "bsz": "148.1", "num_updates": "15800", "lr": "0.00503155", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "900"}
2023-12-13 19:08:41 | INFO | train_inner | {"epoch": 15, "update": 14.43, "loss": "4.389", "nll_loss": "2.983", "ppl": "7.91", "wps": "71572.4", "ups": "19.94", "wpb": "3588.9", "bsz": "141.7", "num_updates": "15900", "lr": "0.0050157", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "905"}
2023-12-13 19:08:46 | INFO | train_inner | {"epoch": 15, "update": 14.521, "loss": "4.412", "nll_loss": "3.009", "ppl": "8.05", "wps": "67743.2", "ups": "18.97", "wpb": "3570.3", "bsz": "145.7", "num_updates": "16000", "lr": "0.005", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "910"}
2023-12-13 19:08:51 | INFO | train_inner | {"epoch": 15, "update": 14.612, "loss": "4.485", "nll_loss": "3.094", "ppl": "8.54", "wps": "65070.9", "ups": "18.27", "wpb": "3561.6", "bsz": "125.6", "num_updates": "16100", "lr": "0.00498445", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "915"}
2023-12-13 19:08:57 | INFO | train_inner | {"epoch": 15, "update": 14.702, "loss": "4.436", "nll_loss": "3.04", "ppl": "8.23", "wps": "66762.2", "ups": "18.73", "wpb": "3565", "bsz": "147.4", "num_updates": "16200", "lr": "0.00496904", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "921"}
2023-12-13 19:09:02 | INFO | train_inner | {"epoch": 15, "update": 14.793, "loss": "4.425", "nll_loss": "3.027", "ppl": "8.15", "wps": "67313.7", "ups": "18.94", "wpb": "3553.1", "bsz": "150.4", "num_updates": "16300", "lr": "0.00495377", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "926"}
2023-12-13 19:09:07 | INFO | train_inner | {"epoch": 15, "update": 14.884, "loss": "4.447", "nll_loss": "3.056", "ppl": "8.32", "wps": "73306.1", "ups": "20.39", "wpb": "3595", "bsz": "155.5", "num_updates": "16400", "lr": "0.00493865", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "931"}
2023-12-13 19:09:12 | INFO | train_inner | {"epoch": 15, "update": 14.975, "loss": "4.507", "nll_loss": "3.123", "ppl": "8.71", "wps": "67728.8", "ups": "18.71", "wpb": "3619.9", "bsz": "131.8", "num_updates": "16500", "lr": "0.00492366", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "936"}
2023-12-13 19:09:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:09:15 | INFO | valid | {"epoch": 15, "valid_loss": "4.504", "valid_nll_loss": "3.127", "valid_ppl": "8.74", "valid_wps": "133730", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "16528", "valid_best_loss": "4.483"}
2023-12-13 19:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16528 updates
2023-12-13 19:09:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint15.pt
2023-12-13 19:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint15.pt
2023-12-13 19:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint15.pt (epoch 15 @ 16528 updates, score 4.504) (writing took 2.0308713745325804 seconds)
2023-12-13 19:09:17 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-12-13 19:09:17 | INFO | train | {"epoch": 15, "train_loss": "4.414", "train_nll_loss": "3.013", "train_ppl": "8.07", "train_wps": "65522.2", "train_ups": "18.28", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "16528", "train_lr": "0.00491949", "train_gnorm": "0.237", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "941"}
2023-12-13 19:09:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:09:17 | INFO | fairseq.trainer | begin training epoch 16
2023-12-13 19:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:09:21 | INFO | train_inner | {"epoch": 16, "update": 15.065, "loss": "4.333", "nll_loss": "2.918", "ppl": "7.56", "wps": "40261.4", "ups": "11.31", "wpb": "3559.9", "bsz": "147.5", "num_updates": "16600", "lr": "0.00490881", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "945"}
2023-12-13 19:09:26 | INFO | train_inner | {"epoch": 16, "update": 15.156, "loss": "4.295", "nll_loss": "2.874", "ppl": "7.33", "wps": "75612.6", "ups": "21.11", "wpb": "3581.5", "bsz": "149", "num_updates": "16700", "lr": "0.00489409", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "950"}
2023-12-13 19:09:31 | INFO | train_inner | {"epoch": 16, "update": 15.247, "loss": "4.319", "nll_loss": "2.901", "ppl": "7.47", "wps": "66751.7", "ups": "18.51", "wpb": "3606.1", "bsz": "142", "num_updates": "16800", "lr": "0.0048795", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "955"}
2023-12-13 19:09:36 | INFO | train_inner | {"epoch": 16, "update": 15.338, "loss": "4.344", "nll_loss": "2.934", "ppl": "7.64", "wps": "75178.9", "ups": "21.02", "wpb": "3576.5", "bsz": "157.9", "num_updates": "16900", "lr": "0.00486504", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "960"}
2023-12-13 19:09:41 | INFO | train_inner | {"epoch": 16, "update": 15.428, "loss": "4.396", "nll_loss": "2.991", "ppl": "7.95", "wps": "66996.5", "ups": "18.78", "wpb": "3568.1", "bsz": "141.3", "num_updates": "17000", "lr": "0.00485071", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "965"}
2023-12-13 19:09:47 | INFO | train_inner | {"epoch": 16, "update": 15.519, "loss": "4.41", "nll_loss": "3.006", "ppl": "8.04", "wps": "65868.8", "ups": "18.31", "wpb": "3598", "bsz": "135.4", "num_updates": "17100", "lr": "0.00483651", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "971"}
2023-12-13 19:09:52 | INFO | train_inner | {"epoch": 16, "update": 15.61, "loss": "4.431", "nll_loss": "3.034", "ppl": "8.19", "wps": "71047.2", "ups": "20.13", "wpb": "3529.7", "bsz": "145.4", "num_updates": "17200", "lr": "0.00482243", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "976"}
2023-12-13 19:09:56 | INFO | train_inner | {"epoch": 16, "update": 15.701, "loss": "4.4", "nll_loss": "2.999", "ppl": "8", "wps": "74455.8", "ups": "20.67", "wpb": "3601.3", "bsz": "157.8", "num_updates": "17300", "lr": "0.00480847", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "981"}
2023-12-13 19:10:02 | INFO | train_inner | {"epoch": 16, "update": 15.791, "loss": "4.42", "nll_loss": "3.021", "ppl": "8.12", "wps": "64705.6", "ups": "18.16", "wpb": "3563.2", "bsz": "137.3", "num_updates": "17400", "lr": "0.00479463", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "986"}
2023-12-13 19:10:07 | INFO | train_inner | {"epoch": 16, "update": 15.882, "loss": "4.407", "nll_loss": "3.009", "ppl": "8.05", "wps": "71620.4", "ups": "19.94", "wpb": "3592.2", "bsz": "151.1", "num_updates": "17500", "lr": "0.00478091", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "991"}
2023-12-13 19:10:12 | INFO | train_inner | {"epoch": 16, "update": 15.973, "loss": "4.449", "nll_loss": "3.055", "ppl": "8.31", "wps": "69927.1", "ups": "19.38", "wpb": "3608.3", "bsz": "139", "num_updates": "17600", "lr": "0.00476731", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "996"}
2023-12-13 19:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:10:15 | INFO | valid | {"epoch": 16, "valid_loss": "4.501", "valid_nll_loss": "3.144", "valid_ppl": "8.84", "valid_wps": "132650", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "17630", "valid_best_loss": "4.483"}
2023-12-13 19:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17630 updates
2023-12-13 19:10:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint16.pt
2023-12-13 19:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint16.pt
2023-12-13 19:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint16.pt (epoch 16 @ 17630 updates, score 4.501) (writing took 1.7364214565604925 seconds)
2023-12-13 19:10:17 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-12-13 19:10:17 | INFO | train | {"epoch": 16, "train_loss": "4.382", "train_nll_loss": "2.977", "train_ppl": "7.87", "train_wps": "66210.6", "train_ups": "18.48", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "17630", "train_lr": "0.00476326", "train_gnorm": "0.236", "train_loss_scale": "32", "train_train_wall": "55", "train_gb_free": "38.9", "train_wall": "1001"}
2023-12-13 19:10:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:10:17 | INFO | fairseq.trainer | begin training epoch 17
2023-12-13 19:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:10:20 | INFO | train_inner | {"epoch": 17, "update": 16.064, "loss": "4.27", "nll_loss": "2.849", "ppl": "7.21", "wps": "44039.5", "ups": "12.26", "wpb": "3593", "bsz": "155.8", "num_updates": "17700", "lr": "0.00475383", "gnorm": "0.225", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1004"}
2023-12-13 19:10:26 | INFO | train_inner | {"epoch": 17, "update": 16.154, "loss": "4.355", "nll_loss": "2.944", "ppl": "7.7", "wps": "68893.8", "ups": "19.23", "wpb": "3583.4", "bsz": "134.6", "num_updates": "17800", "lr": "0.00474045", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1010"}
2023-12-13 19:10:31 | INFO | train_inner | {"epoch": 17, "update": 16.245, "loss": "4.287", "nll_loss": "2.865", "ppl": "7.29", "wps": "69087.3", "ups": "19.16", "wpb": "3605.7", "bsz": "149.1", "num_updates": "17900", "lr": "0.00472719", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1015"}
2023-12-13 19:10:36 | INFO | train_inner | {"epoch": 17, "update": 16.336, "loss": "4.365", "nll_loss": "2.957", "ppl": "7.77", "wps": "66340.8", "ups": "18.73", "wpb": "3541.7", "bsz": "139", "num_updates": "18000", "lr": "0.00471405", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1020"}
2023-12-13 19:10:42 | INFO | train_inner | {"epoch": 17, "update": 16.426, "loss": "4.394", "nll_loss": "2.991", "ppl": "7.95", "wps": "64264.2", "ups": "18.02", "wpb": "3566.6", "bsz": "131.7", "num_updates": "18100", "lr": "0.004701", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1026"}
2023-12-13 19:10:47 | INFO | train_inner | {"epoch": 17, "update": 16.517, "loss": "4.294", "nll_loss": "2.877", "ppl": "7.34", "wps": "71506.6", "ups": "20.15", "wpb": "3548.6", "bsz": "160.7", "num_updates": "18200", "lr": "0.00468807", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1031"}
2023-12-13 19:10:52 | INFO | train_inner | {"epoch": 17, "update": 16.608, "loss": "4.408", "nll_loss": "3.008", "ppl": "8.05", "wps": "67597.7", "ups": "18.74", "wpb": "3606.6", "bsz": "139.3", "num_updates": "18300", "lr": "0.00467525", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1036"}
2023-12-13 19:10:57 | INFO | train_inner | {"epoch": 17, "update": 16.699, "loss": "4.371", "nll_loss": "2.966", "ppl": "7.81", "wps": "68329.7", "ups": "19.26", "wpb": "3548.3", "bsz": "148.1", "num_updates": "18400", "lr": "0.00466252", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1041"}
2023-12-13 19:11:03 | INFO | train_inner | {"epoch": 17, "update": 16.789, "loss": "4.41", "nll_loss": "3.009", "ppl": "8.05", "wps": "66464.4", "ups": "18.48", "wpb": "3597", "bsz": "132.3", "num_updates": "18500", "lr": "0.00464991", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1047"}
2023-12-13 19:11:07 | INFO | train_inner | {"epoch": 17, "update": 16.88, "loss": "4.358", "nll_loss": "2.955", "ppl": "7.75", "wps": "79800.5", "ups": "21.86", "wpb": "3650.2", "bsz": "156.1", "num_updates": "18600", "lr": "0.00463739", "gnorm": "0.231", "loss_scale": "32", "train_wall": "4", "gb_free": "39", "wall": "1051"}
2023-12-13 19:11:12 | INFO | train_inner | {"epoch": 17, "update": 16.971, "loss": "4.342", "nll_loss": "2.936", "ppl": "7.65", "wps": "78596.4", "ups": "21.6", "wpb": "3638.8", "bsz": "158.9", "num_updates": "18700", "lr": "0.00462497", "gnorm": "0.223", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1056"}
2023-12-13 19:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:11:15 | INFO | valid | {"epoch": 17, "valid_loss": "4.495", "valid_nll_loss": "3.108", "valid_ppl": "8.62", "valid_wps": "134853", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "18732", "valid_best_loss": "4.483"}
2023-12-13 19:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18732 updates
2023-12-13 19:11:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint17.pt
2023-12-13 19:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint17.pt
2023-12-13 19:11:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint17.pt (epoch 17 @ 18732 updates, score 4.495) (writing took 1.9359776135534048 seconds)
2023-12-13 19:11:17 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-12-13 19:11:17 | INFO | train | {"epoch": 17, "train_loss": "4.352", "train_nll_loss": "2.943", "train_ppl": "7.69", "train_wps": "65710.7", "train_ups": "18.34", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "18732", "train_lr": "0.00462102", "train_gnorm": "0.235", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "1061"}
2023-12-13 19:11:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:11:17 | INFO | fairseq.trainer | begin training epoch 18
2023-12-13 19:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:11:21 | INFO | train_inner | {"epoch": 18, "update": 17.062, "loss": "4.33", "nll_loss": "2.917", "ppl": "7.55", "wps": "39708.4", "ups": "11.22", "wpb": "3540.4", "bsz": "135.4", "num_updates": "18800", "lr": "0.00461266", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1065"}
2023-12-13 19:11:26 | INFO | train_inner | {"epoch": 18, "update": 17.152, "loss": "4.258", "nll_loss": "2.834", "ppl": "7.13", "wps": "71839.4", "ups": "20.14", "wpb": "3566.2", "bsz": "151", "num_updates": "18900", "lr": "0.00460044", "gnorm": "0.226", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1070"}
2023-12-13 19:11:31 | INFO | train_inner | {"epoch": 18, "update": 17.243, "loss": "4.284", "nll_loss": "2.863", "ppl": "7.27", "wps": "68656.8", "ups": "19.07", "wpb": "3600.2", "bsz": "142", "num_updates": "19000", "lr": "0.00458831", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1075"}
2023-12-13 19:11:36 | INFO | train_inner | {"epoch": 18, "update": 17.334, "loss": "4.311", "nll_loss": "2.893", "ppl": "7.43", "wps": "65923", "ups": "18.73", "wpb": "3520.4", "bsz": "137", "num_updates": "19100", "lr": "0.00457629", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1080"}
2023-12-13 19:11:41 | INFO | train_inner | {"epoch": 18, "update": 17.425, "loss": "4.335", "nll_loss": "2.922", "ppl": "7.58", "wps": "73738.1", "ups": "20.13", "wpb": "3662.4", "bsz": "145.5", "num_updates": "19200", "lr": "0.00456435", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1085"}
2023-12-13 19:11:46 | INFO | train_inner | {"epoch": 18, "update": 17.515, "loss": "4.302", "nll_loss": "2.888", "ppl": "7.4", "wps": "76786.1", "ups": "21.12", "wpb": "3636.6", "bsz": "157", "num_updates": "19300", "lr": "0.00455251", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1090"}
2023-12-13 19:11:51 | INFO | train_inner | {"epoch": 18, "update": 17.606, "loss": "4.324", "nll_loss": "2.914", "ppl": "7.53", "wps": "72709.9", "ups": "20.04", "wpb": "3629", "bsz": "156.8", "num_updates": "19400", "lr": "0.00454077", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1095"}
2023-12-13 19:11:56 | INFO | train_inner | {"epoch": 18, "update": 17.697, "loss": "4.378", "nll_loss": "2.974", "ppl": "7.86", "wps": "69481.3", "ups": "19.25", "wpb": "3608.9", "bsz": "137", "num_updates": "19500", "lr": "0.00452911", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1100"}
2023-12-13 19:12:02 | INFO | train_inner | {"epoch": 18, "update": 17.788, "loss": "4.338", "nll_loss": "2.93", "ppl": "7.62", "wps": "63989.4", "ups": "17.86", "wpb": "3582.6", "bsz": "145.3", "num_updates": "19600", "lr": "0.00451754", "gnorm": "0.229", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1106"}
2023-12-13 19:12:07 | INFO | train_inner | {"epoch": 18, "update": 17.878, "loss": "4.382", "nll_loss": "2.981", "ppl": "7.89", "wps": "67546", "ups": "19.04", "wpb": "3547.7", "bsz": "143.6", "num_updates": "19700", "lr": "0.00450606", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1111"}
2023-12-13 19:12:13 | INFO | train_inner | {"epoch": 18, "update": 17.969, "loss": "4.394", "nll_loss": "2.994", "ppl": "7.97", "wps": "63433.2", "ups": "17.84", "wpb": "3555.5", "bsz": "137.9", "num_updates": "19800", "lr": "0.00449467", "gnorm": "0.243", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1117"}
2023-12-13 19:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:12:16 | INFO | valid | {"epoch": 18, "valid_loss": "4.459", "valid_nll_loss": "3.087", "valid_ppl": "8.5", "valid_wps": "133400", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "19834", "valid_best_loss": "4.459"}
2023-12-13 19:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19834 updates
2023-12-13 19:12:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint18.pt
2023-12-13 19:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint18.pt
2023-12-13 19:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint18.pt (epoch 18 @ 19834 updates, score 4.459) (writing took 2.9197996519505978 seconds)
2023-12-13 19:12:19 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-12-13 19:12:19 | INFO | train | {"epoch": 18, "train_loss": "4.327", "train_nll_loss": "2.915", "train_ppl": "7.54", "train_wps": "63557.3", "train_ups": "17.74", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "19834", "train_lr": "0.00449081", "train_gnorm": "0.236", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1123"}
2023-12-13 19:12:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:12:19 | INFO | fairseq.trainer | begin training epoch 19
2023-12-13 19:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:12:22 | INFO | train_inner | {"epoch": 19, "update": 18.06, "loss": "4.254", "nll_loss": "2.829", "ppl": "7.11", "wps": "37320.7", "ups": "10.47", "wpb": "3564.3", "bsz": "154.6", "num_updates": "19900", "lr": "0.00448336", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1126"}
2023-12-13 19:12:27 | INFO | train_inner | {"epoch": 19, "update": 18.151, "loss": "4.236", "nll_loss": "2.806", "ppl": "7", "wps": "66135.7", "ups": "18.55", "wpb": "3565.9", "bsz": "138", "num_updates": "20000", "lr": "0.00447214", "gnorm": "0.225", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1132"}
2023-12-13 19:12:33 | INFO | train_inner | {"epoch": 19, "update": 18.241, "loss": "4.217", "nll_loss": "2.788", "ppl": "6.91", "wps": "67749.8", "ups": "19.15", "wpb": "3538.2", "bsz": "157.7", "num_updates": "20100", "lr": "0.004461", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1137"}
2023-12-13 19:12:38 | INFO | train_inner | {"epoch": 19, "update": 18.332, "loss": "4.342", "nll_loss": "2.93", "ppl": "7.62", "wps": "62292.5", "ups": "17.72", "wpb": "3514.6", "bsz": "129.8", "num_updates": "20200", "lr": "0.00444994", "gnorm": "0.241", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1142"}
2023-12-13 19:12:44 | INFO | train_inner | {"epoch": 19, "update": 18.423, "loss": "4.326", "nll_loss": "2.913", "ppl": "7.53", "wps": "66812.7", "ups": "18.75", "wpb": "3563.5", "bsz": "133.4", "num_updates": "20300", "lr": "0.00443897", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1148"}
2023-12-13 19:12:49 | INFO | train_inner | {"epoch": 19, "update": 18.514, "loss": "4.313", "nll_loss": "2.899", "ppl": "7.46", "wps": "74144.8", "ups": "20.58", "wpb": "3601.9", "bsz": "142.7", "num_updates": "20400", "lr": "0.00442807", "gnorm": "0.222", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1153"}
2023-12-13 19:12:54 | INFO | train_inner | {"epoch": 19, "update": 18.604, "loss": "4.339", "nll_loss": "2.929", "ppl": "7.62", "wps": "67034.7", "ups": "18.71", "wpb": "3582", "bsz": "144.7", "num_updates": "20500", "lr": "0.00441726", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1158"}
2023-12-13 19:12:59 | INFO | train_inner | {"epoch": 19, "update": 18.695, "loss": "4.277", "nll_loss": "2.859", "ppl": "7.26", "wps": "69891.4", "ups": "19.5", "wpb": "3584.2", "bsz": "165.8", "num_updates": "20600", "lr": "0.00440653", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1163"}
2023-12-13 19:13:04 | INFO | train_inner | {"epoch": 19, "update": 18.786, "loss": "4.298", "nll_loss": "2.885", "ppl": "7.39", "wps": "69293.5", "ups": "19.36", "wpb": "3578.7", "bsz": "152.4", "num_updates": "20700", "lr": "0.00439587", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1168"}
2023-12-13 19:13:09 | INFO | train_inner | {"epoch": 19, "update": 18.877, "loss": "4.304", "nll_loss": "2.893", "ppl": "7.43", "wps": "70897.2", "ups": "19.32", "wpb": "3669", "bsz": "153.7", "num_updates": "20800", "lr": "0.00438529", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1173"}
2023-12-13 19:13:15 | INFO | train_inner | {"epoch": 19, "update": 18.967, "loss": "4.39", "nll_loss": "2.989", "ppl": "7.94", "wps": "61673.2", "ups": "17.23", "wpb": "3578.4", "bsz": "129.3", "num_updates": "20900", "lr": "0.00437479", "gnorm": "0.244", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1179"}
2023-12-13 19:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 19:13:18 | INFO | valid | {"epoch": 19, "valid_loss": "4.439", "valid_nll_loss": "3.087", "valid_ppl": "8.5", "valid_wps": "136176", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "20936", "valid_best_loss": "4.439"}
2023-12-13 19:13:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20936 updates
2023-12-13 19:13:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint19.pt
2023-12-13 19:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_90184/checkpoint19.pt
2023-12-13 19:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_90184/checkpoint19.pt (epoch 19 @ 20936 updates, score 4.439) (writing took 2.809344692155719 seconds)
2023-12-13 19:13:21 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-12-13 19:13:21 | INFO | train | {"epoch": 19, "train_loss": "4.3", "train_nll_loss": "2.884", "train_ppl": "7.38", "train_wps": "63379.1", "train_ups": "17.69", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "20936", "train_lr": "0.00437102", "train_gnorm": "0.234", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "1185"}
2023-12-13 19:13:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 19:13:21 | INFO | fairseq.trainer | begin training epoch 20
2023-12-13 19:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 19:13:25 | INFO | train_inner | {"epoch": 20, "update": 19.058, "loss": "4.281", "nll_loss": "2.862", "ppl": "7.27", "wps": "37043.1", "ups": "10.45", "wpb": "3546", "bsz": "138.4", "num_updates": "21000", "lr": "0.00436436", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1189"}
2023-12-13 19:13:30 | INFO | train_inner | {"epoch": 20, "update": 19.149, "loss": "4.173", "nll_loss": "2.737", "ppl": "6.67", "wps": "74535.6", "ups": "20.73", "wpb": "3595", "bsz": "156.2", "num_updates": "21100", "lr": "0.004354", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1194"}
2023-12-13 19:13:34 | INFO | train_inner | {"epoch": 20, "update": 19.24, "loss": "4.222", "nll_loss": "2.793", "ppl": "6.93", "wps": "72822.4", "ups": "20.25", "wpb": "3597", "bsz": "146.6", "num_updates": "21200", "lr": "0.00434372", "gnorm": "0.226", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1199"}
2023-12-13 19:13:40 | INFO | train_inner | {"epoch": 20, "update": 19.33, "loss": "4.258", "nll_loss": "2.836", "ppl": "7.14", "wps": "69239.7", "ups": "19.19", "wpb": "3608.6", "bsz": "148.8", "num_updates": "21300", "lr": "0.00433351", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1204"}
2023-12-13 19:13:45 | INFO | train_inner | {"epoch": 20, "update": 19.421, "loss": "4.234", "nll_loss": "2.811", "ppl": "7.02", "wps": "70803.4", "ups": "19.65", "wpb": "3603.7", "bsz": "157.4", "num_updates": "21400", "lr": "0.00432338", "gnorm": "0.229", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1209"}
2023-12-13 19:13:50 | INFO | train_inner | {"epoch": 20, "update": 19.512, "loss": "4.31", "nll_loss": "2.893", "ppl": "7.43", "wps": "61827.7", "ups": "17.54", "wpb": "3524.3", "bsz": "130.5", "num_updates": "21500", "lr": "0.00431331", "gnorm": "0.239", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1215"}
2023-12-13 19:13:56 | INFO | train_inner | {"epoch": 20, "update": 19.603, "loss": "4.291", "nll_loss": "2.877", "ppl": "7.34", "wps": "71177.9", "ups": "19.71", "wpb": "3612.1", "bsz": "154.2", "num_updates": "21600", "lr": "0.00430331", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1220"}
2023-12-13 19:14:01 | INFO | train_inner | {"epoch": 20, "update": 19.693, "loss": "4.279", "nll_loss": "2.863", "ppl": "7.28", "wps": "70586", "ups": "19.82", "wpb": "3561.4", "bsz": "151.2", "num_updates": "21700", "lr": "0.00429339", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1225"}
2023-12-13 19:14:06 | INFO | train_inner | {"epoch": 20, "update": 19.784, "loss": "4.295", "nll_loss": "2.882", "ppl": "7.37", "wps": "71007.6", "ups": "19.48", "wpb": "3644.3", "bsz": "150.2", "num_updates": "21800", "lr": "0.00428353", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1230"}
2023-12-13 19:14:11 | INFO | train_inner | {"epoch": 20, "update": 19.875, "loss": "4.32", "nll_loss": "2.908", "ppl": "7.5", "wps": "63151.9", "ups": "17.9", "wpb": "3528.3", "bsz": "133.7", "num_updates": "21900", "lr": "0.00427374", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1235"}
