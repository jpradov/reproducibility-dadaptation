2023-12-13 17:56:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-12-13 17:56:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 74619, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 55, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoint_adam_74619', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=74619, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_adam_74619', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='lstm_wiseman_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.01]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.01]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-12-13 17:56:54 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2023-12-13 17:56:54 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2023-12-13 17:56:54 | INFO | fairseq_cli.train | LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 256, padding_idx=1)
    (lstm): LSTM(256, 256)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 256, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(512, 256)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=256, out_features=256, bias=False)
      (output_proj): Linear(in_features=512, out_features=256, bias=False)
    )
  )
)
2023-12-13 17:56:54 | INFO | fairseq_cli.train | task: TranslationTask
2023-12-13 17:56:54 | INFO | fairseq_cli.train | model: LSTMModel
2023-12-13 17:56:54 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-12-13 17:56:54 | INFO | fairseq_cli.train | num. shared model params: 5,474,304 (num. trained: 5,474,304)
2023-12-13 17:56:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-12-13 17:56:54 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2023-12-13 17:56:54 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2023-12-13 17:56:54 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2023-12-13 17:56:56 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias
2023-12-13 17:56:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 17:56:56 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.392 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-12-13 17:56:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 17:56:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-12-13 17:56:56 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-12-13 17:56:56 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoint_adam_74619/checkpoint_last.pt
2023-12-13 17:56:56 | INFO | fairseq.trainer | No existing checkpoint found checkpoint_adam_74619/checkpoint_last.pt
2023-12-13 17:56:56 | INFO | fairseq.trainer | loading train data for epoch 1
2023-12-13 17:56:56 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2023-12-13 17:56:57 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2023-12-13 17:56:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2023-12-13 17:56:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 17:56:57 | INFO | fairseq.trainer | begin training epoch 1
2023-12-13 17:56:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 17:57:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-12-13 17:57:03 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "11.608", "nll_loss": "11.429", "ppl": "2756.71", "wps": "60481.5", "ups": "16.97", "wpb": "3552.9", "bsz": "139.9", "num_updates": "100", "lr": "0.00025", "gnorm": "0.517", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "7"}
2023-12-13 17:57:08 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "9.941", "nll_loss": "9.454", "ppl": "701.4", "wps": "67079.1", "ups": "18.9", "wpb": "3549.9", "bsz": "135", "num_updates": "200", "lr": "0.0005", "gnorm": "0.718", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "12"}
2023-12-13 17:57:13 | INFO | train_inner | {"epoch": 1, "update": 0.273, "loss": "9.623", "nll_loss": "9.098", "ppl": "548.09", "wps": "72799.3", "ups": "20.15", "wpb": "3612.2", "bsz": "155", "num_updates": "300", "lr": "0.00075", "gnorm": "0.82", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "17"}
2023-12-13 17:57:19 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "9.38", "nll_loss": "8.825", "ppl": "453.46", "wps": "66910.5", "ups": "18.98", "wpb": "3525.7", "bsz": "146.2", "num_updates": "400", "lr": "0.001", "gnorm": "0.643", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "22"}
2023-12-13 17:57:24 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "8.933", "nll_loss": "8.306", "ppl": "316.58", "wps": "70747", "ups": "19.53", "wpb": "3621.6", "bsz": "146.1", "num_updates": "500", "lr": "0.00125", "gnorm": "0.562", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "27"}
2023-12-13 17:57:29 | INFO | train_inner | {"epoch": 1, "update": 0.545, "loss": "8.612", "nll_loss": "7.927", "ppl": "243.4", "wps": "65993.5", "ups": "18.53", "wpb": "3561.6", "bsz": "140.5", "num_updates": "600", "lr": "0.0015", "gnorm": "0.522", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "33"}
2023-12-13 17:57:34 | INFO | train_inner | {"epoch": 1, "update": 0.636, "loss": "8.279", "nll_loss": "7.539", "ppl": "186.04", "wps": "72390.7", "ups": "20.41", "wpb": "3546.7", "bsz": "151", "num_updates": "700", "lr": "0.00175", "gnorm": "0.469", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "38"}
2023-12-13 17:57:39 | INFO | train_inner | {"epoch": 1, "update": 0.727, "loss": "7.911", "nll_loss": "7.112", "ppl": "138.38", "wps": "72726.8", "ups": "20.08", "wpb": "3622.3", "bsz": "153.9", "num_updates": "800", "lr": "0.002", "gnorm": "0.463", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "43"}
2023-12-13 17:57:45 | INFO | train_inner | {"epoch": 1, "update": 0.818, "loss": "7.676", "nll_loss": "6.835", "ppl": "114.2", "wps": "64258.6", "ups": "17.55", "wpb": "3661.5", "bsz": "131", "num_updates": "900", "lr": "0.00225", "gnorm": "0.501", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "48"}
2023-12-13 17:57:50 | INFO | train_inner | {"epoch": 1, "update": 0.908, "loss": "7.267", "nll_loss": "6.361", "ppl": "82.2", "wps": "67649.1", "ups": "18.93", "wpb": "3573.9", "bsz": "142.2", "num_updates": "1000", "lr": "0.0025", "gnorm": "0.468", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "54"}
2023-12-13 17:57:55 | INFO | train_inner | {"epoch": 1, "update": 0.999, "loss": "6.916", "nll_loss": "5.946", "ppl": "61.66", "wps": "67428.8", "ups": "18.78", "wpb": "3590.5", "bsz": "154.7", "num_updates": "1100", "lr": "0.00275", "gnorm": "0.485", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "59"}
2023-12-13 17:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 17:57:57 | INFO | valid | {"epoch": 1, "valid_loss": "6.729", "valid_nll_loss": "5.713", "valid_ppl": "52.46", "valid_wps": "126315", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "1101"}
2023-12-13 17:57:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1101 updates
2023-12-13 17:57:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint1.pt
2023-12-13 17:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint1.pt
2023-12-13 17:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint1.pt (epoch 1 @ 1101 updates, score 6.729) (writing took 2.6495822854340076 seconds)
2023-12-13 17:57:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-12-13 17:58:00 | INFO | train | {"epoch": 1, "train_loss": "8.733", "train_nll_loss": "8.067", "train_ppl": "268.25", "train_wps": "63291.3", "train_ups": "17.66", "train_wpb": "3583.6", "train_bsz": "145", "train_num_updates": "1101", "train_lr": "0.0027525", "train_gnorm": "0.561", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "63"}
2023-12-13 17:58:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 17:58:00 | INFO | fairseq.trainer | begin training epoch 2
2023-12-13 17:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 17:58:05 | INFO | train_inner | {"epoch": 2, "update": 1.09, "loss": "6.789", "nll_loss": "5.79", "ppl": "55.33", "wps": "35985.5", "ups": "10.13", "wpb": "3553.6", "bsz": "127.4", "num_updates": "1200", "lr": "0.003", "gnorm": "0.474", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "69"}
2023-12-13 17:58:11 | INFO | train_inner | {"epoch": 2, "update": 1.181, "loss": "6.437", "nll_loss": "5.376", "ppl": "41.52", "wps": "64524.1", "ups": "18.29", "wpb": "3528.6", "bsz": "158", "num_updates": "1300", "lr": "0.00325", "gnorm": "0.463", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "74"}
2023-12-13 17:58:15 | INFO | train_inner | {"epoch": 2, "update": 1.271, "loss": "6.272", "nll_loss": "5.181", "ppl": "36.27", "wps": "77976.5", "ups": "21.94", "wpb": "3554.8", "bsz": "151.2", "num_updates": "1400", "lr": "0.0035", "gnorm": "0.41", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "79"}
2023-12-13 17:58:20 | INFO | train_inner | {"epoch": 2, "update": 1.362, "loss": "6.145", "nll_loss": "5.028", "ppl": "32.62", "wps": "70400.5", "ups": "19.42", "wpb": "3625.9", "bsz": "142.4", "num_updates": "1500", "lr": "0.00375", "gnorm": "0.404", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "84"}
2023-12-13 17:58:26 | INFO | train_inner | {"epoch": 2, "update": 1.453, "loss": "6.012", "nll_loss": "4.87", "ppl": "29.24", "wps": "66864.8", "ups": "18.69", "wpb": "3578.4", "bsz": "153.4", "num_updates": "1600", "lr": "0.004", "gnorm": "0.4", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "89"}
2023-12-13 17:58:32 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "5.97", "nll_loss": "4.817", "ppl": "28.19", "wps": "58239.1", "ups": "16.22", "wpb": "3589.9", "bsz": "136.5", "num_updates": "1700", "lr": "0.00425", "gnorm": "0.396", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "96"}
2023-12-13 17:58:37 | INFO | train_inner | {"epoch": 2, "update": 1.634, "loss": "5.806", "nll_loss": "4.63", "ppl": "24.76", "wps": "66665.2", "ups": "18.71", "wpb": "3563.7", "bsz": "147.5", "num_updates": "1800", "lr": "0.0045", "gnorm": "0.36", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "101"}
2023-12-13 17:58:43 | INFO | train_inner | {"epoch": 2, "update": 1.725, "loss": "5.82", "nll_loss": "4.642", "ppl": "24.98", "wps": "58797.1", "ups": "16.77", "wpb": "3506.9", "bsz": "141.4", "num_updates": "1900", "lr": "0.00475", "gnorm": "0.374", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "107"}
2023-12-13 17:58:49 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "5.668", "nll_loss": "4.467", "ppl": "22.12", "wps": "67886.9", "ups": "18.65", "wpb": "3640.8", "bsz": "146.5", "num_updates": "2000", "lr": "0.005", "gnorm": "0.339", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "112"}
2023-12-13 17:58:53 | INFO | train_inner | {"epoch": 2, "update": 1.907, "loss": "5.547", "nll_loss": "4.325", "ppl": "20.05", "wps": "75137.8", "ups": "20.56", "wpb": "3655", "bsz": "157.8", "num_updates": "2100", "lr": "0.00525", "gnorm": "0.333", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "117"}
2023-12-13 17:58:59 | INFO | train_inner | {"epoch": 2, "update": 1.997, "loss": "5.624", "nll_loss": "4.414", "ppl": "21.32", "wps": "59545.5", "ups": "16.45", "wpb": "3620", "bsz": "135.4", "num_updates": "2200", "lr": "0.0055", "gnorm": "0.327", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "123"}
2023-12-13 17:59:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 17:59:01 | INFO | valid | {"epoch": 2, "valid_loss": "5.321", "valid_nll_loss": "4.097", "valid_ppl": "17.12", "valid_wps": "120469", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "2203", "valid_best_loss": "5.321"}
2023-12-13 17:59:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2203 updates
2023-12-13 17:59:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint2.pt
2023-12-13 17:59:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint2.pt
2023-12-13 17:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint2.pt (epoch 2 @ 2203 updates, score 5.321) (writing took 2.4067416470497847 seconds)
2023-12-13 17:59:03 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-12-13 17:59:03 | INFO | train | {"epoch": 2, "train_loss": "6.003", "train_nll_loss": "4.861", "train_ppl": "29.06", "train_wps": "61710.9", "train_ups": "17.22", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "2203", "train_lr": "0.0055075", "train_gnorm": "0.389", "train_loss_scale": "64", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "127"}
2023-12-13 17:59:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 17:59:04 | INFO | fairseq.trainer | begin training epoch 3
2023-12-13 17:59:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 17:59:09 | INFO | train_inner | {"epoch": 3, "update": 2.088, "loss": "5.457", "nll_loss": "4.216", "ppl": "18.59", "wps": "35522.3", "ups": "10.06", "wpb": "3529.4", "bsz": "148.2", "num_updates": "2300", "lr": "0.00575", "gnorm": "0.334", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "133"}
2023-12-13 17:59:15 | INFO | train_inner | {"epoch": 3, "update": 2.179, "loss": "5.419", "nll_loss": "4.172", "ppl": "18.03", "wps": "67396.6", "ups": "18.78", "wpb": "3589.3", "bsz": "151.7", "num_updates": "2400", "lr": "0.006", "gnorm": "0.319", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "138"}
2023-12-13 17:59:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-13 17:59:22 | INFO | train_inner | {"epoch": 3, "update": 2.27, "loss": "5.502", "nll_loss": "4.264", "ppl": "19.21", "wps": "51712.5", "ups": "14.56", "wpb": "3551.3", "bsz": "132.3", "num_updates": "2500", "lr": "0.00625", "gnorm": "0.333", "loss_scale": "32", "train_wall": "7", "gb_free": "39", "wall": "145"}
2023-12-13 17:59:28 | INFO | train_inner | {"epoch": 3, "update": 2.361, "loss": "5.495", "nll_loss": "4.255", "ppl": "19.1", "wps": "58356.4", "ups": "16.49", "wpb": "3539", "bsz": "129", "num_updates": "2600", "lr": "0.0065", "gnorm": "0.322", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "151"}
2023-12-13 17:59:33 | INFO | train_inner | {"epoch": 3, "update": 2.452, "loss": "5.384", "nll_loss": "4.129", "ppl": "17.5", "wps": "72353.8", "ups": "19.97", "wpb": "3623.5", "bsz": "149.8", "num_updates": "2700", "lr": "0.00675", "gnorm": "0.298", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "156"}
2023-12-13 17:59:38 | INFO | train_inner | {"epoch": 3, "update": 2.543, "loss": "5.409", "nll_loss": "4.156", "ppl": "17.83", "wps": "66497.6", "ups": "18.57", "wpb": "3581.6", "bsz": "155.4", "num_updates": "2800", "lr": "0.007", "gnorm": "0.315", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "162"}
2023-12-13 17:59:43 | INFO | train_inner | {"epoch": 3, "update": 2.633, "loss": "5.412", "nll_loss": "4.161", "ppl": "17.88", "wps": "68093.6", "ups": "19.22", "wpb": "3542.4", "bsz": "140.6", "num_updates": "2900", "lr": "0.00725", "gnorm": "0.309", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "167"}
2023-12-13 17:59:49 | INFO | train_inner | {"epoch": 3, "update": 2.724, "loss": "5.391", "nll_loss": "4.133", "ppl": "17.54", "wps": "66234.7", "ups": "18.49", "wpb": "3582", "bsz": "139.6", "num_updates": "3000", "lr": "0.0075", "gnorm": "0.303", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "172"}
2023-12-13 17:59:54 | INFO | train_inner | {"epoch": 3, "update": 2.815, "loss": "5.406", "nll_loss": "4.147", "ppl": "17.71", "wps": "64606.2", "ups": "17.75", "wpb": "3640", "bsz": "142.9", "num_updates": "3100", "lr": "0.00775", "gnorm": "0.308", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "178"}
2023-12-13 17:59:59 | INFO | train_inner | {"epoch": 3, "update": 2.906, "loss": "5.318", "nll_loss": "4.049", "ppl": "16.56", "wps": "77231.6", "ups": "21.24", "wpb": "3635.7", "bsz": "147.8", "num_updates": "3200", "lr": "0.008", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "183"}
2023-12-13 18:00:03 | INFO | train_inner | {"epoch": 3, "update": 2.996, "loss": "5.28", "nll_loss": "4.002", "ppl": "16.02", "wps": "83140.1", "ups": "22.96", "wpb": "3620.6", "bsz": "166.2", "num_updates": "3300", "lr": "0.00825", "gnorm": "0.291", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "187"}
2023-12-13 18:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:00:05 | INFO | valid | {"epoch": 3, "valid_loss": "5.104", "valid_nll_loss": "3.836", "valid_ppl": "14.28", "valid_wps": "131707", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "3304", "valid_best_loss": "5.104"}
2023-12-13 18:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3304 updates
2023-12-13 18:00:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint3.pt
2023-12-13 18:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint3.pt
2023-12-13 18:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint3.pt (epoch 3 @ 3304 updates, score 5.104) (writing took 2.465727796778083 seconds)
2023-12-13 18:00:07 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-12-13 18:00:07 | INFO | train | {"epoch": 3, "train_loss": "5.406", "train_nll_loss": "4.153", "train_ppl": "17.79", "train_wps": "61762.1", "train_ups": "17.23", "train_wpb": "3584.5", "train_bsz": "145.5", "train_num_updates": "3304", "train_lr": "0.00826", "train_gnorm": "0.311", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "191"}
2023-12-13 18:00:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:00:07 | INFO | fairseq.trainer | begin training epoch 4
2023-12-13 18:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:00:13 | INFO | train_inner | {"epoch": 4, "update": 3.087, "loss": "5.281", "nll_loss": "3.992", "ppl": "15.92", "wps": "37812.1", "ups": "10.55", "wpb": "3585.4", "bsz": "139.1", "num_updates": "3400", "lr": "0.0085", "gnorm": "0.308", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "197"}
2023-12-13 18:00:18 | INFO | train_inner | {"epoch": 4, "update": 3.178, "loss": "5.185", "nll_loss": "3.883", "ppl": "14.75", "wps": "70778.3", "ups": "19.28", "wpb": "3670.5", "bsz": "149.1", "num_updates": "3500", "lr": "0.00875", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "202"}
2023-12-13 18:00:23 | INFO | train_inner | {"epoch": 4, "update": 3.269, "loss": "5.254", "nll_loss": "3.965", "ppl": "15.61", "wps": "77504.3", "ups": "21.04", "wpb": "3683.7", "bsz": "157.3", "num_updates": "3600", "lr": "0.009", "gnorm": "0.293", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "207"}
2023-12-13 18:00:28 | INFO | train_inner | {"epoch": 4, "update": 3.359, "loss": "5.334", "nll_loss": "4.056", "ppl": "16.64", "wps": "68306.4", "ups": "19.18", "wpb": "3560.9", "bsz": "146.7", "num_updates": "3700", "lr": "0.00925", "gnorm": "0.299", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "212"}
2023-12-13 18:00:34 | INFO | train_inner | {"epoch": 4, "update": 3.45, "loss": "5.386", "nll_loss": "4.11", "ppl": "17.27", "wps": "62432.8", "ups": "17.75", "wpb": "3517.8", "bsz": "133.4", "num_updates": "3800", "lr": "0.0095", "gnorm": "0.298", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "217"}
2023-12-13 18:00:39 | INFO | train_inner | {"epoch": 4, "update": 3.541, "loss": "5.366", "nll_loss": "4.087", "ppl": "17", "wps": "64961.8", "ups": "18.19", "wpb": "3570.6", "bsz": "143.5", "num_updates": "3900", "lr": "0.00975", "gnorm": "0.323", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "223"}
2023-12-13 18:00:45 | INFO | train_inner | {"epoch": 4, "update": 3.632, "loss": "5.266", "nll_loss": "3.972", "ppl": "15.69", "wps": "65408.9", "ups": "18.21", "wpb": "3592.6", "bsz": "168", "num_updates": "4000", "lr": "0.01", "gnorm": "0.303", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "228"}
2023-12-13 18:00:50 | INFO | train_inner | {"epoch": 4, "update": 3.722, "loss": "5.361", "nll_loss": "4.078", "ppl": "16.89", "wps": "69383.9", "ups": "19.44", "wpb": "3568.4", "bsz": "148.3", "num_updates": "4100", "lr": "0.0098773", "gnorm": "0.307", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "234"}
2023-12-13 18:00:54 | INFO | train_inner | {"epoch": 4, "update": 3.813, "loss": "5.276", "nll_loss": "3.985", "ppl": "15.83", "wps": "75954", "ups": "21.12", "wpb": "3596.4", "bsz": "152.5", "num_updates": "4200", "lr": "0.009759", "gnorm": "0.295", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "238"}
2023-12-13 18:01:00 | INFO | train_inner | {"epoch": 4, "update": 3.904, "loss": "5.476", "nll_loss": "4.213", "ppl": "18.55", "wps": "61576.3", "ups": "17.69", "wpb": "3481.3", "bsz": "121", "num_updates": "4300", "lr": "0.00964486", "gnorm": "0.305", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "244"}
2023-12-13 18:01:05 | INFO | train_inner | {"epoch": 4, "update": 3.995, "loss": "5.338", "nll_loss": "4.055", "ppl": "16.62", "wps": "69134", "ups": "19.18", "wpb": "3605.1", "bsz": "142.4", "num_updates": "4400", "lr": "0.00953463", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "249"}
2023-12-13 18:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:01:07 | INFO | valid | {"epoch": 4, "valid_loss": "5.053", "valid_nll_loss": "3.771", "valid_ppl": "13.65", "valid_wps": "132029", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "4406", "valid_best_loss": "5.053"}
2023-12-13 18:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4406 updates
2023-12-13 18:01:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint4.pt
2023-12-13 18:01:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint4.pt
2023-12-13 18:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint4.pt (epoch 4 @ 4406 updates, score 5.053) (writing took 2.74779917858541 seconds)
2023-12-13 18:01:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-12-13 18:01:10 | INFO | train | {"epoch": 4, "train_loss": "5.32", "train_nll_loss": "4.036", "train_ppl": "16.4", "train_wps": "63245.9", "train_ups": "17.65", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "4406", "train_lr": "0.00952813", "train_gnorm": "0.301", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "254"}
2023-12-13 18:01:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:01:10 | INFO | fairseq.trainer | begin training epoch 5
2023-12-13 18:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:01:15 | INFO | train_inner | {"epoch": 5, "update": 4.085, "loss": "5.227", "nll_loss": "3.92", "ppl": "15.13", "wps": "35834.7", "ups": "10.07", "wpb": "3559.2", "bsz": "129", "num_updates": "4500", "lr": "0.00942809", "gnorm": "0.294", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "259"}
2023-12-13 18:01:20 | INFO | train_inner | {"epoch": 5, "update": 4.176, "loss": "5.117", "nll_loss": "3.801", "ppl": "13.94", "wps": "74434.2", "ups": "20.74", "wpb": "3589.3", "bsz": "157.4", "num_updates": "4600", "lr": "0.00932505", "gnorm": "0.282", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "264"}
2023-12-13 18:01:26 | INFO | train_inner | {"epoch": 5, "update": 4.267, "loss": "5.22", "nll_loss": "3.92", "ppl": "15.13", "wps": "66022.8", "ups": "18.51", "wpb": "3566", "bsz": "137.2", "num_updates": "4700", "lr": "0.00922531", "gnorm": "0.289", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "269"}
2023-12-13 18:01:31 | INFO | train_inner | {"epoch": 5, "update": 4.358, "loss": "5.216", "nll_loss": "3.91", "ppl": "15.03", "wps": "66960.7", "ups": "18.6", "wpb": "3600.1", "bsz": "150.7", "num_updates": "4800", "lr": "0.00912871", "gnorm": "0.299", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "275"}
2023-12-13 18:01:36 | INFO | train_inner | {"epoch": 5, "update": 4.448, "loss": "5.1", "nll_loss": "3.782", "ppl": "13.75", "wps": "71756.3", "ups": "19.58", "wpb": "3664.4", "bsz": "160.6", "num_updates": "4900", "lr": "0.00903508", "gnorm": "0.279", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "280"}
2023-12-13 18:01:41 | INFO | train_inner | {"epoch": 5, "update": 4.539, "loss": "5.095", "nll_loss": "3.778", "ppl": "13.72", "wps": "75768.4", "ups": "20.93", "wpb": "3620.6", "bsz": "157.7", "num_updates": "5000", "lr": "0.00894427", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "285"}
2023-12-13 18:01:46 | INFO | train_inner | {"epoch": 5, "update": 4.63, "loss": "5.105", "nll_loss": "3.791", "ppl": "13.85", "wps": "73781.5", "ups": "20.54", "wpb": "3592.7", "bsz": "150.7", "num_updates": "5100", "lr": "0.00885615", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "289"}
2023-12-13 18:01:51 | INFO | train_inner | {"epoch": 5, "update": 4.721, "loss": "5.184", "nll_loss": "3.88", "ppl": "14.73", "wps": "68086.6", "ups": "19.41", "wpb": "3507.3", "bsz": "137.6", "num_updates": "5200", "lr": "0.00877058", "gnorm": "0.287", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "295"}
2023-12-13 18:01:56 | INFO | train_inner | {"epoch": 5, "update": 4.811, "loss": "5.155", "nll_loss": "3.849", "ppl": "14.41", "wps": "69542.5", "ups": "19.27", "wpb": "3609.3", "bsz": "141.9", "num_updates": "5300", "lr": "0.00868744", "gnorm": "0.288", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "300"}
2023-12-13 18:02:02 | INFO | train_inner | {"epoch": 5, "update": 4.902, "loss": "5.186", "nll_loss": "3.88", "ppl": "14.72", "wps": "60158", "ups": "16.93", "wpb": "3553.5", "bsz": "130.3", "num_updates": "5400", "lr": "0.00860663", "gnorm": "0.294", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "306"}
2023-12-13 18:02:07 | INFO | train_inner | {"epoch": 5, "update": 4.993, "loss": "5.133", "nll_loss": "3.825", "ppl": "14.18", "wps": "64371.2", "ups": "18.19", "wpb": "3539.2", "bsz": "141.7", "num_updates": "5500", "lr": "0.00852803", "gnorm": "0.28", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "311"}
2023-12-13 18:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:02:09 | INFO | valid | {"epoch": 5, "valid_loss": "4.926", "valid_nll_loss": "3.634", "valid_ppl": "12.41", "valid_wps": "129256", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "5508", "valid_best_loss": "4.926"}
2023-12-13 18:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5508 updates
2023-12-13 18:02:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint5.pt
2023-12-13 18:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint5.pt
2023-12-13 18:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint5.pt (epoch 5 @ 5508 updates, score 4.926) (writing took 2.9246644265949726 seconds)
2023-12-13 18:02:12 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-12-13 18:02:12 | INFO | train | {"epoch": 5, "train_loss": "5.156", "train_nll_loss": "3.846", "train_ppl": "14.38", "train_wps": "63382.8", "train_ups": "17.69", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "5508", "train_lr": "0.00852183", "train_gnorm": "0.284", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "316"}
2023-12-13 18:02:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:02:12 | INFO | fairseq.trainer | begin training epoch 6
2023-12-13 18:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:02:17 | INFO | train_inner | {"epoch": 6, "update": 5.083, "loss": "4.975", "nll_loss": "3.635", "ppl": "12.42", "wps": "35696", "ups": "10.02", "wpb": "3561.2", "bsz": "142.6", "num_updates": "5600", "lr": "0.00845154", "gnorm": "0.275", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "321"}
2023-12-13 18:02:23 | INFO | train_inner | {"epoch": 6, "update": 5.174, "loss": "4.989", "nll_loss": "3.653", "ppl": "12.58", "wps": "69922.6", "ups": "19.43", "wpb": "3599.5", "bsz": "140.9", "num_updates": "5700", "lr": "0.00837708", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "326"}
2023-12-13 18:02:28 | INFO | train_inner | {"epoch": 6, "update": 5.265, "loss": "5.021", "nll_loss": "3.694", "ppl": "12.94", "wps": "69836.1", "ups": "19.31", "wpb": "3617.4", "bsz": "140.1", "num_updates": "5800", "lr": "0.00830455", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "331"}
2023-12-13 18:02:33 | INFO | train_inner | {"epoch": 6, "update": 5.356, "loss": "5.023", "nll_loss": "3.694", "ppl": "12.95", "wps": "64781.6", "ups": "17.87", "wpb": "3625.9", "bsz": "142.9", "num_updates": "5900", "lr": "0.00823387", "gnorm": "0.289", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "337"}
2023-12-13 18:02:38 | INFO | train_inner | {"epoch": 6, "update": 5.446, "loss": "4.998", "nll_loss": "3.668", "ppl": "12.71", "wps": "72101.9", "ups": "20.07", "wpb": "3593.1", "bsz": "149.9", "num_updates": "6000", "lr": "0.00816497", "gnorm": "0.277", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "342"}
2023-12-13 18:02:43 | INFO | train_inner | {"epoch": 6, "update": 5.537, "loss": "4.953", "nll_loss": "3.618", "ppl": "12.28", "wps": "69505.6", "ups": "19.38", "wpb": "3586.2", "bsz": "162.9", "num_updates": "6100", "lr": "0.00809776", "gnorm": "0.275", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "347"}
2023-12-13 18:02:48 | INFO | train_inner | {"epoch": 6, "update": 5.628, "loss": "4.952", "nll_loss": "3.619", "ppl": "12.29", "wps": "77282.9", "ups": "21.33", "wpb": "3622.8", "bsz": "152.3", "num_updates": "6200", "lr": "0.00803219", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "352"}
2023-12-13 18:02:53 | INFO | train_inner | {"epoch": 6, "update": 5.719, "loss": "4.984", "nll_loss": "3.655", "ppl": "12.6", "wps": "69378.2", "ups": "19.7", "wpb": "3521.7", "bsz": "144.2", "num_updates": "6300", "lr": "0.00796819", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "357"}
2023-12-13 18:02:59 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "5.066", "nll_loss": "3.747", "ppl": "13.43", "wps": "57055.1", "ups": "16.38", "wpb": "3483.5", "bsz": "126.7", "num_updates": "6400", "lr": "0.00790569", "gnorm": "0.281", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "363"}
2023-12-13 18:03:04 | INFO | train_inner | {"epoch": 6, "update": 5.9, "loss": "4.954", "nll_loss": "3.622", "ppl": "12.31", "wps": "75776.9", "ups": "20.83", "wpb": "3638.3", "bsz": "151.6", "num_updates": "6500", "lr": "0.00784465", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "368"}
2023-12-13 18:03:09 | INFO | train_inner | {"epoch": 6, "update": 5.991, "loss": "4.938", "nll_loss": "3.604", "ppl": "12.16", "wps": "68721.3", "ups": "19.31", "wpb": "3558.2", "bsz": "149.8", "num_updates": "6600", "lr": "0.00778499", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "373"}
2023-12-13 18:03:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:03:11 | INFO | valid | {"epoch": 6, "valid_loss": "4.797", "valid_nll_loss": "3.467", "valid_ppl": "11.05", "valid_wps": "132531", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "6610", "valid_best_loss": "4.797"}
2023-12-13 18:03:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6610 updates
2023-12-13 18:03:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint6.pt
2023-12-13 18:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint6.pt
2023-12-13 18:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint6.pt (epoch 6 @ 6610 updates, score 4.797) (writing took 2.999973403289914 seconds)
2023-12-13 18:03:14 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-12-13 18:03:14 | INFO | train | {"epoch": 6, "train_loss": "4.986", "train_nll_loss": "3.655", "train_ppl": "12.6", "train_wps": "63679.6", "train_ups": "17.77", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "6610", "train_lr": "0.0077791", "train_gnorm": "0.273", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "378"}
2023-12-13 18:03:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:03:14 | INFO | fairseq.trainer | begin training epoch 7
2023-12-13 18:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:03:19 | INFO | train_inner | {"epoch": 7, "update": 6.082, "loss": "4.887", "nll_loss": "3.538", "ppl": "11.62", "wps": "35938.3", "ups": "10.05", "wpb": "3575.3", "bsz": "130", "num_updates": "6700", "lr": "0.00772667", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "383"}
2023-12-13 18:03:24 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "4.824", "nll_loss": "3.471", "ppl": "11.08", "wps": "73001.6", "ups": "20.12", "wpb": "3628.5", "bsz": "147.5", "num_updates": "6800", "lr": "0.00766965", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "388"}
2023-12-13 18:03:29 | INFO | train_inner | {"epoch": 7, "update": 6.263, "loss": "4.845", "nll_loss": "3.492", "ppl": "11.25", "wps": "68713.7", "ups": "19.44", "wpb": "3535.5", "bsz": "150.6", "num_updates": "6900", "lr": "0.00761387", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "393"}
2023-12-13 18:03:34 | INFO | train_inner | {"epoch": 7, "update": 6.354, "loss": "4.867", "nll_loss": "3.518", "ppl": "11.46", "wps": "70137.1", "ups": "19.63", "wpb": "3572.1", "bsz": "153.7", "num_updates": "7000", "lr": "0.00755929", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "398"}
2023-12-13 18:03:39 | INFO | train_inner | {"epoch": 7, "update": 6.445, "loss": "4.907", "nll_loss": "3.567", "ppl": "11.85", "wps": "74815.6", "ups": "20.38", "wpb": "3670.4", "bsz": "141.4", "num_updates": "7100", "lr": "0.00750587", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "403"}
2023-12-13 18:03:44 | INFO | train_inner | {"epoch": 7, "update": 6.535, "loss": "4.828", "nll_loss": "3.479", "ppl": "11.15", "wps": "74299.9", "ups": "20.45", "wpb": "3633.5", "bsz": "151.3", "num_updates": "7200", "lr": "0.00745356", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "408"}
2023-12-13 18:03:50 | INFO | train_inner | {"epoch": 7, "update": 6.626, "loss": "4.87", "nll_loss": "3.525", "ppl": "11.52", "wps": "66867.1", "ups": "18.61", "wpb": "3593.7", "bsz": "140.2", "num_updates": "7300", "lr": "0.00740233", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "413"}
2023-12-13 18:03:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-12-13 18:03:55 | INFO | train_inner | {"epoch": 7, "update": 6.718, "loss": "4.888", "nll_loss": "3.546", "ppl": "11.68", "wps": "64284.3", "ups": "18.02", "wpb": "3567.4", "bsz": "147.6", "num_updates": "7400", "lr": "0.00735215", "gnorm": "0.273", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "419"}
2023-12-13 18:04:00 | INFO | train_inner | {"epoch": 7, "update": 6.809, "loss": "4.865", "nll_loss": "3.523", "ppl": "11.5", "wps": "70532.7", "ups": "19.63", "wpb": "3592.5", "bsz": "151.1", "num_updates": "7500", "lr": "0.00730297", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "424"}
2023-12-13 18:04:05 | INFO | train_inner | {"epoch": 7, "update": 6.899, "loss": "4.871", "nll_loss": "3.532", "ppl": "11.57", "wps": "73689.6", "ups": "20.82", "wpb": "3538.7", "bsz": "150.3", "num_updates": "7600", "lr": "0.00725476", "gnorm": "0.26", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "429"}
2023-12-13 18:04:11 | INFO | train_inner | {"epoch": 7, "update": 6.99, "loss": "4.899", "nll_loss": "3.56", "ppl": "11.79", "wps": "63692.1", "ups": "17.92", "wpb": "3554.1", "bsz": "134.6", "num_updates": "7700", "lr": "0.0072075", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "434"}
2023-12-13 18:04:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:04:13 | INFO | valid | {"epoch": 7, "valid_loss": "4.74", "valid_nll_loss": "3.396", "valid_ppl": "10.53", "valid_wps": "133533", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "7711", "valid_best_loss": "4.74"}
2023-12-13 18:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7711 updates
2023-12-13 18:04:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint7.pt
2023-12-13 18:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint7.pt
2023-12-13 18:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint7.pt (epoch 7 @ 7711 updates, score 4.74) (writing took 2.890433609485626 seconds)
2023-12-13 18:04:15 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-12-13 18:04:15 | INFO | train | {"epoch": 7, "train_loss": "4.867", "train_nll_loss": "3.522", "train_ppl": "11.49", "train_wps": "64354.7", "train_ups": "17.96", "train_wpb": "3583.9", "train_bsz": "145.5", "train_num_updates": "7711", "train_lr": "0.00720236", "train_gnorm": "0.266", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "439"}
2023-12-13 18:04:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:04:16 | INFO | fairseq.trainer | begin training epoch 8
2023-12-13 18:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:04:20 | INFO | train_inner | {"epoch": 8, "update": 7.081, "loss": "4.738", "nll_loss": "3.372", "ppl": "10.35", "wps": "37191.9", "ups": "10.48", "wpb": "3548.1", "bsz": "145.7", "num_updates": "7800", "lr": "0.00716115", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "444"}
2023-12-13 18:04:25 | INFO | train_inner | {"epoch": 8, "update": 7.172, "loss": "4.704", "nll_loss": "3.335", "ppl": "10.09", "wps": "75838.5", "ups": "21.2", "wpb": "3578", "bsz": "155.4", "num_updates": "7900", "lr": "0.00711568", "gnorm": "0.25", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "449"}
2023-12-13 18:04:30 | INFO | train_inner | {"epoch": 8, "update": 7.262, "loss": "4.757", "nll_loss": "3.396", "ppl": "10.53", "wps": "70248.7", "ups": "19.6", "wpb": "3583.7", "bsz": "144.6", "num_updates": "8000", "lr": "0.00707107", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "454"}
2023-12-13 18:04:35 | INFO | train_inner | {"epoch": 8, "update": 7.353, "loss": "4.784", "nll_loss": "3.426", "ppl": "10.75", "wps": "67293.4", "ups": "18.7", "wpb": "3597.6", "bsz": "141.9", "num_updates": "8100", "lr": "0.00702728", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "39.1", "wall": "459"}
2023-12-13 18:04:41 | INFO | train_inner | {"epoch": 8, "update": 7.444, "loss": "4.859", "nll_loss": "3.512", "ppl": "11.41", "wps": "64381.2", "ups": "17.99", "wpb": "3578.4", "bsz": "131.8", "num_updates": "8200", "lr": "0.0069843", "gnorm": "0.281", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "465"}
2023-12-13 18:04:46 | INFO | train_inner | {"epoch": 8, "update": 7.534, "loss": "4.771", "nll_loss": "3.415", "ppl": "10.66", "wps": "69250", "ups": "19.44", "wpb": "3561.6", "bsz": "149.1", "num_updates": "8300", "lr": "0.0069421", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "470"}
2023-12-13 18:04:51 | INFO | train_inner | {"epoch": 8, "update": 7.625, "loss": "4.783", "nll_loss": "3.428", "ppl": "10.76", "wps": "71501.4", "ups": "19.79", "wpb": "3613.1", "bsz": "140.1", "num_updates": "8400", "lr": "0.00690066", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "475"}
2023-12-13 18:04:56 | INFO | train_inner | {"epoch": 8, "update": 7.716, "loss": "4.789", "nll_loss": "3.436", "ppl": "10.82", "wps": "68485.9", "ups": "19.35", "wpb": "3539.6", "bsz": "144.7", "num_updates": "8500", "lr": "0.00685994", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "480"}
2023-12-13 18:05:01 | INFO | train_inner | {"epoch": 8, "update": 7.807, "loss": "4.779", "nll_loss": "3.426", "ppl": "10.75", "wps": "72956.2", "ups": "20.38", "wpb": "3579.9", "bsz": "157.5", "num_updates": "8600", "lr": "0.00681994", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "485"}
2023-12-13 18:05:06 | INFO | train_inner | {"epoch": 8, "update": 7.897, "loss": "4.773", "nll_loss": "3.419", "ppl": "10.7", "wps": "75373.2", "ups": "20.82", "wpb": "3619.6", "bsz": "147.7", "num_updates": "8700", "lr": "0.00678064", "gnorm": "0.255", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "490"}
2023-12-13 18:05:11 | INFO | train_inner | {"epoch": 8, "update": 7.988, "loss": "4.822", "nll_loss": "3.477", "ppl": "11.14", "wps": "69336.9", "ups": "19.24", "wpb": "3603.2", "bsz": "143.8", "num_updates": "8800", "lr": "0.006742", "gnorm": "0.261", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "495"}
2023-12-13 18:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:05:13 | INFO | valid | {"epoch": 8, "valid_loss": "4.671", "valid_nll_loss": "3.339", "valid_ppl": "10.12", "valid_wps": "130860", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "8813", "valid_best_loss": "4.671"}
2023-12-13 18:05:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8813 updates
2023-12-13 18:05:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint8.pt
2023-12-13 18:05:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint8.pt
2023-12-13 18:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint8.pt (epoch 8 @ 8813 updates, score 4.671) (writing took 2.569176599383354 seconds)
2023-12-13 18:05:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-12-13 18:05:16 | INFO | train | {"epoch": 8, "train_loss": "4.778", "train_nll_loss": "3.421", "train_ppl": "10.71", "train_wps": "65237.8", "train_ups": "18.2", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "8813", "train_lr": "0.00673702", "train_gnorm": "0.261", "train_loss_scale": "16", "train_train_wall": "55", "train_gb_free": "39", "train_wall": "500"}
2023-12-13 18:05:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:05:16 | INFO | fairseq.trainer | begin training epoch 9
2023-12-13 18:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:05:20 | INFO | train_inner | {"epoch": 9, "update": 8.079, "loss": "4.655", "nll_loss": "3.28", "ppl": "9.71", "wps": "40627.5", "ups": "11.2", "wpb": "3626.4", "bsz": "153", "num_updates": "8900", "lr": "0.00670402", "gnorm": "0.249", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "504"}
2023-12-13 18:05:26 | INFO | train_inner | {"epoch": 9, "update": 8.17, "loss": "4.703", "nll_loss": "3.334", "ppl": "10.08", "wps": "63298.6", "ups": "17.86", "wpb": "3544.2", "bsz": "133.9", "num_updates": "9000", "lr": "0.00666667", "gnorm": "0.247", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "509"}
2023-12-13 18:05:31 | INFO | train_inner | {"epoch": 9, "update": 8.26, "loss": "4.661", "nll_loss": "3.287", "ppl": "9.76", "wps": "75658.4", "ups": "20.85", "wpb": "3628.7", "bsz": "146.5", "num_updates": "9100", "lr": "0.00662994", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "514"}
2023-12-13 18:05:35 | INFO | train_inner | {"epoch": 9, "update": 8.351, "loss": "4.649", "nll_loss": "3.275", "ppl": "9.68", "wps": "76306.7", "ups": "21.05", "wpb": "3624.9", "bsz": "148.9", "num_updates": "9200", "lr": "0.0065938", "gnorm": "0.249", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "519"}
2023-12-13 18:05:40 | INFO | train_inner | {"epoch": 9, "update": 8.442, "loss": "4.63", "nll_loss": "3.255", "ppl": "9.55", "wps": "76545.2", "ups": "21.09", "wpb": "3629.2", "bsz": "161.1", "num_updates": "9300", "lr": "0.00655826", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "524"}
2023-12-13 18:05:45 | INFO | train_inner | {"epoch": 9, "update": 8.533, "loss": "4.705", "nll_loss": "3.342", "ppl": "10.14", "wps": "67530.5", "ups": "18.7", "wpb": "3611.3", "bsz": "145.3", "num_updates": "9400", "lr": "0.00652328", "gnorm": "0.246", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "529"}
2023-12-13 18:05:51 | INFO | train_inner | {"epoch": 9, "update": 8.623, "loss": "4.791", "nll_loss": "3.438", "ppl": "10.84", "wps": "61539.2", "ups": "17.32", "wpb": "3554", "bsz": "127.6", "num_updates": "9500", "lr": "0.00648886", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "535"}
2023-12-13 18:05:57 | INFO | train_inner | {"epoch": 9, "update": 8.714, "loss": "4.725", "nll_loss": "3.364", "ppl": "10.3", "wps": "59768.7", "ups": "17.12", "wpb": "3492", "bsz": "150.6", "num_updates": "9600", "lr": "0.00645497", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "541"}
2023-12-13 18:06:02 | INFO | train_inner | {"epoch": 9, "update": 8.805, "loss": "4.709", "nll_loss": "3.346", "ppl": "10.17", "wps": "67514.3", "ups": "18.94", "wpb": "3565.2", "bsz": "139.6", "num_updates": "9700", "lr": "0.00642161", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "546"}
2023-12-13 18:06:07 | INFO | train_inner | {"epoch": 9, "update": 8.896, "loss": "4.739", "nll_loss": "3.382", "ppl": "10.42", "wps": "68694.2", "ups": "19.17", "wpb": "3583.6", "bsz": "142", "num_updates": "9800", "lr": "0.00638877", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "551"}
2023-12-13 18:06:13 | INFO | train_inner | {"epoch": 9, "update": 8.986, "loss": "4.71", "nll_loss": "3.351", "ppl": "10.2", "wps": "63535.1", "ups": "17.99", "wpb": "3532.1", "bsz": "149.7", "num_updates": "9900", "lr": "0.00635642", "gnorm": "0.253", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "557"}
2023-12-13 18:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:06:15 | INFO | valid | {"epoch": 9, "valid_loss": "4.604", "valid_nll_loss": "3.265", "valid_ppl": "9.61", "valid_wps": "130492", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "9915", "valid_best_loss": "4.604"}
2023-12-13 18:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9915 updates
2023-12-13 18:06:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint9.pt
2023-12-13 18:06:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint9.pt
2023-12-13 18:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint9.pt (epoch 9 @ 9915 updates, score 4.604) (writing took 2.5365687366575003 seconds)
2023-12-13 18:06:18 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-12-13 18:06:18 | INFO | train | {"epoch": 9, "train_loss": "4.697", "train_nll_loss": "3.331", "train_ppl": "10.06", "train_wps": "64033.1", "train_ups": "17.87", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "9915", "train_lr": "0.00635161", "train_gnorm": "0.25", "train_loss_scale": "16", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "561"}
2023-12-13 18:06:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:06:18 | INFO | fairseq.trainer | begin training epoch 10
2023-12-13 18:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:06:22 | INFO | train_inner | {"epoch": 10, "update": 9.077, "loss": "4.586", "nll_loss": "3.203", "ppl": "9.21", "wps": "39116.6", "ups": "10.94", "wpb": "3575.2", "bsz": "147.1", "num_updates": "10000", "lr": "0.00632456", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "566"}
2023-12-13 18:06:27 | INFO | train_inner | {"epoch": 10, "update": 9.168, "loss": "4.587", "nll_loss": "3.203", "ppl": "9.21", "wps": "76851.7", "ups": "21.29", "wpb": "3609.1", "bsz": "145.1", "num_updates": "10100", "lr": "0.00629317", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "571"}
2023-12-13 18:06:32 | INFO | train_inner | {"epoch": 10, "update": 9.259, "loss": "4.574", "nll_loss": "3.188", "ppl": "9.11", "wps": "69681.9", "ups": "19.32", "wpb": "3606.9", "bsz": "153.7", "num_updates": "10200", "lr": "0.00626224", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "576"}
2023-12-13 18:06:37 | INFO | train_inner | {"epoch": 10, "update": 9.349, "loss": "4.647", "nll_loss": "3.274", "ppl": "9.68", "wps": "71976", "ups": "19.84", "wpb": "3628.3", "bsz": "138.3", "num_updates": "10300", "lr": "0.00623177", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "581"}
2023-12-13 18:06:42 | INFO | train_inner | {"epoch": 10, "update": 9.44, "loss": "4.591", "nll_loss": "3.211", "ppl": "9.26", "wps": "73000.8", "ups": "20.39", "wpb": "3579.8", "bsz": "159.6", "num_updates": "10400", "lr": "0.00620174", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "586"}
2023-12-13 18:06:48 | INFO | train_inner | {"epoch": 10, "update": 9.531, "loss": "4.717", "nll_loss": "3.354", "ppl": "10.22", "wps": "62385.9", "ups": "17.59", "wpb": "3546.9", "bsz": "125.4", "num_updates": "10500", "lr": "0.00617213", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "591"}
2023-12-13 18:06:53 | INFO | train_inner | {"epoch": 10, "update": 9.622, "loss": "4.7", "nll_loss": "3.336", "ppl": "10.1", "wps": "66897.2", "ups": "18.43", "wpb": "3629.1", "bsz": "134", "num_updates": "10600", "lr": "0.00614295", "gnorm": "0.257", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "597"}
2023-12-13 18:06:58 | INFO | train_inner | {"epoch": 10, "update": 9.712, "loss": "4.685", "nll_loss": "3.32", "ppl": "9.99", "wps": "68801.4", "ups": "19.66", "wpb": "3499.3", "bsz": "155", "num_updates": "10700", "lr": "0.00611418", "gnorm": "0.299", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "602"}
2023-12-13 18:07:03 | INFO | train_inner | {"epoch": 10, "update": 9.803, "loss": "4.632", "nll_loss": "3.26", "ppl": "9.58", "wps": "68378.8", "ups": "19.14", "wpb": "3573", "bsz": "143", "num_updates": "10800", "lr": "0.00608581", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "607"}
2023-12-13 18:07:08 | INFO | train_inner | {"epoch": 10, "update": 9.894, "loss": "4.595", "nll_loss": "3.219", "ppl": "9.31", "wps": "81081.7", "ups": "22.39", "wpb": "3621.4", "bsz": "161.2", "num_updates": "10900", "lr": "0.00605783", "gnorm": "0.25", "loss_scale": "16", "train_wall": "4", "gb_free": "38.9", "wall": "612"}
2023-12-13 18:07:14 | INFO | train_inner | {"epoch": 10, "update": 9.985, "loss": "4.685", "nll_loss": "3.321", "ppl": "9.99", "wps": "62567.2", "ups": "17.51", "wpb": "3572.3", "bsz": "137", "num_updates": "11000", "lr": "0.00603023", "gnorm": "0.25", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "617"}
2023-12-13 18:07:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:07:16 | INFO | valid | {"epoch": 10, "valid_loss": "4.594", "valid_nll_loss": "3.231", "valid_ppl": "9.39", "valid_wps": "130437", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "11017", "valid_best_loss": "4.594"}
2023-12-13 18:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11017 updates
2023-12-13 18:07:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint10.pt
2023-12-13 18:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint10.pt
2023-12-13 18:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint10.pt (epoch 10 @ 11017 updates, score 4.594) (writing took 2.5476637985557318 seconds)
2023-12-13 18:07:18 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-12-13 18:07:18 | INFO | train | {"epoch": 10, "train_loss": "4.635", "train_nll_loss": "3.261", "train_ppl": "9.59", "train_wps": "64937.2", "train_ups": "18.12", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "11017", "train_lr": "0.00602557", "train_gnorm": "0.253", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "622"}
2023-12-13 18:07:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:07:19 | INFO | fairseq.trainer | begin training epoch 11
2023-12-13 18:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:07:23 | INFO | train_inner | {"epoch": 11, "update": 10.075, "loss": "4.556", "nll_loss": "3.165", "ppl": "8.97", "wps": "36876", "ups": "10.28", "wpb": "3586.2", "bsz": "140.5", "num_updates": "11100", "lr": "0.006003", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "627"}
2023-12-13 18:07:29 | INFO | train_inner | {"epoch": 11, "update": 10.166, "loss": "4.58", "nll_loss": "3.196", "ppl": "9.16", "wps": "63400.2", "ups": "17.89", "wpb": "3543.2", "bsz": "132.3", "num_updates": "11200", "lr": "0.00597614", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "633"}
2023-12-13 18:07:34 | INFO | train_inner | {"epoch": 11, "update": 10.257, "loss": "4.596", "nll_loss": "3.214", "ppl": "9.28", "wps": "65511", "ups": "18.07", "wpb": "3625", "bsz": "136.6", "num_updates": "11300", "lr": "0.00594964", "gnorm": "0.25", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "638"}
2023-12-13 18:07:39 | INFO | train_inner | {"epoch": 11, "update": 10.348, "loss": "4.5", "nll_loss": "3.106", "ppl": "8.61", "wps": "73173.2", "ups": "20.45", "wpb": "3577.6", "bsz": "159", "num_updates": "11400", "lr": "0.00592349", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "643"}
2023-12-13 18:07:45 | INFO | train_inner | {"epoch": 11, "update": 10.438, "loss": "4.63", "nll_loss": "3.256", "ppl": "9.55", "wps": "64236.4", "ups": "18.37", "wpb": "3496.7", "bsz": "142.3", "num_updates": "11500", "lr": "0.00589768", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "649"}
2023-12-13 18:07:50 | INFO | train_inner | {"epoch": 11, "update": 10.529, "loss": "4.526", "nll_loss": "3.138", "ppl": "8.8", "wps": "74451.3", "ups": "20.48", "wpb": "3634.6", "bsz": "158.2", "num_updates": "11600", "lr": "0.0058722", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "653"}
2023-12-13 18:07:55 | INFO | train_inner | {"epoch": 11, "update": 10.62, "loss": "4.588", "nll_loss": "3.212", "ppl": "9.27", "wps": "68234.8", "ups": "18.88", "wpb": "3614.2", "bsz": "146.7", "num_updates": "11700", "lr": "0.00584705", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "659"}
2023-12-13 18:08:00 | INFO | train_inner | {"epoch": 11, "update": 10.711, "loss": "4.647", "nll_loss": "3.278", "ppl": "9.7", "wps": "66349.8", "ups": "18.51", "wpb": "3583.9", "bsz": "135.9", "num_updates": "11800", "lr": "0.00582223", "gnorm": "0.26", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "664"}
2023-12-13 18:08:05 | INFO | train_inner | {"epoch": 11, "update": 10.801, "loss": "4.554", "nll_loss": "3.172", "ppl": "9.01", "wps": "77720.8", "ups": "21.45", "wpb": "3623.5", "bsz": "160.8", "num_updates": "11900", "lr": "0.00579771", "gnorm": "0.253", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "669"}
2023-12-13 18:08:10 | INFO | train_inner | {"epoch": 11, "update": 10.892, "loss": "4.587", "nll_loss": "3.211", "ppl": "9.26", "wps": "71971.1", "ups": "19.87", "wpb": "3622.3", "bsz": "154.6", "num_updates": "12000", "lr": "0.0057735", "gnorm": "0.25", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "674"}
2023-12-13 18:08:15 | INFO | train_inner | {"epoch": 11, "update": 10.983, "loss": "4.671", "nll_loss": "3.308", "ppl": "9.91", "wps": "68664.9", "ups": "19.49", "wpb": "3522.6", "bsz": "132.6", "num_updates": "12100", "lr": "0.0057496", "gnorm": "0.244", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "679"}
2023-12-13 18:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:08:18 | INFO | valid | {"epoch": 11, "valid_loss": "4.554", "valid_nll_loss": "3.205", "valid_ppl": "9.22", "valid_wps": "130560", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "12119", "valid_best_loss": "4.554"}
2023-12-13 18:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12119 updates
2023-12-13 18:08:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint11.pt
2023-12-13 18:08:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint11.pt
2023-12-13 18:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint11.pt (epoch 11 @ 12119 updates, score 4.554) (writing took 2.647402061149478 seconds)
2023-12-13 18:08:20 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-12-13 18:08:20 | INFO | train | {"epoch": 11, "train_loss": "4.584", "train_nll_loss": "3.204", "train_ppl": "9.22", "train_wps": "63824.6", "train_ups": "17.81", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "12119", "train_lr": "0.00574509", "train_gnorm": "0.251", "train_loss_scale": "16", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "684"}
2023-12-13 18:08:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:08:20 | INFO | fairseq.trainer | begin training epoch 12
2023-12-13 18:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:08:25 | INFO | train_inner | {"epoch": 12, "update": 11.074, "loss": "4.496", "nll_loss": "3.103", "ppl": "8.59", "wps": "37808.7", "ups": "10.56", "wpb": "3581.8", "bsz": "145", "num_updates": "12200", "lr": "0.00572598", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "688"}
2023-12-13 18:08:30 | INFO | train_inner | {"epoch": 12, "update": 11.164, "loss": "4.535", "nll_loss": "3.147", "ppl": "8.86", "wps": "67025.1", "ups": "18.87", "wpb": "3551.7", "bsz": "143.1", "num_updates": "12300", "lr": "0.00570266", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "694"}
2023-12-13 18:08:35 | INFO | train_inner | {"epoch": 12, "update": 11.255, "loss": "4.473", "nll_loss": "3.074", "ppl": "8.42", "wps": "68274.8", "ups": "19.37", "wpb": "3524.8", "bsz": "146.2", "num_updates": "12400", "lr": "0.00567962", "gnorm": "0.239", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "699"}
2023-12-13 18:08:40 | INFO | train_inner | {"epoch": 12, "update": 11.346, "loss": "4.465", "nll_loss": "3.068", "ppl": "8.38", "wps": "75339.8", "ups": "20.69", "wpb": "3641.2", "bsz": "155", "num_updates": "12500", "lr": "0.00565685", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "704"}
2023-12-13 18:08:45 | INFO | train_inner | {"epoch": 12, "update": 11.436, "loss": "4.536", "nll_loss": "3.151", "ppl": "8.89", "wps": "72228.1", "ups": "19.9", "wpb": "3630.4", "bsz": "146.9", "num_updates": "12600", "lr": "0.00563436", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "709"}
2023-12-13 18:08:50 | INFO | train_inner | {"epoch": 12, "update": 11.527, "loss": "4.517", "nll_loss": "3.13", "ppl": "8.75", "wps": "71125.9", "ups": "19.41", "wpb": "3665.1", "bsz": "151", "num_updates": "12700", "lr": "0.00561214", "gnorm": "0.237", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "714"}
2023-12-13 18:08:55 | INFO | train_inner | {"epoch": 12, "update": 11.618, "loss": "4.512", "nll_loss": "3.126", "ppl": "8.73", "wps": "77904.5", "ups": "21.3", "wpb": "3657.3", "bsz": "149", "num_updates": "12800", "lr": "0.00559017", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "719"}
2023-12-13 18:09:01 | INFO | train_inner | {"epoch": 12, "update": 11.709, "loss": "4.607", "nll_loss": "3.231", "ppl": "9.39", "wps": "62064.1", "ups": "17.52", "wpb": "3542.2", "bsz": "130", "num_updates": "12900", "lr": "0.00556846", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "724"}
2023-12-13 18:09:06 | INFO | train_inner | {"epoch": 12, "update": 11.799, "loss": "4.545", "nll_loss": "3.164", "ppl": "8.96", "wps": "65406.4", "ups": "18.38", "wpb": "3557.7", "bsz": "146.9", "num_updates": "13000", "lr": "0.005547", "gnorm": "0.241", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "730"}
2023-12-13 18:09:12 | INFO | train_inner | {"epoch": 12, "update": 11.89, "loss": "4.657", "nll_loss": "3.293", "ppl": "9.8", "wps": "57515.5", "ups": "16.31", "wpb": "3527.1", "bsz": "127", "num_updates": "13100", "lr": "0.00552579", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "736"}
2023-12-13 18:09:17 | INFO | train_inner | {"epoch": 12, "update": 11.981, "loss": "4.533", "nll_loss": "3.149", "ppl": "8.87", "wps": "67713.9", "ups": "19.29", "wpb": "3509.5", "bsz": "155.6", "num_updates": "13200", "lr": "0.00550482", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "741"}
2023-12-13 18:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:09:20 | INFO | valid | {"epoch": 12, "valid_loss": "4.53", "valid_nll_loss": "3.188", "valid_ppl": "9.11", "valid_wps": "128112", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "13221", "valid_best_loss": "4.53"}
2023-12-13 18:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13221 updates
2023-12-13 18:09:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint12.pt
2023-12-13 18:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint12.pt
2023-12-13 18:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint12.pt (epoch 12 @ 13221 updates, score 4.53) (writing took 3.135159805417061 seconds)
2023-12-13 18:09:23 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-12-13 18:09:23 | INFO | train | {"epoch": 12, "train_loss": "4.533", "train_nll_loss": "3.147", "train_ppl": "8.86", "train_wps": "63251.7", "train_ups": "17.65", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "13221", "train_lr": "0.00550045", "train_gnorm": "0.243", "train_loss_scale": "16", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "747"}
2023-12-13 18:09:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:09:23 | INFO | fairseq.trainer | begin training epoch 13
2023-12-13 18:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:09:27 | INFO | train_inner | {"epoch": 13, "update": 12.072, "loss": "4.451", "nll_loss": "3.05", "ppl": "8.28", "wps": "37664.4", "ups": "10.31", "wpb": "3654.9", "bsz": "141.8", "num_updates": "13300", "lr": "0.00548408", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "751"}
2023-12-13 18:09:32 | INFO | train_inner | {"epoch": 13, "update": 12.162, "loss": "4.383", "nll_loss": "2.972", "ppl": "7.85", "wps": "70526.1", "ups": "19.67", "wpb": "3585.1", "bsz": "155.2", "num_updates": "13400", "lr": "0.00546358", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "756"}
2023-12-13 18:09:38 | INFO | train_inner | {"epoch": 13, "update": 12.253, "loss": "4.48", "nll_loss": "3.085", "ppl": "8.48", "wps": "64152.6", "ups": "18.03", "wpb": "3558.3", "bsz": "149.4", "num_updates": "13500", "lr": "0.00544331", "gnorm": "0.273", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "761"}
2023-12-13 18:09:43 | INFO | train_inner | {"epoch": 13, "update": 12.344, "loss": "4.459", "nll_loss": "3.063", "ppl": "8.36", "wps": "69047", "ups": "19.14", "wpb": "3606.9", "bsz": "147.8", "num_updates": "13600", "lr": "0.00542326", "gnorm": "0.228", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "767"}
2023-12-13 18:09:48 | INFO | train_inner | {"epoch": 13, "update": 12.435, "loss": "4.503", "nll_loss": "3.111", "ppl": "8.64", "wps": "67912.7", "ups": "19.06", "wpb": "3563.1", "bsz": "139.4", "num_updates": "13700", "lr": "0.00540343", "gnorm": "0.246", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "772"}
2023-12-13 18:09:53 | INFO | train_inner | {"epoch": 13, "update": 12.525, "loss": "4.481", "nll_loss": "3.089", "ppl": "8.51", "wps": "73189.2", "ups": "20.06", "wpb": "3648.9", "bsz": "146.8", "num_updates": "13800", "lr": "0.00538382", "gnorm": "0.228", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "777"}
2023-12-13 18:09:58 | INFO | train_inner | {"epoch": 13, "update": 12.616, "loss": "4.47", "nll_loss": "3.077", "ppl": "8.44", "wps": "73095.8", "ups": "20.39", "wpb": "3584", "bsz": "156", "num_updates": "13900", "lr": "0.00536442", "gnorm": "0.243", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "782"}
2023-12-13 18:10:03 | INFO | train_inner | {"epoch": 13, "update": 12.707, "loss": "4.51", "nll_loss": "3.124", "ppl": "8.72", "wps": "70154.3", "ups": "19.79", "wpb": "3544.4", "bsz": "149", "num_updates": "14000", "lr": "0.00534522", "gnorm": "0.253", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "787"}
2023-12-13 18:10:09 | INFO | train_inner | {"epoch": 13, "update": 12.798, "loss": "4.542", "nll_loss": "3.158", "ppl": "8.93", "wps": "61490.7", "ups": "17.58", "wpb": "3497.8", "bsz": "136.1", "num_updates": "14100", "lr": "0.00532624", "gnorm": "0.255", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "792"}
2023-12-13 18:10:14 | INFO | train_inner | {"epoch": 13, "update": 12.888, "loss": "4.549", "nll_loss": "3.171", "ppl": "9", "wps": "70249.2", "ups": "19.42", "wpb": "3618", "bsz": "143.9", "num_updates": "14200", "lr": "0.00530745", "gnorm": "0.243", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "798"}
2023-12-13 18:10:19 | INFO | train_inner | {"epoch": 13, "update": 12.979, "loss": "4.547", "nll_loss": "3.168", "ppl": "8.99", "wps": "70838.9", "ups": "19.87", "wpb": "3565.7", "bsz": "140.4", "num_updates": "14300", "lr": "0.00528886", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "803"}
2023-12-13 18:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:10:22 | INFO | valid | {"epoch": 13, "valid_loss": "4.51", "valid_nll_loss": "3.149", "valid_ppl": "8.87", "valid_wps": "133249", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "14323", "valid_best_loss": "4.51"}
2023-12-13 18:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14323 updates
2023-12-13 18:10:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint13.pt
2023-12-13 18:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint13.pt
2023-12-13 18:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint13.pt (epoch 13 @ 14323 updates, score 4.51) (writing took 2.6919310614466667 seconds)
2023-12-13 18:10:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-12-13 18:10:24 | INFO | train | {"epoch": 13, "train_loss": "4.489", "train_nll_loss": "3.098", "train_ppl": "8.56", "train_wps": "64303.5", "train_ups": "17.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "14323", "train_lr": "0.00528461", "train_gnorm": "0.243", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "808"}
2023-12-13 18:10:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:10:24 | INFO | fairseq.trainer | begin training epoch 14
2023-12-13 18:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:10:28 | INFO | train_inner | {"epoch": 14, "update": 13.07, "loss": "4.428", "nll_loss": "3.026", "ppl": "8.14", "wps": "38018.5", "ups": "10.67", "wpb": "3564.7", "bsz": "142", "num_updates": "14400", "lr": "0.00527046", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "812"}
2023-12-13 18:10:33 | INFO | train_inner | {"epoch": 14, "update": 13.161, "loss": "4.441", "nll_loss": "3.04", "ppl": "8.22", "wps": "70673.9", "ups": "19.51", "wpb": "3622.3", "bsz": "148", "num_updates": "14500", "lr": "0.00525226", "gnorm": "0.255", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "817"}
2023-12-13 18:10:39 | INFO | train_inner | {"epoch": 14, "update": 13.251, "loss": "4.412", "nll_loss": "3.008", "ppl": "8.05", "wps": "66321.9", "ups": "18.39", "wpb": "3605.8", "bsz": "144.3", "num_updates": "14600", "lr": "0.00523424", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "823"}
2023-12-13 18:10:44 | INFO | train_inner | {"epoch": 14, "update": 13.342, "loss": "4.389", "nll_loss": "2.983", "ppl": "7.91", "wps": "76291.7", "ups": "21.16", "wpb": "3605.2", "bsz": "153.6", "num_updates": "14700", "lr": "0.00521641", "gnorm": "0.228", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "827"}
2023-12-13 18:10:49 | INFO | train_inner | {"epoch": 14, "update": 13.433, "loss": "4.489", "nll_loss": "3.099", "ppl": "8.57", "wps": "69214.4", "ups": "19.43", "wpb": "3563.1", "bsz": "140.2", "num_updates": "14800", "lr": "0.00519875", "gnorm": "0.244", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "832"}
2023-12-13 18:10:54 | INFO | train_inner | {"epoch": 14, "update": 13.524, "loss": "4.48", "nll_loss": "3.086", "ppl": "8.49", "wps": "70974.9", "ups": "19.7", "wpb": "3602.4", "bsz": "138.1", "num_updates": "14900", "lr": "0.00518128", "gnorm": "0.241", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "838"}
2023-12-13 18:10:59 | INFO | train_inner | {"epoch": 14, "update": 13.614, "loss": "4.46", "nll_loss": "3.066", "ppl": "8.38", "wps": "74243.7", "ups": "20.91", "wpb": "3550.8", "bsz": "144", "num_updates": "15000", "lr": "0.00516398", "gnorm": "0.243", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "842"}
2023-12-13 18:11:03 | INFO | train_inner | {"epoch": 14, "update": 13.705, "loss": "4.376", "nll_loss": "2.971", "ppl": "7.84", "wps": "76752.4", "ups": "20.99", "wpb": "3657", "bsz": "167.8", "num_updates": "15100", "lr": "0.00514685", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "847"}
2023-12-13 18:11:09 | INFO | train_inner | {"epoch": 14, "update": 13.796, "loss": "4.495", "nll_loss": "3.107", "ppl": "8.62", "wps": "64689.8", "ups": "18.29", "wpb": "3536", "bsz": "137.6", "num_updates": "15200", "lr": "0.00512989", "gnorm": "0.244", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "853"}
2023-12-13 18:11:14 | INFO | train_inner | {"epoch": 14, "update": 13.887, "loss": "4.539", "nll_loss": "3.159", "ppl": "8.93", "wps": "66473", "ups": "18.84", "wpb": "3527.5", "bsz": "142.1", "num_updates": "15300", "lr": "0.0051131", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "858"}
2023-12-13 18:11:19 | INFO | train_inner | {"epoch": 14, "update": 13.977, "loss": "4.506", "nll_loss": "3.122", "ppl": "8.71", "wps": "67082.3", "ups": "18.79", "wpb": "3570.8", "bsz": "137.9", "num_updates": "15400", "lr": "0.00509647", "gnorm": "0.243", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "863"}
2023-12-13 18:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:11:22 | INFO | valid | {"epoch": 14, "valid_loss": "4.499", "valid_nll_loss": "3.13", "valid_ppl": "8.75", "valid_wps": "130152", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "15425", "valid_best_loss": "4.499"}
2023-12-13 18:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15425 updates
2023-12-13 18:11:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint14.pt
2023-12-13 18:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint14.pt
2023-12-13 18:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint14.pt (epoch 14 @ 15425 updates, score 4.499) (writing took 2.537335976958275 seconds)
2023-12-13 18:11:25 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-12-13 18:11:25 | INFO | train | {"epoch": 14, "train_loss": "4.453", "train_nll_loss": "3.057", "train_ppl": "8.32", "train_wps": "65222.5", "train_ups": "18.2", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "15425", "train_lr": "0.00509234", "train_gnorm": "0.242", "train_loss_scale": "16", "train_train_wall": "55", "train_gb_free": "39", "train_wall": "869"}
2023-12-13 18:11:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:11:25 | INFO | fairseq.trainer | begin training epoch 15
2023-12-13 18:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:11:29 | INFO | train_inner | {"epoch": 15, "update": 14.068, "loss": "4.398", "nll_loss": "2.993", "ppl": "7.96", "wps": "37937.7", "ups": "10.48", "wpb": "3621.4", "bsz": "134.6", "num_updates": "15500", "lr": "0.00508001", "gnorm": "0.237", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "873"}
2023-12-13 18:11:34 | INFO | train_inner | {"epoch": 15, "update": 14.159, "loss": "4.364", "nll_loss": "2.952", "ppl": "7.74", "wps": "73794.2", "ups": "20.49", "wpb": "3601.9", "bsz": "139.1", "num_updates": "15600", "lr": "0.0050637", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "878"}
2023-12-13 18:11:39 | INFO | train_inner | {"epoch": 15, "update": 14.25, "loss": "4.384", "nll_loss": "2.977", "ppl": "7.87", "wps": "67851.7", "ups": "18.95", "wpb": "3580.7", "bsz": "147.5", "num_updates": "15700", "lr": "0.00504754", "gnorm": "0.239", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "883"}
2023-12-13 18:11:45 | INFO | train_inner | {"epoch": 15, "update": 14.34, "loss": "4.443", "nll_loss": "3.043", "ppl": "8.24", "wps": "59820.2", "ups": "16.84", "wpb": "3553.2", "bsz": "128", "num_updates": "15800", "lr": "0.00503155", "gnorm": "0.249", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "889"}
2023-12-13 18:11:50 | INFO | train_inner | {"epoch": 15, "update": 14.431, "loss": "4.401", "nll_loss": "2.998", "ppl": "7.99", "wps": "69280.2", "ups": "19.34", "wpb": "3582.5", "bsz": "158.4", "num_updates": "15900", "lr": "0.0050157", "gnorm": "0.245", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "894"}
2023-12-13 18:11:55 | INFO | train_inner | {"epoch": 15, "update": 14.522, "loss": "4.38", "nll_loss": "2.976", "ppl": "7.87", "wps": "72952.6", "ups": "20.2", "wpb": "3611.1", "bsz": "156.5", "num_updates": "16000", "lr": "0.005", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "899"}
2023-12-13 18:12:00 | INFO | train_inner | {"epoch": 15, "update": 14.613, "loss": "4.414", "nll_loss": "3.014", "ppl": "8.08", "wps": "71062.4", "ups": "19.44", "wpb": "3655.1", "bsz": "149.6", "num_updates": "16100", "lr": "0.00498445", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "904"}
2023-12-13 18:12:06 | INFO | train_inner | {"epoch": 15, "update": 14.703, "loss": "4.473", "nll_loss": "3.081", "ppl": "8.46", "wps": "61513.7", "ups": "17.72", "wpb": "3470.5", "bsz": "131.8", "num_updates": "16200", "lr": "0.00496904", "gnorm": "0.245", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "910"}
2023-12-13 18:12:11 | INFO | train_inner | {"epoch": 15, "update": 14.794, "loss": "4.511", "nll_loss": "3.125", "ppl": "8.73", "wps": "64357.1", "ups": "18.18", "wpb": "3539.9", "bsz": "128.2", "num_updates": "16300", "lr": "0.00495377", "gnorm": "0.255", "loss_scale": "16", "train_wall": "5", "gb_free": "39.1", "wall": "915"}
2023-12-13 18:12:16 | INFO | train_inner | {"epoch": 15, "update": 14.885, "loss": "4.438", "nll_loss": "3.045", "ppl": "8.26", "wps": "80605.6", "ups": "22.44", "wpb": "3592.8", "bsz": "152.1", "num_updates": "16400", "lr": "0.00493865", "gnorm": "0.234", "loss_scale": "16", "train_wall": "4", "gb_free": "39", "wall": "920"}
2023-12-13 18:12:21 | INFO | train_inner | {"epoch": 15, "update": 14.975, "loss": "4.393", "nll_loss": "2.991", "ppl": "7.95", "wps": "69351.1", "ups": "19.21", "wpb": "3609.3", "bsz": "167.8", "num_updates": "16500", "lr": "0.00492366", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "925"}
2023-12-13 18:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:12:24 | INFO | valid | {"epoch": 15, "valid_loss": "4.485", "valid_nll_loss": "3.122", "valid_ppl": "8.7", "valid_wps": "130730", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "16527", "valid_best_loss": "4.485"}
2023-12-13 18:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16527 updates
2023-12-13 18:12:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint15.pt
2023-12-13 18:12:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint15.pt
2023-12-13 18:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint15.pt (epoch 15 @ 16527 updates, score 4.485) (writing took 2.9781694132834673 seconds)
2023-12-13 18:12:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-12-13 18:12:27 | INFO | train | {"epoch": 15, "train_loss": "4.415", "train_nll_loss": "3.014", "train_ppl": "8.08", "train_wps": "63861", "train_ups": "17.82", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "16527", "train_lr": "0.00491964", "train_gnorm": "0.24", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "930"}
2023-12-13 18:12:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:12:27 | INFO | fairseq.trainer | begin training epoch 16
2023-12-13 18:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:12:31 | INFO | train_inner | {"epoch": 16, "update": 15.066, "loss": "4.35", "nll_loss": "2.939", "ppl": "7.67", "wps": "37339.7", "ups": "10.43", "wpb": "3580.8", "bsz": "142.4", "num_updates": "16600", "lr": "0.00490881", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "935"}
2023-12-13 18:12:36 | INFO | train_inner | {"epoch": 16, "update": 15.157, "loss": "4.334", "nll_loss": "2.918", "ppl": "7.56", "wps": "66715.1", "ups": "18.76", "wpb": "3556", "bsz": "145", "num_updates": "16700", "lr": "0.00489409", "gnorm": "0.239", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "940"}
2023-12-13 18:12:41 | INFO | train_inner | {"epoch": 16, "update": 15.248, "loss": "4.321", "nll_loss": "2.906", "ppl": "7.5", "wps": "69744.2", "ups": "19.27", "wpb": "3618.6", "bsz": "162.3", "num_updates": "16800", "lr": "0.0048795", "gnorm": "0.249", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "945"}
2023-12-13 18:12:46 | INFO | train_inner | {"epoch": 16, "update": 15.338, "loss": "4.297", "nll_loss": "2.878", "ppl": "7.35", "wps": "80697.5", "ups": "22.39", "wpb": "3603.7", "bsz": "165.8", "num_updates": "16900", "lr": "0.00486504", "gnorm": "0.235", "loss_scale": "16", "train_wall": "4", "gb_free": "38.9", "wall": "949"}
2023-12-13 18:12:51 | INFO | train_inner | {"epoch": 16, "update": 15.429, "loss": "4.384", "nll_loss": "2.98", "ppl": "7.89", "wps": "71279.1", "ups": "20.07", "wpb": "3551.8", "bsz": "145.2", "num_updates": "17000", "lr": "0.00485071", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "954"}
2023-12-13 18:12:56 | INFO | train_inner | {"epoch": 16, "update": 15.52, "loss": "4.357", "nll_loss": "2.951", "ppl": "7.73", "wps": "68251.4", "ups": "19.16", "wpb": "3561.3", "bsz": "153", "num_updates": "17100", "lr": "0.00483651", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "960"}
2023-12-13 18:13:01 | INFO | train_inner | {"epoch": 16, "update": 15.611, "loss": "4.45", "nll_loss": "3.054", "ppl": "8.31", "wps": "68358.1", "ups": "19.26", "wpb": "3549.9", "bsz": "136.5", "num_updates": "17200", "lr": "0.00482243", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "965"}
2023-12-13 18:13:06 | INFO | train_inner | {"epoch": 16, "update": 15.701, "loss": "4.416", "nll_loss": "3.016", "ppl": "8.09", "wps": "66918.6", "ups": "18.74", "wpb": "3571.1", "bsz": "140.4", "num_updates": "17300", "lr": "0.00480847", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "970"}
2023-12-13 18:13:12 | INFO | train_inner | {"epoch": 16, "update": 15.792, "loss": "4.429", "nll_loss": "3.031", "ppl": "8.17", "wps": "68508.7", "ups": "18.82", "wpb": "3639.5", "bsz": "148.3", "num_updates": "17400", "lr": "0.00479463", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "976"}
2023-12-13 18:13:17 | INFO | train_inner | {"epoch": 16, "update": 15.883, "loss": "4.463", "nll_loss": "3.071", "ppl": "8.41", "wps": "71427.9", "ups": "19.52", "wpb": "3658.6", "bsz": "133.9", "num_updates": "17500", "lr": "0.00478091", "gnorm": "0.244", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "981"}
2023-12-13 18:13:22 | INFO | train_inner | {"epoch": 16, "update": 15.974, "loss": "4.467", "nll_loss": "3.076", "ppl": "8.43", "wps": "64298.4", "ups": "18.17", "wpb": "3539", "bsz": "134.5", "num_updates": "17600", "lr": "0.00476731", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "986"}
2023-12-13 18:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:13:25 | INFO | valid | {"epoch": 16, "valid_loss": "4.471", "valid_nll_loss": "3.113", "valid_ppl": "8.65", "valid_wps": "133102", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "17629", "valid_best_loss": "4.471"}
2023-12-13 18:13:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17629 updates
2023-12-13 18:13:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint16.pt
2023-12-13 18:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint16.pt
2023-12-13 18:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint16.pt (epoch 16 @ 17629 updates, score 4.471) (writing took 2.5610690880566835 seconds)
2023-12-13 18:13:28 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-12-13 18:13:28 | INFO | train | {"epoch": 16, "train_loss": "4.391", "train_nll_loss": "2.987", "train_ppl": "7.93", "train_wps": "64651.9", "train_ups": "18.04", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "17629", "train_lr": "0.00476339", "train_gnorm": "0.244", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "991"}
2023-12-13 18:13:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:13:28 | INFO | fairseq.trainer | begin training epoch 17
2023-12-13 18:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:13:32 | INFO | train_inner | {"epoch": 17, "update": 16.064, "loss": "4.345", "nll_loss": "2.933", "ppl": "7.64", "wps": "37206.9", "ups": "10.32", "wpb": "3606.3", "bsz": "129.4", "num_updates": "17700", "lr": "0.00475383", "gnorm": "0.231", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "996"}
2023-12-13 18:13:37 | INFO | train_inner | {"epoch": 17, "update": 16.155, "loss": "4.303", "nll_loss": "2.884", "ppl": "7.38", "wps": "76708.1", "ups": "21.38", "wpb": "3588.4", "bsz": "153", "num_updates": "17800", "lr": "0.00474045", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1001"}
2023-12-13 18:13:42 | INFO | train_inner | {"epoch": 17, "update": 16.246, "loss": "4.331", "nll_loss": "2.915", "ppl": "7.54", "wps": "69371.7", "ups": "19.51", "wpb": "3555.2", "bsz": "131.3", "num_updates": "17900", "lr": "0.00472719", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1006"}
2023-12-13 18:13:47 | INFO | train_inner | {"epoch": 17, "update": 16.337, "loss": "4.333", "nll_loss": "2.917", "ppl": "7.55", "wps": "67105.9", "ups": "18.83", "wpb": "3564.3", "bsz": "140.2", "num_updates": "18000", "lr": "0.00471405", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1011"}
2023-12-13 18:13:53 | INFO | train_inner | {"epoch": 17, "update": 16.427, "loss": "4.366", "nll_loss": "2.958", "ppl": "7.77", "wps": "67031", "ups": "18.81", "wpb": "3564.1", "bsz": "140.9", "num_updates": "18100", "lr": "0.004701", "gnorm": "0.247", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1016"}
2023-12-13 18:13:58 | INFO | train_inner | {"epoch": 17, "update": 16.518, "loss": "4.379", "nll_loss": "2.975", "ppl": "7.86", "wps": "65511.5", "ups": "18.22", "wpb": "3596.4", "bsz": "145.2", "num_updates": "18200", "lr": "0.00468807", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1022"}
2023-12-13 18:14:03 | INFO | train_inner | {"epoch": 17, "update": 16.609, "loss": "4.367", "nll_loss": "2.961", "ppl": "7.79", "wps": "72315.1", "ups": "20.06", "wpb": "3604.9", "bsz": "148.6", "num_updates": "18300", "lr": "0.00467525", "gnorm": "0.241", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1027"}
2023-12-13 18:14:08 | INFO | train_inner | {"epoch": 17, "update": 16.7, "loss": "4.392", "nll_loss": "2.992", "ppl": "7.96", "wps": "71265.5", "ups": "19.77", "wpb": "3604.9", "bsz": "150.5", "num_updates": "18400", "lr": "0.00466252", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1032"}
2023-12-13 18:14:13 | INFO | train_inner | {"epoch": 17, "update": 16.79, "loss": "4.411", "nll_loss": "3.013", "ppl": "8.07", "wps": "70185.5", "ups": "19.83", "wpb": "3540", "bsz": "144.6", "num_updates": "18500", "lr": "0.00464991", "gnorm": "0.251", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1037"}
2023-12-13 18:14:18 | INFO | train_inner | {"epoch": 17, "update": 16.881, "loss": "4.398", "nll_loss": "2.999", "ppl": "7.99", "wps": "67599.1", "ups": "19.09", "wpb": "3541.8", "bsz": "146.6", "num_updates": "18600", "lr": "0.00463739", "gnorm": "0.241", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1042"}
2023-12-13 18:14:23 | INFO | train_inner | {"epoch": 17, "update": 16.972, "loss": "4.346", "nll_loss": "2.941", "ppl": "7.68", "wps": "72384.7", "ups": "19.72", "wpb": "3670", "bsz": "157.4", "num_updates": "18700", "lr": "0.00462497", "gnorm": "0.23", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1047"}
2023-12-13 18:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:14:26 | INFO | valid | {"epoch": 17, "valid_loss": "4.47", "valid_nll_loss": "3.121", "valid_ppl": "8.7", "valid_wps": "132823", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "18731", "valid_best_loss": "4.47"}
2023-12-13 18:14:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18731 updates
2023-12-13 18:14:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint17.pt
2023-12-13 18:14:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint17.pt
2023-12-13 18:14:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint17.pt (epoch 17 @ 18731 updates, score 4.47) (writing took 2.6578089892864227 seconds)
2023-12-13 18:14:29 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-12-13 18:14:29 | INFO | train | {"epoch": 17, "train_loss": "4.358", "train_nll_loss": "2.95", "train_ppl": "7.73", "train_wps": "64593.2", "train_ups": "18.02", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "18731", "train_lr": "0.00462114", "train_gnorm": "0.241", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "1053"}
2023-12-13 18:14:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:14:29 | INFO | fairseq.trainer | begin training epoch 18
2023-12-13 18:14:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:14:32 | INFO | train_inner | {"epoch": 18, "update": 17.063, "loss": "4.216", "nll_loss": "2.787", "ppl": "6.9", "wps": "41073.9", "ups": "11.43", "wpb": "3593.6", "bsz": "164.7", "num_updates": "18800", "lr": "0.00461266", "gnorm": "0.228", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1056"}
2023-12-13 18:14:38 | INFO | train_inner | {"epoch": 18, "update": 17.153, "loss": "4.226", "nll_loss": "2.798", "ppl": "6.95", "wps": "66115.6", "ups": "18.51", "wpb": "3572.3", "bsz": "159.7", "num_updates": "18900", "lr": "0.00460044", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1061"}
2023-12-13 18:14:43 | INFO | train_inner | {"epoch": 18, "update": 17.244, "loss": "4.32", "nll_loss": "2.905", "ppl": "7.49", "wps": "66428.3", "ups": "18.56", "wpb": "3579.2", "bsz": "135.8", "num_updates": "19000", "lr": "0.00458831", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1067"}
2023-12-13 18:14:48 | INFO | train_inner | {"epoch": 18, "update": 17.335, "loss": "4.306", "nll_loss": "2.89", "ppl": "7.41", "wps": "75695.3", "ups": "21.16", "wpb": "3577.5", "bsz": "152.6", "num_updates": "19100", "lr": "0.00457629", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1071"}
2023-12-13 18:14:53 | INFO | train_inner | {"epoch": 18, "update": 17.426, "loss": "4.372", "nll_loss": "2.967", "ppl": "7.82", "wps": "62638.9", "ups": "17.57", "wpb": "3565.5", "bsz": "133.4", "num_updates": "19200", "lr": "0.00456435", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1077"}
2023-12-13 18:14:58 | INFO | train_inner | {"epoch": 18, "update": 17.516, "loss": "4.361", "nll_loss": "2.954", "ppl": "7.75", "wps": "70152", "ups": "19.7", "wpb": "3560.5", "bsz": "144.5", "num_updates": "19300", "lr": "0.00455251", "gnorm": "0.245", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1082"}
2023-12-13 18:15:04 | INFO | train_inner | {"epoch": 18, "update": 17.607, "loss": "4.349", "nll_loss": "2.942", "ppl": "7.68", "wps": "69921.6", "ups": "19.41", "wpb": "3602.9", "bsz": "147.6", "num_updates": "19400", "lr": "0.00454077", "gnorm": "0.231", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1087"}
2023-12-13 18:15:09 | INFO | train_inner | {"epoch": 18, "update": 17.698, "loss": "4.364", "nll_loss": "2.961", "ppl": "7.78", "wps": "67149.9", "ups": "18.53", "wpb": "3623.2", "bsz": "140.9", "num_updates": "19500", "lr": "0.00452911", "gnorm": "0.242", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1093"}
2023-12-13 18:15:14 | INFO | train_inner | {"epoch": 18, "update": 17.789, "loss": "4.372", "nll_loss": "2.968", "ppl": "7.83", "wps": "68462.7", "ups": "18.97", "wpb": "3609.2", "bsz": "150.3", "num_updates": "19600", "lr": "0.00451754", "gnorm": "0.261", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1098"}
2023-12-13 18:15:20 | INFO | train_inner | {"epoch": 18, "update": 17.879, "loss": "4.374", "nll_loss": "2.972", "ppl": "7.85", "wps": "65033", "ups": "18.14", "wpb": "3586", "bsz": "133.8", "num_updates": "19700", "lr": "0.00450606", "gnorm": "0.229", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1104"}
2023-12-13 18:15:25 | INFO | train_inner | {"epoch": 18, "update": 17.97, "loss": "4.38", "nll_loss": "2.979", "ppl": "7.88", "wps": "70683.9", "ups": "19.85", "wpb": "3561.2", "bsz": "142.2", "num_updates": "19800", "lr": "0.00449467", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1109"}
2023-12-13 18:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:15:28 | INFO | valid | {"epoch": 18, "valid_loss": "4.484", "valid_nll_loss": "3.116", "valid_ppl": "8.67", "valid_wps": "133274", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "19833", "valid_best_loss": "4.47"}
2023-12-13 18:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19833 updates
2023-12-13 18:15:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint18.pt
2023-12-13 18:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint18.pt
2023-12-13 18:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint18.pt (epoch 18 @ 19833 updates, score 4.484) (writing took 1.8403056096285582 seconds)
2023-12-13 18:15:30 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-12-13 18:15:30 | INFO | train | {"epoch": 18, "train_loss": "4.331", "train_nll_loss": "2.921", "train_ppl": "7.57", "train_wps": "64866.6", "train_ups": "18.1", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "19833", "train_lr": "0.00449092", "train_gnorm": "0.24", "train_loss_scale": "16", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1113"}
2023-12-13 18:15:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:15:30 | INFO | fairseq.trainer | begin training epoch 19
2023-12-13 18:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:15:33 | INFO | train_inner | {"epoch": 19, "update": 18.061, "loss": "4.229", "nll_loss": "2.802", "ppl": "6.98", "wps": "44847.2", "ups": "12.52", "wpb": "3583.1", "bsz": "153.9", "num_updates": "19900", "lr": "0.00448336", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1117"}
2023-12-13 18:15:38 | INFO | train_inner | {"epoch": 19, "update": 18.152, "loss": "4.201", "nll_loss": "2.769", "ppl": "6.82", "wps": "71517.3", "ups": "19.81", "wpb": "3610.2", "bsz": "165.7", "num_updates": "20000", "lr": "0.00447214", "gnorm": "0.231", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1122"}
2023-12-13 18:15:43 | INFO | train_inner | {"epoch": 19, "update": 18.242, "loss": "4.289", "nll_loss": "2.87", "ppl": "7.31", "wps": "67871.8", "ups": "18.9", "wpb": "3591.6", "bsz": "140", "num_updates": "20100", "lr": "0.004461", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1127"}
2023-12-13 18:15:48 | INFO | train_inner | {"epoch": 19, "update": 18.333, "loss": "4.258", "nll_loss": "2.836", "ppl": "7.14", "wps": "80706.4", "ups": "22.02", "wpb": "3665.1", "bsz": "159.3", "num_updates": "20200", "lr": "0.00444994", "gnorm": "0.228", "loss_scale": "16", "train_wall": "4", "gb_free": "38.9", "wall": "1131"}
2023-12-13 18:15:53 | INFO | train_inner | {"epoch": 19, "update": 18.424, "loss": "4.326", "nll_loss": "2.914", "ppl": "7.54", "wps": "65955.2", "ups": "18.39", "wpb": "3586.7", "bsz": "134.2", "num_updates": "20300", "lr": "0.00443897", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1137"}
2023-12-13 18:15:58 | INFO | train_inner | {"epoch": 19, "update": 18.515, "loss": "4.306", "nll_loss": "2.891", "ppl": "7.42", "wps": "68406.1", "ups": "18.9", "wpb": "3619.1", "bsz": "142.7", "num_updates": "20400", "lr": "0.00442807", "gnorm": "0.232", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1142"}
2023-12-13 18:16:04 | INFO | train_inner | {"epoch": 19, "update": 18.605, "loss": "4.332", "nll_loss": "2.92", "ppl": "7.57", "wps": "58755.3", "ups": "16.76", "wpb": "3505.5", "bsz": "141.1", "num_updates": "20500", "lr": "0.00441726", "gnorm": "0.251", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1148"}
2023-12-13 18:16:10 | INFO | train_inner | {"epoch": 19, "update": 18.696, "loss": "4.357", "nll_loss": "2.951", "ppl": "7.73", "wps": "66470.6", "ups": "18.57", "wpb": "3579.5", "bsz": "140.6", "num_updates": "20600", "lr": "0.00440653", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1154"}
2023-12-13 18:16:15 | INFO | train_inner | {"epoch": 19, "update": 18.787, "loss": "4.319", "nll_loss": "2.908", "ppl": "7.51", "wps": "69726.4", "ups": "19.45", "wpb": "3585.8", "bsz": "150.1", "num_updates": "20700", "lr": "0.00439587", "gnorm": "0.237", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1159"}
2023-12-13 18:16:20 | INFO | train_inner | {"epoch": 19, "update": 18.877, "loss": "4.325", "nll_loss": "2.917", "ppl": "7.55", "wps": "73755.4", "ups": "20.51", "wpb": "3596.5", "bsz": "152", "num_updates": "20800", "lr": "0.00438529", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1164"}
2023-12-13 18:16:25 | INFO | train_inner | {"epoch": 19, "update": 18.968, "loss": "4.382", "nll_loss": "2.982", "ppl": "7.9", "wps": "65641", "ups": "18.53", "wpb": "3542.7", "bsz": "134.3", "num_updates": "20900", "lr": "0.00437479", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1169"}
2023-12-13 18:16:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:16:29 | INFO | valid | {"epoch": 19, "valid_loss": "4.463", "valid_nll_loss": "3.109", "valid_ppl": "8.63", "valid_wps": "130520", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "20935", "valid_best_loss": "4.463"}
2023-12-13 18:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20935 updates
2023-12-13 18:16:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint19.pt
2023-12-13 18:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint19.pt
2023-12-13 18:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint19.pt (epoch 19 @ 20935 updates, score 4.463) (writing took 2.6283947192132473 seconds)
2023-12-13 18:16:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-12-13 18:16:31 | INFO | train | {"epoch": 19, "train_loss": "4.306", "train_nll_loss": "2.892", "train_ppl": "7.42", "train_wps": "64267.7", "train_ups": "17.93", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "20935", "train_lr": "0.00437113", "train_gnorm": "0.241", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "1175"}
2023-12-13 18:16:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:16:31 | INFO | fairseq.trainer | begin training epoch 20
2023-12-13 18:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:16:34 | INFO | train_inner | {"epoch": 20, "update": 19.059, "loss": "4.268", "nll_loss": "2.845", "ppl": "7.19", "wps": "38734.3", "ups": "10.91", "wpb": "3550", "bsz": "144.9", "num_updates": "21000", "lr": "0.00436436", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1178"}
2023-12-13 18:16:40 | INFO | train_inner | {"epoch": 20, "update": 19.15, "loss": "4.197", "nll_loss": "2.763", "ppl": "6.79", "wps": "60671", "ups": "17.3", "wpb": "3506.5", "bsz": "154.1", "num_updates": "21100", "lr": "0.004354", "gnorm": "0.245", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1184"}
2023-12-13 18:16:46 | INFO | train_inner | {"epoch": 20, "update": 19.24, "loss": "4.302", "nll_loss": "2.884", "ppl": "7.38", "wps": "58234.9", "ups": "16.36", "wpb": "3559.6", "bsz": "125.8", "num_updates": "21200", "lr": "0.00434372", "gnorm": "0.237", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1190"}
2023-12-13 18:16:52 | INFO | train_inner | {"epoch": 20, "update": 19.331, "loss": "4.275", "nll_loss": "2.855", "ppl": "7.24", "wps": "67464.3", "ups": "18.76", "wpb": "3597", "bsz": "139", "num_updates": "21300", "lr": "0.00433351", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1195"}
2023-12-13 18:16:57 | INFO | train_inner | {"epoch": 20, "update": 19.422, "loss": "4.263", "nll_loss": "2.841", "ppl": "7.17", "wps": "73092.4", "ups": "20.28", "wpb": "3603.4", "bsz": "146.1", "num_updates": "21400", "lr": "0.00432338", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1200"}
2023-12-13 18:17:02 | INFO | train_inner | {"epoch": 20, "update": 19.513, "loss": "4.266", "nll_loss": "2.845", "ppl": "7.18", "wps": "70414", "ups": "19.79", "wpb": "3558.3", "bsz": "143.4", "num_updates": "21500", "lr": "0.00431331", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1205"}
2023-12-13 18:17:07 | INFO | train_inner | {"epoch": 20, "update": 19.603, "loss": "4.315", "nll_loss": "2.902", "ppl": "7.47", "wps": "65904", "ups": "18.64", "wpb": "3535.6", "bsz": "139", "num_updates": "21600", "lr": "0.00430331", "gnorm": "0.245", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1211"}
2023-12-13 18:17:12 | INFO | train_inner | {"epoch": 20, "update": 19.694, "loss": "4.289", "nll_loss": "2.874", "ppl": "7.33", "wps": "71381.2", "ups": "19.79", "wpb": "3606.3", "bsz": "148.8", "num_updates": "21700", "lr": "0.00429339", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1216"}
2023-12-13 18:17:17 | INFO | train_inner | {"epoch": 20, "update": 19.785, "loss": "4.28", "nll_loss": "2.866", "ppl": "7.29", "wps": "75000.1", "ups": "20.61", "wpb": "3639.2", "bsz": "162.1", "num_updates": "21800", "lr": "0.00428353", "gnorm": "0.234", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1221"}
2023-12-13 18:17:22 | INFO | train_inner | {"epoch": 20, "update": 19.876, "loss": "4.369", "nll_loss": "2.968", "ppl": "7.83", "wps": "71455.1", "ups": "19.52", "wpb": "3660.6", "bsz": "135.8", "num_updates": "21900", "lr": "0.00427374", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1226"}
2023-12-13 18:17:27 | INFO | train_inner | {"epoch": 20, "update": 19.966, "loss": "4.323", "nll_loss": "2.916", "ppl": "7.55", "wps": "74635.3", "ups": "21.1", "wpb": "3536.8", "bsz": "150.4", "num_updates": "22000", "lr": "0.00426401", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1230"}
2023-12-13 18:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:17:30 | INFO | valid | {"epoch": 20, "valid_loss": "4.444", "valid_nll_loss": "3.068", "valid_ppl": "8.38", "valid_wps": "132568", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "22037", "valid_best_loss": "4.444"}
2023-12-13 18:17:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 22037 updates
2023-12-13 18:17:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint20.pt
2023-12-13 18:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint20.pt
2023-12-13 18:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint20.pt (epoch 20 @ 22037 updates, score 4.444) (writing took 2.604876384139061 seconds)
2023-12-13 18:17:33 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-12-13 18:17:33 | INFO | train | {"epoch": 20, "train_loss": "4.281", "train_nll_loss": "2.863", "train_ppl": "7.27", "train_wps": "64274.6", "train_ups": "17.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "22037", "train_lr": "0.00426043", "train_gnorm": "0.237", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "1236"}
2023-12-13 18:17:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:17:33 | INFO | fairseq.trainer | begin training epoch 21
2023-12-13 18:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:17:36 | INFO | train_inner | {"epoch": 21, "update": 20.057, "loss": "4.232", "nll_loss": "2.805", "ppl": "6.99", "wps": "39638.2", "ups": "11.02", "wpb": "3597.2", "bsz": "142.3", "num_updates": "22100", "lr": "0.00425436", "gnorm": "0.227", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1240"}
2023-12-13 18:17:41 | INFO | train_inner | {"epoch": 21, "update": 20.148, "loss": "4.198", "nll_loss": "2.767", "ppl": "6.8", "wps": "72050.5", "ups": "20.1", "wpb": "3584.6", "bsz": "151.8", "num_updates": "22200", "lr": "0.00424476", "gnorm": "0.231", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1245"}
2023-12-13 18:17:46 | INFO | train_inner | {"epoch": 21, "update": 20.239, "loss": "4.235", "nll_loss": "2.808", "ppl": "7", "wps": "63164.6", "ups": "17.71", "wpb": "3567.1", "bsz": "136.6", "num_updates": "22300", "lr": "0.00423524", "gnorm": "0.242", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1250"}
2023-12-13 18:17:52 | INFO | train_inner | {"epoch": 21, "update": 20.329, "loss": "4.27", "nll_loss": "2.85", "ppl": "7.21", "wps": "70069", "ups": "19.49", "wpb": "3594.7", "bsz": "145", "num_updates": "22400", "lr": "0.00422577", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1255"}
2023-12-13 18:17:57 | INFO | train_inner | {"epoch": 21, "update": 20.42, "loss": "4.276", "nll_loss": "2.858", "ppl": "7.25", "wps": "66569", "ups": "18.64", "wpb": "3570.4", "bsz": "138.3", "num_updates": "22500", "lr": "0.00421637", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1261"}
2023-12-13 18:18:02 | INFO | train_inner | {"epoch": 21, "update": 20.511, "loss": "4.277", "nll_loss": "2.859", "ppl": "7.25", "wps": "65315.6", "ups": "18.51", "wpb": "3528.4", "bsz": "143.6", "num_updates": "22600", "lr": "0.00420703", "gnorm": "0.24", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1266"}
2023-12-13 18:18:07 | INFO | train_inner | {"epoch": 21, "update": 20.602, "loss": "4.286", "nll_loss": "2.868", "ppl": "7.3", "wps": "74874.4", "ups": "20.73", "wpb": "3612.6", "bsz": "137", "num_updates": "22700", "lr": "0.00419775", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1271"}
2023-12-13 18:18:13 | INFO | train_inner | {"epoch": 21, "update": 20.692, "loss": "4.297", "nll_loss": "2.884", "ppl": "7.38", "wps": "66685.2", "ups": "18.57", "wpb": "3591.9", "bsz": "134.8", "num_updates": "22800", "lr": "0.00418854", "gnorm": "0.247", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1276"}
2023-12-13 18:18:18 | INFO | train_inner | {"epoch": 21, "update": 20.783, "loss": "4.252", "nll_loss": "2.833", "ppl": "7.13", "wps": "70580.5", "ups": "19.79", "wpb": "3566.4", "bsz": "150.2", "num_updates": "22900", "lr": "0.00417938", "gnorm": "0.236", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1281"}
2023-12-13 18:18:22 | INFO | train_inner | {"epoch": 21, "update": 20.874, "loss": "4.208", "nll_loss": "2.784", "ppl": "6.89", "wps": "77449", "ups": "21.59", "wpb": "3587.2", "bsz": "174.4", "num_updates": "23000", "lr": "0.00417029", "gnorm": "0.237", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1286"}
2023-12-13 18:18:28 | INFO | train_inner | {"epoch": 21, "update": 20.965, "loss": "4.305", "nll_loss": "2.893", "ppl": "7.43", "wps": "67786.4", "ups": "18.78", "wpb": "3609.3", "bsz": "145.9", "num_updates": "23100", "lr": "0.00416125", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1291"}
2023-12-13 18:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:18:31 | INFO | valid | {"epoch": 21, "valid_loss": "4.444", "valid_nll_loss": "3.093", "valid_ppl": "8.53", "valid_wps": "133782", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "23139", "valid_best_loss": "4.444"}
2023-12-13 18:18:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 23139 updates
2023-12-13 18:18:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint21.pt
2023-12-13 18:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint21.pt
2023-12-13 18:18:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint21.pt (epoch 21 @ 23139 updates, score 4.444) (writing took 2.663637576624751 seconds)
2023-12-13 18:18:33 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-12-13 18:18:33 | INFO | train | {"epoch": 21, "train_loss": "4.26", "train_nll_loss": "2.84", "train_ppl": "7.16", "train_wps": "64923.9", "train_ups": "18.12", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "23139", "train_lr": "0.00415774", "train_gnorm": "0.239", "train_loss_scale": "16", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "1297"}
2023-12-13 18:18:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:18:33 | INFO | fairseq.trainer | begin training epoch 22
2023-12-13 18:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:18:37 | INFO | train_inner | {"epoch": 22, "update": 21.055, "loss": "4.244", "nll_loss": "2.821", "ppl": "7.07", "wps": "38422.8", "ups": "10.75", "wpb": "3575.2", "bsz": "134.5", "num_updates": "23200", "lr": "0.00415227", "gnorm": "0.233", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1301"}
2023-12-13 18:18:42 | INFO | train_inner | {"epoch": 22, "update": 21.146, "loss": "4.186", "nll_loss": "2.753", "ppl": "6.74", "wps": "67565.8", "ups": "18.71", "wpb": "3611.2", "bsz": "148.3", "num_updates": "23300", "lr": "0.00414335", "gnorm": "0.235", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1306"}
2023-12-13 18:18:48 | INFO | train_inner | {"epoch": 22, "update": 21.237, "loss": "4.218", "nll_loss": "2.789", "ppl": "6.91", "wps": "61401.9", "ups": "17.23", "wpb": "3563.6", "bsz": "139.8", "num_updates": "23400", "lr": "0.00413449", "gnorm": "0.237", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1312"}
2023-12-13 18:18:53 | INFO | train_inner | {"epoch": 22, "update": 21.328, "loss": "4.25", "nll_loss": "2.825", "ppl": "7.09", "wps": "71056.3", "ups": "19.82", "wpb": "3584.2", "bsz": "130.3", "num_updates": "23500", "lr": "0.00412568", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1317"}
2023-12-13 18:18:58 | INFO | train_inner | {"epoch": 22, "update": 21.418, "loss": "4.249", "nll_loss": "2.829", "ppl": "7.1", "wps": "73301.7", "ups": "20.15", "wpb": "3638.6", "bsz": "145.7", "num_updates": "23600", "lr": "0.00411693", "gnorm": "0.238", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1322"}
2023-12-13 18:19:03 | INFO | train_inner | {"epoch": 22, "update": 21.509, "loss": "4.231", "nll_loss": "2.806", "ppl": "6.99", "wps": "69181.3", "ups": "19.32", "wpb": "3581.2", "bsz": "143.5", "num_updates": "23700", "lr": "0.00410824", "gnorm": "0.231", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1327"}
2023-12-13 18:19:08 | INFO | train_inner | {"epoch": 22, "update": 21.6, "loss": "4.243", "nll_loss": "2.821", "ppl": "7.07", "wps": "70052.9", "ups": "19.62", "wpb": "3569.8", "bsz": "150.5", "num_updates": "23800", "lr": "0.0040996", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1332"}
2023-12-13 18:19:14 | INFO | train_inner | {"epoch": 22, "update": 21.691, "loss": "4.263", "nll_loss": "2.844", "ppl": "7.18", "wps": "64902.1", "ups": "18.15", "wpb": "3576.5", "bsz": "140", "num_updates": "23900", "lr": "0.00409101", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1338"}
2023-12-13 18:19:19 | INFO | train_inner | {"epoch": 22, "update": 21.781, "loss": "4.269", "nll_loss": "2.85", "ppl": "7.21", "wps": "68184.7", "ups": "19.01", "wpb": "3587.3", "bsz": "145.4", "num_updates": "24000", "lr": "0.00408248", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1343"}
2023-12-13 18:19:24 | INFO | train_inner | {"epoch": 22, "update": 21.872, "loss": "4.23", "nll_loss": "2.809", "ppl": "7.01", "wps": "77362.3", "ups": "21.31", "wpb": "3630.8", "bsz": "166.4", "num_updates": "24100", "lr": "0.004074", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1347"}
2023-12-13 18:19:29 | INFO | train_inner | {"epoch": 22, "update": 21.963, "loss": "4.265", "nll_loss": "2.848", "ppl": "7.2", "wps": "72358.4", "ups": "20.22", "wpb": "3578.4", "bsz": "155.6", "num_updates": "24200", "lr": "0.00406558", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1352"}
2023-12-13 18:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:19:33 | INFO | valid | {"epoch": 22, "valid_loss": "4.451", "valid_nll_loss": "3.076", "valid_ppl": "8.43", "valid_wps": "131750", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "24241", "valid_best_loss": "4.444"}
2023-12-13 18:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 24241 updates
2023-12-13 18:19:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint22.pt
2023-12-13 18:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint22.pt
2023-12-13 18:19:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint22.pt (epoch 22 @ 24241 updates, score 4.451) (writing took 1.8810552284121513 seconds)
2023-12-13 18:19:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-12-13 18:19:34 | INFO | train | {"epoch": 22, "train_loss": "4.239", "train_nll_loss": "2.816", "train_ppl": "7.04", "train_wps": "64770.3", "train_ups": "18.07", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "24241", "train_lr": "0.00406214", "train_gnorm": "0.238", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1358"}
2023-12-13 18:19:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:19:34 | INFO | fairseq.trainer | begin training epoch 23
2023-12-13 18:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:19:38 | INFO | train_inner | {"epoch": 23, "update": 22.054, "loss": "4.199", "nll_loss": "2.768", "ppl": "6.81", "wps": "38482", "ups": "10.96", "wpb": "3512.1", "bsz": "139.9", "num_updates": "24300", "lr": "0.0040572", "gnorm": "0.244", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1362"}
2023-12-13 18:19:43 | INFO | train_inner | {"epoch": 23, "update": 22.144, "loss": "4.165", "nll_loss": "2.73", "ppl": "6.63", "wps": "72101", "ups": "20.2", "wpb": "3570", "bsz": "152.4", "num_updates": "24400", "lr": "0.00404888", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1367"}
2023-12-13 18:19:47 | INFO | train_inner | {"epoch": 23, "update": 22.235, "loss": "4.14", "nll_loss": "2.703", "ppl": "6.51", "wps": "79805.4", "ups": "21.74", "wpb": "3670.7", "bsz": "161.4", "num_updates": "24500", "lr": "0.00404061", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1371"}
2023-12-13 18:19:52 | INFO | train_inner | {"epoch": 23, "update": 22.326, "loss": "4.196", "nll_loss": "2.765", "ppl": "6.8", "wps": "71969.5", "ups": "19.72", "wpb": "3649.3", "bsz": "141", "num_updates": "24600", "lr": "0.00403239", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1376"}
2023-12-13 18:19:58 | INFO | train_inner | {"epoch": 23, "update": 22.417, "loss": "4.177", "nll_loss": "2.746", "ppl": "6.71", "wps": "69454.4", "ups": "19.45", "wpb": "3571.8", "bsz": "159.6", "num_updates": "24700", "lr": "0.00402422", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1381"}
2023-12-13 18:20:02 | INFO | train_inner | {"epoch": 23, "update": 22.507, "loss": "4.176", "nll_loss": "2.746", "ppl": "6.71", "wps": "81808.7", "ups": "22.5", "wpb": "3636.3", "bsz": "159.1", "num_updates": "24800", "lr": "0.0040161", "gnorm": "0.231", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "1386"}
2023-12-13 18:20:07 | INFO | train_inner | {"epoch": 23, "update": 22.598, "loss": "4.248", "nll_loss": "2.828", "ppl": "7.1", "wps": "67790.6", "ups": "18.64", "wpb": "3636.2", "bsz": "146.2", "num_updates": "24900", "lr": "0.00400802", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1391"}
2023-12-13 18:20:13 | INFO | train_inner | {"epoch": 23, "update": 22.689, "loss": "4.26", "nll_loss": "2.84", "ppl": "7.16", "wps": "65143.2", "ups": "18.26", "wpb": "3567.6", "bsz": "137.1", "num_updates": "25000", "lr": "0.004", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1397"}
2023-12-13 18:20:18 | INFO | train_inner | {"epoch": 23, "update": 22.779, "loss": "4.264", "nll_loss": "2.846", "ppl": "7.19", "wps": "64973.5", "ups": "18.41", "wpb": "3528.4", "bsz": "146.2", "num_updates": "25100", "lr": "0.00399202", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1402"}
2023-12-13 18:20:24 | INFO | train_inner | {"epoch": 23, "update": 22.87, "loss": "4.306", "nll_loss": "2.893", "ppl": "7.43", "wps": "58833.2", "ups": "16.74", "wpb": "3514.7", "bsz": "125.8", "num_updates": "25200", "lr": "0.0039841", "gnorm": "0.249", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1408"}
2023-12-13 18:20:30 | INFO | train_inner | {"epoch": 23, "update": 22.961, "loss": "4.289", "nll_loss": "2.874", "ppl": "7.33", "wps": "61637.5", "ups": "17.61", "wpb": "3499.3", "bsz": "131.3", "num_updates": "25300", "lr": "0.00397621", "gnorm": "0.245", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1414"}
2023-12-13 18:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:20:34 | INFO | valid | {"epoch": 23, "valid_loss": "4.442", "valid_nll_loss": "3.066", "valid_ppl": "8.37", "valid_wps": "130681", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "25343", "valid_best_loss": "4.442"}
2023-12-13 18:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 25343 updates
2023-12-13 18:20:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint23.pt
2023-12-13 18:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint23.pt
2023-12-13 18:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint23.pt (epoch 23 @ 25343 updates, score 4.442) (writing took 2.7753816917538643 seconds)
2023-12-13 18:20:36 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-12-13 18:20:36 | INFO | train | {"epoch": 23, "train_loss": "4.219", "train_nll_loss": "2.794", "train_ppl": "6.94", "train_wps": "63806.4", "train_ups": "17.81", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "25343", "train_lr": "0.00397284", "train_gnorm": "0.238", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "1420"}
2023-12-13 18:20:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:20:36 | INFO | fairseq.trainer | begin training epoch 24
2023-12-13 18:20:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:20:39 | INFO | train_inner | {"epoch": 24, "update": 23.052, "loss": "4.153", "nll_loss": "2.719", "ppl": "6.58", "wps": "40385.1", "ups": "11.05", "wpb": "3656.1", "bsz": "159", "num_updates": "25400", "lr": "0.00396838", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1423"}
2023-12-13 18:20:44 | INFO | train_inner | {"epoch": 24, "update": 23.142, "loss": "4.083", "nll_loss": "2.636", "ppl": "6.22", "wps": "68736.9", "ups": "18.99", "wpb": "3619.1", "bsz": "159.5", "num_updates": "25500", "lr": "0.00396059", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1428"}
2023-12-13 18:20:50 | INFO | train_inner | {"epoch": 24, "update": 23.233, "loss": "4.187", "nll_loss": "2.755", "ppl": "6.75", "wps": "67741", "ups": "18.77", "wpb": "3608.6", "bsz": "138.9", "num_updates": "25600", "lr": "0.00395285", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1433"}
2023-12-13 18:20:55 | INFO | train_inner | {"epoch": 24, "update": 23.324, "loss": "4.234", "nll_loss": "2.81", "ppl": "7.01", "wps": "64918.4", "ups": "18.19", "wpb": "3568.4", "bsz": "139.4", "num_updates": "25700", "lr": "0.00394515", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1439"}
2023-12-13 18:21:00 | INFO | train_inner | {"epoch": 24, "update": 23.415, "loss": "4.201", "nll_loss": "2.77", "ppl": "6.82", "wps": "67766.6", "ups": "18.7", "wpb": "3624.2", "bsz": "135.8", "num_updates": "25800", "lr": "0.0039375", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1444"}
2023-12-13 18:21:06 | INFO | train_inner | {"epoch": 24, "update": 23.505, "loss": "4.215", "nll_loss": "2.789", "ppl": "6.91", "wps": "65135.8", "ups": "18.29", "wpb": "3560.8", "bsz": "142", "num_updates": "25900", "lr": "0.00392989", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1450"}
2023-12-13 18:21:11 | INFO | train_inner | {"epoch": 24, "update": 23.596, "loss": "4.181", "nll_loss": "2.749", "ppl": "6.72", "wps": "73590.9", "ups": "20.35", "wpb": "3616.1", "bsz": "150.4", "num_updates": "26000", "lr": "0.00392232", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1455"}
2023-12-13 18:21:16 | INFO | train_inner | {"epoch": 24, "update": 23.687, "loss": "4.227", "nll_loss": "2.803", "ppl": "6.98", "wps": "67848.8", "ups": "19.09", "wpb": "3554.4", "bsz": "144.4", "num_updates": "26100", "lr": "0.0039148", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1460"}
2023-12-13 18:21:21 | INFO | train_inner | {"epoch": 24, "update": 23.778, "loss": "4.246", "nll_loss": "2.825", "ppl": "7.09", "wps": "65196.4", "ups": "18.57", "wpb": "3510.6", "bsz": "142.2", "num_updates": "26200", "lr": "0.00390732", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1465"}
2023-12-13 18:21:27 | INFO | train_inner | {"epoch": 24, "update": 23.868, "loss": "4.331", "nll_loss": "2.922", "ppl": "7.58", "wps": "59423.3", "ups": "16.94", "wpb": "3507", "bsz": "129", "num_updates": "26300", "lr": "0.00389989", "gnorm": "0.285", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1471"}
2023-12-13 18:21:32 | INFO | train_inner | {"epoch": 24, "update": 23.959, "loss": "4.229", "nll_loss": "2.809", "ppl": "7.01", "wps": "70253.4", "ups": "19.6", "wpb": "3583.9", "bsz": "151", "num_updates": "26400", "lr": "0.00389249", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1476"}
2023-12-13 18:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:21:36 | INFO | valid | {"epoch": 24, "valid_loss": "4.427", "valid_nll_loss": "3.069", "valid_ppl": "8.39", "valid_wps": "130238", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "26445", "valid_best_loss": "4.427"}
2023-12-13 18:21:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 26445 updates
2023-12-13 18:21:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint24.pt
2023-12-13 18:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint24.pt
2023-12-13 18:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint24.pt (epoch 24 @ 26445 updates, score 4.427) (writing took 2.5376921501010656 seconds)
2023-12-13 18:21:39 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-12-13 18:21:39 | INFO | train | {"epoch": 24, "train_loss": "4.204", "train_nll_loss": "2.777", "train_ppl": "6.85", "train_wps": "63390.1", "train_ups": "17.69", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "26445", "train_lr": "0.00388918", "train_gnorm": "0.243", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1482"}
2023-12-13 18:21:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:21:39 | INFO | fairseq.trainer | begin training epoch 25
2023-12-13 18:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:21:42 | INFO | train_inner | {"epoch": 25, "update": 24.05, "loss": "4.174", "nll_loss": "2.741", "ppl": "6.68", "wps": "35922.4", "ups": "10.17", "wpb": "3533.8", "bsz": "143.1", "num_updates": "26500", "lr": "0.00388514", "gnorm": "0.241", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1486"}
2023-12-13 18:21:48 | INFO | train_inner | {"epoch": 25, "update": 24.141, "loss": "4.102", "nll_loss": "2.657", "ppl": "6.31", "wps": "69117.1", "ups": "19.07", "wpb": "3624.1", "bsz": "148.4", "num_updates": "26600", "lr": "0.00387783", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1491"}
2023-12-13 18:21:53 | INFO | train_inner | {"epoch": 25, "update": 24.231, "loss": "4.181", "nll_loss": "2.75", "ppl": "6.73", "wps": "69247.9", "ups": "19.29", "wpb": "3590.4", "bsz": "139.1", "num_updates": "26700", "lr": "0.00387056", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1496"}
2023-12-13 18:21:58 | INFO | train_inner | {"epoch": 25, "update": 24.322, "loss": "4.152", "nll_loss": "2.715", "ppl": "6.57", "wps": "70283.9", "ups": "19.45", "wpb": "3613.6", "bsz": "152.6", "num_updates": "26800", "lr": "0.00386334", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1502"}
2023-12-13 18:22:03 | INFO | train_inner | {"epoch": 25, "update": 24.413, "loss": "4.167", "nll_loss": "2.733", "ppl": "6.65", "wps": "65774.2", "ups": "18.96", "wpb": "3469.8", "bsz": "150.4", "num_updates": "26900", "lr": "0.00385615", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1507"}
2023-12-13 18:22:08 | INFO | train_inner | {"epoch": 25, "update": 24.504, "loss": "4.157", "nll_loss": "2.724", "ppl": "6.61", "wps": "75492", "ups": "20.94", "wpb": "3605.6", "bsz": "159.9", "num_updates": "27000", "lr": "0.003849", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1512"}
2023-12-13 18:22:13 | INFO | train_inner | {"epoch": 25, "update": 24.594, "loss": "4.215", "nll_loss": "2.79", "ppl": "6.92", "wps": "74757.9", "ups": "20.52", "wpb": "3642.5", "bsz": "140.8", "num_updates": "27100", "lr": "0.00384189", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1517"}
2023-12-13 18:22:18 | INFO | train_inner | {"epoch": 25, "update": 24.685, "loss": "4.238", "nll_loss": "2.815", "ppl": "7.04", "wps": "63840.5", "ups": "17.73", "wpb": "3601.3", "bsz": "140.6", "num_updates": "27200", "lr": "0.00383482", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1522"}
2023-12-13 18:22:23 | INFO | train_inner | {"epoch": 25, "update": 24.776, "loss": "4.213", "nll_loss": "2.788", "ppl": "6.91", "wps": "71543.6", "ups": "20.21", "wpb": "3539.6", "bsz": "140.3", "num_updates": "27300", "lr": "0.0038278", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1527"}
2023-12-13 18:22:28 | INFO | train_inner | {"epoch": 25, "update": 24.867, "loss": "4.228", "nll_loss": "2.805", "ppl": "6.99", "wps": "73741.3", "ups": "20.6", "wpb": "3578.9", "bsz": "143.8", "num_updates": "27400", "lr": "0.0038208", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1532"}
2023-12-13 18:22:33 | INFO | train_inner | {"epoch": 25, "update": 24.957, "loss": "4.194", "nll_loss": "2.769", "ppl": "6.82", "wps": "74885.4", "ups": "20.52", "wpb": "3649.8", "bsz": "159.2", "num_updates": "27500", "lr": "0.00381385", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1537"}
2023-12-13 18:22:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:22:37 | INFO | valid | {"epoch": 25, "valid_loss": "4.427", "valid_nll_loss": "3.055", "valid_ppl": "8.31", "valid_wps": "134079", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "27547", "valid_best_loss": "4.427"}
2023-12-13 18:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 27547 updates
2023-12-13 18:22:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint25.pt
2023-12-13 18:22:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint25.pt
2023-12-13 18:22:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint25.pt (epoch 25 @ 27547 updates, score 4.427) (writing took 3.467995146289468 seconds)
2023-12-13 18:22:41 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-12-13 18:22:41 | INFO | train | {"epoch": 25, "train_loss": "4.185", "train_nll_loss": "2.755", "train_ppl": "6.75", "train_wps": "63610.6", "train_ups": "17.75", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "27547", "train_lr": "0.0038106", "train_gnorm": "0.238", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "1544"}
2023-12-13 18:22:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:22:41 | INFO | fairseq.trainer | begin training epoch 26
2023-12-13 18:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:22:43 | INFO | train_inner | {"epoch": 26, "update": 25.048, "loss": "4.122", "nll_loss": "2.681", "ppl": "6.41", "wps": "34632.6", "ups": "9.73", "wpb": "3559", "bsz": "143.5", "num_updates": "27600", "lr": "0.00380693", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1547"}
2023-12-13 18:22:48 | INFO | train_inner | {"epoch": 26, "update": 25.139, "loss": "4.096", "nll_loss": "2.652", "ppl": "6.28", "wps": "71328.3", "ups": "19.72", "wpb": "3617.5", "bsz": "148.6", "num_updates": "27700", "lr": "0.00380006", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1552"}
2023-12-13 18:22:54 | INFO | train_inner | {"epoch": 26, "update": 25.23, "loss": "4.099", "nll_loss": "2.655", "ppl": "6.3", "wps": "70758.4", "ups": "19.59", "wpb": "3612.4", "bsz": "152.5", "num_updates": "27800", "lr": "0.00379322", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1557"}
2023-12-13 18:23:00 | INFO | train_inner | {"epoch": 26, "update": 25.32, "loss": "4.19", "nll_loss": "2.758", "ppl": "6.77", "wps": "59101", "ups": "16.7", "wpb": "3538.7", "bsz": "130.2", "num_updates": "27900", "lr": "0.00378641", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1563"}
2023-12-13 18:23:05 | INFO | train_inner | {"epoch": 26, "update": 25.411, "loss": "4.153", "nll_loss": "2.718", "ppl": "6.58", "wps": "71608.6", "ups": "19.72", "wpb": "3631.4", "bsz": "151", "num_updates": "28000", "lr": "0.00377964", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1568"}
2023-12-13 18:23:10 | INFO | train_inner | {"epoch": 26, "update": 25.502, "loss": "4.204", "nll_loss": "2.777", "ppl": "6.85", "wps": "63517.5", "ups": "17.95", "wpb": "3539", "bsz": "133.1", "num_updates": "28100", "lr": "0.00377291", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1574"}
2023-12-13 18:23:16 | INFO | train_inner | {"epoch": 26, "update": 25.593, "loss": "4.257", "nll_loss": "2.836", "ppl": "7.14", "wps": "61472.9", "ups": "17.55", "wpb": "3502", "bsz": "122.6", "num_updates": "28200", "lr": "0.00376622", "gnorm": "0.244", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1580"}
2023-12-13 18:23:21 | INFO | train_inner | {"epoch": 26, "update": 25.683, "loss": "4.223", "nll_loss": "2.799", "ppl": "6.96", "wps": "72327.1", "ups": "19.89", "wpb": "3636", "bsz": "142.6", "num_updates": "28300", "lr": "0.00375956", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1585"}
2023-12-13 18:23:26 | INFO | train_inner | {"epoch": 26, "update": 25.774, "loss": "4.146", "nll_loss": "2.715", "ppl": "6.56", "wps": "71836.2", "ups": "20.03", "wpb": "3585.9", "bsz": "164.3", "num_updates": "28400", "lr": "0.00375293", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1590"}
2023-12-13 18:23:30 | INFO | train_inner | {"epoch": 26, "update": 25.865, "loss": "4.165", "nll_loss": "2.734", "ppl": "6.65", "wps": "80825.5", "ups": "22.59", "wpb": "3577.2", "bsz": "159.2", "num_updates": "28500", "lr": "0.00374634", "gnorm": "0.237", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "1594"}
2023-12-13 18:23:35 | INFO | train_inner | {"epoch": 26, "update": 25.956, "loss": "4.204", "nll_loss": "2.778", "ppl": "6.86", "wps": "70241.2", "ups": "19.42", "wpb": "3616.2", "bsz": "147.4", "num_updates": "28600", "lr": "0.00373979", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1599"}
2023-12-13 18:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:23:40 | INFO | valid | {"epoch": 26, "valid_loss": "4.416", "valid_nll_loss": "3.047", "valid_ppl": "8.27", "valid_wps": "134035", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "28649", "valid_best_loss": "4.416"}
2023-12-13 18:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 28649 updates
2023-12-13 18:23:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint26.pt
2023-12-13 18:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint26.pt
2023-12-13 18:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint26.pt (epoch 26 @ 28649 updates, score 4.416) (writing took 2.532016519457102 seconds)
2023-12-13 18:23:42 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-12-13 18:23:42 | INFO | train | {"epoch": 26, "train_loss": "4.168", "train_nll_loss": "2.736", "train_ppl": "6.66", "train_wps": "64204.7", "train_ups": "17.92", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "28649", "train_lr": "0.00373659", "train_gnorm": "0.239", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1606"}
2023-12-13 18:23:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:23:42 | INFO | fairseq.trainer | begin training epoch 27
2023-12-13 18:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:23:45 | INFO | train_inner | {"epoch": 27, "update": 26.046, "loss": "4.201", "nll_loss": "2.773", "ppl": "6.84", "wps": "36922.9", "ups": "10.37", "wpb": "3561.6", "bsz": "128.4", "num_updates": "28700", "lr": "0.00373327", "gnorm": "0.237", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1609"}
2023-12-13 18:23:50 | INFO | train_inner | {"epoch": 27, "update": 26.137, "loss": "4.077", "nll_loss": "2.627", "ppl": "6.18", "wps": "66583.5", "ups": "18.91", "wpb": "3521.5", "bsz": "140.6", "num_updates": "28800", "lr": "0.00372678", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1614"}
2023-12-13 18:23:56 | INFO | train_inner | {"epoch": 27, "update": 26.228, "loss": "4.115", "nll_loss": "2.672", "ppl": "6.37", "wps": "66357", "ups": "18.59", "wpb": "3569.3", "bsz": "136.2", "num_updates": "28900", "lr": "0.00372033", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1620"}
2023-12-13 18:24:01 | INFO | train_inner | {"epoch": 27, "update": 26.319, "loss": "4.132", "nll_loss": "2.695", "ppl": "6.48", "wps": "73259.5", "ups": "20.48", "wpb": "3577.3", "bsz": "153.8", "num_updates": "29000", "lr": "0.00371391", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1624"}
2023-12-13 18:24:06 | INFO | train_inner | {"epoch": 27, "update": 26.409, "loss": "4.128", "nll_loss": "2.689", "ppl": "6.45", "wps": "65053.1", "ups": "18.14", "wpb": "3586.8", "bsz": "150.5", "num_updates": "29100", "lr": "0.00370752", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1630"}
2023-12-13 18:24:12 | INFO | train_inner | {"epoch": 27, "update": 26.5, "loss": "4.191", "nll_loss": "2.763", "ppl": "6.79", "wps": "65379.4", "ups": "18.27", "wpb": "3578.1", "bsz": "140.8", "num_updates": "29200", "lr": "0.00370117", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1635"}
2023-12-13 18:24:17 | INFO | train_inner | {"epoch": 27, "update": 26.591, "loss": "4.125", "nll_loss": "2.685", "ppl": "6.43", "wps": "73965.1", "ups": "20.52", "wpb": "3605.1", "bsz": "157.4", "num_updates": "29300", "lr": "0.00369484", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1640"}
2023-12-13 18:24:22 | INFO | train_inner | {"epoch": 27, "update": 26.681, "loss": "4.184", "nll_loss": "2.757", "ppl": "6.76", "wps": "72654.5", "ups": "19.84", "wpb": "3661.3", "bsz": "147.4", "num_updates": "29400", "lr": "0.00368856", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1645"}
2023-12-13 18:24:27 | INFO | train_inner | {"epoch": 27, "update": 26.772, "loss": "4.217", "nll_loss": "2.792", "ppl": "6.93", "wps": "63680.6", "ups": "18.01", "wpb": "3535.5", "bsz": "132.4", "num_updates": "29500", "lr": "0.0036823", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1651"}
2023-12-13 18:24:32 | INFO | train_inner | {"epoch": 27, "update": 26.863, "loss": "4.178", "nll_loss": "2.751", "ppl": "6.73", "wps": "75120.4", "ups": "20.86", "wpb": "3601.2", "bsz": "155.4", "num_updates": "29600", "lr": "0.00367607", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1656"}
2023-12-13 18:24:37 | INFO | train_inner | {"epoch": 27, "update": 26.954, "loss": "4.137", "nll_loss": "2.702", "ppl": "6.51", "wps": "72092.9", "ups": "20", "wpb": "3605.3", "bsz": "157.6", "num_updates": "29700", "lr": "0.00366988", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1661"}
2023-12-13 18:24:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:24:41 | INFO | valid | {"epoch": 27, "valid_loss": "4.421", "valid_nll_loss": "3.059", "valid_ppl": "8.33", "valid_wps": "129623", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "29751", "valid_best_loss": "4.416"}
2023-12-13 18:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 29751 updates
2023-12-13 18:24:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint27.pt
2023-12-13 18:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint27.pt
2023-12-13 18:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint27.pt (epoch 27 @ 29751 updates, score 4.421) (writing took 1.8219518531113863 seconds)
2023-12-13 18:24:43 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-12-13 18:24:43 | INFO | train | {"epoch": 27, "train_loss": "4.153", "train_nll_loss": "2.719", "train_ppl": "6.58", "train_wps": "64975.8", "train_ups": "18.13", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "29751", "train_lr": "0.00366673", "train_gnorm": "0.241", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "1667"}
2023-12-13 18:24:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:24:43 | INFO | fairseq.trainer | begin training epoch 28
2023-12-13 18:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:24:46 | INFO | train_inner | {"epoch": 28, "update": 27.044, "loss": "4.143", "nll_loss": "2.708", "ppl": "6.53", "wps": "41803.5", "ups": "11.57", "wpb": "3612", "bsz": "141.4", "num_updates": "29800", "lr": "0.00366372", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1669"}
2023-12-13 18:24:50 | INFO | train_inner | {"epoch": 28, "update": 27.135, "loss": "4.05", "nll_loss": "2.601", "ppl": "6.07", "wps": "72893.8", "ups": "20.32", "wpb": "3587.4", "bsz": "151.4", "num_updates": "29900", "lr": "0.00365758", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1674"}
2023-12-13 18:24:55 | INFO | train_inner | {"epoch": 28, "update": 27.226, "loss": "4.091", "nll_loss": "2.646", "ppl": "6.26", "wps": "72688.4", "ups": "20.21", "wpb": "3597.1", "bsz": "155.4", "num_updates": "30000", "lr": "0.00365148", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1679"}
2023-12-13 18:25:00 | INFO | train_inner | {"epoch": 28, "update": 27.317, "loss": "4.114", "nll_loss": "2.673", "ppl": "6.38", "wps": "70919.1", "ups": "19.75", "wpb": "3590.3", "bsz": "144.6", "num_updates": "30100", "lr": "0.00364541", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1684"}
2023-12-13 18:25:06 | INFO | train_inner | {"epoch": 28, "update": 27.407, "loss": "4.165", "nll_loss": "2.732", "ppl": "6.64", "wps": "64039.6", "ups": "18.05", "wpb": "3547.3", "bsz": "143.4", "num_updates": "30200", "lr": "0.00363937", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1690"}
2023-12-13 18:25:11 | INFO | train_inner | {"epoch": 28, "update": 27.498, "loss": "4.147", "nll_loss": "2.711", "ppl": "6.55", "wps": "67157.6", "ups": "18.66", "wpb": "3598.8", "bsz": "142.3", "num_updates": "30300", "lr": "0.00363336", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1695"}
2023-12-13 18:25:17 | INFO | train_inner | {"epoch": 28, "update": 27.589, "loss": "4.177", "nll_loss": "2.744", "ppl": "6.7", "wps": "59008.7", "ups": "16.85", "wpb": "3502.7", "bsz": "135.4", "num_updates": "30400", "lr": "0.00362738", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1701"}
2023-12-13 18:25:22 | INFO | train_inner | {"epoch": 28, "update": 27.68, "loss": "4.151", "nll_loss": "2.719", "ppl": "6.58", "wps": "72731.8", "ups": "20.02", "wpb": "3632.6", "bsz": "147.9", "num_updates": "30500", "lr": "0.00362143", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1706"}
2023-12-13 18:25:27 | INFO | train_inner | {"epoch": 28, "update": 27.77, "loss": "4.182", "nll_loss": "2.751", "ppl": "6.73", "wps": "69434.3", "ups": "19.44", "wpb": "3572.6", "bsz": "138.1", "num_updates": "30600", "lr": "0.00361551", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1711"}
2023-12-13 18:25:32 | INFO | train_inner | {"epoch": 28, "update": 27.861, "loss": "4.15", "nll_loss": "2.717", "ppl": "6.58", "wps": "73267.4", "ups": "20.23", "wpb": "3620.9", "bsz": "153.9", "num_updates": "30700", "lr": "0.00360961", "gnorm": "0.23", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1716"}
2023-12-13 18:25:38 | INFO | train_inner | {"epoch": 28, "update": 27.952, "loss": "4.17", "nll_loss": "2.739", "ppl": "6.68", "wps": "64237.8", "ups": "18.2", "wpb": "3529.6", "bsz": "144.4", "num_updates": "30800", "lr": "0.00360375", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1722"}
2023-12-13 18:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:25:42 | INFO | valid | {"epoch": 28, "valid_loss": "4.417", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "131800", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "30853", "valid_best_loss": "4.416"}
2023-12-13 18:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 30853 updates
2023-12-13 18:25:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint28.pt
2023-12-13 18:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint28.pt
2023-12-13 18:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint28.pt (epoch 28 @ 30853 updates, score 4.417) (writing took 1.709873417392373 seconds)
2023-12-13 18:25:44 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-12-13 18:25:44 | INFO | train | {"epoch": 28, "train_loss": "4.139", "train_nll_loss": "2.703", "train_ppl": "6.51", "train_wps": "64948.6", "train_ups": "18.12", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "30853", "train_lr": "0.00360065", "train_gnorm": "0.239", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "1728"}
2023-12-13 18:25:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:25:44 | INFO | fairseq.trainer | begin training epoch 29
2023-12-13 18:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:25:46 | INFO | train_inner | {"epoch": 29, "update": 28.043, "loss": "4.143", "nll_loss": "2.708", "ppl": "6.53", "wps": "44118.1", "ups": "12.17", "wpb": "3624.6", "bsz": "137.9", "num_updates": "30900", "lr": "0.00359791", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1730"}
2023-12-13 18:25:51 | INFO | train_inner | {"epoch": 29, "update": 28.133, "loss": "4.018", "nll_loss": "2.56", "ppl": "5.9", "wps": "71494.7", "ups": "19.86", "wpb": "3599.5", "bsz": "142.7", "num_updates": "31000", "lr": "0.00359211", "gnorm": "0.227", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1735"}
2023-12-13 18:25:56 | INFO | train_inner | {"epoch": 29, "update": 28.224, "loss": "4.047", "nll_loss": "2.598", "ppl": "6.05", "wps": "69835.8", "ups": "19.19", "wpb": "3639.6", "bsz": "159.3", "num_updates": "31100", "lr": "0.00358633", "gnorm": "0.226", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1740"}
2023-12-13 18:26:02 | INFO | train_inner | {"epoch": 29, "update": 28.315, "loss": "4.124", "nll_loss": "2.683", "ppl": "6.42", "wps": "62278.9", "ups": "17.41", "wpb": "3576.7", "bsz": "139.4", "num_updates": "31200", "lr": "0.00358057", "gnorm": "0.247", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1746"}
2023-12-13 18:26:08 | INFO | train_inner | {"epoch": 29, "update": 28.406, "loss": "4.129", "nll_loss": "2.689", "ppl": "6.45", "wps": "64023.1", "ups": "18.12", "wpb": "3533.2", "bsz": "136.6", "num_updates": "31300", "lr": "0.00357485", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1751"}
2023-12-13 18:26:13 | INFO | train_inner | {"epoch": 29, "update": 28.496, "loss": "4.099", "nll_loss": "2.659", "ppl": "6.32", "wps": "73133.5", "ups": "20.37", "wpb": "3590.7", "bsz": "159.5", "num_updates": "31400", "lr": "0.00356915", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1756"}
2023-12-13 18:26:17 | INFO | train_inner | {"epoch": 29, "update": 28.587, "loss": "4.079", "nll_loss": "2.636", "ppl": "6.22", "wps": "75095.8", "ups": "20.96", "wpb": "3583.6", "bsz": "169", "num_updates": "31500", "lr": "0.00356348", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1761"}
2023-12-13 18:26:23 | INFO | train_inner | {"epoch": 29, "update": 28.678, "loss": "4.143", "nll_loss": "2.709", "ppl": "6.54", "wps": "66459.3", "ups": "18.57", "wpb": "3577.9", "bsz": "148.6", "num_updates": "31600", "lr": "0.00355784", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1766"}
2023-12-13 18:26:28 | INFO | train_inner | {"epoch": 29, "update": 28.769, "loss": "4.161", "nll_loss": "2.73", "ppl": "6.63", "wps": "63919.3", "ups": "17.98", "wpb": "3554.4", "bsz": "148.5", "num_updates": "31700", "lr": "0.00355222", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1772"}
2023-12-13 18:26:34 | INFO | train_inner | {"epoch": 29, "update": 28.859, "loss": "4.208", "nll_loss": "2.782", "ppl": "6.88", "wps": "63369", "ups": "17.64", "wpb": "3592.3", "bsz": "128.6", "num_updates": "31800", "lr": "0.00354663", "gnorm": "0.248", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1778"}
2023-12-13 18:26:39 | INFO | train_inner | {"epoch": 29, "update": 28.95, "loss": "4.207", "nll_loss": "2.783", "ppl": "6.88", "wps": "64322.2", "ups": "18.01", "wpb": "3570.7", "bsz": "129.8", "num_updates": "31900", "lr": "0.00354107", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1783"}
2023-12-13 18:26:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:26:44 | INFO | valid | {"epoch": 29, "valid_loss": "4.421", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "133261", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "31955", "valid_best_loss": "4.416"}
2023-12-13 18:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 31955 updates
2023-12-13 18:26:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint29.pt
2023-12-13 18:26:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint29.pt
2023-12-13 18:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint29.pt (epoch 29 @ 31955 updates, score 4.421) (writing took 1.8032579086720943 seconds)
2023-12-13 18:26:46 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-12-13 18:26:46 | INFO | train | {"epoch": 29, "train_loss": "4.124", "train_nll_loss": "2.685", "train_ppl": "6.43", "train_wps": "63675.9", "train_ups": "17.77", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "31955", "train_lr": "0.00353802", "train_gnorm": "0.242", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "1790"}
2023-12-13 18:26:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:26:46 | INFO | fairseq.trainer | begin training epoch 30
2023-12-13 18:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:26:48 | INFO | train_inner | {"epoch": 30, "update": 29.041, "loss": "4.127", "nll_loss": "2.689", "ppl": "6.45", "wps": "42106.7", "ups": "11.65", "wpb": "3614.5", "bsz": "132.4", "num_updates": "32000", "lr": "0.00353553", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1792"}
2023-12-13 18:26:54 | INFO | train_inner | {"epoch": 30, "update": 29.132, "loss": "4.047", "nll_loss": "2.594", "ppl": "6.04", "wps": "65524.1", "ups": "18.13", "wpb": "3613.4", "bsz": "138.3", "num_updates": "32100", "lr": "0.00353002", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1797"}
2023-12-13 18:26:59 | INFO | train_inner | {"epoch": 30, "update": 29.222, "loss": "4.111", "nll_loss": "2.668", "ppl": "6.36", "wps": "62497.8", "ups": "17.68", "wpb": "3534.8", "bsz": "137.4", "num_updates": "32200", "lr": "0.00352454", "gnorm": "0.263", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1803"}
2023-12-13 18:27:05 | INFO | train_inner | {"epoch": 30, "update": 29.313, "loss": "4.063", "nll_loss": "2.615", "ppl": "6.12", "wps": "67144.6", "ups": "18.75", "wpb": "3580.3", "bsz": "155.1", "num_updates": "32300", "lr": "0.00351908", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1808"}
2023-12-13 18:27:10 | INFO | train_inner | {"epoch": 30, "update": 29.404, "loss": "4.064", "nll_loss": "2.617", "ppl": "6.13", "wps": "69285.4", "ups": "19.25", "wpb": "3600.1", "bsz": "152.1", "num_updates": "32400", "lr": "0.00351364", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1814"}
2023-12-13 18:27:15 | INFO | train_inner | {"epoch": 30, "update": 29.495, "loss": "4.105", "nll_loss": "2.662", "ppl": "6.33", "wps": "67638.9", "ups": "19.04", "wpb": "3551.6", "bsz": "139.5", "num_updates": "32500", "lr": "0.00350823", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1819"}
2023-12-13 18:27:21 | INFO | train_inner | {"epoch": 30, "update": 29.585, "loss": "4.139", "nll_loss": "2.704", "ppl": "6.51", "wps": "63398.8", "ups": "17.62", "wpb": "3597.7", "bsz": "141.6", "num_updates": "32600", "lr": "0.00350285", "gnorm": "0.241", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1824"}
2023-12-13 18:27:26 | INFO | train_inner | {"epoch": 30, "update": 29.676, "loss": "4.127", "nll_loss": "2.688", "ppl": "6.45", "wps": "63076.5", "ups": "17.78", "wpb": "3546.7", "bsz": "135.7", "num_updates": "32700", "lr": "0.00349749", "gnorm": "0.243", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1830"}
2023-12-13 18:27:31 | INFO | train_inner | {"epoch": 30, "update": 29.767, "loss": "4.163", "nll_loss": "2.733", "ppl": "6.65", "wps": "73739.2", "ups": "20.56", "wpb": "3586", "bsz": "153.8", "num_updates": "32800", "lr": "0.00349215", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1835"}
2023-12-13 18:27:37 | INFO | train_inner | {"epoch": 30, "update": 29.858, "loss": "4.169", "nll_loss": "2.74", "ppl": "6.68", "wps": "64754.1", "ups": "18.17", "wpb": "3564.1", "bsz": "144", "num_updates": "32900", "lr": "0.00348684", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1840"}
2023-12-13 18:27:42 | INFO | train_inner | {"epoch": 30, "update": 29.948, "loss": "4.159", "nll_loss": "2.73", "ppl": "6.63", "wps": "74523.3", "ups": "20.65", "wpb": "3608.4", "bsz": "148.4", "num_updates": "33000", "lr": "0.00348155", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1845"}
2023-12-13 18:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:27:46 | INFO | valid | {"epoch": 30, "valid_loss": "4.425", "valid_nll_loss": "3.057", "valid_ppl": "8.32", "valid_wps": "132070", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "33057", "valid_best_loss": "4.416"}
2023-12-13 18:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 33057 updates
2023-12-13 18:27:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint30.pt
2023-12-13 18:27:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint30.pt
2023-12-13 18:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint30.pt (epoch 30 @ 33057 updates, score 4.425) (writing took 1.7860409077256918 seconds)
2023-12-13 18:27:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-12-13 18:27:48 | INFO | train | {"epoch": 30, "train_loss": "4.109", "train_nll_loss": "2.669", "train_ppl": "6.36", "train_wps": "63854.6", "train_ups": "17.82", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "33057", "train_lr": "0.00347855", "train_gnorm": "0.24", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "1851"}
2023-12-13 18:27:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:27:48 | INFO | fairseq.trainer | begin training epoch 31
2023-12-13 18:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:27:50 | INFO | train_inner | {"epoch": 31, "update": 30.039, "loss": "4.072", "nll_loss": "2.628", "ppl": "6.18", "wps": "42283.2", "ups": "11.73", "wpb": "3604", "bsz": "148.6", "num_updates": "33100", "lr": "0.00347629", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1854"}
2023-12-13 18:27:55 | INFO | train_inner | {"epoch": 31, "update": 30.13, "loss": "4", "nll_loss": "2.539", "ppl": "5.81", "wps": "71490.4", "ups": "19.76", "wpb": "3618.7", "bsz": "142.3", "num_updates": "33200", "lr": "0.00347105", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1859"}
2023-12-13 18:28:01 | INFO | train_inner | {"epoch": 31, "update": 30.221, "loss": "4.074", "nll_loss": "2.627", "ppl": "6.18", "wps": "60956.4", "ups": "17.27", "wpb": "3529.6", "bsz": "139.5", "num_updates": "33300", "lr": "0.00346583", "gnorm": "0.24", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1865"}
2023-12-13 18:28:06 | INFO | train_inner | {"epoch": 31, "update": 30.311, "loss": "4.106", "nll_loss": "2.664", "ppl": "6.34", "wps": "70516.6", "ups": "19.54", "wpb": "3608.8", "bsz": "133.4", "num_updates": "33400", "lr": "0.00346064", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1870"}
2023-12-13 18:28:11 | INFO | train_inner | {"epoch": 31, "update": 30.402, "loss": "4.086", "nll_loss": "2.645", "ppl": "6.26", "wps": "77143", "ups": "21.87", "wpb": "3527.6", "bsz": "163.2", "num_updates": "33500", "lr": "0.00345547", "gnorm": "0.235", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "1874"}
2023-12-13 18:28:16 | INFO | train_inner | {"epoch": 31, "update": 30.493, "loss": "4.118", "nll_loss": "2.676", "ppl": "6.39", "wps": "65325.3", "ups": "18.08", "wpb": "3613", "bsz": "145.5", "num_updates": "33600", "lr": "0.00345033", "gnorm": "0.288", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1880"}
2023-12-13 18:28:22 | INFO | train_inner | {"epoch": 31, "update": 30.583, "loss": "4.159", "nll_loss": "2.725", "ppl": "6.61", "wps": "62888", "ups": "17.77", "wpb": "3539.3", "bsz": "130.3", "num_updates": "33700", "lr": "0.0034452", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1886"}
2023-12-13 18:28:27 | INFO | train_inner | {"epoch": 31, "update": 30.674, "loss": "4.128", "nll_loss": "2.691", "ppl": "6.46", "wps": "68159.2", "ups": "19.26", "wpb": "3538.9", "bsz": "139.8", "num_updates": "33800", "lr": "0.0034401", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1891"}
2023-12-13 18:28:32 | INFO | train_inner | {"epoch": 31, "update": 30.765, "loss": "4.138", "nll_loss": "2.704", "ppl": "6.52", "wps": "71917.8", "ups": "19.75", "wpb": "3641.7", "bsz": "149.9", "num_updates": "33900", "lr": "0.00343503", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1896"}
2023-12-13 18:28:37 | INFO | train_inner | {"epoch": 31, "update": 30.856, "loss": "4.068", "nll_loss": "2.625", "ppl": "6.17", "wps": "75893.5", "ups": "20.74", "wpb": "3658.5", "bsz": "167.3", "num_updates": "34000", "lr": "0.00342997", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1901"}
2023-12-13 18:28:42 | INFO | train_inner | {"epoch": 31, "update": 30.946, "loss": "4.104", "nll_loss": "2.667", "ppl": "6.35", "wps": "70446.2", "ups": "19.51", "wpb": "3610", "bsz": "160.7", "num_updates": "34100", "lr": "0.00342494", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1906"}
2023-12-13 18:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:28:47 | INFO | valid | {"epoch": 31, "valid_loss": "4.427", "valid_nll_loss": "3.049", "valid_ppl": "8.28", "valid_wps": "131232", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "34159", "valid_best_loss": "4.416"}
2023-12-13 18:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 34159 updates
2023-12-13 18:28:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint31.pt
2023-12-13 18:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint31.pt
2023-12-13 18:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint31.pt (epoch 31 @ 34159 updates, score 4.427) (writing took 1.9355336893349886 seconds)
2023-12-13 18:28:49 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-12-13 18:28:49 | INFO | train | {"epoch": 31, "train_loss": "4.1", "train_nll_loss": "2.658", "train_ppl": "6.31", "train_wps": "64521.3", "train_ups": "18", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "34159", "train_lr": "0.00342198", "train_gnorm": "0.246", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "1913"}
2023-12-13 18:28:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:28:49 | INFO | fairseq.trainer | begin training epoch 32
2023-12-13 18:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:28:51 | INFO | train_inner | {"epoch": 32, "update": 31.037, "loss": "4.121", "nll_loss": "2.681", "ppl": "6.41", "wps": "38143.7", "ups": "10.83", "wpb": "3522.9", "bsz": "129.4", "num_updates": "34200", "lr": "0.00341993", "gnorm": "0.248", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1915"}
2023-12-13 18:28:56 | INFO | train_inner | {"epoch": 32, "update": 31.128, "loss": "4.003", "nll_loss": "2.543", "ppl": "5.83", "wps": "67842.8", "ups": "19.09", "wpb": "3553.7", "bsz": "143.9", "num_updates": "34300", "lr": "0.00341494", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1920"}
2023-12-13 18:29:02 | INFO | train_inner | {"epoch": 32, "update": 31.219, "loss": "4.001", "nll_loss": "2.545", "ppl": "5.84", "wps": "69789.7", "ups": "19.57", "wpb": "3566.2", "bsz": "160.2", "num_updates": "34400", "lr": "0.00340997", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1925"}
2023-12-13 18:29:07 | INFO | train_inner | {"epoch": 32, "update": 31.309, "loss": "4.076", "nll_loss": "2.629", "ppl": "6.18", "wps": "67673", "ups": "18.94", "wpb": "3572.6", "bsz": "141.3", "num_updates": "34500", "lr": "0.00340503", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1931"}
2023-12-13 18:29:13 | INFO | train_inner | {"epoch": 32, "update": 31.4, "loss": "4.114", "nll_loss": "2.673", "ppl": "6.38", "wps": "61081.5", "ups": "17.11", "wpb": "3570.2", "bsz": "133.7", "num_updates": "34600", "lr": "0.0034001", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1936"}
2023-12-13 18:29:18 | INFO | train_inner | {"epoch": 32, "update": 31.491, "loss": "4.056", "nll_loss": "2.609", "ppl": "6.1", "wps": "75088", "ups": "20.58", "wpb": "3649.4", "bsz": "164.8", "num_updates": "34700", "lr": "0.0033952", "gnorm": "0.232", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1941"}
2023-12-13 18:29:22 | INFO | train_inner | {"epoch": 32, "update": 31.582, "loss": "4.08", "nll_loss": "2.637", "ppl": "6.22", "wps": "78490.2", "ups": "21.31", "wpb": "3683.8", "bsz": "152.1", "num_updates": "34800", "lr": "0.00339032", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1946"}
2023-12-13 18:29:27 | INFO | train_inner | {"epoch": 32, "update": 31.672, "loss": "4.083", "nll_loss": "2.639", "ppl": "6.23", "wps": "69935.8", "ups": "19.68", "wpb": "3553.4", "bsz": "154", "num_updates": "34900", "lr": "0.00338546", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1951"}
2023-12-13 18:29:33 | INFO | train_inner | {"epoch": 32, "update": 31.763, "loss": "4.132", "nll_loss": "2.697", "ppl": "6.48", "wps": "67488.7", "ups": "18.92", "wpb": "3568", "bsz": "143.2", "num_updates": "35000", "lr": "0.00338062", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1956"}
2023-12-13 18:29:38 | INFO | train_inner | {"epoch": 32, "update": 31.854, "loss": "4.127", "nll_loss": "2.69", "ppl": "6.45", "wps": "64396.8", "ups": "18.04", "wpb": "3568.7", "bsz": "139.5", "num_updates": "35100", "lr": "0.0033758", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1962"}
2023-12-13 18:29:44 | INFO | train_inner | {"epoch": 32, "update": 31.945, "loss": "4.17", "nll_loss": "2.74", "ppl": "6.68", "wps": "61265.1", "ups": "17.33", "wpb": "3535.8", "bsz": "129.2", "num_updates": "35200", "lr": "0.003371", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1968"}
2023-12-13 18:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:29:48 | INFO | valid | {"epoch": 32, "valid_loss": "4.431", "valid_nll_loss": "3.067", "valid_ppl": "8.38", "valid_wps": "131378", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "35261", "valid_best_loss": "4.416"}
2023-12-13 18:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 35261 updates
2023-12-13 18:29:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint32.pt
2023-12-13 18:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint32.pt
2023-12-13 18:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint32.pt (epoch 32 @ 35261 updates, score 4.431) (writing took 2.154251204803586 seconds)
2023-12-13 18:29:50 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-12-13 18:29:50 | INFO | train | {"epoch": 32, "train_loss": "4.087", "train_nll_loss": "2.643", "train_ppl": "6.25", "train_wps": "64168.1", "train_ups": "17.91", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "35261", "train_lr": "0.00336808", "train_gnorm": "0.243", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "1974"}
2023-12-13 18:29:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:29:50 | INFO | fairseq.trainer | begin training epoch 33
2023-12-13 18:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:29:52 | INFO | train_inner | {"epoch": 33, "update": 32.035, "loss": "4.076", "nll_loss": "2.632", "ppl": "6.2", "wps": "43142.7", "ups": "11.9", "wpb": "3626.8", "bsz": "144", "num_updates": "35300", "lr": "0.00336622", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1976"}
2023-12-13 18:29:57 | INFO | train_inner | {"epoch": 33, "update": 32.126, "loss": "3.937", "nll_loss": "2.469", "ppl": "5.54", "wps": "80119.4", "ups": "22.11", "wpb": "3622.9", "bsz": "160.2", "num_updates": "35400", "lr": "0.00336146", "gnorm": "0.229", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "1981"}
2023-12-13 18:30:03 | INFO | train_inner | {"epoch": 33, "update": 32.217, "loss": "4.076", "nll_loss": "2.628", "ppl": "6.18", "wps": "62348.9", "ups": "17.5", "wpb": "3563.1", "bsz": "132.6", "num_updates": "35500", "lr": "0.00335673", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1986"}
2023-12-13 18:30:08 | INFO | train_inner | {"epoch": 33, "update": 32.308, "loss": "4.011", "nll_loss": "2.557", "ppl": "5.89", "wps": "72597.7", "ups": "20.09", "wpb": "3612.8", "bsz": "163.9", "num_updates": "35600", "lr": "0.00335201", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1991"}
2023-12-13 18:30:12 | INFO | train_inner | {"epoch": 33, "update": 32.398, "loss": "4.031", "nll_loss": "2.579", "ppl": "5.98", "wps": "74805.6", "ups": "20.6", "wpb": "3631.8", "bsz": "156.3", "num_updates": "35700", "lr": "0.00334731", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1996"}
2023-12-13 18:30:17 | INFO | train_inner | {"epoch": 33, "update": 32.489, "loss": "4.086", "nll_loss": "2.641", "ppl": "6.24", "wps": "69582.8", "ups": "19.55", "wpb": "3558.4", "bsz": "139.4", "num_updates": "35800", "lr": "0.00334263", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2001"}
2023-12-13 18:30:23 | INFO | train_inner | {"epoch": 33, "update": 32.58, "loss": "4.051", "nll_loss": "2.602", "ppl": "6.07", "wps": "69089", "ups": "19.33", "wpb": "3573.9", "bsz": "147.1", "num_updates": "35900", "lr": "0.00333797", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2006"}
2023-12-13 18:30:28 | INFO | train_inner | {"epoch": 33, "update": 32.671, "loss": "4.119", "nll_loss": "2.682", "ppl": "6.42", "wps": "68694.4", "ups": "19.01", "wpb": "3613.9", "bsz": "141.8", "num_updates": "36000", "lr": "0.00333333", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2012"}
2023-12-13 18:30:34 | INFO | train_inner | {"epoch": 33, "update": 32.761, "loss": "4.167", "nll_loss": "2.736", "ppl": "6.66", "wps": "62990.1", "ups": "17.74", "wpb": "3551.4", "bsz": "137.4", "num_updates": "36100", "lr": "0.00332871", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2017"}
2023-12-13 18:30:39 | INFO | train_inner | {"epoch": 33, "update": 32.852, "loss": "4.127", "nll_loss": "2.692", "ppl": "6.46", "wps": "67158.3", "ups": "18.85", "wpb": "3561.8", "bsz": "144.4", "num_updates": "36200", "lr": "0.00332411", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2023"}
2023-12-13 18:30:44 | INFO | train_inner | {"epoch": 33, "update": 32.943, "loss": "4.129", "nll_loss": "2.693", "ppl": "6.47", "wps": "65548.4", "ups": "18.32", "wpb": "3578.4", "bsz": "137.8", "num_updates": "36300", "lr": "0.00331953", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2028"}
2023-12-13 18:30:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:30:49 | INFO | valid | {"epoch": 33, "valid_loss": "4.423", "valid_nll_loss": "3.048", "valid_ppl": "8.27", "valid_wps": "128614", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "36363", "valid_best_loss": "4.416"}
2023-12-13 18:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 36363 updates
2023-12-13 18:30:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint33.pt
2023-12-13 18:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint33.pt
2023-12-13 18:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint33.pt (epoch 33 @ 36363 updates, score 4.423) (writing took 1.8711162898689508 seconds)
2023-12-13 18:30:51 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-12-13 18:30:51 | INFO | train | {"epoch": 33, "train_loss": "4.074", "train_nll_loss": "2.629", "train_ppl": "6.19", "train_wps": "65226.6", "train_ups": "18.2", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "36363", "train_lr": "0.00331665", "train_gnorm": "0.243", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "2035"}
2023-12-13 18:30:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:30:51 | INFO | fairseq.trainer | begin training epoch 34
2023-12-13 18:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:30:53 | INFO | train_inner | {"epoch": 34, "update": 33.034, "loss": "4.075", "nll_loss": "2.631", "ppl": "6.19", "wps": "41616.2", "ups": "11.67", "wpb": "3567.6", "bsz": "146.1", "num_updates": "36400", "lr": "0.00331497", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2037"}
2023-12-13 18:30:58 | INFO | train_inner | {"epoch": 34, "update": 33.124, "loss": "3.985", "nll_loss": "2.525", "ppl": "5.76", "wps": "74722.5", "ups": "20.54", "wpb": "3637.7", "bsz": "149.1", "num_updates": "36500", "lr": "0.00331042", "gnorm": "0.228", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2042"}
2023-12-13 18:31:03 | INFO | train_inner | {"epoch": 34, "update": 33.215, "loss": "4.01", "nll_loss": "2.553", "ppl": "5.87", "wps": "75710", "ups": "21.01", "wpb": "3603.9", "bsz": "144.7", "num_updates": "36600", "lr": "0.0033059", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2046"}
2023-12-13 18:31:08 | INFO | train_inner | {"epoch": 34, "update": 33.306, "loss": "4.016", "nll_loss": "2.561", "ppl": "5.9", "wps": "67772.6", "ups": "19.23", "wpb": "3523.8", "bsz": "149.8", "num_updates": "36700", "lr": "0.00330139", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2051"}
2023-12-13 18:31:13 | INFO | train_inner | {"epoch": 34, "update": 33.397, "loss": "4.06", "nll_loss": "2.612", "ppl": "6.11", "wps": "65161.9", "ups": "18.27", "wpb": "3567.5", "bsz": "144.3", "num_updates": "36800", "lr": "0.0032969", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2057"}
2023-12-13 18:31:19 | INFO | train_inner | {"epoch": 34, "update": 33.487, "loss": "4.058", "nll_loss": "2.61", "ppl": "6.11", "wps": "66908.1", "ups": "18.8", "wpb": "3558.8", "bsz": "145.8", "num_updates": "36900", "lr": "0.00329243", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2062"}
2023-12-13 18:31:24 | INFO | train_inner | {"epoch": 34, "update": 33.578, "loss": "4.1", "nll_loss": "2.659", "ppl": "6.32", "wps": "63862.6", "ups": "17.82", "wpb": "3582.9", "bsz": "135", "num_updates": "37000", "lr": "0.00328798", "gnorm": "0.254", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2068"}
2023-12-13 18:31:29 | INFO | train_inner | {"epoch": 34, "update": 33.669, "loss": "4.067", "nll_loss": "2.622", "ppl": "6.15", "wps": "72853.4", "ups": "19.86", "wpb": "3669.3", "bsz": "150.4", "num_updates": "37100", "lr": "0.00328355", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2073"}
2023-12-13 18:31:35 | INFO | train_inner | {"epoch": 34, "update": 33.76, "loss": "4.039", "nll_loss": "2.591", "ppl": "6.03", "wps": "68360.8", "ups": "18.67", "wpb": "3661.8", "bsz": "167", "num_updates": "37200", "lr": "0.00327913", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2078"}
2023-12-13 18:31:40 | INFO | train_inner | {"epoch": 34, "update": 33.85, "loss": "4.155", "nll_loss": "2.725", "ppl": "6.61", "wps": "62465.3", "ups": "17.5", "wpb": "3568.4", "bsz": "143.4", "num_updates": "37300", "lr": "0.00327473", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2084"}
2023-12-13 18:31:46 | INFO | train_inner | {"epoch": 34, "update": 33.941, "loss": "4.139", "nll_loss": "2.705", "ppl": "6.52", "wps": "61915.9", "ups": "17.7", "wpb": "3498.1", "bsz": "134.7", "num_updates": "37400", "lr": "0.00327035", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2090"}
2023-12-13 18:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:31:51 | INFO | valid | {"epoch": 34, "valid_loss": "4.412", "valid_nll_loss": "3.028", "valid_ppl": "8.16", "valid_wps": "133351", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "37465", "valid_best_loss": "4.412"}
2023-12-13 18:31:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 37465 updates
2023-12-13 18:31:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint34.pt
2023-12-13 18:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint34.pt
2023-12-13 18:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint34.pt (epoch 34 @ 37465 updates, score 4.412) (writing took 2.64741163700819 seconds)
2023-12-13 18:31:54 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-12-13 18:31:54 | INFO | train | {"epoch": 34, "train_loss": "4.064", "train_nll_loss": "2.618", "train_ppl": "6.14", "train_wps": "62961.7", "train_ups": "17.57", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "37465", "train_lr": "0.00326751", "train_gnorm": "0.247", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "2097"}
2023-12-13 18:31:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:31:54 | INFO | fairseq.trainer | begin training epoch 35
2023-12-13 18:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:31:56 | INFO | train_inner | {"epoch": 35, "update": 34.032, "loss": "4.085", "nll_loss": "2.639", "ppl": "6.23", "wps": "35897.3", "ups": "10.18", "wpb": "3526.1", "bsz": "126", "num_updates": "37500", "lr": "0.00326599", "gnorm": "0.246", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2099"}
2023-12-13 18:32:01 | INFO | train_inner | {"epoch": 35, "update": 34.123, "loss": "3.979", "nll_loss": "2.515", "ppl": "5.72", "wps": "64177.7", "ups": "18.05", "wpb": "3556.2", "bsz": "138.1", "num_updates": "37600", "lr": "0.00326164", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2105"}
2023-12-13 18:32:06 | INFO | train_inner | {"epoch": 35, "update": 34.213, "loss": "3.98", "nll_loss": "2.52", "ppl": "5.74", "wps": "72332.7", "ups": "19.79", "wpb": "3654.5", "bsz": "156.3", "num_updates": "37700", "lr": "0.00325731", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2110"}
2023-12-13 18:32:11 | INFO | train_inner | {"epoch": 35, "update": 34.304, "loss": "4.015", "nll_loss": "2.561", "ppl": "5.9", "wps": "72930.3", "ups": "20.36", "wpb": "3582.5", "bsz": "154.6", "num_updates": "37800", "lr": "0.003253", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2115"}
2023-12-13 18:32:16 | INFO | train_inner | {"epoch": 35, "update": 34.395, "loss": "4.073", "nll_loss": "2.628", "ppl": "6.18", "wps": "68527.4", "ups": "19.46", "wpb": "3520.9", "bsz": "148.4", "num_updates": "37900", "lr": "0.00324871", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2120"}
2023-12-13 18:32:22 | INFO | train_inner | {"epoch": 35, "update": 34.485, "loss": "4.04", "nll_loss": "2.591", "ppl": "6.02", "wps": "69525.4", "ups": "19.17", "wpb": "3627.6", "bsz": "151.3", "num_updates": "38000", "lr": "0.00324443", "gnorm": "0.238", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2125"}
2023-12-13 18:32:27 | INFO | train_inner | {"epoch": 35, "update": 34.576, "loss": "4.051", "nll_loss": "2.603", "ppl": "6.08", "wps": "70544.1", "ups": "20.03", "wpb": "3521.8", "bsz": "152.1", "num_updates": "38100", "lr": "0.00324017", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2130"}
2023-12-13 18:32:32 | INFO | train_inner | {"epoch": 35, "update": 34.667, "loss": "4.087", "nll_loss": "2.644", "ppl": "6.25", "wps": "70117.1", "ups": "19.61", "wpb": "3575.5", "bsz": "133.3", "num_updates": "38200", "lr": "0.00323592", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2135"}
2023-12-13 18:32:37 | INFO | train_inner | {"epoch": 35, "update": 34.758, "loss": "4.066", "nll_loss": "2.62", "ppl": "6.15", "wps": "67136.7", "ups": "18.7", "wpb": "3591", "bsz": "147.9", "num_updates": "38300", "lr": "0.0032317", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2141"}
2023-12-13 18:32:43 | INFO | train_inner | {"epoch": 35, "update": 34.848, "loss": "4.116", "nll_loss": "2.678", "ppl": "6.4", "wps": "65507.4", "ups": "18.14", "wpb": "3611.5", "bsz": "135.8", "num_updates": "38400", "lr": "0.00322749", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2146"}
2023-12-13 18:32:48 | INFO | train_inner | {"epoch": 35, "update": 34.939, "loss": "4.119", "nll_loss": "2.685", "ppl": "6.43", "wps": "70539.2", "ups": "19.37", "wpb": "3642.5", "bsz": "145.5", "num_updates": "38500", "lr": "0.00322329", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2151"}
2023-12-13 18:32:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:32:53 | INFO | valid | {"epoch": 35, "valid_loss": "4.435", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "128732", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "38567", "valid_best_loss": "4.412"}
2023-12-13 18:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 38567 updates
2023-12-13 18:32:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint35.pt
2023-12-13 18:32:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint35.pt
2023-12-13 18:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint35.pt (epoch 35 @ 38567 updates, score 4.435) (writing took 2.423283699899912 seconds)
2023-12-13 18:32:55 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-12-13 18:32:55 | INFO | train | {"epoch": 35, "train_loss": "4.052", "train_nll_loss": "2.604", "train_ppl": "6.08", "train_wps": "63890.5", "train_ups": "17.83", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "38567", "train_lr": "0.00322049", "train_gnorm": "0.245", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2159"}
2023-12-13 18:32:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:32:56 | INFO | fairseq.trainer | begin training epoch 36
2023-12-13 18:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:32:57 | INFO | train_inner | {"epoch": 36, "update": 35.03, "loss": "4.031", "nll_loss": "2.578", "ppl": "5.97", "wps": "37827.7", "ups": "10.67", "wpb": "3543.6", "bsz": "138.3", "num_updates": "38600", "lr": "0.00321911", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2161"}
2023-12-13 18:33:02 | INFO | train_inner | {"epoch": 36, "update": 35.121, "loss": "3.943", "nll_loss": "2.478", "ppl": "5.57", "wps": "71765.6", "ups": "20.1", "wpb": "3570.7", "bsz": "158.2", "num_updates": "38700", "lr": "0.00321495", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2166"}
2023-12-13 18:33:07 | INFO | train_inner | {"epoch": 36, "update": 35.211, "loss": "3.988", "nll_loss": "2.529", "ppl": "5.77", "wps": "69914.8", "ups": "19.4", "wpb": "3603.7", "bsz": "144.7", "num_updates": "38800", "lr": "0.00321081", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2171"}
2023-12-13 18:33:13 | INFO | train_inner | {"epoch": 36, "update": 35.302, "loss": "4.056", "nll_loss": "2.604", "ppl": "6.08", "wps": "60952.5", "ups": "17.2", "wpb": "3542.8", "bsz": "126.6", "num_updates": "38900", "lr": "0.00320668", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2177"}
2023-12-13 18:33:18 | INFO | train_inner | {"epoch": 36, "update": 35.393, "loss": "4.027", "nll_loss": "2.576", "ppl": "5.96", "wps": "67610.7", "ups": "18.88", "wpb": "3581.5", "bsz": "151.6", "num_updates": "39000", "lr": "0.00320256", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2182"}
2023-12-13 18:33:24 | INFO | train_inner | {"epoch": 36, "update": 35.484, "loss": "4.054", "nll_loss": "2.606", "ppl": "6.09", "wps": "68176.7", "ups": "19.14", "wpb": "3562.7", "bsz": "141.4", "num_updates": "39100", "lr": "0.00319847", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2187"}
2023-12-13 18:33:29 | INFO | train_inner | {"epoch": 36, "update": 35.574, "loss": "4.014", "nll_loss": "2.562", "ppl": "5.9", "wps": "71789.4", "ups": "19.57", "wpb": "3668.8", "bsz": "152.4", "num_updates": "39200", "lr": "0.00319438", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2192"}
2023-12-13 18:33:34 | INFO | train_inner | {"epoch": 36, "update": 35.665, "loss": "4.097", "nll_loss": "2.656", "ppl": "6.3", "wps": "65228.4", "ups": "18.09", "wpb": "3604.9", "bsz": "138.5", "num_updates": "39300", "lr": "0.00319032", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2198"}
2023-12-13 18:33:39 | INFO | train_inner | {"epoch": 36, "update": 35.756, "loss": "4.116", "nll_loss": "2.68", "ppl": "6.41", "wps": "70241.8", "ups": "19.82", "wpb": "3544.6", "bsz": "139.5", "num_updates": "39400", "lr": "0.00318626", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2203"}
2023-12-13 18:33:45 | INFO | train_inner | {"epoch": 36, "update": 35.847, "loss": "4.06", "nll_loss": "2.615", "ppl": "6.13", "wps": "63594.5", "ups": "17.96", "wpb": "3540.4", "bsz": "154.1", "num_updates": "39500", "lr": "0.00318223", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2209"}
2023-12-13 18:33:50 | INFO | train_inner | {"epoch": 36, "update": 35.937, "loss": "4.103", "nll_loss": "2.665", "ppl": "6.34", "wps": "67238", "ups": "18.8", "wpb": "3576.1", "bsz": "144.2", "num_updates": "39600", "lr": "0.00317821", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2214"}
2023-12-13 18:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:33:55 | INFO | valid | {"epoch": 36, "valid_loss": "4.42", "valid_nll_loss": "3.055", "valid_ppl": "8.31", "valid_wps": "131789", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "39669", "valid_best_loss": "4.412"}
2023-12-13 18:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 39669 updates
2023-12-13 18:33:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint36.pt
2023-12-13 18:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint36.pt
2023-12-13 18:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint36.pt (epoch 36 @ 39669 updates, score 4.42) (writing took 1.7852332331240177 seconds)
2023-12-13 18:33:57 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-12-13 18:33:57 | INFO | train | {"epoch": 36, "train_loss": "4.042", "train_nll_loss": "2.593", "train_ppl": "6.03", "train_wps": "64352.3", "train_ups": "17.96", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "39669", "train_lr": "0.00317544", "train_gnorm": "0.248", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2221"}
2023-12-13 18:33:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:33:57 | INFO | fairseq.trainer | begin training epoch 37
2023-12-13 18:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:33:58 | INFO | train_inner | {"epoch": 37, "update": 36.028, "loss": "4.018", "nll_loss": "2.565", "ppl": "5.92", "wps": "43488.4", "ups": "12.06", "wpb": "3604.8", "bsz": "154.3", "num_updates": "39700", "lr": "0.0031742", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2222"}
2023-12-13 18:34:03 | INFO | train_inner | {"epoch": 37, "update": 36.119, "loss": "3.929", "nll_loss": "2.464", "ppl": "5.52", "wps": "72118.7", "ups": "20.23", "wpb": "3564.5", "bsz": "160.2", "num_updates": "39800", "lr": "0.00317021", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2227"}
2023-12-13 18:34:09 | INFO | train_inner | {"epoch": 37, "update": 36.21, "loss": "3.938", "nll_loss": "2.47", "ppl": "5.54", "wps": "64914.5", "ups": "18.25", "wpb": "3557.7", "bsz": "145.6", "num_updates": "39900", "lr": "0.00316624", "gnorm": "0.234", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2233"}
2023-12-13 18:34:14 | INFO | train_inner | {"epoch": 37, "update": 36.3, "loss": "3.975", "nll_loss": "2.515", "ppl": "5.71", "wps": "69114.3", "ups": "19.32", "wpb": "3578", "bsz": "149.1", "num_updates": "40000", "lr": "0.00316228", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2238"}
2023-12-13 18:34:19 | INFO | train_inner | {"epoch": 37, "update": 36.391, "loss": "4.008", "nll_loss": "2.552", "ppl": "5.86", "wps": "68158.5", "ups": "18.99", "wpb": "3589.3", "bsz": "154.7", "num_updates": "40100", "lr": "0.00315833", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2243"}
2023-12-13 18:34:25 | INFO | train_inner | {"epoch": 37, "update": 36.482, "loss": "4.036", "nll_loss": "2.586", "ppl": "6", "wps": "66135.7", "ups": "18.58", "wpb": "3559.3", "bsz": "147.6", "num_updates": "40200", "lr": "0.0031544", "gnorm": "0.246", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2248"}
2023-12-13 18:34:30 | INFO | train_inner | {"epoch": 37, "update": 36.573, "loss": "4.074", "nll_loss": "2.631", "ppl": "6.19", "wps": "68254.3", "ups": "19.11", "wpb": "3571.5", "bsz": "142.4", "num_updates": "40300", "lr": "0.00315049", "gnorm": "0.244", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2254"}
2023-12-13 18:34:35 | INFO | train_inner | {"epoch": 37, "update": 36.663, "loss": "4.096", "nll_loss": "2.655", "ppl": "6.3", "wps": "64259.4", "ups": "18.16", "wpb": "3537.9", "bsz": "136.2", "num_updates": "40400", "lr": "0.00314658", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2259"}
2023-12-13 18:34:41 | INFO | train_inner | {"epoch": 37, "update": 36.754, "loss": "4.119", "nll_loss": "2.681", "ppl": "6.41", "wps": "65934.9", "ups": "18.42", "wpb": "3580.2", "bsz": "127.2", "num_updates": "40500", "lr": "0.0031427", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2265"}
2023-12-13 18:34:46 | INFO | train_inner | {"epoch": 37, "update": 36.845, "loss": "4.045", "nll_loss": "2.598", "ppl": "6.05", "wps": "69998.7", "ups": "19.24", "wpb": "3637.5", "bsz": "148.3", "num_updates": "40600", "lr": "0.00313882", "gnorm": "0.236", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2270"}
2023-12-13 18:34:51 | INFO | train_inner | {"epoch": 37, "update": 36.936, "loss": "4.097", "nll_loss": "2.656", "ppl": "6.3", "wps": "67520.3", "ups": "18.52", "wpb": "3646", "bsz": "137.2", "num_updates": "40700", "lr": "0.00313497", "gnorm": "0.246", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2275"}
2023-12-13 18:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:34:56 | INFO | valid | {"epoch": 37, "valid_loss": "4.438", "valid_nll_loss": "3.061", "valid_ppl": "8.34", "valid_wps": "131850", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "40771", "valid_best_loss": "4.412"}
2023-12-13 18:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 40771 updates
2023-12-13 18:34:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint37.pt
2023-12-13 18:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint37.pt
2023-12-13 18:34:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint37.pt (epoch 37 @ 40771 updates, score 4.438) (writing took 1.7459248136729002 seconds)
2023-12-13 18:34:58 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-12-13 18:34:58 | INFO | train | {"epoch": 37, "train_loss": "4.033", "train_nll_loss": "2.582", "train_ppl": "5.99", "train_wps": "64708.4", "train_ups": "18.06", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "40771", "train_lr": "0.00313223", "train_gnorm": "0.245", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2282"}
2023-12-13 18:34:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:34:58 | INFO | fairseq.trainer | begin training epoch 38
2023-12-13 18:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:34:59 | INFO | train_inner | {"epoch": 38, "update": 37.026, "loss": "4.027", "nll_loss": "2.577", "ppl": "5.97", "wps": "45379.5", "ups": "12.51", "wpb": "3628.1", "bsz": "147.8", "num_updates": "40800", "lr": "0.00313112", "gnorm": "0.235", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2283"}
2023-12-13 18:35:04 | INFO | train_inner | {"epoch": 38, "update": 37.117, "loss": "3.916", "nll_loss": "2.445", "ppl": "5.45", "wps": "71782.7", "ups": "20", "wpb": "3588.3", "bsz": "149.7", "num_updates": "40900", "lr": "0.00312729", "gnorm": "0.231", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2288"}
2023-12-13 18:35:10 | INFO | train_inner | {"epoch": 38, "update": 37.208, "loss": "3.958", "nll_loss": "2.495", "ppl": "5.64", "wps": "70311.9", "ups": "19.47", "wpb": "3611.4", "bsz": "152.6", "num_updates": "41000", "lr": "0.00312348", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2293"}
2023-12-13 18:35:15 | INFO | train_inner | {"epoch": 38, "update": 37.299, "loss": "3.989", "nll_loss": "2.528", "ppl": "5.77", "wps": "64063.3", "ups": "18.11", "wpb": "3536.7", "bsz": "134.8", "num_updates": "41100", "lr": "0.00311967", "gnorm": "0.248", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2299"}
2023-12-13 18:35:20 | INFO | train_inner | {"epoch": 38, "update": 37.389, "loss": "4.008", "nll_loss": "2.555", "ppl": "5.87", "wps": "72222.3", "ups": "19.82", "wpb": "3643.8", "bsz": "152.6", "num_updates": "41200", "lr": "0.00311588", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2304"}
2023-12-13 18:35:25 | INFO | train_inner | {"epoch": 38, "update": 37.48, "loss": "4.005", "nll_loss": "2.549", "ppl": "5.85", "wps": "72602.6", "ups": "20.12", "wpb": "3608.9", "bsz": "145.2", "num_updates": "41300", "lr": "0.00311211", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2309"}
2023-12-13 18:35:31 | INFO | train_inner | {"epoch": 38, "update": 37.571, "loss": "4.076", "nll_loss": "2.63", "ppl": "6.19", "wps": "63550.1", "ups": "17.99", "wpb": "3531.8", "bsz": "137.1", "num_updates": "41400", "lr": "0.00310835", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2314"}
2023-12-13 18:35:36 | INFO | train_inner | {"epoch": 38, "update": 37.662, "loss": "4.079", "nll_loss": "2.636", "ppl": "6.21", "wps": "65299.5", "ups": "18.38", "wpb": "3553.3", "bsz": "138.3", "num_updates": "41500", "lr": "0.0031046", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2320"}
2023-12-13 18:35:41 | INFO | train_inner | {"epoch": 38, "update": 37.752, "loss": "4.053", "nll_loss": "2.606", "ppl": "6.09", "wps": "65213.7", "ups": "18.48", "wpb": "3528.2", "bsz": "146.3", "num_updates": "41600", "lr": "0.00310087", "gnorm": "0.255", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2325"}
2023-12-13 18:35:47 | INFO | train_inner | {"epoch": 38, "update": 37.843, "loss": "4.06", "nll_loss": "2.615", "ppl": "6.12", "wps": "69469", "ups": "19.27", "wpb": "3604.2", "bsz": "141.1", "num_updates": "41700", "lr": "0.00309715", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2330"}
2023-12-13 18:35:52 | INFO | train_inner | {"epoch": 38, "update": 37.934, "loss": "4.06", "nll_loss": "2.615", "ppl": "6.13", "wps": "72429.3", "ups": "19.96", "wpb": "3628.7", "bsz": "153.5", "num_updates": "41800", "lr": "0.00309344", "gnorm": "0.249", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2335"}
2023-12-13 18:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:35:57 | INFO | valid | {"epoch": 38, "valid_loss": "4.419", "valid_nll_loss": "3.05", "valid_ppl": "8.28", "valid_wps": "130884", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "41873", "valid_best_loss": "4.412"}
2023-12-13 18:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 41873 updates
2023-12-13 18:35:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint38.pt
2023-12-13 18:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint38.pt
2023-12-13 18:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint38.pt (epoch 38 @ 41873 updates, score 4.419) (writing took 1.9668590724468231 seconds)
2023-12-13 18:35:59 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-12-13 18:35:59 | INFO | train | {"epoch": 38, "train_loss": "4.021", "train_nll_loss": "2.568", "train_ppl": "5.93", "train_wps": "64712.5", "train_ups": "18.06", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "41873", "train_lr": "0.00309074", "train_gnorm": "0.247", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "2343"}
2023-12-13 18:35:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:35:59 | INFO | fairseq.trainer | begin training epoch 39
2023-12-13 18:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:36:00 | INFO | train_inner | {"epoch": 39, "update": 38.025, "loss": "4.046", "nll_loss": "2.599", "ppl": "6.06", "wps": "41114.6", "ups": "11.49", "wpb": "3579.7", "bsz": "151.4", "num_updates": "41900", "lr": "0.00308975", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2344"}
2023-12-13 18:36:06 | INFO | train_inner | {"epoch": 39, "update": 38.115, "loss": "3.903", "nll_loss": "2.43", "ppl": "5.39", "wps": "65815.8", "ups": "18.58", "wpb": "3541.7", "bsz": "147.2", "num_updates": "42000", "lr": "0.00308607", "gnorm": "0.237", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2350"}
2023-12-13 18:36:10 | INFO | train_inner | {"epoch": 39, "update": 38.206, "loss": "3.911", "nll_loss": "2.441", "ppl": "5.43", "wps": "77894.7", "ups": "21.88", "wpb": "3559.5", "bsz": "161.4", "num_updates": "42100", "lr": "0.0030824", "gnorm": "0.234", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "2354"}
2023-12-13 18:36:16 | INFO | train_inner | {"epoch": 39, "update": 38.297, "loss": "4", "nll_loss": "2.542", "ppl": "5.82", "wps": "66437.5", "ups": "18.54", "wpb": "3583.4", "bsz": "131.7", "num_updates": "42200", "lr": "0.00307875", "gnorm": "0.246", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2359"}
2023-12-13 18:36:21 | INFO | train_inner | {"epoch": 39, "update": 38.387, "loss": "4.027", "nll_loss": "2.574", "ppl": "5.95", "wps": "62955.5", "ups": "17.62", "wpb": "3572", "bsz": "139.4", "num_updates": "42300", "lr": "0.0030751", "gnorm": "0.259", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2365"}
2023-12-13 18:36:26 | INFO | train_inner | {"epoch": 39, "update": 38.478, "loss": "3.972", "nll_loss": "2.512", "ppl": "5.7", "wps": "73644.4", "ups": "20.23", "wpb": "3640.2", "bsz": "156", "num_updates": "42400", "lr": "0.00307148", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2370"}
2023-12-13 18:36:31 | INFO | train_inner | {"epoch": 39, "update": 38.569, "loss": "3.963", "nll_loss": "2.504", "ppl": "5.67", "wps": "71883.9", "ups": "19.73", "wpb": "3642.9", "bsz": "161.3", "num_updates": "42500", "lr": "0.00306786", "gnorm": "0.239", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2375"}
2023-12-13 18:36:37 | INFO | train_inner | {"epoch": 39, "update": 38.66, "loss": "4.09", "nll_loss": "2.647", "ppl": "6.27", "wps": "62144.9", "ups": "17.37", "wpb": "3578.7", "bsz": "130.5", "num_updates": "42600", "lr": "0.00306426", "gnorm": "0.268", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2381"}
2023-12-13 18:36:43 | INFO | train_inner | {"epoch": 39, "update": 38.75, "loss": "4.068", "nll_loss": "2.624", "ppl": "6.16", "wps": "61699.2", "ups": "17.59", "wpb": "3507.7", "bsz": "142.2", "num_updates": "42700", "lr": "0.00306067", "gnorm": "0.252", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2387"}
2023-12-13 18:36:48 | INFO | train_inner | {"epoch": 39, "update": 38.841, "loss": "4.065", "nll_loss": "2.62", "ppl": "6.15", "wps": "65227.5", "ups": "18.08", "wpb": "3607.9", "bsz": "140.9", "num_updates": "42800", "lr": "0.00305709", "gnorm": "0.247", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2392"}
2023-12-13 18:36:53 | INFO | train_inner | {"epoch": 39, "update": 38.932, "loss": "4.091", "nll_loss": "2.652", "ppl": "6.29", "wps": "69857.2", "ups": "19.63", "wpb": "3558.8", "bsz": "142.7", "num_updates": "42900", "lr": "0.00305352", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2397"}
2023-12-13 18:36:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:36:59 | INFO | valid | {"epoch": 39, "valid_loss": "4.441", "valid_nll_loss": "3.07", "valid_ppl": "8.4", "valid_wps": "133016", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "42975", "valid_best_loss": "4.412"}
2023-12-13 18:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 42975 updates
2023-12-13 18:36:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint39.pt
2023-12-13 18:37:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint39.pt
2023-12-13 18:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint39.pt (epoch 39 @ 42975 updates, score 4.441) (writing took 1.7591221779584885 seconds)
2023-12-13 18:37:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-12-13 18:37:01 | INFO | train | {"epoch": 39, "train_loss": "4.012", "train_nll_loss": "2.558", "train_ppl": "5.89", "train_wps": "63965.2", "train_ups": "17.85", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "42975", "train_lr": "0.00305086", "train_gnorm": "0.247", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2404"}
2023-12-13 18:37:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:37:01 | INFO | fairseq.trainer | begin training epoch 40
2023-12-13 18:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:37:02 | INFO | train_inner | {"epoch": 40, "update": 39.023, "loss": "4.029", "nll_loss": "2.578", "ppl": "5.97", "wps": "42533.2", "ups": "11.83", "wpb": "3594.7", "bsz": "149.8", "num_updates": "43000", "lr": "0.00304997", "gnorm": "0.254", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2406"}
2023-12-13 18:37:07 | INFO | train_inner | {"epoch": 40, "update": 39.113, "loss": "3.937", "nll_loss": "2.468", "ppl": "5.53", "wps": "69339.7", "ups": "19.12", "wpb": "3627.1", "bsz": "137.1", "num_updates": "43100", "lr": "0.00304643", "gnorm": "0.242", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2411"}
2023-12-13 18:37:12 | INFO | train_inner | {"epoch": 40, "update": 39.204, "loss": "3.953", "nll_loss": "2.488", "ppl": "5.61", "wps": "69811.1", "ups": "19.47", "wpb": "3585.4", "bsz": "139.1", "num_updates": "43200", "lr": "0.0030429", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2416"}
2023-12-13 18:37:18 | INFO | train_inner | {"epoch": 40, "update": 39.295, "loss": "4.044", "nll_loss": "2.592", "ppl": "6.03", "wps": "64964", "ups": "18.31", "wpb": "3547.7", "bsz": "127.6", "num_updates": "43300", "lr": "0.00303939", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2422"}
2023-12-13 18:37:23 | INFO | train_inner | {"epoch": 40, "update": 39.386, "loss": "3.973", "nll_loss": "2.515", "ppl": "5.72", "wps": "67303.6", "ups": "18.72", "wpb": "3596.1", "bsz": "159.3", "num_updates": "43400", "lr": "0.00303588", "gnorm": "0.243", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2427"}
2023-12-13 18:37:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-13 18:37:28 | INFO | train_inner | {"epoch": 40, "update": 39.477, "loss": "4.04", "nll_loss": "2.59", "ppl": "6.02", "wps": "71331.4", "ups": "19.54", "wpb": "3650.2", "bsz": "141.3", "num_updates": "43500", "lr": "0.00303239", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2432"}
2023-12-13 18:37:34 | INFO | train_inner | {"epoch": 40, "update": 39.568, "loss": "4.002", "nll_loss": "2.546", "ppl": "5.84", "wps": "66955.8", "ups": "18.64", "wpb": "3592.2", "bsz": "146.6", "num_updates": "43600", "lr": "0.00302891", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2437"}
2023-12-13 18:37:39 | INFO | train_inner | {"epoch": 40, "update": 39.659, "loss": "4.049", "nll_loss": "2.601", "ppl": "6.07", "wps": "64360.4", "ups": "18.46", "wpb": "3486", "bsz": "142.5", "num_updates": "43700", "lr": "0.00302545", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2443"}
2023-12-13 18:37:44 | INFO | train_inner | {"epoch": 40, "update": 39.75, "loss": "4.023", "nll_loss": "2.572", "ppl": "5.95", "wps": "72816.6", "ups": "20.04", "wpb": "3633.8", "bsz": "154.2", "num_updates": "43800", "lr": "0.00302199", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2448"}
2023-12-13 18:37:49 | INFO | train_inner | {"epoch": 40, "update": 39.84, "loss": "3.967", "nll_loss": "2.508", "ppl": "5.69", "wps": "68510.8", "ups": "19.45", "wpb": "3521.7", "bsz": "157.6", "num_updates": "43900", "lr": "0.00301855", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2453"}
2023-12-13 18:37:55 | INFO | train_inner | {"epoch": 40, "update": 39.931, "loss": "4.091", "nll_loss": "2.651", "ppl": "6.28", "wps": "64500.8", "ups": "17.94", "wpb": "3594.4", "bsz": "132.6", "num_updates": "44000", "lr": "0.00301511", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2458"}
2023-12-13 18:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:38:00 | INFO | valid | {"epoch": 40, "valid_loss": "4.44", "valid_nll_loss": "3.053", "valid_ppl": "8.3", "valid_wps": "127738", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "44076", "valid_best_loss": "4.412"}
2023-12-13 18:38:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 44076 updates
2023-12-13 18:38:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint40.pt
2023-12-13 18:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint40.pt
2023-12-13 18:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint40.pt (epoch 40 @ 44076 updates, score 4.44) (writing took 1.7849166449159384 seconds)
2023-12-13 18:38:01 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-12-13 18:38:01 | INFO | train | {"epoch": 40, "train_loss": "4.004", "train_nll_loss": "2.549", "train_ppl": "5.85", "train_wps": "65002.3", "train_ups": "18.13", "train_wpb": "3584.6", "train_bsz": "145.5", "train_num_updates": "44076", "train_lr": "0.00301251", "train_gnorm": "0.25", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "2465"}
2023-12-13 18:38:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:38:01 | INFO | fairseq.trainer | begin training epoch 41
2023-12-13 18:38:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:38:02 | INFO | train_inner | {"epoch": 41, "update": 40.022, "loss": "3.982", "nll_loss": "2.525", "ppl": "5.76", "wps": "46557.1", "ups": "12.92", "wpb": "3603.1", "bsz": "158.6", "num_updates": "44100", "lr": "0.00301169", "gnorm": "0.24", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "2466"}
2023-12-13 18:38:08 | INFO | train_inner | {"epoch": 41, "update": 40.113, "loss": "3.896", "nll_loss": "2.422", "ppl": "5.36", "wps": "64307.9", "ups": "17.76", "wpb": "3621.2", "bsz": "140.2", "num_updates": "44200", "lr": "0.00300828", "gnorm": "0.234", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2472"}
2023-12-13 18:38:13 | INFO | train_inner | {"epoch": 41, "update": 40.203, "loss": "3.941", "nll_loss": "2.478", "ppl": "5.57", "wps": "69236.4", "ups": "19.37", "wpb": "3574.4", "bsz": "162", "num_updates": "44300", "lr": "0.00300489", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2477"}
2023-12-13 18:38:18 | INFO | train_inner | {"epoch": 41, "update": 40.294, "loss": "3.944", "nll_loss": "2.478", "ppl": "5.57", "wps": "68023", "ups": "19.08", "wpb": "3566", "bsz": "146.2", "num_updates": "44400", "lr": "0.0030015", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2482"}
2023-12-13 18:38:24 | INFO | train_inner | {"epoch": 41, "update": 40.385, "loss": "3.971", "nll_loss": "2.509", "ppl": "5.69", "wps": "70048.2", "ups": "19.23", "wpb": "3642.2", "bsz": "143.4", "num_updates": "44500", "lr": "0.00299813", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2487"}
2023-12-13 18:38:29 | INFO | train_inner | {"epoch": 41, "update": 40.475, "loss": "3.998", "nll_loss": "2.541", "ppl": "5.82", "wps": "67824.3", "ups": "19.15", "wpb": "3540.9", "bsz": "143.4", "num_updates": "44600", "lr": "0.00299476", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2493"}
2023-12-13 18:38:34 | INFO | train_inner | {"epoch": 41, "update": 40.566, "loss": "4.034", "nll_loss": "2.585", "ppl": "6", "wps": "71400.3", "ups": "19.85", "wpb": "3597.9", "bsz": "142.9", "num_updates": "44700", "lr": "0.00299141", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2498"}
2023-12-13 18:38:39 | INFO | train_inner | {"epoch": 41, "update": 40.657, "loss": "4.033", "nll_loss": "2.583", "ppl": "5.99", "wps": "68820.2", "ups": "19.33", "wpb": "3560.6", "bsz": "140.2", "num_updates": "44800", "lr": "0.00298807", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2503"}
2023-12-13 18:38:44 | INFO | train_inner | {"epoch": 41, "update": 40.748, "loss": "4.007", "nll_loss": "2.554", "ppl": "5.87", "wps": "68271.1", "ups": "18.81", "wpb": "3629.6", "bsz": "152.2", "num_updates": "44900", "lr": "0.00298474", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2508"}
2023-12-13 18:38:50 | INFO | train_inner | {"epoch": 41, "update": 40.838, "loss": "4.051", "nll_loss": "2.604", "ppl": "6.08", "wps": "66336.9", "ups": "18.46", "wpb": "3593.5", "bsz": "140.2", "num_updates": "45000", "lr": "0.00298142", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2514"}
2023-12-13 18:38:55 | INFO | train_inner | {"epoch": 41, "update": 40.929, "loss": "4.06", "nll_loss": "2.616", "ppl": "6.13", "wps": "68124.9", "ups": "19.38", "wpb": "3515.1", "bsz": "141.5", "num_updates": "45100", "lr": "0.00297812", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2519"}
2023-12-13 18:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:39:01 | INFO | valid | {"epoch": 41, "valid_loss": "4.432", "valid_nll_loss": "3.048", "valid_ppl": "8.27", "valid_wps": "129737", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "45178", "valid_best_loss": "4.412"}
2023-12-13 18:39:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 45178 updates
2023-12-13 18:39:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint41.pt
2023-12-13 18:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint41.pt
2023-12-13 18:39:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint41.pt (epoch 41 @ 45178 updates, score 4.432) (writing took 1.8168572653084993 seconds)
2023-12-13 18:39:02 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-12-13 18:39:02 | INFO | train | {"epoch": 41, "train_loss": "3.994", "train_nll_loss": "2.538", "train_ppl": "5.81", "train_wps": "64749", "train_ups": "18.07", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "45178", "train_lr": "0.00297554", "train_gnorm": "0.247", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2526"}
2023-12-13 18:39:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:39:02 | INFO | fairseq.trainer | begin training epoch 42
2023-12-13 18:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:39:04 | INFO | train_inner | {"epoch": 42, "update": 41.02, "loss": "4.009", "nll_loss": "2.555", "ppl": "5.88", "wps": "41313.5", "ups": "11.52", "wpb": "3587.6", "bsz": "138.6", "num_updates": "45200", "lr": "0.00297482", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2527"}
2023-12-13 18:39:08 | INFO | train_inner | {"epoch": 42, "update": 41.111, "loss": "3.884", "nll_loss": "2.41", "ppl": "5.31", "wps": "74959.1", "ups": "21.05", "wpb": "3561.1", "bsz": "153.4", "num_updates": "45300", "lr": "0.00297154", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2532"}
2023-12-13 18:39:13 | INFO | train_inner | {"epoch": 42, "update": 41.201, "loss": "3.856", "nll_loss": "2.378", "ppl": "5.2", "wps": "73449.2", "ups": "20.39", "wpb": "3602", "bsz": "170.3", "num_updates": "45400", "lr": "0.00296826", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2537"}
2023-12-13 18:39:19 | INFO | train_inner | {"epoch": 42, "update": 41.292, "loss": "3.976", "nll_loss": "2.514", "ppl": "5.71", "wps": "65875.4", "ups": "18.4", "wpb": "3581", "bsz": "129.5", "num_updates": "45500", "lr": "0.002965", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2543"}
2023-12-13 18:39:24 | INFO | train_inner | {"epoch": 42, "update": 41.383, "loss": "4.011", "nll_loss": "2.555", "ppl": "5.88", "wps": "65401.6", "ups": "18.19", "wpb": "3595.9", "bsz": "134.2", "num_updates": "45600", "lr": "0.00296174", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2548"}
2023-12-13 18:39:30 | INFO | train_inner | {"epoch": 42, "update": 41.474, "loss": "3.991", "nll_loss": "2.535", "ppl": "5.8", "wps": "68296.9", "ups": "18.81", "wpb": "3630", "bsz": "150.3", "num_updates": "45700", "lr": "0.0029585", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2553"}
2023-12-13 18:39:35 | INFO | train_inner | {"epoch": 42, "update": 41.564, "loss": "4.021", "nll_loss": "2.567", "ppl": "5.92", "wps": "65098.6", "ups": "18.4", "wpb": "3538.5", "bsz": "133.9", "num_updates": "45800", "lr": "0.00295527", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2559"}
2023-12-13 18:39:40 | INFO | train_inner | {"epoch": 42, "update": 41.655, "loss": "3.964", "nll_loss": "2.504", "ppl": "5.67", "wps": "71541.5", "ups": "19.91", "wpb": "3593.9", "bsz": "156.2", "num_updates": "45900", "lr": "0.00295205", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2564"}
2023-12-13 18:39:46 | INFO | train_inner | {"epoch": 42, "update": 41.746, "loss": "4.048", "nll_loss": "2.601", "ppl": "6.07", "wps": "63133.2", "ups": "17.93", "wpb": "3520.2", "bsz": "139.8", "num_updates": "46000", "lr": "0.00294884", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2569"}
2023-12-13 18:39:51 | INFO | train_inner | {"epoch": 42, "update": 41.837, "loss": "4.011", "nll_loss": "2.56", "ppl": "5.9", "wps": "63615.7", "ups": "18", "wpb": "3533.7", "bsz": "160.6", "num_updates": "46100", "lr": "0.00294564", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2575"}
2023-12-13 18:39:56 | INFO | train_inner | {"epoch": 42, "update": 41.927, "loss": "4.054", "nll_loss": "2.607", "ppl": "6.09", "wps": "72571.9", "ups": "20.18", "wpb": "3596.4", "bsz": "136.9", "num_updates": "46200", "lr": "0.00294245", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2580"}
2023-12-13 18:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:40:02 | INFO | valid | {"epoch": 42, "valid_loss": "4.429", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "131128", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "46280", "valid_best_loss": "4.412"}
2023-12-13 18:40:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 46280 updates
2023-12-13 18:40:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint42.pt
2023-12-13 18:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint42.pt
2023-12-13 18:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint42.pt (epoch 42 @ 46280 updates, score 4.429) (writing took 1.7716573309153318 seconds)
2023-12-13 18:40:03 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-12-13 18:40:03 | INFO | train | {"epoch": 42, "train_loss": "3.984", "train_nll_loss": "2.526", "train_ppl": "5.76", "train_wps": "64626.5", "train_ups": "18.03", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "46280", "train_lr": "0.00293991", "train_gnorm": "0.247", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2587"}
2023-12-13 18:40:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:40:03 | INFO | fairseq.trainer | begin training epoch 43
2023-12-13 18:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:40:05 | INFO | train_inner | {"epoch": 43, "update": 42.018, "loss": "4.002", "nll_loss": "2.548", "ppl": "5.85", "wps": "44153.9", "ups": "11.96", "wpb": "3691.6", "bsz": "140.3", "num_updates": "46300", "lr": "0.00293927", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2588"}
2023-12-13 18:40:10 | INFO | train_inner | {"epoch": 43, "update": 42.109, "loss": "3.844", "nll_loss": "2.363", "ppl": "5.14", "wps": "71135.1", "ups": "19.8", "wpb": "3592.7", "bsz": "157.5", "num_updates": "46400", "lr": "0.0029361", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2593"}
2023-12-13 18:40:15 | INFO | train_inner | {"epoch": 43, "update": 42.2, "loss": "3.958", "nll_loss": "2.496", "ppl": "5.64", "wps": "70334.2", "ups": "19.45", "wpb": "3616.6", "bsz": "147.6", "num_updates": "46500", "lr": "0.00293294", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2598"}
2023-12-13 18:40:20 | INFO | train_inner | {"epoch": 43, "update": 42.29, "loss": "3.938", "nll_loss": "2.472", "ppl": "5.55", "wps": "64973.5", "ups": "18.54", "wpb": "3505.4", "bsz": "151.9", "num_updates": "46600", "lr": "0.00292979", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2604"}
2023-12-13 18:40:25 | INFO | train_inner | {"epoch": 43, "update": 42.381, "loss": "3.973", "nll_loss": "2.511", "ppl": "5.7", "wps": "66382", "ups": "18.75", "wpb": "3539.9", "bsz": "137.4", "num_updates": "46700", "lr": "0.00292666", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2609"}
2023-12-13 18:40:30 | INFO | train_inner | {"epoch": 43, "update": 42.472, "loss": "3.966", "nll_loss": "2.504", "ppl": "5.67", "wps": "73822.9", "ups": "20.36", "wpb": "3626", "bsz": "146.9", "num_updates": "46800", "lr": "0.00292353", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2614"}
2023-12-13 18:40:36 | INFO | train_inner | {"epoch": 43, "update": 42.563, "loss": "4.029", "nll_loss": "2.578", "ppl": "5.97", "wps": "62203.7", "ups": "17.27", "wpb": "3601", "bsz": "140.5", "num_updates": "46900", "lr": "0.00292041", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2620"}
2023-12-13 18:40:41 | INFO | train_inner | {"epoch": 43, "update": 42.653, "loss": "3.958", "nll_loss": "2.5", "ppl": "5.66", "wps": "77016.7", "ups": "21.28", "wpb": "3619.2", "bsz": "162.1", "num_updates": "47000", "lr": "0.0029173", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2625"}
2023-12-13 18:40:46 | INFO | train_inner | {"epoch": 43, "update": 42.744, "loss": "4.087", "nll_loss": "2.645", "ppl": "6.25", "wps": "65794.1", "ups": "18.58", "wpb": "3540.2", "bsz": "127.7", "num_updates": "47100", "lr": "0.0029142", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2630"}
2023-12-13 18:40:52 | INFO | train_inner | {"epoch": 43, "update": 42.835, "loss": "4.024", "nll_loss": "2.571", "ppl": "5.94", "wps": "64633.2", "ups": "18.09", "wpb": "3572.9", "bsz": "136.6", "num_updates": "47200", "lr": "0.00291111", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2636"}
2023-12-13 18:40:57 | INFO | train_inner | {"epoch": 43, "update": 42.926, "loss": "4.043", "nll_loss": "2.594", "ppl": "6.04", "wps": "63534.7", "ups": "17.79", "wpb": "3571", "bsz": "130.3", "num_updates": "47300", "lr": "0.00290803", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2641"}
2023-12-13 18:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:41:03 | INFO | valid | {"epoch": 43, "valid_loss": "4.435", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "133569", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "47382", "valid_best_loss": "4.412"}
2023-12-13 18:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 47382 updates
2023-12-13 18:41:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint43.pt
2023-12-13 18:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint43.pt
2023-12-13 18:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint43.pt (epoch 43 @ 47382 updates, score 4.435) (writing took 1.7554456684738398 seconds)
2023-12-13 18:41:04 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-12-13 18:41:04 | INFO | train | {"epoch": 43, "train_loss": "3.978", "train_nll_loss": "2.519", "train_ppl": "5.73", "train_wps": "64688.2", "train_ups": "18.05", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "47382", "train_lr": "0.00290552", "train_gnorm": "0.249", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "2648"}
2023-12-13 18:41:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:41:05 | INFO | fairseq.trainer | begin training epoch 44
2023-12-13 18:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:41:06 | INFO | train_inner | {"epoch": 44, "update": 43.016, "loss": "3.96", "nll_loss": "2.501", "ppl": "5.66", "wps": "43827.1", "ups": "12.16", "wpb": "3605", "bsz": "152.6", "num_updates": "47400", "lr": "0.00290496", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2649"}
2023-12-13 18:41:10 | INFO | train_inner | {"epoch": 44, "update": 43.107, "loss": "3.883", "nll_loss": "2.411", "ppl": "5.32", "wps": "72963", "ups": "20.66", "wpb": "3531.8", "bsz": "154.3", "num_updates": "47500", "lr": "0.00290191", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2654"}
2023-12-13 18:41:15 | INFO | train_inner | {"epoch": 44, "update": 43.198, "loss": "3.908", "nll_loss": "2.436", "ppl": "5.41", "wps": "71163.3", "ups": "19.98", "wpb": "3561.6", "bsz": "148.2", "num_updates": "47600", "lr": "0.00289886", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2659"}
2023-12-13 18:41:20 | INFO | train_inner | {"epoch": 44, "update": 43.289, "loss": "3.917", "nll_loss": "2.448", "ppl": "5.46", "wps": "72177.2", "ups": "20.32", "wpb": "3552.5", "bsz": "153.8", "num_updates": "47700", "lr": "0.00289581", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2664"}
2023-12-13 18:41:26 | INFO | train_inner | {"epoch": 44, "update": 43.379, "loss": "3.953", "nll_loss": "2.49", "ppl": "5.62", "wps": "66822.8", "ups": "18.62", "wpb": "3589.1", "bsz": "155.3", "num_updates": "47800", "lr": "0.00289278", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2669"}
2023-12-13 18:41:31 | INFO | train_inner | {"epoch": 44, "update": 43.47, "loss": "3.956", "nll_loss": "2.494", "ppl": "5.63", "wps": "71805.5", "ups": "19.78", "wpb": "3629.4", "bsz": "145.8", "num_updates": "47900", "lr": "0.00288976", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2675"}
2023-12-13 18:41:37 | INFO | train_inner | {"epoch": 44, "update": 43.561, "loss": "4", "nll_loss": "2.544", "ppl": "5.83", "wps": "61053.5", "ups": "17.06", "wpb": "3579.5", "bsz": "132.6", "num_updates": "48000", "lr": "0.00288675", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2680"}
2023-12-13 18:41:42 | INFO | train_inner | {"epoch": 44, "update": 43.652, "loss": "3.963", "nll_loss": "2.503", "ppl": "5.67", "wps": "66196", "ups": "18.58", "wpb": "3563.3", "bsz": "148.3", "num_updates": "48100", "lr": "0.00288375", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2686"}
2023-12-13 18:41:47 | INFO | train_inner | {"epoch": 44, "update": 43.742, "loss": "4.006", "nll_loss": "2.552", "ppl": "5.87", "wps": "70854.8", "ups": "19.63", "wpb": "3608.7", "bsz": "146.4", "num_updates": "48200", "lr": "0.00288076", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2691"}
2023-12-13 18:41:52 | INFO | train_inner | {"epoch": 44, "update": 43.833, "loss": "4.019", "nll_loss": "2.568", "ppl": "5.93", "wps": "67845.9", "ups": "18.75", "wpb": "3617.9", "bsz": "145.2", "num_updates": "48300", "lr": "0.00287777", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2696"}
2023-12-13 18:41:58 | INFO | train_inner | {"epoch": 44, "update": 43.924, "loss": "4.055", "nll_loss": "2.609", "ppl": "6.1", "wps": "61784.4", "ups": "17.3", "wpb": "3571.2", "bsz": "134.7", "num_updates": "48400", "lr": "0.0028748", "gnorm": "0.256", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2702"}
2023-12-13 18:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:42:04 | INFO | valid | {"epoch": 44, "valid_loss": "4.422", "valid_nll_loss": "3.045", "valid_ppl": "8.25", "valid_wps": "134763", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "48484", "valid_best_loss": "4.412"}
2023-12-13 18:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 48484 updates
2023-12-13 18:42:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint44.pt
2023-12-13 18:42:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint44.pt
2023-12-13 18:42:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint44.pt (epoch 44 @ 48484 updates, score 4.422) (writing took 1.6524212453514338 seconds)
2023-12-13 18:42:05 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-12-13 18:42:05 | INFO | train | {"epoch": 44, "train_loss": "3.968", "train_nll_loss": "2.508", "train_ppl": "5.69", "train_wps": "65042.7", "train_ups": "18.15", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "48484", "train_lr": "0.00287231", "train_gnorm": "0.248", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2709"}
2023-12-13 18:42:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:42:05 | INFO | fairseq.trainer | begin training epoch 45
2023-12-13 18:42:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:42:06 | INFO | train_inner | {"epoch": 45, "update": 44.015, "loss": "3.952", "nll_loss": "2.492", "ppl": "5.63", "wps": "47259.8", "ups": "13.03", "wpb": "3626.4", "bsz": "152.4", "num_updates": "48500", "lr": "0.00287183", "gnorm": "0.236", "loss_scale": "32", "train_wall": "4", "gb_free": "39", "wall": "2710"}
2023-12-13 18:42:11 | INFO | train_inner | {"epoch": 45, "update": 44.105, "loss": "3.886", "nll_loss": "2.41", "ppl": "5.31", "wps": "65071.6", "ups": "18.18", "wpb": "3579.4", "bsz": "144.2", "num_updates": "48600", "lr": "0.00286888", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2715"}
2023-12-13 18:42:16 | INFO | train_inner | {"epoch": 45, "update": 44.196, "loss": "3.862", "nll_loss": "2.385", "ppl": "5.23", "wps": "76376.6", "ups": "21.07", "wpb": "3625", "bsz": "166.2", "num_updates": "48700", "lr": "0.00286593", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2720"}
2023-12-13 18:42:21 | INFO | train_inner | {"epoch": 45, "update": 44.287, "loss": "3.918", "nll_loss": "2.448", "ppl": "5.46", "wps": "70157.6", "ups": "19.58", "wpb": "3583.5", "bsz": "138.2", "num_updates": "48800", "lr": "0.00286299", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2725"}
2023-12-13 18:42:27 | INFO | train_inner | {"epoch": 45, "update": 44.377, "loss": "3.96", "nll_loss": "2.498", "ppl": "5.65", "wps": "68092.9", "ups": "18.86", "wpb": "3610.4", "bsz": "140.3", "num_updates": "48900", "lr": "0.00286006", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2730"}
2023-12-13 18:42:32 | INFO | train_inner | {"epoch": 45, "update": 44.468, "loss": "4.008", "nll_loss": "2.554", "ppl": "5.87", "wps": "67792.4", "ups": "18.87", "wpb": "3592.8", "bsz": "139.8", "num_updates": "49000", "lr": "0.00285714", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2736"}
2023-12-13 18:42:37 | INFO | train_inner | {"epoch": 45, "update": 44.559, "loss": "3.941", "nll_loss": "2.477", "ppl": "5.57", "wps": "68086.3", "ups": "19.13", "wpb": "3558.6", "bsz": "146.4", "num_updates": "49100", "lr": "0.00285423", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2741"}
2023-12-13 18:42:42 | INFO | train_inner | {"epoch": 45, "update": 44.65, "loss": "3.962", "nll_loss": "2.502", "ppl": "5.67", "wps": "71376", "ups": "20.22", "wpb": "3529.2", "bsz": "154.2", "num_updates": "49200", "lr": "0.00285133", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2746"}
2023-12-13 18:42:47 | INFO | train_inner | {"epoch": 45, "update": 44.74, "loss": "4.007", "nll_loss": "2.555", "ppl": "5.88", "wps": "65314.4", "ups": "18.45", "wpb": "3540.1", "bsz": "137.3", "num_updates": "49300", "lr": "0.00284844", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2751"}
2023-12-13 18:42:53 | INFO | train_inner | {"epoch": 45, "update": 44.831, "loss": "4.011", "nll_loss": "2.557", "ppl": "5.89", "wps": "67876.9", "ups": "19.23", "wpb": "3529.5", "bsz": "132.7", "num_updates": "49400", "lr": "0.00284555", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2756"}
2023-12-13 18:42:58 | INFO | train_inner | {"epoch": 45, "update": 44.922, "loss": "4.022", "nll_loss": "2.572", "ppl": "5.95", "wps": "72245.3", "ups": "20.1", "wpb": "3594.3", "bsz": "143.8", "num_updates": "49500", "lr": "0.00284268", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2761"}
2023-12-13 18:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:43:03 | INFO | valid | {"epoch": 45, "valid_loss": "4.434", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "131312", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "49586", "valid_best_loss": "4.412"}
2023-12-13 18:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 49586 updates
2023-12-13 18:43:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint45.pt
2023-12-13 18:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint45.pt
2023-12-13 18:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint45.pt (epoch 45 @ 49586 updates, score 4.434) (writing took 1.8972251936793327 seconds)
2023-12-13 18:43:05 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-12-13 18:43:05 | INFO | train | {"epoch": 45, "train_loss": "3.961", "train_nll_loss": "2.499", "train_ppl": "5.65", "train_wps": "65634.5", "train_ups": "18.32", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "49586", "train_lr": "0.00284021", "train_gnorm": "0.25", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "2769"}
2023-12-13 18:43:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:43:05 | INFO | fairseq.trainer | begin training epoch 46
2023-12-13 18:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:43:06 | INFO | train_inner | {"epoch": 46, "update": 45.013, "loss": "4.018", "nll_loss": "2.568", "ppl": "5.93", "wps": "41660.3", "ups": "11.49", "wpb": "3625.2", "bsz": "141.8", "num_updates": "49600", "lr": "0.00283981", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2770"}
2023-12-13 18:43:11 | INFO | train_inner | {"epoch": 46, "update": 45.103, "loss": "3.856", "nll_loss": "2.377", "ppl": "5.19", "wps": "78558.3", "ups": "21.64", "wpb": "3631.1", "bsz": "160.5", "num_updates": "49700", "lr": "0.00283695", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2775"}
2023-12-13 18:43:16 | INFO | train_inner | {"epoch": 46, "update": 45.194, "loss": "3.884", "nll_loss": "2.407", "ppl": "5.3", "wps": "70532.7", "ups": "19.58", "wpb": "3601.8", "bsz": "135.3", "num_updates": "49800", "lr": "0.0028341", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2780"}
2023-12-13 18:43:21 | INFO | train_inner | {"epoch": 46, "update": 45.285, "loss": "3.879", "nll_loss": "2.403", "ppl": "5.29", "wps": "68107.7", "ups": "19.27", "wpb": "3534", "bsz": "147.5", "num_updates": "49900", "lr": "0.00283126", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2785"}
2023-12-13 18:43:26 | INFO | train_inner | {"epoch": 46, "update": 45.376, "loss": "3.934", "nll_loss": "2.469", "ppl": "5.54", "wps": "71786.5", "ups": "19.79", "wpb": "3626.7", "bsz": "148.2", "num_updates": "50000", "lr": "0.00282843", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2790"}
2023-12-13 18:43:31 | INFO | train_inner | {"epoch": 46, "update": 45.466, "loss": "3.926", "nll_loss": "2.46", "ppl": "5.5", "wps": "71234.2", "ups": "19.59", "wpb": "3636.7", "bsz": "156.3", "num_updates": "50100", "lr": "0.0028256", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2795"}
2023-12-13 18:43:37 | INFO | train_inner | {"epoch": 46, "update": 45.557, "loss": "3.949", "nll_loss": "2.487", "ppl": "5.61", "wps": "64398.6", "ups": "18.14", "wpb": "3549.4", "bsz": "151.8", "num_updates": "50200", "lr": "0.00282279", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2801"}
2023-12-13 18:43:42 | INFO | train_inner | {"epoch": 46, "update": 45.648, "loss": "4.024", "nll_loss": "2.571", "ppl": "5.94", "wps": "67511.2", "ups": "18.85", "wpb": "3581.7", "bsz": "125.8", "num_updates": "50300", "lr": "0.00281998", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2806"}
2023-12-13 18:43:47 | INFO | train_inner | {"epoch": 46, "update": 45.739, "loss": "3.967", "nll_loss": "2.51", "ppl": "5.7", "wps": "75858.4", "ups": "20.94", "wpb": "3622.6", "bsz": "157.5", "num_updates": "50400", "lr": "0.00281718", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2811"}
2023-12-13 18:43:53 | INFO | train_inner | {"epoch": 46, "update": 45.829, "loss": "4.023", "nll_loss": "2.572", "ppl": "5.95", "wps": "62600.8", "ups": "17.77", "wpb": "3522.9", "bsz": "138.9", "num_updates": "50500", "lr": "0.00281439", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2816"}
2023-12-13 18:43:59 | INFO | train_inner | {"epoch": 46, "update": 45.92, "loss": "4.025", "nll_loss": "2.573", "ppl": "5.95", "wps": "58432.7", "ups": "16.38", "wpb": "3568.1", "bsz": "130.2", "num_updates": "50600", "lr": "0.00281161", "gnorm": "0.257", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2823"}
2023-12-13 18:44:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:44:05 | INFO | valid | {"epoch": 46, "valid_loss": "4.429", "valid_nll_loss": "3.067", "valid_ppl": "8.38", "valid_wps": "131173", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "50688", "valid_best_loss": "4.412"}
2023-12-13 18:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 50688 updates
2023-12-13 18:44:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint46.pt
2023-12-13 18:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint46.pt
2023-12-13 18:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint46.pt (epoch 46 @ 50688 updates, score 4.429) (writing took 1.7800702396780252 seconds)
2023-12-13 18:44:07 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-12-13 18:44:07 | INFO | train | {"epoch": 46, "train_loss": "3.952", "train_nll_loss": "2.49", "train_ppl": "5.62", "train_wps": "64383.9", "train_ups": "17.97", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "50688", "train_lr": "0.00280917", "train_gnorm": "0.25", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "2830"}
2023-12-13 18:44:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:44:07 | INFO | fairseq.trainer | begin training epoch 47
2023-12-13 18:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:44:07 | INFO | train_inner | {"epoch": 47, "update": 46.011, "loss": "4", "nll_loss": "2.547", "ppl": "5.85", "wps": "42044.6", "ups": "11.7", "wpb": "3594.6", "bsz": "151.8", "num_updates": "50700", "lr": "0.00280883", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2831"}
2023-12-13 18:44:13 | INFO | train_inner | {"epoch": 47, "update": 46.102, "loss": "3.845", "nll_loss": "2.364", "ppl": "5.15", "wps": "64711.7", "ups": "18.3", "wpb": "3535.3", "bsz": "148.9", "num_updates": "50800", "lr": "0.00280607", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2837"}
2023-12-13 18:44:18 | INFO | train_inner | {"epoch": 47, "update": 46.192, "loss": "3.922", "nll_loss": "2.453", "ppl": "5.47", "wps": "69084.9", "ups": "19.11", "wpb": "3615", "bsz": "134.3", "num_updates": "50900", "lr": "0.00280331", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2842"}
2023-12-13 18:44:23 | INFO | train_inner | {"epoch": 47, "update": 46.283, "loss": "3.916", "nll_loss": "2.448", "ppl": "5.46", "wps": "73570.5", "ups": "19.96", "wpb": "3685.4", "bsz": "148.2", "num_updates": "51000", "lr": "0.00280056", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2847"}
2023-12-13 18:44:29 | INFO | train_inner | {"epoch": 47, "update": 46.374, "loss": "3.979", "nll_loss": "2.519", "ppl": "5.73", "wps": "60886.9", "ups": "17.09", "wpb": "3561.8", "bsz": "129.4", "num_updates": "51100", "lr": "0.00279782", "gnorm": "0.253", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2853"}
2023-12-13 18:44:34 | INFO | train_inner | {"epoch": 47, "update": 46.465, "loss": "3.931", "nll_loss": "2.466", "ppl": "5.52", "wps": "70405.8", "ups": "19.72", "wpb": "3569.9", "bsz": "155.4", "num_updates": "51200", "lr": "0.00279508", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2858"}
2023-12-13 18:44:40 | INFO | train_inner | {"epoch": 47, "update": 46.555, "loss": "3.972", "nll_loss": "2.511", "ppl": "5.7", "wps": "61340.4", "ups": "17.3", "wpb": "3546.2", "bsz": "139.3", "num_updates": "51300", "lr": "0.00279236", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2864"}
2023-12-13 18:44:45 | INFO | train_inner | {"epoch": 47, "update": 46.646, "loss": "3.966", "nll_loss": "2.506", "ppl": "5.68", "wps": "70258.5", "ups": "19.23", "wpb": "3653.2", "bsz": "149.6", "num_updates": "51400", "lr": "0.00278964", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2869"}
2023-12-13 18:44:50 | INFO | train_inner | {"epoch": 47, "update": 46.737, "loss": "3.907", "nll_loss": "2.44", "ppl": "5.43", "wps": "73210.2", "ups": "20.51", "wpb": "3569.1", "bsz": "160", "num_updates": "51500", "lr": "0.00278693", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2874"}
2023-12-13 18:44:55 | INFO | train_inner | {"epoch": 47, "update": 46.828, "loss": "3.971", "nll_loss": "2.513", "ppl": "5.71", "wps": "71077.4", "ups": "19.54", "wpb": "3636.6", "bsz": "145.3", "num_updates": "51600", "lr": "0.00278423", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2879"}
2023-12-13 18:45:00 | INFO | train_inner | {"epoch": 47, "update": 46.918, "loss": "3.985", "nll_loss": "2.53", "ppl": "5.78", "wps": "68903.2", "ups": "19.77", "wpb": "3485.5", "bsz": "145.1", "num_updates": "51700", "lr": "0.00278154", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2884"}
2023-12-13 18:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:45:06 | INFO | valid | {"epoch": 47, "valid_loss": "4.43", "valid_nll_loss": "3.054", "valid_ppl": "8.31", "valid_wps": "132424", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "51790", "valid_best_loss": "4.412"}
2023-12-13 18:45:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 51790 updates
2023-12-13 18:45:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint47.pt
2023-12-13 18:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint47.pt
2023-12-13 18:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint47.pt (epoch 47 @ 51790 updates, score 4.43) (writing took 1.6890592761337757 seconds)
2023-12-13 18:45:08 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-12-13 18:45:08 | INFO | train | {"epoch": 47, "train_loss": "3.944", "train_nll_loss": "2.481", "train_ppl": "5.58", "train_wps": "64246.2", "train_ups": "17.93", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "51790", "train_lr": "0.00277912", "train_gnorm": "0.251", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2892"}
2023-12-13 18:45:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:45:08 | INFO | fairseq.trainer | begin training epoch 48
2023-12-13 18:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:45:09 | INFO | train_inner | {"epoch": 48, "update": 47.009, "loss": "4.016", "nll_loss": "2.565", "ppl": "5.92", "wps": "39293", "ups": "11.07", "wpb": "3550.6", "bsz": "139", "num_updates": "51800", "lr": "0.00277885", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2893"}
2023-12-13 18:45:14 | INFO | train_inner | {"epoch": 48, "update": 47.1, "loss": "3.818", "nll_loss": "2.333", "ppl": "5.04", "wps": "68430.4", "ups": "19.1", "wpb": "3583", "bsz": "155", "num_updates": "51900", "lr": "0.00277617", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2898"}
2023-12-13 18:45:20 | INFO | train_inner | {"epoch": 48, "update": 47.191, "loss": "3.894", "nll_loss": "2.421", "ppl": "5.36", "wps": "63983.1", "ups": "17.87", "wpb": "3580.1", "bsz": "144.9", "num_updates": "52000", "lr": "0.0027735", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2904"}
2023-12-13 18:45:25 | INFO | train_inner | {"epoch": 48, "update": 47.281, "loss": "3.916", "nll_loss": "2.445", "ppl": "5.45", "wps": "67573.2", "ups": "19.06", "wpb": "3544.5", "bsz": "131.8", "num_updates": "52100", "lr": "0.00277084", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2909"}
2023-12-13 18:45:30 | INFO | train_inner | {"epoch": 48, "update": 47.372, "loss": "3.93", "nll_loss": "2.462", "ppl": "5.51", "wps": "73483.6", "ups": "20.09", "wpb": "3657.1", "bsz": "144.8", "num_updates": "52200", "lr": "0.00276818", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2914"}
2023-12-13 18:45:36 | INFO | train_inner | {"epoch": 48, "update": 47.463, "loss": "3.957", "nll_loss": "2.494", "ppl": "5.63", "wps": "60981.9", "ups": "17.25", "wpb": "3535.3", "bsz": "136.7", "num_updates": "52300", "lr": "0.00276553", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2920"}
2023-12-13 18:45:40 | INFO | train_inner | {"epoch": 48, "update": 47.554, "loss": "3.937", "nll_loss": "2.473", "ppl": "5.55", "wps": "79871.3", "ups": "21.99", "wpb": "3632.2", "bsz": "155.9", "num_updates": "52400", "lr": "0.00276289", "gnorm": "0.247", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "2924"}
2023-12-13 18:45:46 | INFO | train_inner | {"epoch": 48, "update": 47.644, "loss": "4.016", "nll_loss": "2.563", "ppl": "5.91", "wps": "66302.9", "ups": "18.49", "wpb": "3585.9", "bsz": "130.2", "num_updates": "52500", "lr": "0.00276026", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2930"}
2023-12-13 18:45:51 | INFO | train_inner | {"epoch": 48, "update": 47.735, "loss": "3.995", "nll_loss": "2.539", "ppl": "5.81", "wps": "62443.5", "ups": "17.71", "wpb": "3526.2", "bsz": "141.5", "num_updates": "52600", "lr": "0.00275764", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2935"}
2023-12-13 18:45:56 | INFO | train_inner | {"epoch": 48, "update": 47.826, "loss": "3.946", "nll_loss": "2.484", "ppl": "5.59", "wps": "74081.7", "ups": "20.42", "wpb": "3627.3", "bsz": "151.7", "num_updates": "52700", "lr": "0.00275502", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2940"}
2023-12-13 18:46:01 | INFO | train_inner | {"epoch": 48, "update": 47.917, "loss": "3.954", "nll_loss": "2.497", "ppl": "5.64", "wps": "74132.5", "ups": "20.82", "wpb": "3560.2", "bsz": "163.8", "num_updates": "52800", "lr": "0.00275241", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2945"}
2023-12-13 18:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:46:07 | INFO | valid | {"epoch": 48, "valid_loss": "4.433", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "127822", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "52892", "valid_best_loss": "4.412"}
2023-12-13 18:46:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 52892 updates
2023-12-13 18:46:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint48.pt
2023-12-13 18:46:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint48.pt
2023-12-13 18:46:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint48.pt (epoch 48 @ 52892 updates, score 4.433) (writing took 1.9050310906022787 seconds)
2023-12-13 18:46:09 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-12-13 18:46:09 | INFO | train | {"epoch": 48, "train_loss": "3.938", "train_nll_loss": "2.474", "train_ppl": "5.55", "train_wps": "64568.2", "train_ups": "18.02", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "52892", "train_lr": "0.00275001", "train_gnorm": "0.254", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2953"}
2023-12-13 18:46:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:46:09 | INFO | fairseq.trainer | begin training epoch 49
2023-12-13 18:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:46:10 | INFO | train_inner | {"epoch": 49, "update": 48.007, "loss": "3.955", "nll_loss": "2.495", "ppl": "5.64", "wps": "41758.5", "ups": "11.64", "wpb": "3588.8", "bsz": "145.8", "num_updates": "52900", "lr": "0.00274981", "gnorm": "0.272", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2954"}
2023-12-13 18:46:15 | INFO | train_inner | {"epoch": 49, "update": 48.098, "loss": "3.78", "nll_loss": "2.29", "ppl": "4.89", "wps": "71175.8", "ups": "19.57", "wpb": "3637.2", "bsz": "163.8", "num_updates": "53000", "lr": "0.00274721", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2959"}
2023-12-13 18:46:20 | INFO | train_inner | {"epoch": 49, "update": 48.189, "loss": "3.876", "nll_loss": "2.402", "ppl": "5.29", "wps": "68803.1", "ups": "19.41", "wpb": "3544.5", "bsz": "155.1", "num_updates": "53100", "lr": "0.00274462", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2964"}
2023-12-13 18:46:26 | INFO | train_inner | {"epoch": 49, "update": 48.279, "loss": "3.893", "nll_loss": "2.422", "ppl": "5.36", "wps": "63520.5", "ups": "17.61", "wpb": "3606.7", "bsz": "151.7", "num_updates": "53200", "lr": "0.00274204", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2969"}
2023-12-13 18:46:31 | INFO | train_inner | {"epoch": 49, "update": 48.37, "loss": "3.933", "nll_loss": "2.469", "ppl": "5.54", "wps": "67889.3", "ups": "19.18", "wpb": "3540.4", "bsz": "148.7", "num_updates": "53300", "lr": "0.00273947", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2975"}
2023-12-13 18:46:36 | INFO | train_inner | {"epoch": 49, "update": 48.461, "loss": "3.929", "nll_loss": "2.463", "ppl": "5.51", "wps": "74073.6", "ups": "20.57", "wpb": "3601.3", "bsz": "146.1", "num_updates": "53400", "lr": "0.0027369", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2980"}
2023-12-13 18:46:41 | INFO | train_inner | {"epoch": 49, "update": 48.552, "loss": "3.926", "nll_loss": "2.46", "ppl": "5.5", "wps": "69473.5", "ups": "19.54", "wpb": "3554.7", "bsz": "150.9", "num_updates": "53500", "lr": "0.00273434", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2985"}
2023-12-13 18:46:46 | INFO | train_inner | {"epoch": 49, "update": 48.642, "loss": "3.959", "nll_loss": "2.501", "ppl": "5.66", "wps": "77941", "ups": "21.23", "wpb": "3670.6", "bsz": "153.8", "num_updates": "53600", "lr": "0.00273179", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2989"}
2023-12-13 18:46:51 | INFO | train_inner | {"epoch": 49, "update": 48.733, "loss": "3.989", "nll_loss": "2.531", "ppl": "5.78", "wps": "64716.5", "ups": "18.08", "wpb": "3578.5", "bsz": "127.1", "num_updates": "53700", "lr": "0.00272925", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2995"}
2023-12-13 18:46:57 | INFO | train_inner | {"epoch": 49, "update": 48.824, "loss": "4.009", "nll_loss": "2.555", "ppl": "5.88", "wps": "64233.6", "ups": "18.23", "wpb": "3523.9", "bsz": "131", "num_updates": "53800", "lr": "0.00272671", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3000"}
2023-12-13 18:47:02 | INFO | train_inner | {"epoch": 49, "update": 48.915, "loss": "3.985", "nll_loss": "2.528", "ppl": "5.77", "wps": "69673.2", "ups": "19.37", "wpb": "3596.4", "bsz": "136.6", "num_updates": "53900", "lr": "0.00272418", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3006"}
2023-12-13 18:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:47:09 | INFO | valid | {"epoch": 49, "valid_loss": "4.43", "valid_nll_loss": "3.057", "valid_ppl": "8.32", "valid_wps": "131732", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "53994", "valid_best_loss": "4.412"}
2023-12-13 18:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 53994 updates
2023-12-13 18:47:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint49.pt
2023-12-13 18:47:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint49.pt
2023-12-13 18:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint49.pt (epoch 49 @ 53994 updates, score 4.43) (writing took 1.842174457386136 seconds)
2023-12-13 18:47:10 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-12-13 18:47:10 | INFO | train | {"epoch": 49, "train_loss": "3.933", "train_nll_loss": "2.468", "train_ppl": "5.53", "train_wps": "64718.7", "train_ups": "18.06", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "53994", "train_lr": "0.00272181", "train_gnorm": "0.252", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3014"}
2023-12-13 18:47:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:47:11 | INFO | fairseq.trainer | begin training epoch 50
2023-12-13 18:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:47:11 | INFO | train_inner | {"epoch": 50, "update": 49.005, "loss": "3.987", "nll_loss": "2.529", "ppl": "5.77", "wps": "38600", "ups": "10.84", "wpb": "3559.3", "bsz": "132.2", "num_updates": "54000", "lr": "0.00272166", "gnorm": "0.259", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3015"}
2023-12-13 18:47:16 | INFO | train_inner | {"epoch": 50, "update": 49.096, "loss": "3.821", "nll_loss": "2.337", "ppl": "5.05", "wps": "74112", "ups": "20.31", "wpb": "3648.7", "bsz": "154.6", "num_updates": "54100", "lr": "0.00271914", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3020"}
2023-12-13 18:47:22 | INFO | train_inner | {"epoch": 50, "update": 49.187, "loss": "3.879", "nll_loss": "2.403", "ppl": "5.29", "wps": "61618.6", "ups": "17.6", "wpb": "3501.1", "bsz": "138.4", "num_updates": "54200", "lr": "0.00271663", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3025"}
2023-12-13 18:47:27 | INFO | train_inner | {"epoch": 50, "update": 49.278, "loss": "3.879", "nll_loss": "2.404", "ppl": "5.29", "wps": "68088.7", "ups": "18.89", "wpb": "3603.7", "bsz": "146.1", "num_updates": "54300", "lr": "0.00271413", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3031"}
2023-12-13 18:47:32 | INFO | train_inner | {"epoch": 50, "update": 49.368, "loss": "3.941", "nll_loss": "2.475", "ppl": "5.56", "wps": "69599", "ups": "19.65", "wpb": "3542.2", "bsz": "132.6", "num_updates": "54400", "lr": "0.00271163", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3036"}
2023-12-13 18:47:37 | INFO | train_inner | {"epoch": 50, "update": 49.459, "loss": "3.917", "nll_loss": "2.45", "ppl": "5.46", "wps": "68212.7", "ups": "19.11", "wpb": "3570.2", "bsz": "147.4", "num_updates": "54500", "lr": "0.00270914", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3041"}
2023-12-13 18:47:42 | INFO | train_inner | {"epoch": 50, "update": 49.55, "loss": "3.9", "nll_loss": "2.43", "ppl": "5.39", "wps": "75860.7", "ups": "20.83", "wpb": "3641.7", "bsz": "155.1", "num_updates": "54600", "lr": "0.00270666", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3046"}
2023-12-13 18:47:47 | INFO | train_inner | {"epoch": 50, "update": 49.641, "loss": "3.976", "nll_loss": "2.517", "ppl": "5.73", "wps": "65844.9", "ups": "18.37", "wpb": "3583.5", "bsz": "135.7", "num_updates": "54700", "lr": "0.00270418", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3051"}
2023-12-13 18:47:53 | INFO | train_inner | {"epoch": 50, "update": 49.731, "loss": "3.945", "nll_loss": "2.482", "ppl": "5.59", "wps": "63420.9", "ups": "18.22", "wpb": "3480.7", "bsz": "145.4", "num_updates": "54800", "lr": "0.00270172", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3057"}
2023-12-13 18:47:58 | INFO | train_inner | {"epoch": 50, "update": 49.822, "loss": "3.946", "nll_loss": "2.485", "ppl": "5.6", "wps": "74054.3", "ups": "20.51", "wpb": "3611.4", "bsz": "157.8", "num_updates": "54900", "lr": "0.00269925", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3062"}
2023-12-13 18:48:03 | INFO | train_inner | {"epoch": 50, "update": 49.913, "loss": "3.996", "nll_loss": "2.542", "ppl": "5.82", "wps": "74558.5", "ups": "20.49", "wpb": "3637.9", "bsz": "139", "num_updates": "55000", "lr": "0.0026968", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3067"}
2023-12-13 18:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:48:09 | INFO | valid | {"epoch": 50, "valid_loss": "4.431", "valid_nll_loss": "3.076", "valid_ppl": "8.43", "valid_wps": "130665", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "55096", "valid_best_loss": "4.412"}
2023-12-13 18:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 55096 updates
2023-12-13 18:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint50.pt
2023-12-13 18:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint50.pt
2023-12-13 18:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint50.pt (epoch 50 @ 55096 updates, score 4.431) (writing took 1.9410955980420113 seconds)
2023-12-13 18:48:11 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-12-13 18:48:11 | INFO | train | {"epoch": 50, "train_loss": "3.923", "train_nll_loss": "2.456", "train_ppl": "5.49", "train_wps": "64847.8", "train_ups": "18.1", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "55096", "train_lr": "0.00269445", "train_gnorm": "0.252", "train_loss_scale": "32", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "3075"}
2023-12-13 18:48:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:48:11 | INFO | fairseq.trainer | begin training epoch 51
2023-12-13 18:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:48:12 | INFO | train_inner | {"epoch": 51, "update": 50.004, "loss": "3.961", "nll_loss": "2.502", "ppl": "5.67", "wps": "40664.8", "ups": "11.3", "wpb": "3598.9", "bsz": "148.8", "num_updates": "55100", "lr": "0.00269435", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3075"}
2023-12-13 18:48:17 | INFO | train_inner | {"epoch": 51, "update": 50.094, "loss": "3.827", "nll_loss": "2.343", "ppl": "5.07", "wps": "68144.7", "ups": "18.99", "wpb": "3588.7", "bsz": "154.9", "num_updates": "55200", "lr": "0.00269191", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3081"}
2023-12-13 18:48:22 | INFO | train_inner | {"epoch": 51, "update": 50.185, "loss": "3.864", "nll_loss": "2.386", "ppl": "5.23", "wps": "65562.9", "ups": "18.22", "wpb": "3598", "bsz": "141.5", "num_updates": "55300", "lr": "0.00268947", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3086"}
2023-12-13 18:48:27 | INFO | train_inner | {"epoch": 51, "update": 50.276, "loss": "3.867", "nll_loss": "2.391", "ppl": "5.25", "wps": "75174.5", "ups": "20.9", "wpb": "3596.2", "bsz": "150.3", "num_updates": "55400", "lr": "0.00268705", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3091"}
2023-12-13 18:48:32 | INFO | train_inner | {"epoch": 51, "update": 50.367, "loss": "3.905", "nll_loss": "2.436", "ppl": "5.41", "wps": "73976.9", "ups": "20.79", "wpb": "3558.1", "bsz": "147.7", "num_updates": "55500", "lr": "0.00268462", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3096"}
2023-12-13 18:48:37 | INFO | train_inner | {"epoch": 51, "update": 50.457, "loss": "3.902", "nll_loss": "2.431", "ppl": "5.39", "wps": "65844.4", "ups": "18.75", "wpb": "3511.1", "bsz": "143.8", "num_updates": "55600", "lr": "0.00268221", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3101"}
2023-12-13 18:48:43 | INFO | train_inner | {"epoch": 51, "update": 50.548, "loss": "3.912", "nll_loss": "2.446", "ppl": "5.45", "wps": "68299.5", "ups": "19", "wpb": "3595.3", "bsz": "158.7", "num_updates": "55700", "lr": "0.0026798", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3106"}
2023-12-13 18:48:47 | INFO | train_inner | {"epoch": 51, "update": 50.639, "loss": "3.923", "nll_loss": "2.458", "ppl": "5.49", "wps": "73316.8", "ups": "20.24", "wpb": "3622.3", "bsz": "152.4", "num_updates": "55800", "lr": "0.0026774", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3111"}
2023-12-13 18:48:53 | INFO | train_inner | {"epoch": 51, "update": 50.73, "loss": "3.93", "nll_loss": "2.465", "ppl": "5.52", "wps": "63246.1", "ups": "17.63", "wpb": "3588.2", "bsz": "146.9", "num_updates": "55900", "lr": "0.002675", "gnorm": "0.285", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3117"}
2023-12-13 18:48:58 | INFO | train_inner | {"epoch": 51, "update": 50.82, "loss": "3.972", "nll_loss": "2.514", "ppl": "5.71", "wps": "70155.8", "ups": "19.68", "wpb": "3564.9", "bsz": "138.4", "num_updates": "56000", "lr": "0.00267261", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3122"}
2023-12-13 18:49:04 | INFO | train_inner | {"epoch": 51, "update": 50.911, "loss": "4.037", "nll_loss": "2.588", "ppl": "6.01", "wps": "64216.5", "ups": "17.72", "wpb": "3624.7", "bsz": "127.1", "num_updates": "56100", "lr": "0.00267023", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3128"}
2023-12-13 18:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:49:11 | INFO | valid | {"epoch": 51, "valid_loss": "4.448", "valid_nll_loss": "3.065", "valid_ppl": "8.37", "valid_wps": "130614", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "56198", "valid_best_loss": "4.412"}
2023-12-13 18:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 56198 updates
2023-12-13 18:49:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint51.pt
2023-12-13 18:49:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint51.pt
2023-12-13 18:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint51.pt (epoch 51 @ 56198 updates, score 4.448) (writing took 1.866159450262785 seconds)
2023-12-13 18:49:13 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-12-13 18:49:13 | INFO | train | {"epoch": 51, "train_loss": "3.918", "train_nll_loss": "2.451", "train_ppl": "5.47", "train_wps": "64241.5", "train_ups": "17.93", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "56198", "train_lr": "0.0026679", "train_gnorm": "0.255", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3136"}
2023-12-13 18:49:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:49:13 | INFO | fairseq.trainer | begin training epoch 52
2023-12-13 18:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:49:13 | INFO | train_inner | {"epoch": 52, "update": 51.002, "loss": "3.956", "nll_loss": "2.495", "ppl": "5.64", "wps": "39393.7", "ups": "11.03", "wpb": "3572.9", "bsz": "138.5", "num_updates": "56200", "lr": "0.00266785", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3137"}
2023-12-13 18:49:19 | INFO | train_inner | {"epoch": 52, "update": 51.093, "loss": "3.832", "nll_loss": "2.349", "ppl": "5.09", "wps": "63266.8", "ups": "17.86", "wpb": "3542.3", "bsz": "151.4", "num_updates": "56300", "lr": "0.00266548", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3142"}
2023-12-13 18:49:24 | INFO | train_inner | {"epoch": 52, "update": 51.183, "loss": "3.858", "nll_loss": "2.382", "ppl": "5.21", "wps": "69248.3", "ups": "19.2", "wpb": "3605.9", "bsz": "151.7", "num_updates": "56400", "lr": "0.00266312", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3148"}
2023-12-13 18:49:29 | INFO | train_inner | {"epoch": 52, "update": 51.274, "loss": "3.812", "nll_loss": "2.327", "ppl": "5.02", "wps": "73745.2", "ups": "20.45", "wpb": "3606.8", "bsz": "159.4", "num_updates": "56500", "lr": "0.00266076", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3152"}
2023-12-13 18:49:35 | INFO | train_inner | {"epoch": 52, "update": 51.365, "loss": "3.941", "nll_loss": "2.473", "ppl": "5.55", "wps": "59746", "ups": "16.62", "wpb": "3594.6", "bsz": "117.4", "num_updates": "56600", "lr": "0.00265841", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3158"}
2023-12-13 18:49:40 | INFO | train_inner | {"epoch": 52, "update": 51.456, "loss": "3.931", "nll_loss": "2.465", "ppl": "5.52", "wps": "65930.1", "ups": "18.62", "wpb": "3541", "bsz": "135.9", "num_updates": "56700", "lr": "0.00265606", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3164"}
2023-12-13 18:49:45 | INFO | train_inner | {"epoch": 52, "update": 51.546, "loss": "3.903", "nll_loss": "2.434", "ppl": "5.4", "wps": "67059.4", "ups": "18.94", "wpb": "3539.7", "bsz": "157.2", "num_updates": "56800", "lr": "0.00265372", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3169"}
2023-12-13 18:49:50 | INFO | train_inner | {"epoch": 52, "update": 51.637, "loss": "3.917", "nll_loss": "2.452", "ppl": "5.47", "wps": "70634.7", "ups": "19.65", "wpb": "3594.7", "bsz": "155.4", "num_updates": "56900", "lr": "0.00265139", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3174"}
2023-12-13 18:49:55 | INFO | train_inner | {"epoch": 52, "update": 51.728, "loss": "3.936", "nll_loss": "2.472", "ppl": "5.55", "wps": "72138.9", "ups": "20.03", "wpb": "3601.9", "bsz": "148.3", "num_updates": "57000", "lr": "0.00264906", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3179"}
2023-12-13 18:50:01 | INFO | train_inner | {"epoch": 52, "update": 51.819, "loss": "3.919", "nll_loss": "2.452", "ppl": "5.47", "wps": "68318.7", "ups": "19.34", "wpb": "3532.6", "bsz": "142.9", "num_updates": "57100", "lr": "0.00264674", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3184"}
2023-12-13 18:50:06 | INFO | train_inner | {"epoch": 52, "update": 51.909, "loss": "3.964", "nll_loss": "2.505", "ppl": "5.68", "wps": "71522.6", "ups": "19.96", "wpb": "3583.6", "bsz": "139.4", "num_updates": "57200", "lr": "0.00264443", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3189"}
2023-12-13 18:50:11 | INFO | train_inner | {"epoch": 52, "update": 52.0, "loss": "4.002", "nll_loss": "2.549", "ppl": "5.85", "wps": "70710.3", "ups": "19.22", "wpb": "3678.7", "bsz": "142", "num_updates": "57300", "lr": "0.00264212", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3195"}
2023-12-13 18:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:50:12 | INFO | valid | {"epoch": 52, "valid_loss": "4.439", "valid_nll_loss": "3.07", "valid_ppl": "8.4", "valid_wps": "131219", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "57300", "valid_best_loss": "4.412"}
2023-12-13 18:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 57300 updates
2023-12-13 18:50:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint52.pt
2023-12-13 18:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint52.pt
2023-12-13 18:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint52.pt (epoch 52 @ 57300 updates, score 4.439) (writing took 2.21223927102983 seconds)
2023-12-13 18:50:14 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-12-13 18:50:14 | INFO | train | {"epoch": 52, "train_loss": "3.911", "train_nll_loss": "2.442", "train_ppl": "5.43", "train_wps": "64023.1", "train_ups": "17.87", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "57300", "train_lr": "0.00264212", "train_gnorm": "0.254", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3198"}
2023-12-13 18:50:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:50:14 | INFO | fairseq.trainer | begin training epoch 53
2023-12-13 18:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:50:19 | INFO | train_inner | {"epoch": 53, "update": 52.091, "loss": "3.811", "nll_loss": "2.323", "ppl": "5.01", "wps": "41140", "ups": "11.49", "wpb": "3580", "bsz": "139.4", "num_updates": "57400", "lr": "0.00263982", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3203"}
2023-12-13 18:50:24 | INFO | train_inner | {"epoch": 53, "update": 52.181, "loss": "3.838", "nll_loss": "2.356", "ppl": "5.12", "wps": "73668.4", "ups": "20.19", "wpb": "3648.8", "bsz": "149", "num_updates": "57500", "lr": "0.00263752", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3208"}
2023-12-13 18:50:30 | INFO | train_inner | {"epoch": 53, "update": 52.272, "loss": "3.852", "nll_loss": "2.374", "ppl": "5.18", "wps": "69630.5", "ups": "19.35", "wpb": "3597.6", "bsz": "147.7", "num_updates": "57600", "lr": "0.00263523", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3213"}
2023-12-13 18:50:35 | INFO | train_inner | {"epoch": 53, "update": 52.363, "loss": "3.883", "nll_loss": "2.409", "ppl": "5.31", "wps": "67780.4", "ups": "19.18", "wpb": "3534.2", "bsz": "140.6", "num_updates": "57700", "lr": "0.00263295", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3219"}
2023-12-13 18:50:40 | INFO | train_inner | {"epoch": 53, "update": 52.454, "loss": "3.935", "nll_loss": "2.468", "ppl": "5.53", "wps": "64282.1", "ups": "18.11", "wpb": "3550.3", "bsz": "139.4", "num_updates": "57800", "lr": "0.00263067", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3224"}
2023-12-13 18:50:46 | INFO | train_inner | {"epoch": 53, "update": 52.544, "loss": "3.893", "nll_loss": "2.421", "ppl": "5.36", "wps": "69732.4", "ups": "19.2", "wpb": "3632.2", "bsz": "147.8", "num_updates": "57900", "lr": "0.0026284", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3229"}
2023-12-13 18:50:50 | INFO | train_inner | {"epoch": 53, "update": 52.635, "loss": "3.912", "nll_loss": "2.445", "ppl": "5.45", "wps": "74879.5", "ups": "20.74", "wpb": "3610.9", "bsz": "160.3", "num_updates": "58000", "lr": "0.00262613", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3234"}
2023-12-13 18:50:56 | INFO | train_inner | {"epoch": 53, "update": 52.726, "loss": "3.929", "nll_loss": "2.466", "ppl": "5.52", "wps": "63921.7", "ups": "18.17", "wpb": "3517.8", "bsz": "155.7", "num_updates": "58100", "lr": "0.00262387", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3240"}
2023-12-13 18:51:01 | INFO | train_inner | {"epoch": 53, "update": 52.817, "loss": "3.952", "nll_loss": "2.49", "ppl": "5.62", "wps": "64700.1", "ups": "18.12", "wpb": "3570.7", "bsz": "138.6", "num_updates": "58200", "lr": "0.00262161", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3245"}
2023-12-13 18:51:07 | INFO | train_inner | {"epoch": 53, "update": 52.907, "loss": "3.989", "nll_loss": "2.533", "ppl": "5.79", "wps": "65536.4", "ups": "18.27", "wpb": "3587.7", "bsz": "136.4", "num_updates": "58300", "lr": "0.00261936", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3251"}
2023-12-13 18:51:12 | INFO | train_inner | {"epoch": 53, "update": 52.998, "loss": "3.955", "nll_loss": "2.495", "ppl": "5.64", "wps": "66638.5", "ups": "18.6", "wpb": "3581.9", "bsz": "144.8", "num_updates": "58400", "lr": "0.00261712", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3256"}
2023-12-13 18:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:51:14 | INFO | valid | {"epoch": 53, "valid_loss": "4.446", "valid_nll_loss": "3.07", "valid_ppl": "8.4", "valid_wps": "132678", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "58402", "valid_best_loss": "4.412"}
2023-12-13 18:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 58402 updates
2023-12-13 18:51:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint53.pt
2023-12-13 18:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint53.pt
2023-12-13 18:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint53.pt (epoch 53 @ 58402 updates, score 4.446) (writing took 1.9252039529383183 seconds)
2023-12-13 18:51:16 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-12-13 18:51:16 | INFO | train | {"epoch": 53, "train_loss": "3.905", "train_nll_loss": "2.435", "train_ppl": "5.41", "train_wps": "64471", "train_ups": "17.99", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "58402", "train_lr": "0.00261707", "train_gnorm": "0.255", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3259"}
2023-12-13 18:51:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:51:16 | INFO | fairseq.trainer | begin training epoch 54
2023-12-13 18:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:51:21 | INFO | train_inner | {"epoch": 54, "update": 53.089, "loss": "3.814", "nll_loss": "2.33", "ppl": "5.03", "wps": "42387.6", "ups": "11.79", "wpb": "3593.9", "bsz": "149.3", "num_updates": "58500", "lr": "0.00261488", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3264"}
2023-12-13 18:51:26 | INFO | train_inner | {"epoch": 54, "update": 53.18, "loss": "3.829", "nll_loss": "2.344", "ppl": "5.08", "wps": "71992.1", "ups": "20.24", "wpb": "3557.7", "bsz": "139.8", "num_updates": "58600", "lr": "0.00261265", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3269"}
2023-12-13 18:51:31 | INFO | train_inner | {"epoch": 54, "update": 53.27, "loss": "3.879", "nll_loss": "2.406", "ppl": "5.3", "wps": "72748.5", "ups": "20.35", "wpb": "3575.4", "bsz": "152.5", "num_updates": "58700", "lr": "0.00261042", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3274"}
2023-12-13 18:51:36 | INFO | train_inner | {"epoch": 54, "update": 53.361, "loss": "3.905", "nll_loss": "2.433", "ppl": "5.4", "wps": "63231.5", "ups": "17.7", "wpb": "3571.7", "bsz": "139.5", "num_updates": "58800", "lr": "0.0026082", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3280"}
2023-12-13 18:51:42 | INFO | train_inner | {"epoch": 54, "update": 53.452, "loss": "3.87", "nll_loss": "2.395", "ppl": "5.26", "wps": "68233.8", "ups": "18.99", "wpb": "3593.2", "bsz": "150.1", "num_updates": "58900", "lr": "0.00260599", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3285"}
2023-12-13 18:51:47 | INFO | train_inner | {"epoch": 54, "update": 53.543, "loss": "3.905", "nll_loss": "2.435", "ppl": "5.41", "wps": "67724.7", "ups": "19.04", "wpb": "3557.4", "bsz": "139.4", "num_updates": "59000", "lr": "0.00260378", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3291"}
2023-12-13 18:51:52 | INFO | train_inner | {"epoch": 54, "update": 53.633, "loss": "3.961", "nll_loss": "2.501", "ppl": "5.66", "wps": "63528.9", "ups": "17.88", "wpb": "3552.2", "bsz": "135.4", "num_updates": "59100", "lr": "0.00260157", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3296"}
2023-12-13 18:51:58 | INFO | train_inner | {"epoch": 54, "update": 53.724, "loss": "3.918", "nll_loss": "2.45", "ppl": "5.46", "wps": "67490.7", "ups": "18.77", "wpb": "3595.6", "bsz": "145", "num_updates": "59200", "lr": "0.00259938", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3301"}
2023-12-13 18:52:03 | INFO | train_inner | {"epoch": 54, "update": 53.815, "loss": "3.914", "nll_loss": "2.448", "ppl": "5.46", "wps": "67346", "ups": "18.62", "wpb": "3617.2", "bsz": "151.7", "num_updates": "59300", "lr": "0.00259718", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3307"}
2023-12-13 18:52:09 | INFO | train_inner | {"epoch": 54, "update": 53.906, "loss": "3.94", "nll_loss": "2.477", "ppl": "5.57", "wps": "62394.5", "ups": "17.37", "wpb": "3591.2", "bsz": "138.8", "num_updates": "59400", "lr": "0.002595", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3313"}
2023-12-13 18:52:14 | INFO | train_inner | {"epoch": 54, "update": 53.996, "loss": "3.95", "nll_loss": "2.49", "ppl": "5.62", "wps": "74803.6", "ups": "20.61", "wpb": "3629.7", "bsz": "155", "num_updates": "59500", "lr": "0.00259281", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3317"}
2023-12-13 18:52:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:52:15 | INFO | valid | {"epoch": 54, "valid_loss": "4.449", "valid_nll_loss": "3.093", "valid_ppl": "8.54", "valid_wps": "131603", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "59504", "valid_best_loss": "4.412"}
2023-12-13 18:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 59504 updates
2023-12-13 18:52:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint54.pt
2023-12-13 18:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint54.pt
2023-12-13 18:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint54.pt (epoch 54 @ 59504 updates, score 4.449) (writing took 1.888045011088252 seconds)
2023-12-13 18:52:17 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-12-13 18:52:17 | INFO | train | {"epoch": 54, "train_loss": "3.897", "train_nll_loss": "2.427", "train_ppl": "5.38", "train_wps": "64300.1", "train_ups": "17.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "59504", "train_lr": "0.00259273", "train_gnorm": "0.255", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3321"}
2023-12-13 18:52:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 18:52:17 | INFO | fairseq.trainer | begin training epoch 55
2023-12-13 18:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 18:52:22 | INFO | train_inner | {"epoch": 55, "update": 54.087, "loss": "3.776", "nll_loss": "2.287", "ppl": "4.88", "wps": "43904.5", "ups": "12.36", "wpb": "3552.2", "bsz": "165", "num_updates": "59600", "lr": "0.00259064", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3326"}
2023-12-13 18:52:27 | INFO | train_inner | {"epoch": 55, "update": 54.178, "loss": "3.833", "nll_loss": "2.35", "ppl": "5.1", "wps": "67134.4", "ups": "19.05", "wpb": "3523.3", "bsz": "142.6", "num_updates": "59700", "lr": "0.00258847", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3331"}
2023-12-13 18:52:32 | INFO | train_inner | {"epoch": 55, "update": 54.269, "loss": "3.865", "nll_loss": "2.39", "ppl": "5.24", "wps": "68426.6", "ups": "18.81", "wpb": "3638.1", "bsz": "146.3", "num_updates": "59800", "lr": "0.0025863", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3336"}
2023-12-13 18:52:37 | INFO | train_inner | {"epoch": 55, "update": 54.359, "loss": "3.883", "nll_loss": "2.411", "ppl": "5.32", "wps": "75519.6", "ups": "20.96", "wpb": "3603.7", "bsz": "151.4", "num_updates": "59900", "lr": "0.00258414", "gnorm": "0.248", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "3341"}
2023-12-13 18:52:43 | INFO | train_inner | {"epoch": 55, "update": 54.45, "loss": "3.894", "nll_loss": "2.423", "ppl": "5.36", "wps": "63142.3", "ups": "17.85", "wpb": "3537.3", "bsz": "144.2", "num_updates": "60000", "lr": "0.00258199", "gnorm": "0.26", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "3346"}
2023-12-13 18:52:48 | INFO | train_inner | {"epoch": 55, "update": 54.541, "loss": "3.887", "nll_loss": "2.414", "ppl": "5.33", "wps": "69060.6", "ups": "19.25", "wpb": "3588.3", "bsz": "146.2", "num_updates": "60100", "lr": "0.00257984", "gnorm": "0.257", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "3352"}
2023-12-13 18:52:53 | INFO | train_inner | {"epoch": 55, "update": 54.632, "loss": "3.884", "nll_loss": "2.412", "ppl": "5.32", "wps": "68456.3", "ups": "18.87", "wpb": "3627.8", "bsz": "147.2", "num_updates": "60200", "lr": "0.0025777", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "3357"}
2023-12-13 18:52:58 | INFO | train_inner | {"epoch": 55, "update": 54.722, "loss": "3.886", "nll_loss": "2.415", "ppl": "5.33", "wps": "73615.2", "ups": "20.28", "wpb": "3630.7", "bsz": "143.9", "num_updates": "60300", "lr": "0.00257556", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "3362"}
2023-12-13 18:53:04 | INFO | train_inner | {"epoch": 55, "update": 54.813, "loss": "3.959", "nll_loss": "2.499", "ppl": "5.65", "wps": "65859.9", "ups": "18.38", "wpb": "3583.6", "bsz": "139.4", "num_updates": "60400", "lr": "0.00257343", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "3367"}
2023-12-13 18:53:09 | INFO | train_inner | {"epoch": 55, "update": 54.904, "loss": "3.962", "nll_loss": "2.502", "ppl": "5.66", "wps": "65390.1", "ups": "18.05", "wpb": "3623.5", "bsz": "131.9", "num_updates": "60500", "lr": "0.0025713", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "3373"}
2023-12-13 18:53:14 | INFO | train_inner | {"epoch": 55, "update": 54.995, "loss": "3.972", "nll_loss": "2.517", "ppl": "5.72", "wps": "65530.3", "ups": "18.66", "wpb": "3512.3", "bsz": "145.7", "num_updates": "60600", "lr": "0.00256917", "gnorm": "0.263", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "3378"}
2023-12-13 18:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 18:53:16 | INFO | valid | {"epoch": 55, "valid_loss": "4.453", "valid_nll_loss": "3.084", "valid_ppl": "8.48", "valid_wps": "130354", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "60606", "valid_best_loss": "4.412"}
2023-12-13 18:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 60606 updates
2023-12-13 18:53:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint55.pt
2023-12-13 18:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoint_adam_74619/checkpoint55.pt
2023-12-13 18:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_adam_74619/checkpoint55.pt (epoch 55 @ 60606 updates, score 4.453) (writing took 1.9324586428701878 seconds)
2023-12-13 18:53:18 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-12-13 18:53:18 | INFO | train | {"epoch": 55, "train_loss": "3.892", "train_nll_loss": "2.421", "train_ppl": "5.36", "train_wps": "64741.6", "train_ups": "18.07", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "60606", "train_lr": "0.00256905", "train_gnorm": "0.256", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3382"}
2023-12-13 18:53:18 | INFO | fairseq_cli.train | done training in 3381.5 seconds
