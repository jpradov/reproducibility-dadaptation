2023-12-10 10:21:27 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-12-10 10:21:29 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 77516, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 55, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=77516, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='lstm_wiseman_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.01]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.01]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-12-10 10:21:30 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2023-12-10 10:21:30 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2023-12-10 10:21:30 | INFO | fairseq_cli.train | LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 256, padding_idx=1)
    (lstm): LSTM(256, 256)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 256, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(512, 256)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=256, out_features=256, bias=False)
      (output_proj): Linear(in_features=512, out_features=256, bias=False)
    )
  )
)
2023-12-10 10:21:30 | INFO | fairseq_cli.train | task: TranslationTask
2023-12-10 10:21:30 | INFO | fairseq_cli.train | model: LSTMModel
2023-12-10 10:21:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-12-10 10:21:30 | INFO | fairseq_cli.train | num. shared model params: 5,474,304 (num. trained: 5,474,304)
2023-12-10 10:21:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-12-10 10:21:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2023-12-10 10:21:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2023-12-10 10:21:30 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2023-12-10 10:21:32 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias
2023-12-10 10:21:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-10 10:21:32 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.392 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-12-10 10:21:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-10 10:21:32 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-12-10 10:21:32 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-12-10 10:21:32 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt
2023-12-10 10:21:32 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt
2023-12-10 10:21:32 | INFO | fairseq.trainer | loading train data for epoch 1
2023-12-10 10:21:32 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2023-12-10 10:21:32 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2023-12-10 10:21:32 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2023-12-10 10:21:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:21:32 | INFO | fairseq.trainer | begin training epoch 1
2023-12-10 10:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:21:38 | INFO | train_inner | {"epoch": 1, "update": 0.091, "loss": "11.659", "nll_loss": "11.489", "ppl": "2874.07", "wps": "65237.9", "ups": "18.53", "wpb": "3517.4", "bsz": "142.7", "num_updates": "100", "lr": "0.00025", "gnorm": "0.554", "loss_scale": "128", "train_wall": "6", "gb_free": "39", "wall": "6"}
2023-12-10 10:21:43 | INFO | train_inner | {"epoch": 1, "update": 0.181, "loss": "9.976", "nll_loss": "9.493", "ppl": "720.7", "wps": "68211.1", "ups": "18.64", "wpb": "3660.1", "bsz": "124.2", "num_updates": "200", "lr": "0.0005", "gnorm": "0.675", "loss_scale": "128", "train_wall": "5", "gb_free": "38.9", "wall": "11"}
2023-12-10 10:21:49 | INFO | train_inner | {"epoch": 1, "update": 0.272, "loss": "9.7", "nll_loss": "9.188", "ppl": "583.06", "wps": "63926.5", "ups": "18.07", "wpb": "3537.5", "bsz": "135.2", "num_updates": "300", "lr": "0.00075", "gnorm": "0.822", "loss_scale": "128", "train_wall": "5", "gb_free": "39", "wall": "17"}
2023-12-10 10:21:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-12-10 10:21:54 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "9.404", "nll_loss": "8.85", "ppl": "461.51", "wps": "61549.1", "ups": "17.44", "wpb": "3528.5", "bsz": "139.2", "num_updates": "400", "lr": "0.001", "gnorm": "0.71", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "23"}
2023-12-10 10:21:59 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "8.871", "nll_loss": "8.234", "ppl": "301.03", "wps": "75051.3", "ups": "20.68", "wpb": "3629.4", "bsz": "149.3", "num_updates": "500", "lr": "0.00125", "gnorm": "0.562", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "27"}
2023-12-10 10:22:04 | INFO | train_inner | {"epoch": 1, "update": 0.545, "loss": "8.48", "nll_loss": "7.775", "ppl": "219.03", "wps": "77983.8", "ups": "21.6", "wpb": "3610.1", "bsz": "157.2", "num_updates": "600", "lr": "0.0015", "gnorm": "0.53", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "32"}
2023-12-10 10:22:10 | INFO | train_inner | {"epoch": 1, "update": 0.636, "loss": "8.297", "nll_loss": "7.562", "ppl": "188.96", "wps": "61533.6", "ups": "17.52", "wpb": "3511.7", "bsz": "137.5", "num_updates": "700", "lr": "0.00175", "gnorm": "0.469", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "38"}
2023-12-10 10:22:15 | INFO | train_inner | {"epoch": 1, "update": 0.727, "loss": "7.876", "nll_loss": "7.074", "ppl": "134.71", "wps": "73662.8", "ups": "20.32", "wpb": "3625.5", "bsz": "153.3", "num_updates": "800", "lr": "0.002", "gnorm": "0.488", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "43"}
2023-12-10 10:22:20 | INFO | train_inner | {"epoch": 1, "update": 0.818, "loss": "7.497", "nll_loss": "6.632", "ppl": "99.16", "wps": "69012.7", "ups": "19.02", "wpb": "3629.3", "bsz": "146.2", "num_updates": "900", "lr": "0.00225", "gnorm": "0.474", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "48"}
2023-12-10 10:22:25 | INFO | train_inner | {"epoch": 1, "update": 0.908, "loss": "7.129", "nll_loss": "6.201", "ppl": "73.58", "wps": "70509.3", "ups": "19.74", "wpb": "3571.5", "bsz": "162.8", "num_updates": "1000", "lr": "0.0025", "gnorm": "0.517", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "53"}
2023-12-10 10:22:30 | INFO | train_inner | {"epoch": 1, "update": 0.999, "loss": "6.866", "nll_loss": "5.889", "ppl": "59.27", "wps": "65910", "ups": "18.35", "wpb": "3591.7", "bsz": "151.5", "num_updates": "1100", "lr": "0.00275", "gnorm": "0.479", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "58"}
2023-12-10 10:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:22:32 | INFO | valid | {"epoch": 1, "valid_loss": "6.608", "valid_nll_loss": "5.597", "valid_ppl": "48.39", "valid_wps": "135758", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "1101"}
2023-12-10 10:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1101 updates
2023-12-10 10:22:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint1.pt
2023-12-10 10:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint1.pt
2023-12-10 10:22:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 1101 updates, score 6.608) (writing took 2.4419947690330446 seconds)
2023-12-10 10:22:34 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-12-10 10:22:34 | INFO | train | {"epoch": 1, "train_loss": "8.697", "train_nll_loss": "8.026", "train_ppl": "260.62", "train_wps": "63818.1", "train_ups": "17.81", "train_wpb": "3583.2", "train_bsz": "145.4", "train_num_updates": "1101", "train_lr": "0.0027525", "train_gnorm": "0.571", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "62"}
2023-12-10 10:22:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:22:34 | INFO | fairseq.trainer | begin training epoch 2
2023-12-10 10:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:22:40 | INFO | train_inner | {"epoch": 2, "update": 1.09, "loss": "6.596", "nll_loss": "5.569", "ppl": "47.47", "wps": "38744.9", "ups": "10.87", "wpb": "3564.6", "bsz": "151.8", "num_updates": "1200", "lr": "0.003", "gnorm": "0.424", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "68"}
2023-12-10 10:22:45 | INFO | train_inner | {"epoch": 2, "update": 1.181, "loss": "6.405", "nll_loss": "5.34", "ppl": "40.49", "wps": "72119.1", "ups": "19.96", "wpb": "3612.5", "bsz": "149.6", "num_updates": "1300", "lr": "0.00325", "gnorm": "0.446", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "73"}
2023-12-10 10:22:50 | INFO | train_inner | {"epoch": 2, "update": 1.271, "loss": "6.281", "nll_loss": "5.19", "ppl": "36.51", "wps": "62015.5", "ups": "17.35", "wpb": "3574.3", "bsz": "136", "num_updates": "1400", "lr": "0.0035", "gnorm": "0.42", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "78"}
2023-12-10 10:22:56 | INFO | train_inner | {"epoch": 2, "update": 1.362, "loss": "6.165", "nll_loss": "5.05", "ppl": "33.12", "wps": "63110.1", "ups": "17.38", "wpb": "3630.6", "bsz": "128.6", "num_updates": "1500", "lr": "0.00375", "gnorm": "0.412", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "84"}
2023-12-10 10:23:02 | INFO | train_inner | {"epoch": 2, "update": 1.453, "loss": "6.048", "nll_loss": "4.912", "ppl": "30.11", "wps": "64965.1", "ups": "18.15", "wpb": "3580.2", "bsz": "127.6", "num_updates": "1600", "lr": "0.004", "gnorm": "0.384", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "90"}
2023-12-10 10:23:07 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "5.872", "nll_loss": "4.704", "ppl": "26.07", "wps": "69378.6", "ups": "19.37", "wpb": "3580.9", "bsz": "155.2", "num_updates": "1700", "lr": "0.00425", "gnorm": "0.401", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "95"}
2023-12-10 10:23:12 | INFO | train_inner | {"epoch": 2, "update": 1.634, "loss": "5.773", "nll_loss": "4.59", "ppl": "24.08", "wps": "68202.2", "ups": "19.19", "wpb": "3554.4", "bsz": "159.3", "num_updates": "1800", "lr": "0.0045", "gnorm": "0.396", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "100"}
2023-12-10 10:23:17 | INFO | train_inner | {"epoch": 2, "update": 1.725, "loss": "5.748", "nll_loss": "4.561", "ppl": "23.61", "wps": "68736.7", "ups": "19.32", "wpb": "3557.9", "bsz": "142.7", "num_updates": "1900", "lr": "0.00475", "gnorm": "0.351", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "105"}
2023-12-10 10:23:22 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "5.58", "nll_loss": "4.365", "ppl": "20.6", "wps": "74780.2", "ups": "20.81", "wpb": "3594", "bsz": "168.9", "num_updates": "2000", "lr": "0.005", "gnorm": "0.36", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "110"}
2023-12-10 10:23:27 | INFO | train_inner | {"epoch": 2, "update": 1.907, "loss": "5.601", "nll_loss": "4.389", "ppl": "20.95", "wps": "66774", "ups": "18.62", "wpb": "3586.3", "bsz": "147.7", "num_updates": "2100", "lr": "0.00525", "gnorm": "0.333", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "115"}
2023-12-10 10:23:33 | INFO | train_inner | {"epoch": 2, "update": 1.997, "loss": "5.651", "nll_loss": "4.445", "ppl": "21.78", "wps": "64573.9", "ups": "18.01", "wpb": "3585.7", "bsz": "133", "num_updates": "2200", "lr": "0.0055", "gnorm": "0.352", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "121"}
2023-12-10 10:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:23:34 | INFO | valid | {"epoch": 2, "valid_loss": "5.356", "valid_nll_loss": "4.131", "valid_ppl": "17.52", "valid_wps": "130545", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "2203", "valid_best_loss": "5.356"}
2023-12-10 10:23:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2203 updates
2023-12-10 10:23:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint2.pt
2023-12-10 10:23:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint2.pt
2023-12-10 10:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 2203 updates, score 5.356) (writing took 2.3081784239038825 seconds)
2023-12-10 10:23:37 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-12-10 10:23:37 | INFO | train | {"epoch": 2, "train_loss": "5.974", "train_nll_loss": "4.828", "train_ppl": "28.4", "train_wps": "63199.2", "train_ups": "17.64", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "2203", "train_lr": "0.0055075", "train_gnorm": "0.389", "train_loss_scale": "64", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "125"}
2023-12-10 10:23:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:23:37 | INFO | fairseq.trainer | begin training epoch 3
2023-12-10 10:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:23:42 | INFO | train_inner | {"epoch": 3, "update": 2.088, "loss": "5.469", "nll_loss": "4.23", "ppl": "18.76", "wps": "39077.7", "ups": "10.86", "wpb": "3599.9", "bsz": "138", "num_updates": "2300", "lr": "0.00575", "gnorm": "0.333", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "130"}
2023-12-10 10:23:48 | INFO | train_inner | {"epoch": 3, "update": 2.179, "loss": "5.531", "nll_loss": "4.301", "ppl": "19.71", "wps": "63570.7", "ups": "18.06", "wpb": "3519.4", "bsz": "132.2", "num_updates": "2400", "lr": "0.006", "gnorm": "0.34", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "136"}
2023-12-10 10:23:53 | INFO | train_inner | {"epoch": 3, "update": 2.27, "loss": "5.41", "nll_loss": "4.162", "ppl": "17.9", "wps": "68901", "ups": "19.39", "wpb": "3553.2", "bsz": "154.2", "num_updates": "2500", "lr": "0.00625", "gnorm": "0.326", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "141"}
2023-12-10 10:23:58 | INFO | train_inner | {"epoch": 3, "update": 2.36, "loss": "5.432", "nll_loss": "4.185", "ppl": "18.19", "wps": "64693", "ups": "17.83", "wpb": "3627.9", "bsz": "141.1", "num_updates": "2600", "lr": "0.0065", "gnorm": "0.326", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "146"}
2023-12-10 10:24:04 | INFO | train_inner | {"epoch": 3, "update": 2.451, "loss": "5.351", "nll_loss": "4.091", "ppl": "17.05", "wps": "68484.7", "ups": "19.05", "wpb": "3594.2", "bsz": "156.9", "num_updates": "2700", "lr": "0.00675", "gnorm": "0.32", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "152"}
2023-12-10 10:24:09 | INFO | train_inner | {"epoch": 3, "update": 2.542, "loss": "5.377", "nll_loss": "4.12", "ppl": "17.39", "wps": "69556.4", "ups": "19.29", "wpb": "3605", "bsz": "143.3", "num_updates": "2800", "lr": "0.007", "gnorm": "0.316", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "157"}
2023-12-10 10:24:15 | INFO | train_inner | {"epoch": 3, "update": 2.632, "loss": "5.388", "nll_loss": "4.13", "ppl": "17.51", "wps": "59987.3", "ups": "16.84", "wpb": "3561.3", "bsz": "158.6", "num_updates": "2900", "lr": "0.00725", "gnorm": "0.333", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "163"}
2023-12-10 10:24:20 | INFO | train_inner | {"epoch": 3, "update": 2.723, "loss": "5.417", "nll_loss": "4.167", "ppl": "17.96", "wps": "67251.4", "ups": "18.92", "wpb": "3554.7", "bsz": "146.7", "num_updates": "3000", "lr": "0.0075", "gnorm": "0.314", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "168"}
2023-12-10 10:24:25 | INFO | train_inner | {"epoch": 3, "update": 2.814, "loss": "5.38", "nll_loss": "4.117", "ppl": "17.35", "wps": "67510.9", "ups": "18.54", "wpb": "3642.1", "bsz": "135.7", "num_updates": "3100", "lr": "0.00775", "gnorm": "0.319", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "174"}
2023-12-10 10:24:31 | INFO | train_inner | {"epoch": 3, "update": 2.905, "loss": "5.433", "nll_loss": "4.173", "ppl": "18.04", "wps": "61419.6", "ups": "17.45", "wpb": "3519.6", "bsz": "148.4", "num_updates": "3200", "lr": "0.008", "gnorm": "0.338", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "179"}
2023-12-10 10:24:36 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "5.374", "nll_loss": "4.113", "ppl": "17.31", "wps": "72715.4", "ups": "19.97", "wpb": "3640.8", "bsz": "141.5", "num_updates": "3300", "lr": "0.00825", "gnorm": "0.299", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "184"}
2023-12-10 10:24:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:24:38 | INFO | valid | {"epoch": 3, "valid_loss": "5.127", "valid_nll_loss": "3.867", "valid_ppl": "14.59", "valid_wps": "131004", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "3305", "valid_best_loss": "5.127"}
2023-12-10 10:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3305 updates
2023-12-10 10:24:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint3.pt
2023-12-10 10:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint3.pt
2023-12-10 10:24:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 3305 updates, score 5.127) (writing took 2.243904309812933 seconds)
2023-12-10 10:24:40 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-12-10 10:24:40 | INFO | train | {"epoch": 3, "train_loss": "5.412", "train_nll_loss": "4.16", "train_ppl": "17.87", "train_wps": "62402.8", "train_ups": "17.41", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "3305", "train_lr": "0.0082625", "train_gnorm": "0.324", "train_loss_scale": "64", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "188"}
2023-12-10 10:24:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:24:40 | INFO | fairseq.trainer | begin training epoch 4
2023-12-10 10:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:24:45 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "5.198", "nll_loss": "3.899", "ppl": "14.92", "wps": "38373.4", "ups": "10.75", "wpb": "3568.5", "bsz": "145.2", "num_updates": "3400", "lr": "0.0085", "gnorm": "0.309", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "194"}
2023-12-10 10:24:51 | INFO | train_inner | {"epoch": 4, "update": 3.177, "loss": "5.324", "nll_loss": "4.046", "ppl": "16.51", "wps": "62588.8", "ups": "17.67", "wpb": "3542.3", "bsz": "138.9", "num_updates": "3500", "lr": "0.00875", "gnorm": "0.321", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "199"}
2023-12-10 10:24:56 | INFO | train_inner | {"epoch": 4, "update": 3.268, "loss": "5.29", "nll_loss": "4.004", "ppl": "16.04", "wps": "68519.4", "ups": "18.72", "wpb": "3660.5", "bsz": "156.7", "num_updates": "3600", "lr": "0.009", "gnorm": "0.317", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "205"}
2023-12-10 10:25:02 | INFO | train_inner | {"epoch": 4, "update": 3.358, "loss": "5.373", "nll_loss": "4.098", "ppl": "17.13", "wps": "65411.3", "ups": "18.3", "wpb": "3574.1", "bsz": "135.4", "num_updates": "3700", "lr": "0.00925", "gnorm": "0.313", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "210"}
2023-12-10 10:25:08 | INFO | train_inner | {"epoch": 4, "update": 3.449, "loss": "5.373", "nll_loss": "4.099", "ppl": "17.13", "wps": "61801.2", "ups": "17.14", "wpb": "3605.7", "bsz": "133.2", "num_updates": "3800", "lr": "0.0095", "gnorm": "0.312", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "216"}
2023-12-10 10:25:13 | INFO | train_inner | {"epoch": 4, "update": 3.54, "loss": "5.33", "nll_loss": "4.048", "ppl": "16.54", "wps": "72293.8", "ups": "20.1", "wpb": "3597.3", "bsz": "149.1", "num_updates": "3900", "lr": "0.00975", "gnorm": "0.31", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "221"}
2023-12-10 10:25:18 | INFO | train_inner | {"epoch": 4, "update": 3.631, "loss": "5.418", "nll_loss": "4.148", "ppl": "17.73", "wps": "63279.8", "ups": "17.89", "wpb": "3537.2", "bsz": "128.1", "num_updates": "4000", "lr": "0.01", "gnorm": "0.319", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "226"}
2023-12-10 10:25:24 | INFO | train_inner | {"epoch": 4, "update": 3.721, "loss": "5.334", "nll_loss": "4.053", "ppl": "16.59", "wps": "67271.2", "ups": "18.85", "wpb": "3568.2", "bsz": "152.2", "num_updates": "4100", "lr": "0.0098773", "gnorm": "0.314", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "232"}
2023-12-10 10:25:29 | INFO | train_inner | {"epoch": 4, "update": 3.812, "loss": "5.332", "nll_loss": "4.042", "ppl": "16.48", "wps": "67984.5", "ups": "18.76", "wpb": "3623.5", "bsz": "154.4", "num_updates": "4200", "lr": "0.009759", "gnorm": "0.344", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "237"}
2023-12-10 10:25:35 | INFO | train_inner | {"epoch": 4, "update": 3.903, "loss": "5.322", "nll_loss": "4.037", "ppl": "16.42", "wps": "63238.4", "ups": "17.89", "wpb": "3534.9", "bsz": "162.6", "num_updates": "4300", "lr": "0.00964486", "gnorm": "0.329", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "243"}
2023-12-10 10:25:40 | INFO | train_inner | {"epoch": 4, "update": 3.994, "loss": "5.319", "nll_loss": "4.034", "ppl": "16.38", "wps": "65491.9", "ups": "18.2", "wpb": "3598.6", "bsz": "147.8", "num_updates": "4400", "lr": "0.00953463", "gnorm": "0.301", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "248"}
2023-12-10 10:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:25:42 | INFO | valid | {"epoch": 4, "valid_loss": "5.058", "valid_nll_loss": "3.786", "valid_ppl": "13.8", "valid_wps": "131836", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "4407", "valid_best_loss": "5.058"}
2023-12-10 10:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4407 updates
2023-12-10 10:25:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint4.pt
2023-12-10 10:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint4.pt
2023-12-10 10:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 4407 updates, score 5.058) (writing took 2.24607377871871 seconds)
2023-12-10 10:25:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-12-10 10:25:44 | INFO | train | {"epoch": 4, "train_loss": "5.33", "train_nll_loss": "4.048", "train_ppl": "16.54", "train_wps": "61657.4", "train_ups": "17.21", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "4407", "train_lr": "0.00952705", "train_gnorm": "0.317", "train_loss_scale": "64", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "252"}
2023-12-10 10:25:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:25:44 | INFO | fairseq.trainer | begin training epoch 5
2023-12-10 10:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:25:49 | INFO | train_inner | {"epoch": 5, "update": 4.084, "loss": "5.192", "nll_loss": "3.883", "ppl": "14.75", "wps": "39000.4", "ups": "10.93", "wpb": "3569.1", "bsz": "141", "num_updates": "4500", "lr": "0.00942809", "gnorm": "0.306", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "257"}
2023-12-10 10:25:54 | INFO | train_inner | {"epoch": 5, "update": 4.175, "loss": "5.183", "nll_loss": "3.872", "ppl": "14.64", "wps": "74030.3", "ups": "20.53", "wpb": "3606.2", "bsz": "153.2", "num_updates": "4600", "lr": "0.00932505", "gnorm": "0.309", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "262"}
2023-12-10 10:26:00 | INFO | train_inner | {"epoch": 5, "update": 4.266, "loss": "5.226", "nll_loss": "3.921", "ppl": "15.15", "wps": "64360.8", "ups": "17.98", "wpb": "3580.1", "bsz": "140.4", "num_updates": "4700", "lr": "0.00922531", "gnorm": "0.319", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "268"}
2023-12-10 10:26:05 | INFO | train_inner | {"epoch": 5, "update": 4.357, "loss": "5.171", "nll_loss": "3.862", "ppl": "14.54", "wps": "65708.3", "ups": "18.67", "wpb": "3519.3", "bsz": "144.6", "num_updates": "4800", "lr": "0.00912871", "gnorm": "0.299", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "273"}
2023-12-10 10:26:10 | INFO | train_inner | {"epoch": 5, "update": 4.447, "loss": "5.171", "nll_loss": "3.864", "ppl": "14.56", "wps": "66225.6", "ups": "18.4", "wpb": "3599.2", "bsz": "146.1", "num_updates": "4900", "lr": "0.00903508", "gnorm": "0.31", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "279"}
2023-12-10 10:26:16 | INFO | train_inner | {"epoch": 5, "update": 4.538, "loss": "5.165", "nll_loss": "3.858", "ppl": "14.5", "wps": "66836.2", "ups": "18.56", "wpb": "3601", "bsz": "149.8", "num_updates": "5000", "lr": "0.00894427", "gnorm": "0.315", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "284"}
2023-12-10 10:26:21 | INFO | train_inner | {"epoch": 5, "update": 4.629, "loss": "5.156", "nll_loss": "3.848", "ppl": "14.4", "wps": "67022.8", "ups": "18.65", "wpb": "3592.8", "bsz": "144.1", "num_updates": "5100", "lr": "0.00885615", "gnorm": "0.303", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "289"}
2023-12-10 10:26:26 | INFO | train_inner | {"epoch": 5, "update": 4.72, "loss": "5.131", "nll_loss": "3.82", "ppl": "14.12", "wps": "68449", "ups": "18.77", "wpb": "3646.4", "bsz": "152.2", "num_updates": "5200", "lr": "0.00877058", "gnorm": "0.309", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "295"}
2023-12-10 10:26:33 | INFO | train_inner | {"epoch": 5, "update": 4.81, "loss": "5.256", "nll_loss": "3.962", "ppl": "15.59", "wps": "56923.8", "ups": "16.18", "wpb": "3517.7", "bsz": "126.9", "num_updates": "5300", "lr": "0.00868744", "gnorm": "0.336", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "301"}
2023-12-10 10:26:38 | INFO | train_inner | {"epoch": 5, "update": 4.901, "loss": "5.137", "nll_loss": "3.829", "ppl": "14.21", "wps": "62191.9", "ups": "17.44", "wpb": "3565.4", "bsz": "144.8", "num_updates": "5400", "lr": "0.00860663", "gnorm": "0.297", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "307"}
2023-12-10 10:26:44 | INFO | train_inner | {"epoch": 5, "update": 4.992, "loss": "5.073", "nll_loss": "3.758", "ppl": "13.53", "wps": "70487.7", "ups": "19.38", "wpb": "3636.6", "bsz": "155.8", "num_updates": "5500", "lr": "0.00852803", "gnorm": "0.289", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "312"}
2023-12-10 10:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:26:46 | INFO | valid | {"epoch": 5, "valid_loss": "4.953", "valid_nll_loss": "3.663", "valid_ppl": "12.66", "valid_wps": "121268", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "5509", "valid_best_loss": "4.953"}
2023-12-10 10:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5509 updates
2023-12-10 10:26:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint5.pt
2023-12-10 10:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint5.pt
2023-12-10 10:26:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 5509 updates, score 4.953) (writing took 2.2301724907010794 seconds)
2023-12-10 10:26:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-12-10 10:26:48 | INFO | train | {"epoch": 5, "train_loss": "5.168", "train_nll_loss": "3.86", "train_ppl": "14.52", "train_wps": "61817.6", "train_ups": "17.25", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "5509", "train_lr": "0.00852106", "train_gnorm": "0.309", "train_loss_scale": "64", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "316"}
2023-12-10 10:26:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:26:48 | INFO | fairseq.trainer | begin training epoch 6
2023-12-10 10:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:26:53 | INFO | train_inner | {"epoch": 6, "update": 5.083, "loss": "5.028", "nll_loss": "3.699", "ppl": "12.99", "wps": "36897.6", "ups": "10.32", "wpb": "3575.9", "bsz": "143.2", "num_updates": "5600", "lr": "0.00845154", "gnorm": "0.3", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "321"}
2023-12-10 10:26:59 | INFO | train_inner | {"epoch": 6, "update": 5.173, "loss": "4.998", "nll_loss": "3.662", "ppl": "12.65", "wps": "61084", "ups": "17.18", "wpb": "3556.2", "bsz": "140.3", "num_updates": "5700", "lr": "0.00837708", "gnorm": "0.309", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "327"}
2023-12-10 10:27:05 | INFO | train_inner | {"epoch": 6, "update": 5.264, "loss": "5.102", "nll_loss": "3.785", "ppl": "13.79", "wps": "60829.5", "ups": "17.4", "wpb": "3495.5", "bsz": "124.5", "num_updates": "5800", "lr": "0.00830455", "gnorm": "0.31", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "333"}
2023-12-10 10:27:10 | INFO | train_inner | {"epoch": 6, "update": 5.355, "loss": "4.955", "nll_loss": "3.618", "ppl": "12.28", "wps": "63067.5", "ups": "17.69", "wpb": "3565.6", "bsz": "163.2", "num_updates": "5900", "lr": "0.00823387", "gnorm": "0.289", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "339"}
2023-12-10 10:27:16 | INFO | train_inner | {"epoch": 6, "update": 5.446, "loss": "5.037", "nll_loss": "3.714", "ppl": "13.12", "wps": "67798.8", "ups": "18.92", "wpb": "3582.9", "bsz": "137", "num_updates": "6000", "lr": "0.00816497", "gnorm": "0.299", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "344"}
2023-12-10 10:27:21 | INFO | train_inner | {"epoch": 6, "update": 5.536, "loss": "4.932", "nll_loss": "3.599", "ppl": "12.12", "wps": "75250.2", "ups": "20.65", "wpb": "3644.8", "bsz": "164.7", "num_updates": "6100", "lr": "0.00809776", "gnorm": "0.275", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "349"}
2023-12-10 10:27:26 | INFO | train_inner | {"epoch": 6, "update": 5.627, "loss": "4.982", "nll_loss": "3.654", "ppl": "12.59", "wps": "73157.7", "ups": "20.38", "wpb": "3590.6", "bsz": "151.3", "num_updates": "6200", "lr": "0.00803219", "gnorm": "0.299", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "354"}
2023-12-10 10:27:31 | INFO | train_inner | {"epoch": 6, "update": 5.718, "loss": "4.991", "nll_loss": "3.663", "ppl": "12.66", "wps": "65930.8", "ups": "18.11", "wpb": "3640.3", "bsz": "140.2", "num_updates": "6300", "lr": "0.00796819", "gnorm": "0.287", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "359"}
2023-12-10 10:27:37 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "5.091", "nll_loss": "3.776", "ppl": "13.7", "wps": "61753.6", "ups": "17.44", "wpb": "3540.4", "bsz": "134.2", "num_updates": "6400", "lr": "0.00790569", "gnorm": "0.315", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "365"}
2023-12-10 10:27:42 | INFO | train_inner | {"epoch": 6, "update": 5.899, "loss": "5.021", "nll_loss": "3.7", "ppl": "12.99", "wps": "64906.4", "ups": "18.31", "wpb": "3545.5", "bsz": "143.3", "num_updates": "6500", "lr": "0.00784465", "gnorm": "0.296", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "370"}
2023-12-10 10:27:47 | INFO | train_inner | {"epoch": 6, "update": 5.99, "loss": "4.9", "nll_loss": "3.562", "ppl": "11.81", "wps": "71010.2", "ups": "19.4", "wpb": "3661.2", "bsz": "154.2", "num_updates": "6600", "lr": "0.00778499", "gnorm": "0.283", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "376"}
2023-12-10 10:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:27:49 | INFO | valid | {"epoch": 6, "valid_loss": "4.806", "valid_nll_loss": "3.512", "valid_ppl": "11.41", "valid_wps": "131972", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "6611", "valid_best_loss": "4.806"}
2023-12-10 10:27:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6611 updates
2023-12-10 10:27:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint6.pt
2023-12-10 10:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint6.pt
2023-12-10 10:27:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint6.pt (epoch 6 @ 6611 updates, score 4.806) (writing took 2.3168842080049217 seconds)
2023-12-10 10:27:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-12-10 10:27:52 | INFO | train | {"epoch": 6, "train_loss": "5.001", "train_nll_loss": "3.673", "train_ppl": "12.75", "train_wps": "62053.4", "train_ups": "17.32", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "6611", "train_lr": "0.00777851", "train_gnorm": "0.297", "train_loss_scale": "64", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "380"}
2023-12-10 10:27:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:27:52 | INFO | fairseq.trainer | begin training epoch 7
2023-12-10 10:27:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:27:56 | INFO | train_inner | {"epoch": 7, "update": 6.081, "loss": "4.86", "nll_loss": "3.51", "ppl": "11.39", "wps": "39284.9", "ups": "10.98", "wpb": "3579", "bsz": "152.5", "num_updates": "6700", "lr": "0.00772667", "gnorm": "0.305", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "385"}
2023-12-10 10:28:03 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "4.876", "nll_loss": "3.528", "ppl": "11.54", "wps": "57794.9", "ups": "16.22", "wpb": "3562.8", "bsz": "139.3", "num_updates": "6800", "lr": "0.00766965", "gnorm": "0.287", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "391"}
2023-12-10 10:28:08 | INFO | train_inner | {"epoch": 7, "update": 6.262, "loss": "4.824", "nll_loss": "3.472", "ppl": "11.09", "wps": "74849", "ups": "20.52", "wpb": "3647.1", "bsz": "146.1", "num_updates": "6900", "lr": "0.00761387", "gnorm": "0.274", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "396"}
2023-12-10 10:28:13 | INFO | train_inner | {"epoch": 7, "update": 6.353, "loss": "4.949", "nll_loss": "3.615", "ppl": "12.26", "wps": "62180.5", "ups": "17.51", "wpb": "3551.8", "bsz": "130.2", "num_updates": "7000", "lr": "0.00755929", "gnorm": "0.287", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "401"}
2023-12-10 10:28:18 | INFO | train_inner | {"epoch": 7, "update": 6.444, "loss": "4.867", "nll_loss": "3.521", "ppl": "11.48", "wps": "68807.3", "ups": "19.17", "wpb": "3588.5", "bsz": "148.6", "num_updates": "7100", "lr": "0.00750587", "gnorm": "0.286", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "407"}
2023-12-10 10:28:24 | INFO | train_inner | {"epoch": 7, "update": 6.534, "loss": "4.9", "nll_loss": "3.56", "ppl": "11.79", "wps": "65279.7", "ups": "18.3", "wpb": "3568.1", "bsz": "143", "num_updates": "7200", "lr": "0.00745356", "gnorm": "0.294", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "412"}
2023-12-10 10:28:29 | INFO | train_inner | {"epoch": 7, "update": 6.625, "loss": "4.867", "nll_loss": "3.524", "ppl": "11.51", "wps": "78130.1", "ups": "21.61", "wpb": "3614.9", "bsz": "161.8", "num_updates": "7300", "lr": "0.00740233", "gnorm": "0.288", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "417"}
2023-12-10 10:28:34 | INFO | train_inner | {"epoch": 7, "update": 6.716, "loss": "4.874", "nll_loss": "3.533", "ppl": "11.58", "wps": "72071.8", "ups": "20.14", "wpb": "3578", "bsz": "152.2", "num_updates": "7400", "lr": "0.00735215", "gnorm": "0.279", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "422"}
2023-12-10 10:28:39 | INFO | train_inner | {"epoch": 7, "update": 6.807, "loss": "4.901", "nll_loss": "3.563", "ppl": "11.82", "wps": "68797.5", "ups": "19.15", "wpb": "3593.5", "bsz": "142.6", "num_updates": "7500", "lr": "0.00730297", "gnorm": "0.284", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "427"}
2023-12-10 10:28:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-10 10:28:44 | INFO | train_inner | {"epoch": 7, "update": 6.898, "loss": "4.883", "nll_loss": "3.543", "ppl": "11.65", "wps": "65715.7", "ups": "18.41", "wpb": "3568.8", "bsz": "149", "num_updates": "7600", "lr": "0.00725476", "gnorm": "0.299", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "432"}
2023-12-10 10:28:49 | INFO | train_inner | {"epoch": 7, "update": 6.989, "loss": "4.906", "nll_loss": "3.571", "ppl": "11.89", "wps": "68130.7", "ups": "19.02", "wpb": "3582.2", "bsz": "138.2", "num_updates": "7700", "lr": "0.0072075", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "438"}
2023-12-10 10:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:28:51 | INFO | valid | {"epoch": 7, "valid_loss": "4.72", "valid_nll_loss": "3.357", "valid_ppl": "10.25", "valid_wps": "131753", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "7712", "valid_best_loss": "4.72"}
2023-12-10 10:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7712 updates
2023-12-10 10:28:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint7.pt
2023-12-10 10:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint7.pt
2023-12-10 10:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint7.pt (epoch 7 @ 7712 updates, score 4.72) (writing took 2.3626424348913133 seconds)
2023-12-10 10:28:54 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-12-10 10:28:54 | INFO | train | {"epoch": 7, "train_loss": "4.882", "train_nll_loss": "3.539", "train_ppl": "11.63", "train_wps": "63364.5", "train_ups": "17.68", "train_wpb": "3583.3", "train_bsz": "145.5", "train_num_updates": "7712", "train_lr": "0.00720189", "train_gnorm": "0.287", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "442"}
2023-12-10 10:28:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:28:54 | INFO | fairseq.trainer | begin training epoch 8
2023-12-10 10:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:28:59 | INFO | train_inner | {"epoch": 8, "update": 7.08, "loss": "4.771", "nll_loss": "3.41", "ppl": "10.63", "wps": "38893.9", "ups": "10.64", "wpb": "3655.3", "bsz": "135.4", "num_updates": "7800", "lr": "0.00716115", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "447"}
2023-12-10 10:29:04 | INFO | train_inner | {"epoch": 8, "update": 7.171, "loss": "4.704", "nll_loss": "3.337", "ppl": "10.1", "wps": "77123.4", "ups": "21.27", "wpb": "3626.6", "bsz": "158.2", "num_updates": "7900", "lr": "0.00711568", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "452"}
2023-12-10 10:29:09 | INFO | train_inner | {"epoch": 8, "update": 7.261, "loss": "4.797", "nll_loss": "3.441", "ppl": "10.86", "wps": "66396.8", "ups": "18.73", "wpb": "3544.9", "bsz": "140.7", "num_updates": "8000", "lr": "0.00707107", "gnorm": "0.281", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "457"}
2023-12-10 10:29:14 | INFO | train_inner | {"epoch": 8, "update": 7.352, "loss": "4.768", "nll_loss": "3.41", "ppl": "10.63", "wps": "64725.5", "ups": "18.23", "wpb": "3550.4", "bsz": "149.4", "num_updates": "8100", "lr": "0.00702728", "gnorm": "0.28", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "462"}
2023-12-10 10:29:19 | INFO | train_inner | {"epoch": 8, "update": 7.443, "loss": "4.742", "nll_loss": "3.379", "ppl": "10.4", "wps": "71283.5", "ups": "19.68", "wpb": "3622.5", "bsz": "162.6", "num_updates": "8200", "lr": "0.0069843", "gnorm": "0.298", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "468"}
2023-12-10 10:29:25 | INFO | train_inner | {"epoch": 8, "update": 7.534, "loss": "4.801", "nll_loss": "3.448", "ppl": "10.92", "wps": "67100", "ups": "18.58", "wpb": "3611.3", "bsz": "153.1", "num_updates": "8300", "lr": "0.0069421", "gnorm": "0.285", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "473"}
2023-12-10 10:29:30 | INFO | train_inner | {"epoch": 8, "update": 7.624, "loss": "4.78", "nll_loss": "3.426", "ppl": "10.75", "wps": "67544", "ups": "18.74", "wpb": "3604.9", "bsz": "150.5", "num_updates": "8400", "lr": "0.00690066", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "478"}
2023-12-10 10:29:36 | INFO | train_inner | {"epoch": 8, "update": 7.715, "loss": "4.81", "nll_loss": "3.462", "ppl": "11.02", "wps": "65286.7", "ups": "18.21", "wpb": "3586", "bsz": "140.4", "num_updates": "8500", "lr": "0.00685994", "gnorm": "0.292", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "484"}
2023-12-10 10:29:41 | INFO | train_inner | {"epoch": 8, "update": 7.806, "loss": "4.911", "nll_loss": "3.578", "ppl": "11.94", "wps": "66023.4", "ups": "18.56", "wpb": "3556.8", "bsz": "124.4", "num_updates": "8600", "lr": "0.00681994", "gnorm": "0.304", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "489"}
2023-12-10 10:29:46 | INFO | train_inner | {"epoch": 8, "update": 7.897, "loss": "4.835", "nll_loss": "3.491", "ppl": "11.25", "wps": "63897.6", "ups": "18.36", "wpb": "3480.5", "bsz": "142.5", "num_updates": "8700", "lr": "0.00678064", "gnorm": "0.281", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "495"}
2023-12-10 10:29:52 | INFO | train_inner | {"epoch": 8, "update": 7.987, "loss": "4.808", "nll_loss": "3.459", "ppl": "11", "wps": "63585.1", "ups": "17.91", "wpb": "3550.8", "bsz": "140", "num_updates": "8800", "lr": "0.006742", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "500"}
2023-12-10 10:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:29:54 | INFO | valid | {"epoch": 8, "valid_loss": "4.661", "valid_nll_loss": "3.326", "valid_ppl": "10.03", "valid_wps": "134618", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "8814", "valid_best_loss": "4.661"}
2023-12-10 10:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8814 updates
2023-12-10 10:29:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint8.pt
2023-12-10 10:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint8.pt
2023-12-10 10:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint8.pt (epoch 8 @ 8814 updates, score 4.661) (writing took 10.180924103129655 seconds)
2023-12-10 10:30:05 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-12-10 10:30:05 | INFO | train | {"epoch": 8, "train_loss": "4.79", "train_nll_loss": "3.437", "train_ppl": "10.83", "train_wps": "55347.6", "train_ups": "15.44", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "8814", "train_lr": "0.00673664", "train_gnorm": "0.283", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "513"}
2023-12-10 10:30:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:30:05 | INFO | fairseq.trainer | begin training epoch 9
2023-12-10 10:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:30:10 | INFO | train_inner | {"epoch": 9, "update": 8.078, "loss": "4.628", "nll_loss": "3.249", "ppl": "9.51", "wps": "20027.6", "ups": "5.52", "wpb": "3630.2", "bsz": "152.2", "num_updates": "8900", "lr": "0.00670402", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "518"}
2023-12-10 10:30:16 | INFO | train_inner | {"epoch": 9, "update": 8.169, "loss": "4.736", "nll_loss": "3.372", "ppl": "10.35", "wps": "61355.2", "ups": "17.27", "wpb": "3552.9", "bsz": "120.8", "num_updates": "9000", "lr": "0.00666667", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "524"}
2023-12-10 10:30:22 | INFO | train_inner | {"epoch": 9, "update": 8.26, "loss": "4.735", "nll_loss": "3.371", "ppl": "10.34", "wps": "62230", "ups": "17.5", "wpb": "3555.1", "bsz": "127.5", "num_updates": "9100", "lr": "0.00662994", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "530"}
2023-12-10 10:30:27 | INFO | train_inner | {"epoch": 9, "update": 8.35, "loss": "4.719", "nll_loss": "3.356", "ppl": "10.24", "wps": "65616.8", "ups": "18.06", "wpb": "3633.8", "bsz": "144", "num_updates": "9200", "lr": "0.0065938", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "535"}
2023-12-10 10:30:32 | INFO | train_inner | {"epoch": 9, "update": 8.441, "loss": "4.67", "nll_loss": "3.301", "ppl": "9.85", "wps": "69772.2", "ups": "19.21", "wpb": "3631.8", "bsz": "151.6", "num_updates": "9300", "lr": "0.00655826", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "541"}
2023-12-10 10:30:37 | INFO | train_inner | {"epoch": 9, "update": 8.532, "loss": "4.687", "nll_loss": "3.322", "ppl": "10", "wps": "73099.6", "ups": "20.18", "wpb": "3622.8", "bsz": "152.7", "num_updates": "9400", "lr": "0.00652328", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "546"}
2023-12-10 10:30:43 | INFO | train_inner | {"epoch": 9, "update": 8.623, "loss": "4.741", "nll_loss": "3.384", "ppl": "10.44", "wps": "65895.7", "ups": "18.68", "wpb": "3527.1", "bsz": "151.6", "num_updates": "9500", "lr": "0.00648886", "gnorm": "0.293", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "551"}
2023-12-10 10:30:48 | INFO | train_inner | {"epoch": 9, "update": 8.713, "loss": "4.727", "nll_loss": "3.369", "ppl": "10.33", "wps": "65970.2", "ups": "18.71", "wpb": "3525.8", "bsz": "146.3", "num_updates": "9600", "lr": "0.00645497", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "556"}
2023-12-10 10:30:53 | INFO | train_inner | {"epoch": 9, "update": 8.804, "loss": "4.717", "nll_loss": "3.358", "ppl": "10.25", "wps": "70291.1", "ups": "19.56", "wpb": "3593.4", "bsz": "154.6", "num_updates": "9700", "lr": "0.00642161", "gnorm": "0.287", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "561"}
2023-12-10 10:30:59 | INFO | train_inner | {"epoch": 9, "update": 8.895, "loss": "4.731", "nll_loss": "3.373", "ppl": "10.36", "wps": "64800.6", "ups": "18.16", "wpb": "3567.4", "bsz": "147.7", "num_updates": "9800", "lr": "0.00638877", "gnorm": "0.274", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "567"}
2023-12-10 10:31:04 | INFO | train_inner | {"epoch": 9, "update": 8.985, "loss": "4.713", "nll_loss": "3.355", "ppl": "10.23", "wps": "68328.2", "ups": "19.06", "wpb": "3584", "bsz": "151.4", "num_updates": "9900", "lr": "0.00635642", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "572"}
2023-12-10 10:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:31:06 | INFO | valid | {"epoch": 9, "valid_loss": "4.628", "valid_nll_loss": "3.271", "valid_ppl": "9.66", "valid_wps": "129358", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "9916", "valid_best_loss": "4.628"}
2023-12-10 10:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9916 updates
2023-12-10 10:31:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint9.pt
2023-12-10 10:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint9.pt
2023-12-10 10:31:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint9.pt (epoch 9 @ 9916 updates, score 4.628) (writing took 2.147931362967938 seconds)
2023-12-10 10:31:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-12-10 10:31:08 | INFO | train | {"epoch": 9, "train_loss": "4.709", "train_nll_loss": "3.346", "train_ppl": "10.17", "train_wps": "62451.7", "train_ups": "17.43", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "9916", "train_lr": "0.00635129", "train_gnorm": "0.273", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "577"}
2023-12-10 10:31:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:31:08 | INFO | fairseq.trainer | begin training epoch 10
2023-12-10 10:31:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:31:13 | INFO | train_inner | {"epoch": 10, "update": 9.076, "loss": "4.546", "nll_loss": "3.157", "ppl": "8.92", "wps": "40606.7", "ups": "11.14", "wpb": "3644.3", "bsz": "152.9", "num_updates": "10000", "lr": "0.00632456", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "581"}
2023-12-10 10:31:19 | INFO | train_inner | {"epoch": 10, "update": 9.167, "loss": "4.654", "nll_loss": "3.28", "ppl": "9.71", "wps": "60914", "ups": "17.57", "wpb": "3466.6", "bsz": "134.8", "num_updates": "10100", "lr": "0.00629317", "gnorm": "0.278", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "587"}
2023-12-10 10:31:24 | INFO | train_inner | {"epoch": 10, "update": 9.258, "loss": "4.651", "nll_loss": "3.28", "ppl": "9.71", "wps": "70410.7", "ups": "19.58", "wpb": "3596.6", "bsz": "141.8", "num_updates": "10200", "lr": "0.00626224", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "592"}
2023-12-10 10:31:29 | INFO | train_inner | {"epoch": 10, "update": 9.348, "loss": "4.616", "nll_loss": "3.239", "ppl": "9.44", "wps": "71968.9", "ups": "19.91", "wpb": "3615.5", "bsz": "156.2", "num_updates": "10300", "lr": "0.00623177", "gnorm": "0.274", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "597"}
2023-12-10 10:31:34 | INFO | train_inner | {"epoch": 10, "update": 9.439, "loss": "4.626", "nll_loss": "3.249", "ppl": "9.51", "wps": "67323.4", "ups": "18.5", "wpb": "3639", "bsz": "149.4", "num_updates": "10400", "lr": "0.00620174", "gnorm": "0.282", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "602"}
2023-12-10 10:31:39 | INFO | train_inner | {"epoch": 10, "update": 9.53, "loss": "4.617", "nll_loss": "3.243", "ppl": "9.46", "wps": "72971.1", "ups": "20.11", "wpb": "3628.1", "bsz": "157.4", "num_updates": "10500", "lr": "0.00617213", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "607"}
2023-12-10 10:31:44 | INFO | train_inner | {"epoch": 10, "update": 9.621, "loss": "4.662", "nll_loss": "3.297", "ppl": "9.83", "wps": "66448.2", "ups": "18.9", "wpb": "3515.9", "bsz": "147.8", "num_updates": "10600", "lr": "0.00614295", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "613"}
2023-12-10 10:31:50 | INFO | train_inner | {"epoch": 10, "update": 9.711, "loss": "4.652", "nll_loss": "3.284", "ppl": "9.74", "wps": "69838.9", "ups": "19.43", "wpb": "3594.8", "bsz": "141.4", "num_updates": "10700", "lr": "0.00611418", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "618"}
2023-12-10 10:31:55 | INFO | train_inner | {"epoch": 10, "update": 9.802, "loss": "4.656", "nll_loss": "3.288", "ppl": "9.77", "wps": "66843.7", "ups": "18.36", "wpb": "3640.3", "bsz": "149.8", "num_updates": "10800", "lr": "0.00608581", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "623"}
2023-12-10 10:32:01 | INFO | train_inner | {"epoch": 10, "update": 9.893, "loss": "4.726", "nll_loss": "3.369", "ppl": "10.33", "wps": "58818.8", "ups": "16.66", "wpb": "3530.4", "bsz": "127.9", "num_updates": "10900", "lr": "0.00605783", "gnorm": "0.278", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "629"}
2023-12-10 10:32:07 | INFO | train_inner | {"epoch": 10, "update": 9.984, "loss": "4.731", "nll_loss": "3.376", "ppl": "10.38", "wps": "60746.2", "ups": "17.09", "wpb": "3555.1", "bsz": "141.4", "num_updates": "11000", "lr": "0.00603023", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "635"}
2023-12-10 10:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:32:09 | INFO | valid | {"epoch": 10, "valid_loss": "4.586", "valid_nll_loss": "3.226", "valid_ppl": "9.36", "valid_wps": "131354", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "11018", "valid_best_loss": "4.586"}
2023-12-10 10:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11018 updates
2023-12-10 10:32:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint10.pt
2023-12-10 10:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint10.pt
2023-12-10 10:32:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint10.pt (epoch 10 @ 11018 updates, score 4.586) (writing took 2.288096615113318 seconds)
2023-12-10 10:32:11 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-12-10 10:32:11 | INFO | train | {"epoch": 10, "train_loss": "4.648", "train_nll_loss": "3.278", "train_ppl": "9.7", "train_wps": "62715.3", "train_ups": "17.5", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "11018", "train_lr": "0.0060253", "train_gnorm": "0.272", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "640"}
2023-12-10 10:32:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:32:11 | INFO | fairseq.trainer | begin training epoch 11
2023-12-10 10:32:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:32:16 | INFO | train_inner | {"epoch": 11, "update": 10.074, "loss": "4.534", "nll_loss": "3.144", "ppl": "8.84", "wps": "38800.8", "ups": "10.83", "wpb": "3581.8", "bsz": "146.1", "num_updates": "11100", "lr": "0.006003", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "644"}
2023-12-10 10:32:21 | INFO | train_inner | {"epoch": 11, "update": 10.165, "loss": "4.528", "nll_loss": "3.139", "ppl": "8.81", "wps": "69273.2", "ups": "19.52", "wpb": "3549.4", "bsz": "148.5", "num_updates": "11200", "lr": "0.00597614", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "649"}
2023-12-10 10:32:27 | INFO | train_inner | {"epoch": 11, "update": 10.256, "loss": "4.543", "nll_loss": "3.157", "ppl": "8.92", "wps": "65958.9", "ups": "18.24", "wpb": "3616.4", "bsz": "154.2", "num_updates": "11300", "lr": "0.00594964", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "655"}
2023-12-10 10:32:32 | INFO | train_inner | {"epoch": 11, "update": 10.347, "loss": "4.566", "nll_loss": "3.182", "ppl": "9.07", "wps": "69406.2", "ups": "19.26", "wpb": "3603.5", "bsz": "146.6", "num_updates": "11400", "lr": "0.00592349", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "660"}
2023-12-10 10:32:37 | INFO | train_inner | {"epoch": 11, "update": 10.437, "loss": "4.58", "nll_loss": "3.201", "ppl": "9.19", "wps": "71378", "ups": "19.81", "wpb": "3603.1", "bsz": "147.7", "num_updates": "11500", "lr": "0.00589768", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "665"}
2023-12-10 10:32:42 | INFO | train_inner | {"epoch": 11, "update": 10.528, "loss": "4.609", "nll_loss": "3.235", "ppl": "9.42", "wps": "66952.1", "ups": "18.65", "wpb": "3589.7", "bsz": "143.1", "num_updates": "11600", "lr": "0.0058722", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "670"}
2023-12-10 10:32:48 | INFO | train_inner | {"epoch": 11, "update": 10.619, "loss": "4.614", "nll_loss": "3.241", "ppl": "9.46", "wps": "66843.7", "ups": "18.5", "wpb": "3613", "bsz": "138.9", "num_updates": "11700", "lr": "0.00584705", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "676"}
2023-12-10 10:32:53 | INFO | train_inner | {"epoch": 11, "update": 10.71, "loss": "4.598", "nll_loss": "3.222", "ppl": "9.33", "wps": "65279.9", "ups": "18.22", "wpb": "3582", "bsz": "152.2", "num_updates": "11800", "lr": "0.00582223", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "681"}
2023-12-10 10:32:58 | INFO | train_inner | {"epoch": 11, "update": 10.8, "loss": "4.613", "nll_loss": "3.241", "ppl": "9.46", "wps": "69251.4", "ups": "19.49", "wpb": "3552.7", "bsz": "145.6", "num_updates": "11900", "lr": "0.00579771", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "686"}
2023-12-10 10:33:04 | INFO | train_inner | {"epoch": 11, "update": 10.891, "loss": "4.693", "nll_loss": "3.333", "ppl": "10.07", "wps": "66096.7", "ups": "18.66", "wpb": "3541.4", "bsz": "129.4", "num_updates": "12000", "lr": "0.0057735", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "692"}
2023-12-10 10:33:09 | INFO | train_inner | {"epoch": 11, "update": 10.982, "loss": "4.634", "nll_loss": "3.265", "ppl": "9.61", "wps": "62624.8", "ups": "17.48", "wpb": "3582", "bsz": "141.8", "num_updates": "12100", "lr": "0.0057496", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "698"}
2023-12-10 10:33:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:33:12 | INFO | valid | {"epoch": 11, "valid_loss": "4.563", "valid_nll_loss": "3.209", "valid_ppl": "9.24", "valid_wps": "130612", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "12120", "valid_best_loss": "4.563"}
2023-12-10 10:33:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12120 updates
2023-12-10 10:33:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint11.pt
2023-12-10 10:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint11.pt
2023-12-10 10:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint11.pt (epoch 11 @ 12120 updates, score 4.563) (writing took 2.3219180959276855 seconds)
2023-12-10 10:33:14 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-12-10 10:33:14 | INFO | train | {"epoch": 11, "train_loss": "4.589", "train_nll_loss": "3.211", "train_ppl": "9.26", "train_wps": "63061.3", "train_ups": "17.6", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "12120", "train_lr": "0.00574485", "train_gnorm": "0.264", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "702"}
2023-12-10 10:33:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:33:14 | INFO | fairseq.trainer | begin training epoch 12
2023-12-10 10:33:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:33:19 | INFO | train_inner | {"epoch": 12, "update": 11.073, "loss": "4.474", "nll_loss": "3.08", "ppl": "8.45", "wps": "39293.2", "ups": "10.89", "wpb": "3609.7", "bsz": "151.9", "num_updates": "12200", "lr": "0.00572598", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "707"}
2023-12-10 10:33:25 | INFO | train_inner | {"epoch": 12, "update": 11.163, "loss": "4.532", "nll_loss": "3.142", "ppl": "8.83", "wps": "56877.9", "ups": "16.11", "wpb": "3530.6", "bsz": "131.7", "num_updates": "12300", "lr": "0.00570266", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "713"}
2023-12-10 10:33:30 | INFO | train_inner | {"epoch": 12, "update": 11.254, "loss": "4.553", "nll_loss": "3.167", "ppl": "8.98", "wps": "65057.8", "ups": "18.11", "wpb": "3592.8", "bsz": "141.9", "num_updates": "12400", "lr": "0.00567962", "gnorm": "0.289", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "718"}
2023-12-10 10:33:35 | INFO | train_inner | {"epoch": 12, "update": 11.345, "loss": "4.527", "nll_loss": "3.14", "ppl": "8.82", "wps": "74148.1", "ups": "20.35", "wpb": "3644.1", "bsz": "140.4", "num_updates": "12500", "lr": "0.00565685", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "723"}
2023-12-10 10:33:40 | INFO | train_inner | {"epoch": 12, "update": 11.436, "loss": "4.507", "nll_loss": "3.12", "ppl": "8.69", "wps": "78132.3", "ups": "21.41", "wpb": "3649.3", "bsz": "164.2", "num_updates": "12600", "lr": "0.00563436", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "728"}
2023-12-10 10:33:45 | INFO | train_inner | {"epoch": 12, "update": 11.526, "loss": "4.547", "nll_loss": "3.164", "ppl": "8.96", "wps": "64991", "ups": "18.03", "wpb": "3605.5", "bsz": "148.2", "num_updates": "12700", "lr": "0.00561214", "gnorm": "0.277", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "734"}
2023-12-10 10:33:51 | INFO | train_inner | {"epoch": 12, "update": 11.617, "loss": "4.513", "nll_loss": "3.126", "ppl": "8.73", "wps": "68674.4", "ups": "18.76", "wpb": "3661.4", "bsz": "156.8", "num_updates": "12800", "lr": "0.00559017", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "739"}
2023-12-10 10:33:56 | INFO | train_inner | {"epoch": 12, "update": 11.708, "loss": "4.554", "nll_loss": "3.174", "ppl": "9.03", "wps": "66091.1", "ups": "18.66", "wpb": "3542.8", "bsz": "143.1", "num_updates": "12900", "lr": "0.00556846", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "744"}
2023-12-10 10:34:01 | INFO | train_inner | {"epoch": 12, "update": 11.799, "loss": "4.576", "nll_loss": "3.199", "ppl": "9.18", "wps": "66450.7", "ups": "18.98", "wpb": "3501", "bsz": "141.3", "num_updates": "13000", "lr": "0.005547", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "750"}
2023-12-10 10:34:07 | INFO | train_inner | {"epoch": 12, "update": 11.889, "loss": "4.612", "nll_loss": "3.239", "ppl": "9.44", "wps": "60040.7", "ups": "17.08", "wpb": "3515.5", "bsz": "143.8", "num_updates": "13100", "lr": "0.00552579", "gnorm": "0.293", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "755"}
2023-12-10 10:34:12 | INFO | train_inner | {"epoch": 12, "update": 11.98, "loss": "4.57", "nll_loss": "3.194", "ppl": "9.15", "wps": "69570.6", "ups": "19.41", "wpb": "3583.8", "bsz": "141.3", "num_updates": "13200", "lr": "0.00550482", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "761"}
2023-12-10 10:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:34:15 | INFO | valid | {"epoch": 12, "valid_loss": "4.536", "valid_nll_loss": "3.182", "valid_ppl": "9.08", "valid_wps": "129057", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "13222", "valid_best_loss": "4.536"}
2023-12-10 10:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13222 updates
2023-12-10 10:34:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint12.pt
2023-12-10 10:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint12.pt
2023-12-10 10:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint12.pt (epoch 12 @ 13222 updates, score 4.536) (writing took 2.5110160768963397 seconds)
2023-12-10 10:34:18 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-12-10 10:34:18 | INFO | train | {"epoch": 12, "train_loss": "4.543", "train_nll_loss": "3.16", "train_ppl": "8.94", "train_wps": "62039.2", "train_ups": "17.31", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "13222", "train_lr": "0.00550024", "train_gnorm": "0.266", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "766"}
2023-12-10 10:34:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:34:18 | INFO | fairseq.trainer | begin training epoch 13
2023-12-10 10:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:34:22 | INFO | train_inner | {"epoch": 13, "update": 12.071, "loss": "4.43", "nll_loss": "3.029", "ppl": "8.16", "wps": "37348.5", "ups": "10.43", "wpb": "3580.5", "bsz": "149.7", "num_updates": "13300", "lr": "0.00548408", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "770"}
2023-12-10 10:34:27 | INFO | train_inner | {"epoch": 13, "update": 12.162, "loss": "4.428", "nll_loss": "3.027", "ppl": "8.15", "wps": "73350.8", "ups": "20.31", "wpb": "3611.3", "bsz": "160.9", "num_updates": "13400", "lr": "0.00546358", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "775"}
2023-12-10 10:34:32 | INFO | train_inner | {"epoch": 13, "update": 12.252, "loss": "4.453", "nll_loss": "3.056", "ppl": "8.32", "wps": "68700.1", "ups": "18.8", "wpb": "3653.9", "bsz": "148.1", "num_updates": "13500", "lr": "0.00544331", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "780"}
2023-12-10 10:34:37 | INFO | train_inner | {"epoch": 13, "update": 12.343, "loss": "4.449", "nll_loss": "3.053", "ppl": "8.3", "wps": "71502.9", "ups": "19.96", "wpb": "3581.9", "bsz": "155.4", "num_updates": "13600", "lr": "0.00542326", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "785"}
2023-12-10 10:34:42 | INFO | train_inner | {"epoch": 13, "update": 12.434, "loss": "4.48", "nll_loss": "3.086", "ppl": "8.49", "wps": "68312.3", "ups": "19.24", "wpb": "3550.7", "bsz": "148.2", "num_updates": "13700", "lr": "0.00540343", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "791"}
2023-12-10 10:34:48 | INFO | train_inner | {"epoch": 13, "update": 12.525, "loss": "4.574", "nll_loss": "3.195", "ppl": "9.16", "wps": "61315.7", "ups": "17.48", "wpb": "3507.3", "bsz": "130.2", "num_updates": "13800", "lr": "0.00538382", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "796"}
2023-12-10 10:34:53 | INFO | train_inner | {"epoch": 13, "update": 12.615, "loss": "4.502", "nll_loss": "3.115", "ppl": "8.67", "wps": "72420.7", "ups": "19.93", "wpb": "3633", "bsz": "156", "num_updates": "13900", "lr": "0.00536442", "gnorm": "0.272", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "801"}
2023-12-10 10:34:59 | INFO | train_inner | {"epoch": 13, "update": 12.706, "loss": "4.526", "nll_loss": "3.144", "ppl": "8.84", "wps": "66881.5", "ups": "18.25", "wpb": "3664.2", "bsz": "141.5", "num_updates": "14000", "lr": "0.00534522", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "807"}
2023-12-10 10:35:05 | INFO | train_inner | {"epoch": 13, "update": 12.797, "loss": "4.599", "nll_loss": "3.226", "ppl": "9.35", "wps": "51693.5", "ups": "14.79", "wpb": "3495.2", "bsz": "124.5", "num_updates": "14100", "lr": "0.00532624", "gnorm": "0.278", "loss_scale": "32", "train_wall": "7", "gb_free": "39", "wall": "814"}
2023-12-10 10:35:11 | INFO | train_inner | {"epoch": 13, "update": 12.887, "loss": "4.553", "nll_loss": "3.175", "ppl": "9.03", "wps": "66887.8", "ups": "18.61", "wpb": "3594.1", "bsz": "141.8", "num_updates": "14200", "lr": "0.00530745", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "819"}
2023-12-10 10:35:16 | INFO | train_inner | {"epoch": 13, "update": 12.978, "loss": "4.55", "nll_loss": "3.171", "ppl": "9.01", "wps": "64201.6", "ups": "18.05", "wpb": "3557.3", "bsz": "139", "num_updates": "14300", "lr": "0.00528886", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "825"}
2023-12-10 10:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:35:19 | INFO | valid | {"epoch": 13, "valid_loss": "4.524", "valid_nll_loss": "3.164", "valid_ppl": "8.97", "valid_wps": "131481", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "14324", "valid_best_loss": "4.524"}
2023-12-10 10:35:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14324 updates
2023-12-10 10:35:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint13.pt
2023-12-10 10:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint13.pt
2023-12-10 10:35:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint13.pt (epoch 13 @ 14324 updates, score 4.524) (writing took 2.0632702787406743 seconds)
2023-12-10 10:35:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-12-10 10:35:21 | INFO | train | {"epoch": 13, "train_loss": "4.5", "train_nll_loss": "3.111", "train_ppl": "8.64", "train_wps": "62359.9", "train_ups": "17.4", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "14324", "train_lr": "0.00528443", "train_gnorm": "0.263", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "829"}
2023-12-10 10:35:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:35:21 | INFO | fairseq.trainer | begin training epoch 14
2023-12-10 10:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:35:26 | INFO | train_inner | {"epoch": 14, "update": 13.069, "loss": "4.394", "nll_loss": "2.987", "ppl": "7.93", "wps": "38484.8", "ups": "10.73", "wpb": "3585.7", "bsz": "148.3", "num_updates": "14400", "lr": "0.00527046", "gnorm": "0.275", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "834"}
2023-12-10 10:35:31 | INFO | train_inner | {"epoch": 14, "update": 13.16, "loss": "4.408", "nll_loss": "3.005", "ppl": "8.03", "wps": "69179", "ups": "19.43", "wpb": "3560.2", "bsz": "148.1", "num_updates": "14500", "lr": "0.00525226", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "839"}
2023-12-10 10:35:36 | INFO | train_inner | {"epoch": 14, "update": 13.25, "loss": "4.427", "nll_loss": "3.025", "ppl": "8.14", "wps": "68183.5", "ups": "18.96", "wpb": "3596.9", "bsz": "143", "num_updates": "14600", "lr": "0.00523424", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "844"}
2023-12-10 10:35:42 | INFO | train_inner | {"epoch": 14, "update": 13.341, "loss": "4.467", "nll_loss": "3.072", "ppl": "8.41", "wps": "59692.6", "ups": "16.55", "wpb": "3607.1", "bsz": "138.1", "num_updates": "14700", "lr": "0.00521641", "gnorm": "0.257", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "850"}
2023-12-10 10:35:48 | INFO | train_inner | {"epoch": 14, "update": 13.432, "loss": "4.528", "nll_loss": "3.143", "ppl": "8.84", "wps": "59554.4", "ups": "16.9", "wpb": "3524.8", "bsz": "135.2", "num_updates": "14800", "lr": "0.00519875", "gnorm": "0.276", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "856"}
2023-12-10 10:35:53 | INFO | train_inner | {"epoch": 14, "update": 13.523, "loss": "4.445", "nll_loss": "3.048", "ppl": "8.27", "wps": "68139.4", "ups": "18.74", "wpb": "3636.9", "bsz": "143.9", "num_updates": "14900", "lr": "0.00518128", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "862"}
2023-12-10 10:35:59 | INFO | train_inner | {"epoch": 14, "update": 13.613, "loss": "4.474", "nll_loss": "3.081", "ppl": "8.46", "wps": "65977", "ups": "18.03", "wpb": "3659.1", "bsz": "140.3", "num_updates": "15000", "lr": "0.00516398", "gnorm": "0.276", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "867"}
2023-12-10 10:36:04 | INFO | train_inner | {"epoch": 14, "update": 13.704, "loss": "4.488", "nll_loss": "3.101", "ppl": "8.58", "wps": "71596.1", "ups": "19.93", "wpb": "3591.6", "bsz": "142.4", "num_updates": "15100", "lr": "0.00514685", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "872"}
2023-12-10 10:36:10 | INFO | train_inner | {"epoch": 14, "update": 13.795, "loss": "4.484", "nll_loss": "3.092", "ppl": "8.53", "wps": "62238.3", "ups": "17.55", "wpb": "3547.2", "bsz": "137.5", "num_updates": "15200", "lr": "0.00512989", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "878"}
2023-12-10 10:36:15 | INFO | train_inner | {"epoch": 14, "update": 13.886, "loss": "4.524", "nll_loss": "3.143", "ppl": "8.84", "wps": "65209.7", "ups": "18.33", "wpb": "3556.7", "bsz": "142.8", "num_updates": "15300", "lr": "0.0051131", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "883"}
2023-12-10 10:36:20 | INFO | train_inner | {"epoch": 14, "update": 13.976, "loss": "4.443", "nll_loss": "3.051", "ppl": "8.29", "wps": "74161.1", "ups": "20.87", "wpb": "3553.4", "bsz": "175.2", "num_updates": "15400", "lr": "0.00509647", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "888"}
2023-12-10 10:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:36:23 | INFO | valid | {"epoch": 14, "valid_loss": "4.498", "valid_nll_loss": "3.12", "valid_ppl": "8.7", "valid_wps": "130596", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "15426", "valid_best_loss": "4.498"}
2023-12-10 10:36:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15426 updates
2023-12-10 10:36:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint14.pt
2023-12-10 10:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint14.pt
2023-12-10 10:36:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint14.pt (epoch 14 @ 15426 updates, score 4.498) (writing took 2.289028235245496 seconds)
2023-12-10 10:36:25 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-12-10 10:36:25 | INFO | train | {"epoch": 14, "train_loss": "4.46", "train_nll_loss": "3.066", "train_ppl": "8.38", "train_wps": "61785.6", "train_ups": "17.24", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "15426", "train_lr": "0.00509218", "train_gnorm": "0.263", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "893"}
2023-12-10 10:36:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:36:25 | INFO | fairseq.trainer | begin training epoch 15
2023-12-10 10:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:36:29 | INFO | train_inner | {"epoch": 15, "update": 14.067, "loss": "4.36", "nll_loss": "2.95", "ppl": "7.73", "wps": "39026", "ups": "10.98", "wpb": "3555.8", "bsz": "151.7", "num_updates": "15500", "lr": "0.00508001", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "897"}
2023-12-10 10:36:34 | INFO | train_inner | {"epoch": 15, "update": 14.158, "loss": "4.345", "nll_loss": "2.934", "ppl": "7.64", "wps": "69499.5", "ups": "19.26", "wpb": "3608.6", "bsz": "152.1", "num_updates": "15600", "lr": "0.0050637", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "902"}
2023-12-10 10:36:40 | INFO | train_inner | {"epoch": 15, "update": 14.249, "loss": "4.449", "nll_loss": "3.051", "ppl": "8.29", "wps": "59537.3", "ups": "16.96", "wpb": "3511.2", "bsz": "134.6", "num_updates": "15700", "lr": "0.00504754", "gnorm": "0.254", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "908"}
2023-12-10 10:36:45 | INFO | train_inner | {"epoch": 15, "update": 14.339, "loss": "4.36", "nll_loss": "2.951", "ppl": "7.73", "wps": "73748.7", "ups": "20.56", "wpb": "3587.1", "bsz": "160.6", "num_updates": "15800", "lr": "0.00503155", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "913"}
2023-12-10 10:36:51 | INFO | train_inner | {"epoch": 15, "update": 14.43, "loss": "4.402", "nll_loss": "2.998", "ppl": "7.99", "wps": "63184.1", "ups": "17.32", "wpb": "3647.6", "bsz": "159.8", "num_updates": "15900", "lr": "0.0050157", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "919"}
2023-12-10 10:36:56 | INFO | train_inner | {"epoch": 15, "update": 14.521, "loss": "4.433", "nll_loss": "3.037", "ppl": "8.21", "wps": "64616.1", "ups": "17.81", "wpb": "3627.8", "bsz": "149.5", "num_updates": "16000", "lr": "0.005", "gnorm": "0.257", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "925"}
2023-12-10 10:37:01 | INFO | train_inner | {"epoch": 15, "update": 14.612, "loss": "4.381", "nll_loss": "2.98", "ppl": "7.89", "wps": "77715.6", "ups": "21.42", "wpb": "3628.7", "bsz": "163.4", "num_updates": "16100", "lr": "0.00498445", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "929"}
2023-12-10 10:37:06 | INFO | train_inner | {"epoch": 15, "update": 14.702, "loss": "4.463", "nll_loss": "3.071", "ppl": "8.4", "wps": "70569.1", "ups": "19.78", "wpb": "3567.1", "bsz": "140.9", "num_updates": "16200", "lr": "0.00496904", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "934"}
2023-12-10 10:37:11 | INFO | train_inner | {"epoch": 15, "update": 14.793, "loss": "4.44", "nll_loss": "3.048", "ppl": "8.27", "wps": "69736.2", "ups": "19.53", "wpb": "3569.9", "bsz": "146.6", "num_updates": "16300", "lr": "0.00495377", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "939"}
2023-12-10 10:37:17 | INFO | train_inner | {"epoch": 15, "update": 14.884, "loss": "4.509", "nll_loss": "3.124", "ppl": "8.72", "wps": "61485.2", "ups": "17.06", "wpb": "3604.8", "bsz": "128.3", "num_updates": "16400", "lr": "0.00493865", "gnorm": "0.259", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "945"}
2023-12-10 10:37:23 | INFO | train_inner | {"epoch": 15, "update": 14.975, "loss": "4.538", "nll_loss": "3.159", "ppl": "8.93", "wps": "58304.6", "ups": "16.53", "wpb": "3528", "bsz": "124", "num_updates": "16500", "lr": "0.00492366", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "951"}
2023-12-10 10:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:37:26 | INFO | valid | {"epoch": 15, "valid_loss": "4.486", "valid_nll_loss": "3.13", "valid_ppl": "8.76", "valid_wps": "129870", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "16528", "valid_best_loss": "4.486"}
2023-12-10 10:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16528 updates
2023-12-10 10:37:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint15.pt
2023-12-10 10:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint15.pt
2023-12-10 10:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint15.pt (epoch 15 @ 16528 updates, score 4.486) (writing took 2.28401840897277 seconds)
2023-12-10 10:37:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-12-10 10:37:29 | INFO | train | {"epoch": 15, "train_loss": "4.429", "train_nll_loss": "3.031", "train_ppl": "8.17", "train_wps": "62097.4", "train_ups": "17.33", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "16528", "train_lr": "0.00491949", "train_gnorm": "0.257", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "957"}
2023-12-10 10:37:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:37:29 | INFO | fairseq.trainer | begin training epoch 16
2023-12-10 10:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:37:33 | INFO | train_inner | {"epoch": 16, "update": 15.065, "loss": "4.379", "nll_loss": "2.971", "ppl": "7.84", "wps": "36582.6", "ups": "10.27", "wpb": "3562.1", "bsz": "136.8", "num_updates": "16600", "lr": "0.00490881", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "961"}
2023-12-10 10:37:38 | INFO | train_inner | {"epoch": 16, "update": 15.156, "loss": "4.331", "nll_loss": "2.916", "ppl": "7.55", "wps": "74172.2", "ups": "20.43", "wpb": "3630.4", "bsz": "149.5", "num_updates": "16700", "lr": "0.00489409", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "966"}
2023-12-10 10:37:43 | INFO | train_inner | {"epoch": 16, "update": 15.247, "loss": "4.266", "nll_loss": "2.844", "ppl": "7.18", "wps": "73399.4", "ups": "20.36", "wpb": "3604.4", "bsz": "171.9", "num_updates": "16800", "lr": "0.0048795", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "971"}
2023-12-10 10:37:49 | INFO | train_inner | {"epoch": 16, "update": 15.338, "loss": "4.429", "nll_loss": "3.03", "ppl": "8.17", "wps": "56878.7", "ups": "16.01", "wpb": "3552.4", "bsz": "133.8", "num_updates": "16900", "lr": "0.00486504", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "977"}
2023-12-10 10:37:54 | INFO | train_inner | {"epoch": 16, "update": 15.428, "loss": "4.396", "nll_loss": "2.993", "ppl": "7.96", "wps": "64262.2", "ups": "18.08", "wpb": "3554.6", "bsz": "145.1", "num_updates": "17000", "lr": "0.00485071", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "983"}
2023-12-10 10:38:00 | INFO | train_inner | {"epoch": 16, "update": 15.519, "loss": "4.353", "nll_loss": "2.945", "ppl": "7.7", "wps": "69661.4", "ups": "19.48", "wpb": "3576.1", "bsz": "153.3", "num_updates": "17100", "lr": "0.00483651", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "988"}
2023-12-10 10:38:05 | INFO | train_inner | {"epoch": 16, "update": 15.61, "loss": "4.418", "nll_loss": "3.018", "ppl": "8.1", "wps": "68523.6", "ups": "18.92", "wpb": "3621.8", "bsz": "135.9", "num_updates": "17200", "lr": "0.00482243", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "993"}
2023-12-10 10:38:10 | INFO | train_inner | {"epoch": 16, "update": 15.701, "loss": "4.408", "nll_loss": "3.012", "ppl": "8.06", "wps": "69816.3", "ups": "19.57", "wpb": "3568.2", "bsz": "153.4", "num_updates": "17300", "lr": "0.00480847", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "998"}
2023-12-10 10:38:15 | INFO | train_inner | {"epoch": 16, "update": 15.791, "loss": "4.447", "nll_loss": "3.055", "ppl": "8.31", "wps": "66144.6", "ups": "18.26", "wpb": "3621.9", "bsz": "139.5", "num_updates": "17400", "lr": "0.00479463", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1004"}
2023-12-10 10:38:21 | INFO | train_inner | {"epoch": 16, "update": 15.882, "loss": "4.444", "nll_loss": "3.051", "ppl": "8.29", "wps": "62707.2", "ups": "17.34", "wpb": "3616.7", "bsz": "140", "num_updates": "17500", "lr": "0.00478091", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1009"}
2023-12-10 10:38:26 | INFO | train_inner | {"epoch": 16, "update": 15.973, "loss": "4.433", "nll_loss": "3.039", "ppl": "8.22", "wps": "70571.5", "ups": "19.89", "wpb": "3547.7", "bsz": "148.2", "num_updates": "17600", "lr": "0.00476731", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1014"}
2023-12-10 10:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:38:30 | INFO | valid | {"epoch": 16, "valid_loss": "4.49", "valid_nll_loss": "3.137", "valid_ppl": "8.8", "valid_wps": "125873", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "17630", "valid_best_loss": "4.486"}
2023-12-10 10:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17630 updates
2023-12-10 10:38:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint16.pt
2023-12-10 10:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint16.pt
2023-12-10 10:38:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint16.pt (epoch 16 @ 17630 updates, score 4.49) (writing took 1.5846683052368462 seconds)
2023-12-10 10:38:32 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-12-10 10:38:32 | INFO | train | {"epoch": 16, "train_loss": "4.393", "train_nll_loss": "2.99", "train_ppl": "7.94", "train_wps": "62672.2", "train_ups": "17.49", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "17630", "train_lr": "0.00476326", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1020"}
2023-12-10 10:38:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:38:32 | INFO | fairseq.trainer | begin training epoch 17
2023-12-10 10:38:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:38:36 | INFO | train_inner | {"epoch": 17, "update": 16.064, "loss": "4.363", "nll_loss": "2.953", "ppl": "7.74", "wps": "37382", "ups": "10.77", "wpb": "3471.7", "bsz": "131.7", "num_updates": "17700", "lr": "0.00475383", "gnorm": "0.263", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1024"}
2023-12-10 10:38:40 | INFO | train_inner | {"epoch": 17, "update": 16.154, "loss": "4.295", "nll_loss": "2.877", "ppl": "7.35", "wps": "76396.1", "ups": "21.05", "wpb": "3628.9", "bsz": "153.2", "num_updates": "17800", "lr": "0.00474045", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1028"}
2023-12-10 10:38:46 | INFO | train_inner | {"epoch": 17, "update": 16.245, "loss": "4.355", "nll_loss": "2.943", "ppl": "7.69", "wps": "57440.2", "ups": "16.29", "wpb": "3525.1", "bsz": "131.4", "num_updates": "17900", "lr": "0.00472719", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1035"}
2023-12-10 10:38:52 | INFO | train_inner | {"epoch": 17, "update": 16.336, "loss": "4.351", "nll_loss": "2.939", "ppl": "7.67", "wps": "63528.8", "ups": "17.75", "wpb": "3579.2", "bsz": "140.4", "num_updates": "18000", "lr": "0.00471405", "gnorm": "0.253", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1040"}
2023-12-10 10:38:58 | INFO | train_inner | {"epoch": 17, "update": 16.426, "loss": "4.401", "nll_loss": "3", "ppl": "8", "wps": "63177.5", "ups": "17.41", "wpb": "3627.9", "bsz": "138.2", "num_updates": "18100", "lr": "0.004701", "gnorm": "0.253", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1046"}
2023-12-10 10:39:03 | INFO | train_inner | {"epoch": 17, "update": 16.517, "loss": "4.414", "nll_loss": "3.016", "ppl": "8.09", "wps": "66011.5", "ups": "18.3", "wpb": "3607.4", "bsz": "139.8", "num_updates": "18200", "lr": "0.00468807", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1051"}
2023-12-10 10:39:09 | INFO | train_inner | {"epoch": 17, "update": 16.608, "loss": "4.355", "nll_loss": "2.948", "ppl": "7.72", "wps": "66199.9", "ups": "18.33", "wpb": "3610.9", "bsz": "155.1", "num_updates": "18300", "lr": "0.00467525", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1057"}
2023-12-10 10:39:14 | INFO | train_inner | {"epoch": 17, "update": 16.699, "loss": "4.403", "nll_loss": "3.005", "ppl": "8.03", "wps": "64461.6", "ups": "18.52", "wpb": "3481.2", "bsz": "147.7", "num_updates": "18400", "lr": "0.00466252", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1062"}
2023-12-10 10:39:20 | INFO | train_inner | {"epoch": 17, "update": 16.789, "loss": "4.363", "nll_loss": "2.957", "ppl": "7.76", "wps": "66339.3", "ups": "18.4", "wpb": "3606.4", "bsz": "145.7", "num_updates": "18500", "lr": "0.00464991", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1068"}
2023-12-10 10:39:25 | INFO | train_inner | {"epoch": 17, "update": 16.88, "loss": "4.402", "nll_loss": "3.004", "ppl": "8.02", "wps": "70885.3", "ups": "19.67", "wpb": "3603.8", "bsz": "141.9", "num_updates": "18600", "lr": "0.00463739", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1073"}
2023-12-10 10:39:30 | INFO | train_inner | {"epoch": 17, "update": 16.971, "loss": "4.344", "nll_loss": "2.938", "ppl": "7.67", "wps": "67228", "ups": "18.77", "wpb": "3582.1", "bsz": "165.8", "num_updates": "18700", "lr": "0.00462497", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1078"}
2023-12-10 10:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:39:33 | INFO | valid | {"epoch": 17, "valid_loss": "4.466", "valid_nll_loss": "3.09", "valid_ppl": "8.52", "valid_wps": "124572", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "18732", "valid_best_loss": "4.466"}
2023-12-10 10:39:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18732 updates
2023-12-10 10:39:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint17.pt
2023-12-10 10:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint17.pt
2023-12-10 10:39:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint17.pt (epoch 17 @ 18732 updates, score 4.466) (writing took 2.2030250607058406 seconds)
2023-12-10 10:39:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-12-10 10:39:35 | INFO | train | {"epoch": 17, "train_loss": "4.365", "train_nll_loss": "2.958", "train_ppl": "7.77", "train_wps": "61962.3", "train_ups": "17.29", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "18732", "train_lr": "0.00462102", "train_gnorm": "0.258", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "1083"}
2023-12-10 10:39:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:39:35 | INFO | fairseq.trainer | begin training epoch 18
2023-12-10 10:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:39:39 | INFO | train_inner | {"epoch": 18, "update": 17.062, "loss": "4.279", "nll_loss": "2.86", "ppl": "7.26", "wps": "42150", "ups": "11.5", "wpb": "3665.2", "bsz": "144.2", "num_updates": "18800", "lr": "0.00461266", "gnorm": "0.233", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1087"}
2023-12-10 10:39:44 | INFO | train_inner | {"epoch": 18, "update": 17.152, "loss": "4.298", "nll_loss": "2.878", "ppl": "7.35", "wps": "61913", "ups": "17.53", "wpb": "3531.4", "bsz": "131.8", "num_updates": "18900", "lr": "0.00460044", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1093"}
2023-12-10 10:39:49 | INFO | train_inner | {"epoch": 18, "update": 17.243, "loss": "4.283", "nll_loss": "2.865", "ppl": "7.29", "wps": "71875", "ups": "19.81", "wpb": "3628.5", "bsz": "150.6", "num_updates": "19000", "lr": "0.00458831", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1098"}
2023-12-10 10:39:54 | INFO | train_inner | {"epoch": 18, "update": 17.334, "loss": "4.298", "nll_loss": "2.883", "ppl": "7.38", "wps": "71418.5", "ups": "19.8", "wpb": "3607.7", "bsz": "149.2", "num_updates": "19100", "lr": "0.00457629", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1103"}
2023-12-10 10:40:00 | INFO | train_inner | {"epoch": 18, "update": 17.425, "loss": "4.356", "nll_loss": "2.947", "ppl": "7.71", "wps": "61943.9", "ups": "17.59", "wpb": "3521", "bsz": "134.4", "num_updates": "19200", "lr": "0.00456435", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1108"}
2023-12-10 10:40:06 | INFO | train_inner | {"epoch": 18, "update": 17.515, "loss": "4.347", "nll_loss": "2.939", "ppl": "7.67", "wps": "61725.5", "ups": "17.15", "wpb": "3599.6", "bsz": "143.4", "num_updates": "19300", "lr": "0.00455251", "gnorm": "0.244", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1114"}
2023-12-10 10:40:12 | INFO | train_inner | {"epoch": 18, "update": 17.606, "loss": "4.393", "nll_loss": "2.992", "ppl": "7.96", "wps": "64212.4", "ups": "18", "wpb": "3567", "bsz": "135.8", "num_updates": "19400", "lr": "0.00454077", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1120"}
2023-12-10 10:40:17 | INFO | train_inner | {"epoch": 18, "update": 17.697, "loss": "4.377", "nll_loss": "2.973", "ppl": "7.85", "wps": "65023.1", "ups": "18.01", "wpb": "3610.7", "bsz": "137.7", "num_updates": "19500", "lr": "0.00452911", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1125"}
2023-12-10 10:40:23 | INFO | train_inner | {"epoch": 18, "update": 17.788, "loss": "4.355", "nll_loss": "2.95", "ppl": "7.72", "wps": "65572.6", "ups": "18.41", "wpb": "3562.2", "bsz": "150.3", "num_updates": "19600", "lr": "0.00451754", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1131"}
2023-12-10 10:40:28 | INFO | train_inner | {"epoch": 18, "update": 17.878, "loss": "4.345", "nll_loss": "2.941", "ppl": "7.68", "wps": "71259.3", "ups": "19.74", "wpb": "3610.2", "bsz": "167.4", "num_updates": "19700", "lr": "0.00450606", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1136"}
2023-12-10 10:40:33 | INFO | train_inner | {"epoch": 18, "update": 17.969, "loss": "4.364", "nll_loss": "2.96", "ppl": "7.78", "wps": "62535.5", "ups": "17.64", "wpb": "3544.9", "bsz": "151.3", "num_updates": "19800", "lr": "0.00449467", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1141"}
2023-12-10 10:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:40:37 | INFO | valid | {"epoch": 18, "valid_loss": "4.456", "valid_nll_loss": "3.099", "valid_ppl": "8.57", "valid_wps": "130294", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "19834", "valid_best_loss": "4.456"}
2023-12-10 10:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19834 updates
2023-12-10 10:40:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint18.pt
2023-12-10 10:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint18.pt
2023-12-10 10:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint18.pt (epoch 18 @ 19834 updates, score 4.456) (writing took 2.253967651166022 seconds)
2023-12-10 10:40:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-12-10 10:40:39 | INFO | train | {"epoch": 18, "train_loss": "4.335", "train_nll_loss": "2.925", "train_ppl": "7.6", "train_wps": "62016.1", "train_ups": "17.31", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "19834", "train_lr": "0.00449081", "train_gnorm": "0.254", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "1147"}
2023-12-10 10:40:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:40:39 | INFO | fairseq.trainer | begin training epoch 19
2023-12-10 10:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:40:42 | INFO | train_inner | {"epoch": 19, "update": 18.06, "loss": "4.286", "nll_loss": "2.869", "ppl": "7.31", "wps": "39594.4", "ups": "11.05", "wpb": "3583.4", "bsz": "145.7", "num_updates": "19900", "lr": "0.00448336", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1150"}
2023-12-10 10:40:47 | INFO | train_inner | {"epoch": 19, "update": 18.151, "loss": "4.199", "nll_loss": "2.768", "ppl": "6.81", "wps": "71877", "ups": "19.89", "wpb": "3613.1", "bsz": "165.4", "num_updates": "20000", "lr": "0.00447214", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1155"}
2023-12-10 10:40:53 | INFO | train_inner | {"epoch": 19, "update": 18.241, "loss": "4.255", "nll_loss": "2.832", "ppl": "7.12", "wps": "67665.4", "ups": "18.67", "wpb": "3624", "bsz": "146.1", "num_updates": "20100", "lr": "0.004461", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1161"}
2023-12-10 10:40:58 | INFO | train_inner | {"epoch": 19, "update": 18.332, "loss": "4.264", "nll_loss": "2.843", "ppl": "7.18", "wps": "65019.2", "ups": "18.49", "wpb": "3517.1", "bsz": "154.2", "num_updates": "20200", "lr": "0.00444994", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1166"}
2023-12-10 10:41:04 | INFO | train_inner | {"epoch": 19, "update": 18.423, "loss": "4.325", "nll_loss": "2.912", "ppl": "7.53", "wps": "64788.4", "ups": "17.94", "wpb": "3611.6", "bsz": "134.3", "num_updates": "20300", "lr": "0.00443897", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1172"}
2023-12-10 10:41:09 | INFO | train_inner | {"epoch": 19, "update": 18.514, "loss": "4.254", "nll_loss": "2.833", "ppl": "7.12", "wps": "72468", "ups": "19.9", "wpb": "3641.2", "bsz": "159.4", "num_updates": "20400", "lr": "0.00442807", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1177"}
2023-12-10 10:41:14 | INFO | train_inner | {"epoch": 19, "update": 18.604, "loss": "4.383", "nll_loss": "2.98", "ppl": "7.89", "wps": "62418.7", "ups": "17.45", "wpb": "3577.5", "bsz": "129.6", "num_updates": "20500", "lr": "0.00441726", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1183"}
2023-12-10 10:41:20 | INFO | train_inner | {"epoch": 19, "update": 18.695, "loss": "4.413", "nll_loss": "3.016", "ppl": "8.09", "wps": "63152.6", "ups": "17.68", "wpb": "3572.8", "bsz": "132.6", "num_updates": "20600", "lr": "0.00440653", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1188"}
2023-12-10 10:41:26 | INFO | train_inner | {"epoch": 19, "update": 18.786, "loss": "4.36", "nll_loss": "2.957", "ppl": "7.76", "wps": "63404.7", "ups": "17.7", "wpb": "3582.2", "bsz": "143.8", "num_updates": "20700", "lr": "0.00439587", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1194"}
2023-12-10 10:41:32 | INFO | train_inner | {"epoch": 19, "update": 18.877, "loss": "4.402", "nll_loss": "3.004", "ppl": "8.02", "wps": "60578.8", "ups": "17.1", "wpb": "3541.9", "bsz": "126.6", "num_updates": "20800", "lr": "0.00438529", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1200"}
2023-12-10 10:41:37 | INFO | train_inner | {"epoch": 19, "update": 18.967, "loss": "4.294", "nll_loss": "2.881", "ppl": "7.37", "wps": "67764.4", "ups": "18.99", "wpb": "3569.3", "bsz": "162.8", "num_updates": "20900", "lr": "0.00437479", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1205"}
2023-12-10 10:41:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:41:40 | INFO | valid | {"epoch": 19, "valid_loss": "4.493", "valid_nll_loss": "3.155", "valid_ppl": "8.91", "valid_wps": "132095", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "20936", "valid_best_loss": "4.456"}
2023-12-10 10:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20936 updates
2023-12-10 10:41:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint19.pt
2023-12-10 10:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint19.pt
2023-12-10 10:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint19.pt (epoch 19 @ 20936 updates, score 4.493) (writing took 1.6778433760628104 seconds)
2023-12-10 10:41:42 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-12-10 10:41:42 | INFO | train | {"epoch": 19, "train_loss": "4.312", "train_nll_loss": "2.899", "train_ppl": "7.46", "train_wps": "62591.5", "train_ups": "17.47", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "20936", "train_lr": "0.00437102", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1210"}
2023-12-10 10:41:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:41:42 | INFO | fairseq.trainer | begin training epoch 20
2023-12-10 10:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:41:46 | INFO | train_inner | {"epoch": 20, "update": 19.058, "loss": "4.299", "nll_loss": "2.881", "ppl": "7.37", "wps": "38743.1", "ups": "10.85", "wpb": "3571.8", "bsz": "133", "num_updates": "21000", "lr": "0.00436436", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1214"}
2023-12-10 10:41:52 | INFO | train_inner | {"epoch": 20, "update": 19.149, "loss": "4.233", "nll_loss": "2.807", "ppl": "7", "wps": "63758", "ups": "18.13", "wpb": "3517.2", "bsz": "141.6", "num_updates": "21100", "lr": "0.004354", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1220"}
2023-12-10 10:41:57 | INFO | train_inner | {"epoch": 20, "update": 19.24, "loss": "4.229", "nll_loss": "2.803", "ppl": "6.98", "wps": "72253.5", "ups": "19.98", "wpb": "3616.1", "bsz": "149.4", "num_updates": "21200", "lr": "0.00434372", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1225"}
2023-12-10 10:42:02 | INFO | train_inner | {"epoch": 20, "update": 19.33, "loss": "4.231", "nll_loss": "2.805", "ppl": "6.99", "wps": "65830.7", "ups": "18.3", "wpb": "3597.3", "bsz": "155", "num_updates": "21300", "lr": "0.00433351", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1230"}
2023-12-10 10:42:08 | INFO | train_inner | {"epoch": 20, "update": 19.421, "loss": "4.288", "nll_loss": "2.87", "ppl": "7.31", "wps": "64255.5", "ups": "17.87", "wpb": "3595.4", "bsz": "149.7", "num_updates": "21400", "lr": "0.00432338", "gnorm": "0.272", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1236"}
2023-12-10 10:42:13 | INFO | train_inner | {"epoch": 20, "update": 19.512, "loss": "4.262", "nll_loss": "2.844", "ppl": "7.18", "wps": "65896.2", "ups": "18.5", "wpb": "3562.9", "bsz": "153.2", "num_updates": "21500", "lr": "0.00431331", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1241"}
2023-12-10 10:42:18 | INFO | train_inner | {"epoch": 20, "update": 19.603, "loss": "4.317", "nll_loss": "2.909", "ppl": "7.51", "wps": "68294.6", "ups": "18.83", "wpb": "3626.9", "bsz": "154", "num_updates": "21600", "lr": "0.00430331", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1247"}
2023-12-10 10:42:24 | INFO | train_inner | {"epoch": 20, "update": 19.693, "loss": "4.326", "nll_loss": "2.916", "ppl": "7.55", "wps": "67737.6", "ups": "18.88", "wpb": "3588", "bsz": "144.6", "num_updates": "21700", "lr": "0.00429339", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1252"}
2023-12-10 10:42:29 | INFO | train_inner | {"epoch": 20, "update": 19.784, "loss": "4.323", "nll_loss": "2.914", "ppl": "7.54", "wps": "67147.8", "ups": "18.54", "wpb": "3621.8", "bsz": "145.9", "num_updates": "21800", "lr": "0.00428353", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1257"}
2023-12-10 10:42:35 | INFO | train_inner | {"epoch": 20, "update": 19.875, "loss": "4.358", "nll_loss": "2.952", "ppl": "7.74", "wps": "60696.2", "ups": "17.26", "wpb": "3515.9", "bsz": "129.5", "num_updates": "21900", "lr": "0.00427374", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1263"}
2023-12-10 10:42:40 | INFO | train_inner | {"epoch": 20, "update": 19.966, "loss": "4.365", "nll_loss": "2.963", "ppl": "7.8", "wps": "65537.3", "ups": "18.32", "wpb": "3578", "bsz": "141.9", "num_updates": "22000", "lr": "0.00426401", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1268"}
2023-12-10 10:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:42:44 | INFO | valid | {"epoch": 20, "valid_loss": "4.461", "valid_nll_loss": "3.106", "valid_ppl": "8.61", "valid_wps": "129396", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "22038", "valid_best_loss": "4.456"}
2023-12-10 10:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 22038 updates
2023-12-10 10:42:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint20.pt
2023-12-10 10:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint20.pt
2023-12-10 10:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint20.pt (epoch 20 @ 22038 updates, score 4.461) (writing took 5.750028820708394 seconds)
2023-12-10 10:42:50 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-12-10 10:42:50 | INFO | train | {"epoch": 20, "train_loss": "4.291", "train_nll_loss": "2.875", "train_ppl": "7.34", "train_wps": "58117.2", "train_ups": "16.22", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "22038", "train_lr": "0.00426034", "train_gnorm": "0.26", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "1278"}
2023-12-10 10:42:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:42:50 | INFO | fairseq.trainer | begin training epoch 21
2023-12-10 10:42:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:42:53 | INFO | train_inner | {"epoch": 21, "update": 20.056, "loss": "4.232", "nll_loss": "2.806", "ppl": "6.99", "wps": "28048.3", "ups": "7.8", "wpb": "3594.7", "bsz": "140.9", "num_updates": "22100", "lr": "0.00425436", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1281"}
2023-12-10 10:42:59 | INFO | train_inner | {"epoch": 21, "update": 20.147, "loss": "4.21", "nll_loss": "2.779", "ppl": "6.86", "wps": "65138", "ups": "18.08", "wpb": "3602.8", "bsz": "142.3", "num_updates": "22200", "lr": "0.00424476", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1287"}
2023-12-10 10:43:03 | INFO | train_inner | {"epoch": 21, "update": 20.238, "loss": "4.176", "nll_loss": "2.741", "ppl": "6.69", "wps": "74893.8", "ups": "20.82", "wpb": "3596.7", "bsz": "157.8", "num_updates": "22300", "lr": "0.00423524", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1292"}
2023-12-10 10:43:09 | INFO | train_inner | {"epoch": 21, "update": 20.328, "loss": "4.233", "nll_loss": "2.808", "ppl": "7", "wps": "68967", "ups": "19.09", "wpb": "3612.2", "bsz": "147.1", "num_updates": "22400", "lr": "0.00422577", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1297"}
2023-12-10 10:43:14 | INFO | train_inner | {"epoch": 21, "update": 20.419, "loss": "4.29", "nll_loss": "2.874", "ppl": "7.33", "wps": "63091", "ups": "17.82", "wpb": "3540", "bsz": "135", "num_updates": "22500", "lr": "0.00421637", "gnorm": "0.252", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1302"}
2023-12-10 10:43:20 | INFO | train_inner | {"epoch": 21, "update": 20.51, "loss": "4.27", "nll_loss": "2.852", "ppl": "7.22", "wps": "67640.5", "ups": "18.84", "wpb": "3589.5", "bsz": "149.4", "num_updates": "22600", "lr": "0.00420703", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1308"}
2023-12-10 10:43:25 | INFO | train_inner | {"epoch": 21, "update": 20.601, "loss": "4.295", "nll_loss": "2.881", "ppl": "7.37", "wps": "63532", "ups": "17.89", "wpb": "3550.6", "bsz": "149.5", "num_updates": "22700", "lr": "0.00419775", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1313"}
2023-12-10 10:43:31 | INFO | train_inner | {"epoch": 21, "update": 20.691, "loss": "4.289", "nll_loss": "2.875", "ppl": "7.34", "wps": "67650.7", "ups": "18.76", "wpb": "3606.7", "bsz": "141.8", "num_updates": "22800", "lr": "0.00418854", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1319"}
2023-12-10 10:43:36 | INFO | train_inner | {"epoch": 21, "update": 20.782, "loss": "4.3", "nll_loss": "2.888", "ppl": "7.4", "wps": "61462", "ups": "16.9", "wpb": "3637.6", "bsz": "141.7", "num_updates": "22900", "lr": "0.00417938", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1325"}
2023-12-10 10:43:42 | INFO | train_inner | {"epoch": 21, "update": 20.873, "loss": "4.255", "nll_loss": "2.838", "ppl": "7.15", "wps": "66672", "ups": "18.53", "wpb": "3598.6", "bsz": "157.9", "num_updates": "23000", "lr": "0.00417029", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1330"}
2023-12-10 10:43:48 | INFO | train_inner | {"epoch": 21, "update": 20.964, "loss": "4.327", "nll_loss": "2.92", "ppl": "7.57", "wps": "58262.8", "ups": "16.53", "wpb": "3524", "bsz": "140.8", "num_updates": "23100", "lr": "0.00416125", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1336"}
2023-12-10 10:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:43:52 | INFO | valid | {"epoch": 21, "valid_loss": "4.44", "valid_nll_loss": "3.072", "valid_ppl": "8.41", "valid_wps": "126654", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "23140", "valid_best_loss": "4.44"}
2023-12-10 10:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 23140 updates
2023-12-10 10:43:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint21.pt
2023-12-10 10:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint21.pt
2023-12-10 10:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint21.pt (epoch 21 @ 23140 updates, score 4.44) (writing took 2.1365375979803503 seconds)
2023-12-10 10:43:54 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-12-10 10:43:54 | INFO | train | {"epoch": 21, "train_loss": "4.264", "train_nll_loss": "2.845", "train_ppl": "7.19", "train_wps": "61745.8", "train_ups": "17.23", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "23140", "train_lr": "0.00415765", "train_gnorm": "0.253", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1342"}
2023-12-10 10:43:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:43:54 | INFO | fairseq.trainer | begin training epoch 22
2023-12-10 10:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:43:58 | INFO | train_inner | {"epoch": 22, "update": 21.054, "loss": "4.251", "nll_loss": "2.83", "ppl": "7.11", "wps": "35603.1", "ups": "10.05", "wpb": "3541.3", "bsz": "144.6", "num_updates": "23200", "lr": "0.00415227", "gnorm": "0.249", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1346"}
2023-12-10 10:44:03 | INFO | train_inner | {"epoch": 22, "update": 21.145, "loss": "4.17", "nll_loss": "2.736", "ppl": "6.66", "wps": "71258.6", "ups": "19.92", "wpb": "3576.4", "bsz": "156.3", "num_updates": "23300", "lr": "0.00414335", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1351"}
2023-12-10 10:44:08 | INFO | train_inner | {"epoch": 22, "update": 21.236, "loss": "4.208", "nll_loss": "2.778", "ppl": "6.86", "wps": "65265.6", "ups": "18.05", "wpb": "3616.8", "bsz": "139.2", "num_updates": "23400", "lr": "0.00413449", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1357"}
2023-12-10 10:44:14 | INFO | train_inner | {"epoch": 22, "update": 21.327, "loss": "4.245", "nll_loss": "2.823", "ppl": "7.08", "wps": "63954.4", "ups": "17.52", "wpb": "3649.3", "bsz": "142.6", "num_updates": "23500", "lr": "0.00412568", "gnorm": "0.253", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1362"}
2023-12-10 10:44:20 | INFO | train_inner | {"epoch": 22, "update": 21.417, "loss": "4.229", "nll_loss": "2.804", "ppl": "6.99", "wps": "62269.2", "ups": "17.62", "wpb": "3534.4", "bsz": "150.2", "num_updates": "23600", "lr": "0.00411693", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1368"}
2023-12-10 10:44:25 | INFO | train_inner | {"epoch": 22, "update": 21.508, "loss": "4.288", "nll_loss": "2.873", "ppl": "7.33", "wps": "67849.9", "ups": "18.93", "wpb": "3584.3", "bsz": "138.9", "num_updates": "23700", "lr": "0.00410824", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1373"}
2023-12-10 10:44:31 | INFO | train_inner | {"epoch": 22, "update": 21.599, "loss": "4.267", "nll_loss": "2.85", "ppl": "7.21", "wps": "62948.9", "ups": "17.78", "wpb": "3540.7", "bsz": "145.4", "num_updates": "23800", "lr": "0.0040996", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1379"}
2023-12-10 10:44:36 | INFO | train_inner | {"epoch": 22, "update": 21.69, "loss": "4.266", "nll_loss": "2.848", "ppl": "7.2", "wps": "71757.4", "ups": "19.92", "wpb": "3601.5", "bsz": "149.2", "num_updates": "23900", "lr": "0.00409101", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1384"}
2023-12-10 10:44:41 | INFO | train_inner | {"epoch": 22, "update": 21.78, "loss": "4.294", "nll_loss": "2.881", "ppl": "7.36", "wps": "62162.2", "ups": "17.52", "wpb": "3548.8", "bsz": "138.8", "num_updates": "24000", "lr": "0.00408248", "gnorm": "0.263", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "1390"}
2023-12-10 10:44:47 | INFO | train_inner | {"epoch": 22, "update": 21.871, "loss": "4.281", "nll_loss": "2.867", "ppl": "7.29", "wps": "65884.5", "ups": "18.31", "wpb": "3598", "bsz": "146.1", "num_updates": "24100", "lr": "0.004074", "gnorm": "0.264", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "1395"}
2023-12-10 10:44:53 | INFO | train_inner | {"epoch": 22, "update": 21.962, "loss": "4.288", "nll_loss": "2.876", "ppl": "7.34", "wps": "64046", "ups": "17.81", "wpb": "3597", "bsz": "142.1", "num_updates": "24200", "lr": "0.00406558", "gnorm": "0.251", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "1401"}
2023-12-10 10:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:44:56 | INFO | valid | {"epoch": 22, "valid_loss": "4.435", "valid_nll_loss": "3.077", "valid_ppl": "8.44", "valid_wps": "130462", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "24242", "valid_best_loss": "4.435"}
2023-12-10 10:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 24242 updates
2023-12-10 10:44:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint22.pt
2023-12-10 10:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint22.pt
2023-12-10 10:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint22.pt (epoch 22 @ 24242 updates, score 4.435) (writing took 2.239641868043691 seconds)
2023-12-10 10:44:58 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-12-10 10:44:58 | INFO | train | {"epoch": 22, "train_loss": "4.248", "train_nll_loss": "2.827", "train_ppl": "7.1", "train_wps": "61377", "train_ups": "17.13", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "24242", "train_lr": "0.00406205", "train_gnorm": "0.256", "train_loss_scale": "64", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1406"}
2023-12-10 10:44:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:44:58 | INFO | fairseq.trainer | begin training epoch 23
2023-12-10 10:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:45:01 | INFO | train_inner | {"epoch": 23, "update": 22.053, "loss": "4.162", "nll_loss": "2.729", "ppl": "6.63", "wps": "43001.1", "ups": "11.66", "wpb": "3687.5", "bsz": "158.3", "num_updates": "24300", "lr": "0.0040572", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "1409"}
2023-12-10 10:45:07 | INFO | train_inner | {"epoch": 23, "update": 22.143, "loss": "4.098", "nll_loss": "2.652", "ppl": "6.29", "wps": "67264.7", "ups": "18.39", "wpb": "3657.8", "bsz": "160.2", "num_updates": "24400", "lr": "0.00404888", "gnorm": "0.241", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "1415"}
2023-12-10 10:45:13 | INFO | train_inner | {"epoch": 23, "update": 22.234, "loss": "4.22", "nll_loss": "2.79", "ppl": "6.92", "wps": "58862.1", "ups": "16.63", "wpb": "3539.5", "bsz": "127.5", "num_updates": "24500", "lr": "0.00404061", "gnorm": "0.26", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "1421"}
2023-12-10 10:45:19 | INFO | train_inner | {"epoch": 23, "update": 22.325, "loss": "4.297", "nll_loss": "2.881", "ppl": "7.37", "wps": "55087.9", "ups": "15.78", "wpb": "3490.2", "bsz": "126.6", "num_updates": "24600", "lr": "0.00403239", "gnorm": "0.266", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "1427"}
2023-12-10 10:45:24 | INFO | train_inner | {"epoch": 23, "update": 22.416, "loss": "4.212", "nll_loss": "2.785", "ppl": "6.89", "wps": "76217.8", "ups": "20.98", "wpb": "3633", "bsz": "148.7", "num_updates": "24700", "lr": "0.00402422", "gnorm": "0.237", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "1432"}
2023-12-10 10:45:29 | INFO | train_inner | {"epoch": 23, "update": 22.506, "loss": "4.24", "nll_loss": "2.816", "ppl": "7.04", "wps": "64529.4", "ups": "18.04", "wpb": "3578", "bsz": "137.9", "num_updates": "24800", "lr": "0.0040161", "gnorm": "0.27", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "1437"}
2023-12-10 10:45:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-10 10:45:35 | INFO | train_inner | {"epoch": 23, "update": 22.598, "loss": "4.276", "nll_loss": "2.858", "ppl": "7.25", "wps": "58745.6", "ups": "16.58", "wpb": "3542.6", "bsz": "139.8", "num_updates": "24900", "lr": "0.00400802", "gnorm": "0.281", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1443"}
2023-12-10 10:45:40 | INFO | train_inner | {"epoch": 23, "update": 22.689, "loss": "4.221", "nll_loss": "2.798", "ppl": "6.95", "wps": "69259.1", "ups": "19.25", "wpb": "3597.5", "bsz": "150.4", "num_updates": "25000", "lr": "0.004", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1449"}
2023-12-10 10:45:45 | INFO | train_inner | {"epoch": 23, "update": 22.779, "loss": "4.218", "nll_loss": "2.797", "ppl": "6.95", "wps": "71961.7", "ups": "19.97", "wpb": "3604.3", "bsz": "165.3", "num_updates": "25100", "lr": "0.00399202", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1454"}
2023-12-10 10:45:51 | INFO | train_inner | {"epoch": 23, "update": 22.87, "loss": "4.265", "nll_loss": "2.847", "ppl": "7.2", "wps": "67418.4", "ups": "18.43", "wpb": "3657.6", "bsz": "135", "num_updates": "25200", "lr": "0.0039841", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1459"}
2023-12-10 10:45:56 | INFO | train_inner | {"epoch": 23, "update": 22.961, "loss": "4.275", "nll_loss": "2.862", "ppl": "7.27", "wps": "66837.5", "ups": "19.23", "wpb": "3475.7", "bsz": "150.3", "num_updates": "25300", "lr": "0.00397621", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1464"}
2023-12-10 10:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:46:00 | INFO | valid | {"epoch": 23, "valid_loss": "4.434", "valid_nll_loss": "3.053", "valid_ppl": "8.3", "valid_wps": "129707", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "25343", "valid_best_loss": "4.434"}
2023-12-10 10:46:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 25343 updates
2023-12-10 10:46:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint23.pt
2023-12-10 10:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint23.pt
2023-12-10 10:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint23.pt (epoch 23 @ 25343 updates, score 4.434) (writing took 2.190357503015548 seconds)
2023-12-10 10:46:02 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-12-10 10:46:02 | INFO | train | {"epoch": 23, "train_loss": "4.226", "train_nll_loss": "2.801", "train_ppl": "6.97", "train_wps": "61986.8", "train_ups": "17.3", "train_wpb": "3583.9", "train_bsz": "145.5", "train_num_updates": "25343", "train_lr": "0.00397284", "train_gnorm": "0.255", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "1470"}
2023-12-10 10:46:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:46:02 | INFO | fairseq.trainer | begin training epoch 24
2023-12-10 10:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:46:05 | INFO | train_inner | {"epoch": 24, "update": 23.052, "loss": "4.186", "nll_loss": "2.758", "ppl": "6.77", "wps": "41946.3", "ups": "11.6", "wpb": "3615.3", "bsz": "153", "num_updates": "25400", "lr": "0.00396838", "gnorm": "0.235", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1473"}
2023-12-10 10:46:10 | INFO | train_inner | {"epoch": 24, "update": 23.142, "loss": "4.15", "nll_loss": "2.711", "ppl": "6.55", "wps": "62360", "ups": "17.21", "wpb": "3623.9", "bsz": "132.8", "num_updates": "25500", "lr": "0.00396059", "gnorm": "0.244", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1479"}
2023-12-10 10:46:16 | INFO | train_inner | {"epoch": 24, "update": 23.233, "loss": "4.156", "nll_loss": "2.718", "ppl": "6.58", "wps": "64045.2", "ups": "18.12", "wpb": "3534", "bsz": "147.1", "num_updates": "25600", "lr": "0.00395285", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1484"}
2023-12-10 10:46:21 | INFO | train_inner | {"epoch": 24, "update": 23.324, "loss": "4.15", "nll_loss": "2.715", "ppl": "6.57", "wps": "71823.6", "ups": "19.78", "wpb": "3631.1", "bsz": "164.2", "num_updates": "25700", "lr": "0.00394515", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1489"}
2023-12-10 10:46:27 | INFO | train_inner | {"epoch": 24, "update": 23.415, "loss": "4.215", "nll_loss": "2.789", "ppl": "6.91", "wps": "64042.5", "ups": "17.79", "wpb": "3599", "bsz": "136.3", "num_updates": "25800", "lr": "0.0039375", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1495"}
2023-12-10 10:46:33 | INFO | train_inner | {"epoch": 24, "update": 23.505, "loss": "4.22", "nll_loss": "2.794", "ppl": "6.94", "wps": "58189.7", "ups": "16.4", "wpb": "3547.7", "bsz": "140.9", "num_updates": "25900", "lr": "0.00392989", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1501"}
2023-12-10 10:46:38 | INFO | train_inner | {"epoch": 24, "update": 23.596, "loss": "4.178", "nll_loss": "2.748", "ppl": "6.72", "wps": "72441.9", "ups": "20.41", "wpb": "3548.5", "bsz": "154.5", "num_updates": "26000", "lr": "0.00392232", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1506"}
2023-12-10 10:46:43 | INFO | train_inner | {"epoch": 24, "update": 23.687, "loss": "4.225", "nll_loss": "2.804", "ppl": "6.98", "wps": "71211.6", "ups": "19.75", "wpb": "3606", "bsz": "155.5", "num_updates": "26100", "lr": "0.0039148", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1511"}
2023-12-10 10:46:48 | INFO | train_inner | {"epoch": 24, "update": 23.778, "loss": "4.249", "nll_loss": "2.83", "ppl": "7.11", "wps": "66628.4", "ups": "18.86", "wpb": "3533.3", "bsz": "140.6", "num_updates": "26200", "lr": "0.00390732", "gnorm": "0.272", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1516"}
2023-12-10 10:46:54 | INFO | train_inner | {"epoch": 24, "update": 23.868, "loss": "4.274", "nll_loss": "2.857", "ppl": "7.25", "wps": "61674.9", "ups": "17.17", "wpb": "3591.2", "bsz": "134.1", "num_updates": "26300", "lr": "0.00389989", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1522"}
2023-12-10 10:46:59 | INFO | train_inner | {"epoch": 24, "update": 23.959, "loss": "4.252", "nll_loss": "2.836", "ppl": "7.14", "wps": "68399.2", "ups": "19.11", "wpb": "3578.3", "bsz": "149.4", "num_updates": "26400", "lr": "0.00389249", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1527"}
2023-12-10 10:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:47:03 | INFO | valid | {"epoch": 24, "valid_loss": "4.433", "valid_nll_loss": "3.074", "valid_ppl": "8.42", "valid_wps": "130849", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "26445", "valid_best_loss": "4.433"}
2023-12-10 10:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 26445 updates
2023-12-10 10:47:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint24.pt
2023-12-10 10:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint24.pt
2023-12-10 10:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint24.pt (epoch 24 @ 26445 updates, score 4.433) (writing took 2.23103014100343 seconds)
2023-12-10 10:47:05 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-12-10 10:47:05 | INFO | train | {"epoch": 24, "train_loss": "4.208", "train_nll_loss": "2.781", "train_ppl": "6.87", "train_wps": "62462.7", "train_ups": "17.43", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "26445", "train_lr": "0.00388918", "train_gnorm": "0.252", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "1533"}
2023-12-10 10:47:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:47:05 | INFO | fairseq.trainer | begin training epoch 25
2023-12-10 10:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:47:09 | INFO | train_inner | {"epoch": 25, "update": 24.05, "loss": "4.192", "nll_loss": "2.764", "ppl": "6.79", "wps": "37302.6", "ups": "10.49", "wpb": "3557.2", "bsz": "138.9", "num_updates": "26500", "lr": "0.00388514", "gnorm": "0.247", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1537"}
2023-12-10 10:47:14 | INFO | train_inner | {"epoch": 25, "update": 24.141, "loss": "4.061", "nll_loss": "2.611", "ppl": "6.11", "wps": "69826.7", "ups": "19.53", "wpb": "3575.6", "bsz": "156.3", "num_updates": "26600", "lr": "0.00387783", "gnorm": "0.239", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1542"}
2023-12-10 10:47:20 | INFO | train_inner | {"epoch": 25, "update": 24.231, "loss": "4.185", "nll_loss": "2.753", "ppl": "6.74", "wps": "62195.8", "ups": "17.41", "wpb": "3571.9", "bsz": "136.7", "num_updates": "26700", "lr": "0.00387056", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1548"}
2023-12-10 10:47:25 | INFO | train_inner | {"epoch": 25, "update": 24.322, "loss": "4.133", "nll_loss": "2.696", "ppl": "6.48", "wps": "70779.4", "ups": "19.68", "wpb": "3595.7", "bsz": "164.1", "num_updates": "26800", "lr": "0.00386334", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1553"}
2023-12-10 10:47:30 | INFO | train_inner | {"epoch": 25, "update": 24.413, "loss": "4.173", "nll_loss": "2.742", "ppl": "6.69", "wps": "69272.3", "ups": "19.3", "wpb": "3589.8", "bsz": "153.4", "num_updates": "26900", "lr": "0.00385615", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1558"}
2023-12-10 10:47:35 | INFO | train_inner | {"epoch": 25, "update": 24.504, "loss": "4.197", "nll_loss": "2.769", "ppl": "6.82", "wps": "67875.4", "ups": "19.09", "wpb": "3556.2", "bsz": "144.9", "num_updates": "27000", "lr": "0.003849", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1563"}
2023-12-10 10:47:41 | INFO | train_inner | {"epoch": 25, "update": 24.594, "loss": "4.216", "nll_loss": "2.792", "ppl": "6.92", "wps": "64615.5", "ups": "17.88", "wpb": "3614.2", "bsz": "141.4", "num_updates": "27100", "lr": "0.00384189", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1569"}
2023-12-10 10:47:46 | INFO | train_inner | {"epoch": 25, "update": 24.685, "loss": "4.235", "nll_loss": "2.812", "ppl": "7.02", "wps": "66110.1", "ups": "18.79", "wpb": "3518.6", "bsz": "151", "num_updates": "27200", "lr": "0.00383482", "gnorm": "0.312", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1574"}
2023-12-10 10:47:52 | INFO | train_inner | {"epoch": 25, "update": 24.776, "loss": "4.268", "nll_loss": "2.852", "ppl": "7.22", "wps": "59758", "ups": "16.84", "wpb": "3548.6", "bsz": "135.2", "num_updates": "27300", "lr": "0.0038278", "gnorm": "0.248", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1580"}
2023-12-10 10:47:57 | INFO | train_inner | {"epoch": 25, "update": 24.867, "loss": "4.217", "nll_loss": "2.793", "ppl": "6.93", "wps": "65484.3", "ups": "17.88", "wpb": "3663.2", "bsz": "142.9", "num_updates": "27400", "lr": "0.0038208", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1586"}
2023-12-10 10:48:03 | INFO | train_inner | {"epoch": 25, "update": 24.957, "loss": "4.267", "nll_loss": "2.851", "ppl": "7.22", "wps": "66777", "ups": "18.44", "wpb": "3621.1", "bsz": "134.6", "num_updates": "27500", "lr": "0.00381385", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1591"}
2023-12-10 10:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:48:07 | INFO | valid | {"epoch": 25, "valid_loss": "4.42", "valid_nll_loss": "3.047", "valid_ppl": "8.27", "valid_wps": "131232", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "27547", "valid_best_loss": "4.42"}
2023-12-10 10:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 27547 updates
2023-12-10 10:48:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint25.pt
2023-12-10 10:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint25.pt
2023-12-10 10:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint25.pt (epoch 25 @ 27547 updates, score 4.42) (writing took 2.3315169070847332 seconds)
2023-12-10 10:48:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-12-10 10:48:09 | INFO | train | {"epoch": 25, "train_loss": "4.193", "train_nll_loss": "2.764", "train_ppl": "6.79", "train_wps": "61574.2", "train_ups": "17.18", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "27547", "train_lr": "0.0038106", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1597"}
2023-12-10 10:48:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:48:09 | INFO | fairseq.trainer | begin training epoch 26
2023-12-10 10:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:48:12 | INFO | train_inner | {"epoch": 26, "update": 25.048, "loss": "4.185", "nll_loss": "2.756", "ppl": "6.75", "wps": "38122.5", "ups": "10.65", "wpb": "3580.3", "bsz": "139", "num_updates": "27600", "lr": "0.00380693", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1600"}
2023-12-10 10:48:18 | INFO | train_inner | {"epoch": 26, "update": 25.139, "loss": "4.074", "nll_loss": "2.624", "ppl": "6.16", "wps": "60428.2", "ups": "17.16", "wpb": "3522.2", "bsz": "150.8", "num_updates": "27700", "lr": "0.00380006", "gnorm": "0.254", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1606"}
2023-12-10 10:48:24 | INFO | train_inner | {"epoch": 26, "update": 25.23, "loss": "4.172", "nll_loss": "2.737", "ppl": "6.67", "wps": "64842.7", "ups": "17.78", "wpb": "3645.9", "bsz": "127.3", "num_updates": "27800", "lr": "0.00379322", "gnorm": "0.246", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1612"}
2023-12-10 10:48:29 | INFO | train_inner | {"epoch": 26, "update": 25.32, "loss": "4.212", "nll_loss": "2.783", "ppl": "6.88", "wps": "63000.9", "ups": "17.97", "wpb": "3505.2", "bsz": "126.6", "num_updates": "27900", "lr": "0.00378641", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1617"}
2023-12-10 10:48:34 | INFO | train_inner | {"epoch": 26, "update": 25.411, "loss": "4.104", "nll_loss": "2.666", "ppl": "6.34", "wps": "75286.3", "ups": "20.53", "wpb": "3666.7", "bsz": "158.2", "num_updates": "28000", "lr": "0.00377964", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1622"}
2023-12-10 10:48:39 | INFO | train_inner | {"epoch": 26, "update": 25.502, "loss": "4.113", "nll_loss": "2.673", "ppl": "6.38", "wps": "70194.7", "ups": "19.39", "wpb": "3620.1", "bsz": "158.8", "num_updates": "28100", "lr": "0.00377291", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1627"}
2023-12-10 10:48:45 | INFO | train_inner | {"epoch": 26, "update": 25.593, "loss": "4.207", "nll_loss": "2.781", "ppl": "6.87", "wps": "64980.3", "ups": "18.46", "wpb": "3520.3", "bsz": "142.6", "num_updates": "28200", "lr": "0.00376622", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1633"}
2023-12-10 10:48:50 | INFO | train_inner | {"epoch": 26, "update": 25.683, "loss": "4.235", "nll_loss": "2.812", "ppl": "7.02", "wps": "63806.4", "ups": "17.76", "wpb": "3593.5", "bsz": "137.6", "num_updates": "28300", "lr": "0.00375956", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1639"}
2023-12-10 10:48:56 | INFO | train_inner | {"epoch": 26, "update": 25.774, "loss": "4.236", "nll_loss": "2.816", "ppl": "7.04", "wps": "65459.9", "ups": "18.25", "wpb": "3586", "bsz": "139.8", "num_updates": "28400", "lr": "0.00375293", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1644"}
2023-12-10 10:49:01 | INFO | train_inner | {"epoch": 26, "update": 25.865, "loss": "4.201", "nll_loss": "2.776", "ppl": "6.85", "wps": "71116", "ups": "19.78", "wpb": "3594.7", "bsz": "155.3", "num_updates": "28500", "lr": "0.00374634", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1649"}
2023-12-10 10:49:06 | INFO | train_inner | {"epoch": 26, "update": 25.956, "loss": "4.187", "nll_loss": "2.762", "ppl": "6.79", "wps": "66344.7", "ups": "18.59", "wpb": "3568.9", "bsz": "163.1", "num_updates": "28600", "lr": "0.00373979", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1654"}
2023-12-10 10:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:49:10 | INFO | valid | {"epoch": 26, "valid_loss": "4.426", "valid_nll_loss": "3.05", "valid_ppl": "8.28", "valid_wps": "127624", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "28649", "valid_best_loss": "4.42"}
2023-12-10 10:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 28649 updates
2023-12-10 10:49:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint26.pt
2023-12-10 10:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint26.pt
2023-12-10 10:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint26.pt (epoch 26 @ 28649 updates, score 4.426) (writing took 1.62948093470186 seconds)
2023-12-10 10:49:12 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-12-10 10:49:12 | INFO | train | {"epoch": 26, "train_loss": "4.174", "train_nll_loss": "2.743", "train_ppl": "6.7", "train_wps": "62986.7", "train_ups": "17.58", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "28649", "train_lr": "0.00373659", "train_gnorm": "0.253", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "1660"}
2023-12-10 10:49:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:49:12 | INFO | fairseq.trainer | begin training epoch 27
2023-12-10 10:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:49:15 | INFO | train_inner | {"epoch": 27, "update": 26.046, "loss": "4.168", "nll_loss": "2.736", "ppl": "6.66", "wps": "40573.7", "ups": "11.36", "wpb": "3570.1", "bsz": "135.3", "num_updates": "28700", "lr": "0.00373327", "gnorm": "0.241", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1663"}
2023-12-10 10:49:21 | INFO | train_inner | {"epoch": 27, "update": 26.137, "loss": "4.093", "nll_loss": "2.647", "ppl": "6.26", "wps": "62631.3", "ups": "17.73", "wpb": "3531.9", "bsz": "150.6", "num_updates": "28800", "lr": "0.00372678", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1669"}
2023-12-10 10:49:26 | INFO | train_inner | {"epoch": 27, "update": 26.228, "loss": "4.147", "nll_loss": "2.711", "ppl": "6.55", "wps": "67007.3", "ups": "18.74", "wpb": "3575.6", "bsz": "140.2", "num_updates": "28900", "lr": "0.00372033", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1674"}
2023-12-10 10:49:32 | INFO | train_inner | {"epoch": 27, "update": 26.319, "loss": "4.157", "nll_loss": "2.72", "ppl": "6.59", "wps": "62105.7", "ups": "17.29", "wpb": "3591.3", "bsz": "129.7", "num_updates": "29000", "lr": "0.00371391", "gnorm": "0.251", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1680"}
2023-12-10 10:49:37 | INFO | train_inner | {"epoch": 27, "update": 26.409, "loss": "4.13", "nll_loss": "2.695", "ppl": "6.47", "wps": "71662.2", "ups": "19.86", "wpb": "3608.6", "bsz": "158.6", "num_updates": "29100", "lr": "0.00370752", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1685"}
2023-12-10 10:49:42 | INFO | train_inner | {"epoch": 27, "update": 26.5, "loss": "4.133", "nll_loss": "2.697", "ppl": "6.48", "wps": "74881.1", "ups": "20.68", "wpb": "3620.8", "bsz": "158.6", "num_updates": "29200", "lr": "0.00370117", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1690"}
2023-12-10 10:49:48 | INFO | train_inner | {"epoch": 27, "update": 26.591, "loss": "4.206", "nll_loss": "2.781", "ppl": "6.87", "wps": "61599.9", "ups": "16.9", "wpb": "3645.3", "bsz": "139.9", "num_updates": "29300", "lr": "0.00369484", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1696"}
2023-12-10 10:49:53 | INFO | train_inner | {"epoch": 27, "update": 26.681, "loss": "4.182", "nll_loss": "2.754", "ppl": "6.75", "wps": "64054.7", "ups": "18.04", "wpb": "3550.8", "bsz": "143.4", "num_updates": "29400", "lr": "0.00368856", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1701"}
2023-12-10 10:49:58 | INFO | train_inner | {"epoch": 27, "update": 26.772, "loss": "4.209", "nll_loss": "2.784", "ppl": "6.89", "wps": "70210.3", "ups": "19.51", "wpb": "3598.8", "bsz": "139.2", "num_updates": "29500", "lr": "0.0036823", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1706"}
2023-12-10 10:50:04 | INFO | train_inner | {"epoch": 27, "update": 26.863, "loss": "4.168", "nll_loss": "2.738", "ppl": "6.67", "wps": "67755", "ups": "18.84", "wpb": "3596.3", "bsz": "150.1", "num_updates": "29600", "lr": "0.00367607", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1712"}
2023-12-10 10:50:09 | INFO | train_inner | {"epoch": 27, "update": 26.954, "loss": "4.194", "nll_loss": "2.768", "ppl": "6.81", "wps": "62878.7", "ups": "17.67", "wpb": "3559", "bsz": "150.1", "num_updates": "29700", "lr": "0.00366988", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1717"}
2023-12-10 10:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:50:14 | INFO | valid | {"epoch": 27, "valid_loss": "4.422", "valid_nll_loss": "3.051", "valid_ppl": "8.29", "valid_wps": "124463", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "29751", "valid_best_loss": "4.42"}
2023-12-10 10:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 29751 updates
2023-12-10 10:50:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint27.pt
2023-12-10 10:50:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint27.pt
2023-12-10 10:50:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint27.pt (epoch 27 @ 29751 updates, score 4.422) (writing took 1.7717334320768714 seconds)
2023-12-10 10:50:15 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-12-10 10:50:15 | INFO | train | {"epoch": 27, "train_loss": "4.161", "train_nll_loss": "2.728", "train_ppl": "6.63", "train_wps": "62259.7", "train_ups": "17.37", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "29751", "train_lr": "0.00366673", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1724"}
2023-12-10 10:50:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:50:15 | INFO | fairseq.trainer | begin training epoch 28
2023-12-10 10:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:50:18 | INFO | train_inner | {"epoch": 28, "update": 27.044, "loss": "4.147", "nll_loss": "2.712", "ppl": "6.55", "wps": "39621.3", "ups": "11.08", "wpb": "3577.5", "bsz": "143.4", "num_updates": "29800", "lr": "0.00366372", "gnorm": "0.246", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1726"}
2023-12-10 10:50:24 | INFO | train_inner | {"epoch": 28, "update": 27.135, "loss": "4.073", "nll_loss": "2.624", "ppl": "6.16", "wps": "65635.7", "ups": "17.92", "wpb": "3662.7", "bsz": "136.6", "num_updates": "29900", "lr": "0.00365758", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1732"}
2023-12-10 10:50:30 | INFO | train_inner | {"epoch": 28, "update": 27.226, "loss": "4.117", "nll_loss": "2.673", "ppl": "6.38", "wps": "62356.5", "ups": "17.55", "wpb": "3552.8", "bsz": "140.6", "num_updates": "30000", "lr": "0.00365148", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1738"}
2023-12-10 10:50:35 | INFO | train_inner | {"epoch": 28, "update": 27.317, "loss": "4.11", "nll_loss": "2.668", "ppl": "6.36", "wps": "66271.1", "ups": "18.28", "wpb": "3625.8", "bsz": "145.5", "num_updates": "30100", "lr": "0.00364541", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1743"}
2023-12-10 10:50:41 | INFO | train_inner | {"epoch": 28, "update": 27.407, "loss": "4.201", "nll_loss": "2.771", "ppl": "6.83", "wps": "55827.1", "ups": "15.89", "wpb": "3512.6", "bsz": "117.7", "num_updates": "30200", "lr": "0.00363937", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1749"}
2023-12-10 10:50:47 | INFO | train_inner | {"epoch": 28, "update": 27.498, "loss": "4.127", "nll_loss": "2.688", "ppl": "6.44", "wps": "64929.2", "ups": "18.34", "wpb": "3540.9", "bsz": "148", "num_updates": "30300", "lr": "0.00363336", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1755"}
2023-12-10 10:50:53 | INFO | train_inner | {"epoch": 28, "update": 27.589, "loss": "4.147", "nll_loss": "2.711", "ppl": "6.55", "wps": "62030.4", "ups": "17.53", "wpb": "3537.6", "bsz": "144.2", "num_updates": "30400", "lr": "0.00362738", "gnorm": "0.26", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1761"}
2023-12-10 10:50:58 | INFO | train_inner | {"epoch": 28, "update": 27.68, "loss": "4.161", "nll_loss": "2.73", "ppl": "6.63", "wps": "68579.2", "ups": "19.33", "wpb": "3548.1", "bsz": "155", "num_updates": "30500", "lr": "0.00362143", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1766"}
2023-12-10 10:51:03 | INFO | train_inner | {"epoch": 28, "update": 27.77, "loss": "4.148", "nll_loss": "2.717", "ppl": "6.57", "wps": "67444.1", "ups": "18.71", "wpb": "3605.6", "bsz": "161.4", "num_updates": "30600", "lr": "0.00361551", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1771"}
2023-12-10 10:51:08 | INFO | train_inner | {"epoch": 28, "update": 27.861, "loss": "4.18", "nll_loss": "2.753", "ppl": "6.74", "wps": "68415.3", "ups": "18.95", "wpb": "3610.5", "bsz": "146.1", "num_updates": "30700", "lr": "0.00360961", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1776"}
2023-12-10 10:51:14 | INFO | train_inner | {"epoch": 28, "update": 27.952, "loss": "4.192", "nll_loss": "2.767", "ppl": "6.81", "wps": "66426.6", "ups": "18.25", "wpb": "3639.3", "bsz": "153.2", "num_updates": "30800", "lr": "0.00360375", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1782"}
2023-12-10 10:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:51:18 | INFO | valid | {"epoch": 28, "valid_loss": "4.43", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "129624", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "30853", "valid_best_loss": "4.42"}
2023-12-10 10:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 30853 updates
2023-12-10 10:51:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint28.pt
2023-12-10 10:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint28.pt
2023-12-10 10:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint28.pt (epoch 28 @ 30853 updates, score 4.43) (writing took 1.7203000709414482 seconds)
2023-12-10 10:51:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-12-10 10:51:20 | INFO | train | {"epoch": 28, "train_loss": "4.144", "train_nll_loss": "2.709", "train_ppl": "6.54", "train_wps": "61466.1", "train_ups": "17.15", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "30853", "train_lr": "0.00360065", "train_gnorm": "0.254", "train_loss_scale": "32", "train_train_wall": "60", "train_gb_free": "39", "train_wall": "1788"}
2023-12-10 10:51:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:51:20 | INFO | fairseq.trainer | begin training epoch 29
2023-12-10 10:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:51:23 | INFO | train_inner | {"epoch": 29, "update": 28.043, "loss": "4.099", "nll_loss": "2.657", "ppl": "6.31", "wps": "40372.3", "ups": "11.39", "wpb": "3544.3", "bsz": "147.8", "num_updates": "30900", "lr": "0.00359791", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1791"}
2023-12-10 10:51:28 | INFO | train_inner | {"epoch": 29, "update": 28.133, "loss": "4.063", "nll_loss": "2.615", "ppl": "6.13", "wps": "73492.3", "ups": "20.05", "wpb": "3666.1", "bsz": "147.5", "num_updates": "31000", "lr": "0.00359211", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1796"}
2023-12-10 10:51:33 | INFO | train_inner | {"epoch": 29, "update": 28.224, "loss": "4.046", "nll_loss": "2.596", "ppl": "6.05", "wps": "71459.1", "ups": "19.83", "wpb": "3603.7", "bsz": "161.6", "num_updates": "31100", "lr": "0.00358633", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1801"}
2023-12-10 10:51:38 | INFO | train_inner | {"epoch": 29, "update": 28.315, "loss": "4.103", "nll_loss": "2.66", "ppl": "6.32", "wps": "67365.9", "ups": "18.78", "wpb": "3586.7", "bsz": "148.1", "num_updates": "31200", "lr": "0.00358057", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1806"}
2023-12-10 10:51:43 | INFO | train_inner | {"epoch": 29, "update": 28.406, "loss": "4.083", "nll_loss": "2.641", "ppl": "6.24", "wps": "67174.8", "ups": "18.87", "wpb": "3560.6", "bsz": "156.2", "num_updates": "31300", "lr": "0.00357485", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1811"}
2023-12-10 10:51:49 | INFO | train_inner | {"epoch": 29, "update": 28.496, "loss": "4.145", "nll_loss": "2.711", "ppl": "6.55", "wps": "65827.7", "ups": "18.2", "wpb": "3616.5", "bsz": "141.2", "num_updates": "31400", "lr": "0.00356915", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1817"}
2023-12-10 10:51:54 | INFO | train_inner | {"epoch": 29, "update": 28.587, "loss": "4.187", "nll_loss": "2.757", "ppl": "6.76", "wps": "64763.4", "ups": "18.4", "wpb": "3519.5", "bsz": "137", "num_updates": "31500", "lr": "0.00356348", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1822"}
2023-12-10 10:52:00 | INFO | train_inner | {"epoch": 29, "update": 28.678, "loss": "4.178", "nll_loss": "2.747", "ppl": "6.71", "wps": "58618.1", "ups": "16.37", "wpb": "3579.8", "bsz": "136.3", "num_updates": "31600", "lr": "0.00355784", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1828"}
2023-12-10 10:52:06 | INFO | train_inner | {"epoch": 29, "update": 28.769, "loss": "4.208", "nll_loss": "2.782", "ppl": "6.88", "wps": "62511.8", "ups": "17.94", "wpb": "3484.3", "bsz": "137", "num_updates": "31700", "lr": "0.00355222", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1834"}
2023-12-10 10:52:11 | INFO | train_inner | {"epoch": 29, "update": 28.859, "loss": "4.15", "nll_loss": "2.717", "ppl": "6.58", "wps": "70907.4", "ups": "19.14", "wpb": "3705.5", "bsz": "148.8", "num_updates": "31800", "lr": "0.00354663", "gnorm": "0.242", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1839"}
2023-12-10 10:52:16 | INFO | train_inner | {"epoch": 29, "update": 28.95, "loss": "4.19", "nll_loss": "2.764", "ppl": "6.79", "wps": "66352.3", "ups": "18.41", "wpb": "3604.3", "bsz": "144", "num_updates": "31900", "lr": "0.00354107", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1845"}
2023-12-10 10:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:52:21 | INFO | valid | {"epoch": 29, "valid_loss": "4.438", "valid_nll_loss": "3.062", "valid_ppl": "8.35", "valid_wps": "128944", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "31955", "valid_best_loss": "4.42"}
2023-12-10 10:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 31955 updates
2023-12-10 10:52:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint29.pt
2023-12-10 10:52:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint29.pt
2023-12-10 10:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint29.pt (epoch 29 @ 31955 updates, score 4.438) (writing took 1.597847049124539 seconds)
2023-12-10 10:52:23 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-12-10 10:52:23 | INFO | train | {"epoch": 29, "train_loss": "4.132", "train_nll_loss": "2.696", "train_ppl": "6.48", "train_wps": "62574.4", "train_ups": "17.46", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "31955", "train_lr": "0.00353802", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "1851"}
2023-12-10 10:52:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:52:23 | INFO | fairseq.trainer | begin training epoch 30
2023-12-10 10:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:52:25 | INFO | train_inner | {"epoch": 30, "update": 29.041, "loss": "4.112", "nll_loss": "2.672", "ppl": "6.37", "wps": "40636.7", "ups": "11.51", "wpb": "3531.3", "bsz": "145.4", "num_updates": "32000", "lr": "0.00353553", "gnorm": "0.252", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1853"}
2023-12-10 10:52:31 | INFO | train_inner | {"epoch": 30, "update": 29.132, "loss": "4.079", "nll_loss": "2.632", "ppl": "6.2", "wps": "61478.8", "ups": "17.34", "wpb": "3545.6", "bsz": "143", "num_updates": "32100", "lr": "0.00353002", "gnorm": "0.257", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1859"}
2023-12-10 10:52:37 | INFO | train_inner | {"epoch": 30, "update": 29.222, "loss": "4.043", "nll_loss": "2.59", "ppl": "6.02", "wps": "64409.9", "ups": "17.9", "wpb": "3598.5", "bsz": "153.7", "num_updates": "32200", "lr": "0.00352454", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1865"}
2023-12-10 10:52:42 | INFO | train_inner | {"epoch": 30, "update": 29.313, "loss": "4.049", "nll_loss": "2.599", "ppl": "6.06", "wps": "69624.3", "ups": "18.97", "wpb": "3670.7", "bsz": "154.5", "num_updates": "32300", "lr": "0.00351908", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1870"}
2023-12-10 10:52:47 | INFO | train_inner | {"epoch": 30, "update": 29.404, "loss": "4.102", "nll_loss": "2.662", "ppl": "6.33", "wps": "67975.4", "ups": "18.72", "wpb": "3631.9", "bsz": "147.5", "num_updates": "32400", "lr": "0.00351364", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1875"}
2023-12-10 10:52:52 | INFO | train_inner | {"epoch": 30, "update": 29.495, "loss": "4.137", "nll_loss": "2.701", "ppl": "6.5", "wps": "67936.5", "ups": "19.01", "wpb": "3573.4", "bsz": "137.6", "num_updates": "32500", "lr": "0.00350823", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1881"}
2023-12-10 10:52:58 | INFO | train_inner | {"epoch": 30, "update": 29.585, "loss": "4.136", "nll_loss": "2.699", "ppl": "6.49", "wps": "64578.4", "ups": "18.1", "wpb": "3568", "bsz": "136.8", "num_updates": "32600", "lr": "0.00350285", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1886"}
2023-12-10 10:53:04 | INFO | train_inner | {"epoch": 30, "update": 29.676, "loss": "4.195", "nll_loss": "2.766", "ppl": "6.8", "wps": "58706.1", "ups": "16.59", "wpb": "3537.7", "bsz": "129", "num_updates": "32700", "lr": "0.00349749", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1892"}
2023-12-10 10:53:10 | INFO | train_inner | {"epoch": 30, "update": 29.767, "loss": "4.169", "nll_loss": "2.74", "ppl": "6.68", "wps": "62034.2", "ups": "17.69", "wpb": "3507", "bsz": "146.7", "num_updates": "32800", "lr": "0.00349215", "gnorm": "0.259", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1898"}
2023-12-10 10:53:15 | INFO | train_inner | {"epoch": 30, "update": 29.858, "loss": "4.159", "nll_loss": "2.728", "ppl": "6.63", "wps": "62337.9", "ups": "17.51", "wpb": "3560.5", "bsz": "141", "num_updates": "32900", "lr": "0.00348684", "gnorm": "0.259", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1903"}
2023-12-10 10:53:20 | INFO | train_inner | {"epoch": 30, "update": 29.948, "loss": "4.118", "nll_loss": "2.685", "ppl": "6.43", "wps": "82586.1", "ups": "22.5", "wpb": "3670.9", "bsz": "167.5", "num_updates": "33000", "lr": "0.00348155", "gnorm": "0.253", "loss_scale": "32", "train_wall": "4", "gb_free": "38.9", "wall": "1908"}
2023-12-10 10:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:53:25 | INFO | valid | {"epoch": 30, "valid_loss": "4.426", "valid_nll_loss": "3.038", "valid_ppl": "8.22", "valid_wps": "129774", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "33057", "valid_best_loss": "4.42"}
2023-12-10 10:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 33057 updates
2023-12-10 10:53:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint30.pt
2023-12-10 10:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint30.pt
2023-12-10 10:53:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint30.pt (epoch 30 @ 33057 updates, score 4.426) (writing took 1.6214996515773237 seconds)
2023-12-10 10:53:26 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-12-10 10:53:26 | INFO | train | {"epoch": 30, "train_loss": "4.117", "train_nll_loss": "2.678", "train_ppl": "6.4", "train_wps": "62180.3", "train_ups": "17.35", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "33057", "train_lr": "0.00347855", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "38.9", "train_wall": "1914"}
2023-12-10 10:53:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:53:26 | INFO | fairseq.trainer | begin training epoch 31
2023-12-10 10:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:53:29 | INFO | train_inner | {"epoch": 31, "update": 30.039, "loss": "4.13", "nll_loss": "2.693", "ppl": "6.47", "wps": "40037.9", "ups": "11.28", "wpb": "3548.8", "bsz": "135.6", "num_updates": "33100", "lr": "0.00347629", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1917"}
2023-12-10 10:53:34 | INFO | train_inner | {"epoch": 31, "update": 30.13, "loss": "4.037", "nll_loss": "2.584", "ppl": "6", "wps": "62806.8", "ups": "17.59", "wpb": "3570.8", "bsz": "141.4", "num_updates": "33200", "lr": "0.00347105", "gnorm": "0.255", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1922"}
2023-12-10 10:53:40 | INFO | train_inner | {"epoch": 31, "update": 30.221, "loss": "4.052", "nll_loss": "2.601", "ppl": "6.07", "wps": "64894.8", "ups": "18.38", "wpb": "3530.8", "bsz": "143.8", "num_updates": "33300", "lr": "0.00346583", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1928"}
2023-12-10 10:53:45 | INFO | train_inner | {"epoch": 31, "update": 30.311, "loss": "4.077", "nll_loss": "2.629", "ppl": "6.19", "wps": "63535", "ups": "17.7", "wpb": "3589.7", "bsz": "140.6", "num_updates": "33400", "lr": "0.00346064", "gnorm": "0.256", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1934"}
2023-12-10 10:53:50 | INFO | train_inner | {"epoch": 31, "update": 30.402, "loss": "4.116", "nll_loss": "2.676", "ppl": "6.39", "wps": "70862.4", "ups": "19.9", "wpb": "3560.1", "bsz": "148.3", "num_updates": "33500", "lr": "0.00345547", "gnorm": "0.278", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1939"}
2023-12-10 10:53:56 | INFO | train_inner | {"epoch": 31, "update": 30.493, "loss": "4.121", "nll_loss": "2.682", "ppl": "6.42", "wps": "68532.3", "ups": "19.11", "wpb": "3586.8", "bsz": "139", "num_updates": "33600", "lr": "0.00345033", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1944"}
2023-12-10 10:54:01 | INFO | train_inner | {"epoch": 31, "update": 30.583, "loss": "4.157", "nll_loss": "2.722", "ppl": "6.6", "wps": "63541.3", "ups": "17.86", "wpb": "3558.1", "bsz": "132.7", "num_updates": "33700", "lr": "0.0034452", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1949"}
2023-12-10 10:54:07 | INFO | train_inner | {"epoch": 31, "update": 30.674, "loss": "4.159", "nll_loss": "2.727", "ppl": "6.62", "wps": "65425.7", "ups": "17.97", "wpb": "3640.5", "bsz": "147.1", "num_updates": "33800", "lr": "0.0034401", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1955"}
2023-12-10 10:54:12 | INFO | train_inner | {"epoch": 31, "update": 30.765, "loss": "4.119", "nll_loss": "2.681", "ppl": "6.41", "wps": "65796.8", "ups": "18.42", "wpb": "3571.2", "bsz": "147.9", "num_updates": "33900", "lr": "0.00343503", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1960"}
2023-12-10 10:54:17 | INFO | train_inner | {"epoch": 31, "update": 30.856, "loss": "4.078", "nll_loss": "2.637", "ppl": "6.22", "wps": "74077", "ups": "20.4", "wpb": "3630.7", "bsz": "165.5", "num_updates": "34000", "lr": "0.00342997", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1965"}
2023-12-10 10:54:22 | INFO | train_inner | {"epoch": 31, "update": 30.946, "loss": "4.14", "nll_loss": "2.708", "ppl": "6.53", "wps": "68224.7", "ups": "18.96", "wpb": "3597.6", "bsz": "151.4", "num_updates": "34100", "lr": "0.00342494", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1971"}
2023-12-10 10:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:54:27 | INFO | valid | {"epoch": 31, "valid_loss": "4.409", "valid_nll_loss": "3.051", "valid_ppl": "8.29", "valid_wps": "125529", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "34159", "valid_best_loss": "4.409"}
2023-12-10 10:54:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 34159 updates
2023-12-10 10:54:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint31.pt
2023-12-10 10:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint31.pt
2023-12-10 10:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint31.pt (epoch 31 @ 34159 updates, score 4.409) (writing took 2.3172166268341243 seconds)
2023-12-10 10:54:30 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-12-10 10:54:30 | INFO | train | {"epoch": 31, "train_loss": "4.106", "train_nll_loss": "2.665", "train_ppl": "6.34", "train_wps": "62404.7", "train_ups": "17.41", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "34159", "train_lr": "0.00342198", "train_gnorm": "0.258", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "1978"}
2023-12-10 10:54:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:54:30 | INFO | fairseq.trainer | begin training epoch 32
2023-12-10 10:54:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:54:32 | INFO | train_inner | {"epoch": 32, "update": 31.037, "loss": "4.073", "nll_loss": "2.628", "ppl": "6.18", "wps": "37862.9", "ups": "10.55", "wpb": "3589.5", "bsz": "147.2", "num_updates": "34200", "lr": "0.00341993", "gnorm": "0.247", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1980"}
2023-12-10 10:54:38 | INFO | train_inner | {"epoch": 32, "update": 31.128, "loss": "4.056", "nll_loss": "2.604", "ppl": "6.08", "wps": "62591.2", "ups": "17.71", "wpb": "3534.5", "bsz": "125", "num_updates": "34300", "lr": "0.00341494", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1986"}
2023-12-10 10:54:43 | INFO | train_inner | {"epoch": 32, "update": 31.219, "loss": "4.067", "nll_loss": "2.62", "ppl": "6.15", "wps": "69203.9", "ups": "19.07", "wpb": "3629.1", "bsz": "144.5", "num_updates": "34400", "lr": "0.00340997", "gnorm": "0.241", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1991"}
2023-12-10 10:54:48 | INFO | train_inner | {"epoch": 32, "update": 31.309, "loss": "3.993", "nll_loss": "2.537", "ppl": "5.8", "wps": "74255.6", "ups": "20.41", "wpb": "3638.6", "bsz": "167", "num_updates": "34500", "lr": "0.00340503", "gnorm": "0.244", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1996"}
2023-12-10 10:54:53 | INFO | train_inner | {"epoch": 32, "update": 31.4, "loss": "4.086", "nll_loss": "2.64", "ppl": "6.23", "wps": "62928.1", "ups": "17.47", "wpb": "3601.9", "bsz": "143.5", "num_updates": "34600", "lr": "0.0034001", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2002"}
2023-12-10 10:54:59 | INFO | train_inner | {"epoch": 32, "update": 31.491, "loss": "4.106", "nll_loss": "2.665", "ppl": "6.34", "wps": "63720.3", "ups": "17.6", "wpb": "3620.9", "bsz": "146.8", "num_updates": "34700", "lr": "0.0033952", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2007"}
2023-12-10 10:55:05 | INFO | train_inner | {"epoch": 32, "update": 31.582, "loss": "4.135", "nll_loss": "2.7", "ppl": "6.5", "wps": "63005.7", "ups": "17.61", "wpb": "3578", "bsz": "137.6", "num_updates": "34800", "lr": "0.00339032", "gnorm": "0.268", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2013"}
2023-12-10 10:55:11 | INFO | train_inner | {"epoch": 32, "update": 31.672, "loss": "4.095", "nll_loss": "2.652", "ppl": "6.28", "wps": "60411.3", "ups": "17.06", "wpb": "3542", "bsz": "153.9", "num_updates": "34900", "lr": "0.00338546", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2019"}
2023-12-10 10:55:16 | INFO | train_inner | {"epoch": 32, "update": 31.763, "loss": "4.123", "nll_loss": "2.688", "ppl": "6.45", "wps": "66599.5", "ups": "18.9", "wpb": "3524.1", "bsz": "146.4", "num_updates": "35000", "lr": "0.00338062", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2024"}
2023-12-10 10:55:22 | INFO | train_inner | {"epoch": 32, "update": 31.854, "loss": "4.155", "nll_loss": "2.723", "ppl": "6.6", "wps": "57978.8", "ups": "16.33", "wpb": "3550.8", "bsz": "137.8", "num_updates": "35100", "lr": "0.0033758", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2030"}
2023-12-10 10:55:27 | INFO | train_inner | {"epoch": 32, "update": 31.945, "loss": "4.109", "nll_loss": "2.673", "ppl": "6.38", "wps": "70560", "ups": "19.37", "wpb": "3642", "bsz": "153", "num_updates": "35200", "lr": "0.003371", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2035"}
2023-12-10 10:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:55:32 | INFO | valid | {"epoch": 32, "valid_loss": "4.42", "valid_nll_loss": "3.054", "valid_ppl": "8.3", "valid_wps": "126137", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "35261", "valid_best_loss": "4.409"}
2023-12-10 10:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 35261 updates
2023-12-10 10:55:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint32.pt
2023-12-10 10:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint32.pt
2023-12-10 10:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint32.pt (epoch 32 @ 35261 updates, score 4.42) (writing took 5.119749933015555 seconds)
2023-12-10 10:55:37 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-12-10 10:55:37 | INFO | train | {"epoch": 32, "train_loss": "4.092", "train_nll_loss": "2.65", "train_ppl": "6.28", "train_wps": "58567.1", "train_ups": "16.34", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "35261", "train_lr": "0.00336808", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "60", "train_gb_free": "38.9", "train_wall": "2045"}
2023-12-10 10:55:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:55:37 | INFO | fairseq.trainer | begin training epoch 33
2023-12-10 10:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:55:39 | INFO | train_inner | {"epoch": 33, "update": 32.035, "loss": "4.086", "nll_loss": "2.644", "ppl": "6.25", "wps": "29808.9", "ups": "8.33", "wpb": "3580.6", "bsz": "144.8", "num_updates": "35300", "lr": "0.00336622", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2047"}
2023-12-10 10:55:45 | INFO | train_inner | {"epoch": 33, "update": 32.126, "loss": "4.032", "nll_loss": "2.576", "ppl": "5.96", "wps": "62028.5", "ups": "17.12", "wpb": "3623.8", "bsz": "129.8", "num_updates": "35400", "lr": "0.00336146", "gnorm": "0.253", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2053"}
2023-12-10 10:55:50 | INFO | train_inner | {"epoch": 33, "update": 32.217, "loss": "4.015", "nll_loss": "2.56", "ppl": "5.9", "wps": "70872", "ups": "19.7", "wpb": "3596.8", "bsz": "147.8", "num_updates": "35500", "lr": "0.00335673", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2058"}
2023-12-10 10:55:55 | INFO | train_inner | {"epoch": 33, "update": 32.308, "loss": "4.022", "nll_loss": "2.569", "ppl": "5.93", "wps": "71918.3", "ups": "19.96", "wpb": "3602.4", "bsz": "157.3", "num_updates": "35600", "lr": "0.00335201", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2063"}
2023-12-10 10:56:01 | INFO | train_inner | {"epoch": 33, "update": 32.398, "loss": "4.059", "nll_loss": "2.61", "ppl": "6.1", "wps": "64520.4", "ups": "18.48", "wpb": "3492.2", "bsz": "142.6", "num_updates": "35700", "lr": "0.00334731", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2069"}
2023-12-10 10:56:06 | INFO | train_inner | {"epoch": 33, "update": 32.489, "loss": "4.143", "nll_loss": "2.707", "ppl": "6.53", "wps": "61959.8", "ups": "17.26", "wpb": "3588.9", "bsz": "133.7", "num_updates": "35800", "lr": "0.00334263", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2075"}
2023-12-10 10:56:12 | INFO | train_inner | {"epoch": 33, "update": 32.58, "loss": "4.122", "nll_loss": "2.684", "ppl": "6.42", "wps": "62732.9", "ups": "17.82", "wpb": "3520.6", "bsz": "135.4", "num_updates": "35900", "lr": "0.00333797", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2080"}
2023-12-10 10:56:17 | INFO | train_inner | {"epoch": 33, "update": 32.671, "loss": "4.064", "nll_loss": "2.619", "ppl": "6.14", "wps": "71793.8", "ups": "19.85", "wpb": "3616.4", "bsz": "157.8", "num_updates": "36000", "lr": "0.00333333", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2085"}
2023-12-10 10:56:22 | INFO | train_inner | {"epoch": 33, "update": 32.761, "loss": "4.067", "nll_loss": "2.624", "ppl": "6.16", "wps": "65800.1", "ups": "18.42", "wpb": "3571.6", "bsz": "164.3", "num_updates": "36100", "lr": "0.00332871", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2091"}
2023-12-10 10:56:29 | INFO | train_inner | {"epoch": 33, "update": 32.852, "loss": "4.145", "nll_loss": "2.714", "ppl": "6.56", "wps": "59487.9", "ups": "16.56", "wpb": "3591.2", "bsz": "143.4", "num_updates": "36200", "lr": "0.00332411", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2097"}
2023-12-10 10:56:34 | INFO | train_inner | {"epoch": 33, "update": 32.943, "loss": "4.141", "nll_loss": "2.708", "ppl": "6.53", "wps": "62521", "ups": "17.25", "wpb": "3623.7", "bsz": "136.2", "num_updates": "36300", "lr": "0.00331953", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2102"}
2023-12-10 10:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:56:39 | INFO | valid | {"epoch": 33, "valid_loss": "4.42", "valid_nll_loss": "3.032", "valid_ppl": "8.18", "valid_wps": "127108", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "36363", "valid_best_loss": "4.409"}
2023-12-10 10:56:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 36363 updates
2023-12-10 10:56:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint33.pt
2023-12-10 10:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint33.pt
2023-12-10 10:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint33.pt (epoch 33 @ 36363 updates, score 4.42) (writing took 1.7114364677108824 seconds)
2023-12-10 10:56:41 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-12-10 10:56:41 | INFO | train | {"epoch": 33, "train_loss": "4.079", "train_nll_loss": "2.635", "train_ppl": "6.21", "train_wps": "61604.3", "train_ups": "17.19", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "36363", "train_lr": "0.00331665", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "60", "train_gb_free": "38.9", "train_wall": "2109"}
2023-12-10 10:56:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:56:41 | INFO | fairseq.trainer | begin training epoch 34
2023-12-10 10:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:56:44 | INFO | train_inner | {"epoch": 34, "update": 33.034, "loss": "4.058", "nll_loss": "2.611", "ppl": "6.11", "wps": "37997.4", "ups": "10.84", "wpb": "3503.7", "bsz": "146", "num_updates": "36400", "lr": "0.00331497", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2112"}
2023-12-10 10:56:49 | INFO | train_inner | {"epoch": 34, "update": 33.124, "loss": "4.012", "nll_loss": "2.556", "ppl": "5.88", "wps": "68341.8", "ups": "18.89", "wpb": "3618.6", "bsz": "146.9", "num_updates": "36500", "lr": "0.00331042", "gnorm": "0.245", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2117"}
2023-12-10 10:56:55 | INFO | train_inner | {"epoch": 34, "update": 33.215, "loss": "4.006", "nll_loss": "2.549", "ppl": "5.85", "wps": "61701.6", "ups": "17.07", "wpb": "3615", "bsz": "142.7", "num_updates": "36600", "lr": "0.0033059", "gnorm": "0.248", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2123"}
2023-12-10 10:57:00 | INFO | train_inner | {"epoch": 34, "update": 33.306, "loss": "4.038", "nll_loss": "2.587", "ppl": "6.01", "wps": "63220.5", "ups": "17.97", "wpb": "3518.8", "bsz": "147.9", "num_updates": "36700", "lr": "0.00330139", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2128"}
2023-12-10 10:57:05 | INFO | train_inner | {"epoch": 34, "update": 33.397, "loss": "4.039", "nll_loss": "2.587", "ppl": "6.01", "wps": "70615.1", "ups": "19.53", "wpb": "3616", "bsz": "155", "num_updates": "36800", "lr": "0.0032969", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2134"}
2023-12-10 10:57:11 | INFO | train_inner | {"epoch": 34, "update": 33.487, "loss": "4.128", "nll_loss": "2.69", "ppl": "6.45", "wps": "60173.2", "ups": "17.07", "wpb": "3524.7", "bsz": "125.8", "num_updates": "36900", "lr": "0.00329243", "gnorm": "0.264", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2139"}
2023-12-10 10:57:17 | INFO | train_inner | {"epoch": 34, "update": 33.578, "loss": "4.118", "nll_loss": "2.678", "ppl": "6.4", "wps": "59090.5", "ups": "16.62", "wpb": "3554.7", "bsz": "131.4", "num_updates": "37000", "lr": "0.00328798", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2145"}
2023-12-10 10:57:22 | INFO | train_inner | {"epoch": 34, "update": 33.669, "loss": "4.083", "nll_loss": "2.641", "ppl": "6.24", "wps": "74289.3", "ups": "20.33", "wpb": "3654.9", "bsz": "153", "num_updates": "37100", "lr": "0.00328355", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2150"}
2023-12-10 10:57:27 | INFO | train_inner | {"epoch": 34, "update": 33.76, "loss": "4.055", "nll_loss": "2.608", "ppl": "6.1", "wps": "74457.8", "ups": "20.55", "wpb": "3623.4", "bsz": "153", "num_updates": "37200", "lr": "0.00327913", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2155"}
2023-12-10 10:57:33 | INFO | train_inner | {"epoch": 34, "update": 33.85, "loss": "4.111", "nll_loss": "2.673", "ppl": "6.38", "wps": "62602.7", "ups": "17.58", "wpb": "3560.2", "bsz": "146.5", "num_updates": "37300", "lr": "0.00327473", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2161"}
2023-12-10 10:57:38 | INFO | train_inner | {"epoch": 34, "update": 33.941, "loss": "4.118", "nll_loss": "2.682", "ppl": "6.42", "wps": "72109.4", "ups": "20.07", "wpb": "3592.6", "bsz": "148.6", "num_updates": "37400", "lr": "0.00327035", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2166"}
2023-12-10 10:57:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:57:42 | INFO | valid | {"epoch": 34, "valid_loss": "4.423", "valid_nll_loss": "3.034", "valid_ppl": "8.19", "valid_wps": "124659", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "37465", "valid_best_loss": "4.409"}
2023-12-10 10:57:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 37465 updates
2023-12-10 10:57:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint34.pt
2023-12-10 10:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint34.pt
2023-12-10 10:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint34.pt (epoch 34 @ 37465 updates, score 4.423) (writing took 1.788364534266293 seconds)
2023-12-10 10:57:44 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-12-10 10:57:44 | INFO | train | {"epoch": 34, "train_loss": "4.068", "train_nll_loss": "2.623", "train_ppl": "6.16", "train_wps": "62745.2", "train_ups": "17.51", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "37465", "train_lr": "0.00326751", "train_gnorm": "0.257", "train_loss_scale": "32", "train_train_wall": "59", "train_gb_free": "39", "train_wall": "2172"}
2023-12-10 10:57:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:57:44 | INFO | fairseq.trainer | begin training epoch 35
2023-12-10 10:57:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:57:46 | INFO | train_inner | {"epoch": 35, "update": 34.032, "loss": "4.015", "nll_loss": "2.563", "ppl": "5.91", "wps": "43871", "ups": "12.09", "wpb": "3628.5", "bsz": "153.9", "num_updates": "37500", "lr": "0.00326599", "gnorm": "0.237", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2174"}
2023-12-10 10:57:51 | INFO | train_inner | {"epoch": 35, "update": 34.123, "loss": "3.961", "nll_loss": "2.498", "ppl": "5.65", "wps": "68267.4", "ups": "18.95", "wpb": "3602.6", "bsz": "157.4", "num_updates": "37600", "lr": "0.00326164", "gnorm": "0.243", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2179"}
2023-12-10 10:57:56 | INFO | train_inner | {"epoch": 35, "update": 34.213, "loss": "3.996", "nll_loss": "2.541", "ppl": "5.82", "wps": "78141.7", "ups": "21.67", "wpb": "3605.4", "bsz": "155.3", "num_updates": "37700", "lr": "0.00325731", "gnorm": "0.236", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2184"}
2023-12-10 10:58:01 | INFO | train_inner | {"epoch": 35, "update": 34.304, "loss": "3.977", "nll_loss": "2.517", "ppl": "5.73", "wps": "71457.1", "ups": "19.94", "wpb": "3583.5", "bsz": "159.9", "num_updates": "37800", "lr": "0.003253", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2189"}
2023-12-10 10:58:07 | INFO | train_inner | {"epoch": 35, "update": 34.395, "loss": "4.078", "nll_loss": "2.633", "ppl": "6.2", "wps": "61780.5", "ups": "17.51", "wpb": "3528.1", "bsz": "134.1", "num_updates": "37900", "lr": "0.00324871", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2195"}
2023-12-10 10:58:12 | INFO | train_inner | {"epoch": 35, "update": 34.485, "loss": "4.062", "nll_loss": "2.614", "ppl": "6.12", "wps": "69832.3", "ups": "19.24", "wpb": "3628.8", "bsz": "139.6", "num_updates": "38000", "lr": "0.00324443", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2200"}
2023-12-10 10:58:17 | INFO | train_inner | {"epoch": 35, "update": 34.576, "loss": "4.063", "nll_loss": "2.618", "ppl": "6.14", "wps": "71077.7", "ups": "19.83", "wpb": "3584.7", "bsz": "159.8", "num_updates": "38100", "lr": "0.00324017", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2205"}
2023-12-10 10:58:22 | INFO | train_inner | {"epoch": 35, "update": 34.667, "loss": "4.068", "nll_loss": "2.625", "ppl": "6.17", "wps": "70826.7", "ups": "19.54", "wpb": "3624.4", "bsz": "152", "num_updates": "38200", "lr": "0.00323592", "gnorm": "0.254", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2210"}
2023-12-10 10:58:27 | INFO | train_inner | {"epoch": 35, "update": 34.758, "loss": "4.06", "nll_loss": "2.614", "ppl": "6.12", "wps": "68842.5", "ups": "18.9", "wpb": "3643.2", "bsz": "148.9", "num_updates": "38300", "lr": "0.0032317", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2215"}
2023-12-10 10:58:34 | INFO | train_inner | {"epoch": 35, "update": 34.848, "loss": "4.184", "nll_loss": "2.754", "ppl": "6.75", "wps": "54991", "ups": "15.86", "wpb": "3466.8", "bsz": "115.1", "num_updates": "38400", "lr": "0.00322749", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2222"}
2023-12-10 10:58:39 | INFO | train_inner | {"epoch": 35, "update": 34.939, "loss": "4.15", "nll_loss": "2.718", "ppl": "6.58", "wps": "64084.3", "ups": "18.08", "wpb": "3543.9", "bsz": "130.2", "num_updates": "38500", "lr": "0.00322329", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2227"}
2023-12-10 10:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:58:44 | INFO | valid | {"epoch": 35, "valid_loss": "4.416", "valid_nll_loss": "3.042", "valid_ppl": "8.24", "valid_wps": "127335", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "38567", "valid_best_loss": "4.409"}
2023-12-10 10:58:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 38567 updates
2023-12-10 10:58:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint35.pt
2023-12-10 10:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint35.pt
2023-12-10 10:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint35.pt (epoch 35 @ 38567 updates, score 4.416) (writing took 1.8899786127731204 seconds)
2023-12-10 10:58:46 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-12-10 10:58:46 | INFO | train | {"epoch": 35, "train_loss": "4.057", "train_nll_loss": "2.61", "train_ppl": "6.1", "train_wps": "63783.4", "train_ups": "17.8", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "38567", "train_lr": "0.00322049", "train_gnorm": "0.257", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2234"}
2023-12-10 10:58:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:58:46 | INFO | fairseq.trainer | begin training epoch 36
2023-12-10 10:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:58:48 | INFO | train_inner | {"epoch": 36, "update": 35.03, "loss": "4.054", "nll_loss": "2.607", "ppl": "6.09", "wps": "41359.9", "ups": "11.57", "wpb": "3575.4", "bsz": "146.6", "num_updates": "38600", "lr": "0.00321911", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2236"}
2023-12-10 10:58:53 | INFO | train_inner | {"epoch": 36, "update": 35.121, "loss": "3.866", "nll_loss": "2.389", "ppl": "5.24", "wps": "74370.9", "ups": "20.71", "wpb": "3591.7", "bsz": "170.2", "num_updates": "38700", "lr": "0.00321495", "gnorm": "0.231", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2241"}
2023-12-10 10:58:58 | INFO | train_inner | {"epoch": 36, "update": 35.211, "loss": "4.023", "nll_loss": "2.567", "ppl": "5.93", "wps": "65220.1", "ups": "18", "wpb": "3623.3", "bsz": "137.4", "num_updates": "38800", "lr": "0.00321081", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2246"}
2023-12-10 10:59:03 | INFO | train_inner | {"epoch": 36, "update": 35.302, "loss": "3.976", "nll_loss": "2.516", "ppl": "5.72", "wps": "70489.1", "ups": "19.45", "wpb": "3624.4", "bsz": "159", "num_updates": "38900", "lr": "0.00320668", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2251"}
2023-12-10 10:59:09 | INFO | train_inner | {"epoch": 36, "update": 35.393, "loss": "4.044", "nll_loss": "2.593", "ppl": "6.03", "wps": "66814.6", "ups": "18.85", "wpb": "3545.4", "bsz": "133.8", "num_updates": "39000", "lr": "0.00320256", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2257"}
2023-12-10 10:59:14 | INFO | train_inner | {"epoch": 36, "update": 35.484, "loss": "4.052", "nll_loss": "2.603", "ppl": "6.08", "wps": "63481.2", "ups": "17.95", "wpb": "3536.8", "bsz": "140.8", "num_updates": "39100", "lr": "0.00319847", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2262"}
2023-12-10 10:59:20 | INFO | train_inner | {"epoch": 36, "update": 35.574, "loss": "4.089", "nll_loss": "2.647", "ppl": "6.26", "wps": "65798.2", "ups": "18.22", "wpb": "3611.8", "bsz": "140.7", "num_updates": "39200", "lr": "0.00319438", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2268"}
2023-12-10 10:59:25 | INFO | train_inner | {"epoch": 36, "update": 35.665, "loss": "4.092", "nll_loss": "2.65", "ppl": "6.28", "wps": "64337.6", "ups": "18.15", "wpb": "3544.9", "bsz": "138.9", "num_updates": "39300", "lr": "0.00319032", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2273"}
2023-12-10 10:59:30 | INFO | train_inner | {"epoch": 36, "update": 35.756, "loss": "4.074", "nll_loss": "2.631", "ppl": "6.2", "wps": "70788.1", "ups": "19.95", "wpb": "3548.7", "bsz": "149.4", "num_updates": "39400", "lr": "0.00318626", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2278"}
2023-12-10 10:59:36 | INFO | train_inner | {"epoch": 36, "update": 35.847, "loss": "4.135", "nll_loss": "2.699", "ppl": "6.5", "wps": "65782.6", "ups": "18.05", "wpb": "3644.1", "bsz": "132.5", "num_updates": "39500", "lr": "0.00318223", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2284"}
2023-12-10 10:59:41 | INFO | train_inner | {"epoch": 36, "update": 35.937, "loss": "4.087", "nll_loss": "2.647", "ppl": "6.27", "wps": "65373.2", "ups": "18.37", "wpb": "3558.3", "bsz": "153.5", "num_updates": "39600", "lr": "0.00317821", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2289"}
2023-12-10 10:59:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 10:59:47 | INFO | valid | {"epoch": 36, "valid_loss": "4.411", "valid_nll_loss": "3.036", "valid_ppl": "8.2", "valid_wps": "129766", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "39669", "valid_best_loss": "4.409"}
2023-12-10 10:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 39669 updates
2023-12-10 10:59:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint36.pt
2023-12-10 10:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint36.pt
2023-12-10 10:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint36.pt (epoch 36 @ 39669 updates, score 4.411) (writing took 1.601952224969864 seconds)
2023-12-10 10:59:48 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-12-10 10:59:48 | INFO | train | {"epoch": 36, "train_loss": "4.045", "train_nll_loss": "2.596", "train_ppl": "6.04", "train_wps": "63404.5", "train_ups": "17.69", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "39669", "train_lr": "0.00317544", "train_gnorm": "0.256", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "2296"}
2023-12-10 10:59:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 10:59:48 | INFO | fairseq.trainer | begin training epoch 37
2023-12-10 10:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 10:59:50 | INFO | train_inner | {"epoch": 37, "update": 36.028, "loss": "4.07", "nll_loss": "2.626", "ppl": "6.17", "wps": "41271", "ups": "11.38", "wpb": "3626.7", "bsz": "142.2", "num_updates": "39700", "lr": "0.0031742", "gnorm": "0.258", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2298"}
2023-12-10 10:59:55 | INFO | train_inner | {"epoch": 37, "update": 36.119, "loss": "3.949", "nll_loss": "2.483", "ppl": "5.59", "wps": "74306.4", "ups": "20.25", "wpb": "3668.7", "bsz": "148.2", "num_updates": "39800", "lr": "0.00317021", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2303"}
2023-12-10 10:59:59 | INFO | train_inner | {"epoch": 37, "update": 36.21, "loss": "3.947", "nll_loss": "2.483", "ppl": "5.59", "wps": "78004.2", "ups": "21.65", "wpb": "3602.8", "bsz": "152.6", "num_updates": "39900", "lr": "0.00316624", "gnorm": "0.24", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2308"}
2023-12-10 11:00:05 | INFO | train_inner | {"epoch": 37, "update": 36.3, "loss": "4.027", "nll_loss": "2.574", "ppl": "5.95", "wps": "63279", "ups": "17.75", "wpb": "3565.9", "bsz": "139.8", "num_updates": "40000", "lr": "0.00316228", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2313"}
2023-12-10 11:00:11 | INFO | train_inner | {"epoch": 37, "update": 36.391, "loss": "4.045", "nll_loss": "2.593", "ppl": "6.03", "wps": "61854.2", "ups": "17.34", "wpb": "3566.9", "bsz": "133.6", "num_updates": "40100", "lr": "0.00315833", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2319"}
2023-12-10 11:00:16 | INFO | train_inner | {"epoch": 37, "update": 36.482, "loss": "4.004", "nll_loss": "2.549", "ppl": "5.85", "wps": "71000.2", "ups": "19.75", "wpb": "3595.5", "bsz": "145.4", "num_updates": "40200", "lr": "0.0031544", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2324"}
2023-12-10 11:00:21 | INFO | train_inner | {"epoch": 37, "update": 36.573, "loss": "4.042", "nll_loss": "2.596", "ppl": "6.05", "wps": "71496.2", "ups": "20", "wpb": "3574.1", "bsz": "161.5", "num_updates": "40300", "lr": "0.00315049", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2329"}
2023-12-10 11:00:27 | INFO | train_inner | {"epoch": 37, "update": 36.663, "loss": "4.121", "nll_loss": "2.684", "ppl": "6.43", "wps": "61661.9", "ups": "17.44", "wpb": "3535.3", "bsz": "130.1", "num_updates": "40400", "lr": "0.00314658", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2335"}
2023-12-10 11:00:32 | INFO | train_inner | {"epoch": 37, "update": 36.754, "loss": "4.089", "nll_loss": "2.647", "ppl": "6.26", "wps": "61003.7", "ups": "17.27", "wpb": "3532.4", "bsz": "139", "num_updates": "40500", "lr": "0.0031427", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2341"}
2023-12-10 11:00:38 | INFO | train_inner | {"epoch": 37, "update": 36.845, "loss": "4.075", "nll_loss": "2.633", "ppl": "6.2", "wps": "59373.8", "ups": "16.62", "wpb": "3572.2", "bsz": "139.8", "num_updates": "40600", "lr": "0.00313882", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2347"}
2023-12-10 11:00:43 | INFO | train_inner | {"epoch": 37, "update": 36.936, "loss": "4.064", "nll_loss": "2.621", "ppl": "6.15", "wps": "73386.1", "ups": "20.55", "wpb": "3570.9", "bsz": "157.4", "num_updates": "40700", "lr": "0.00313497", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2351"}
2023-12-10 11:00:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:00:48 | INFO | valid | {"epoch": 37, "valid_loss": "4.426", "valid_nll_loss": "3.054", "valid_ppl": "8.31", "valid_wps": "131176", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "40771", "valid_best_loss": "4.409"}
2023-12-10 11:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 40771 updates
2023-12-10 11:00:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint37.pt
2023-12-10 11:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint37.pt
2023-12-10 11:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint37.pt (epoch 37 @ 40771 updates, score 4.426) (writing took 1.6593170217238367 seconds)
2023-12-10 11:00:50 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-12-10 11:00:50 | INFO | train | {"epoch": 37, "train_loss": "4.035", "train_nll_loss": "2.585", "train_ppl": "6", "train_wps": "63952.9", "train_ups": "17.85", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "40771", "train_lr": "0.00313223", "train_gnorm": "0.258", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "2358"}
2023-12-10 11:00:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:00:50 | INFO | fairseq.trainer | begin training epoch 38
2023-12-10 11:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:00:51 | INFO | train_inner | {"epoch": 38, "update": 37.026, "loss": "4.016", "nll_loss": "2.564", "ppl": "5.91", "wps": "43711.1", "ups": "12.25", "wpb": "3568.2", "bsz": "151.6", "num_updates": "40800", "lr": "0.00313112", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2360"}
2023-12-10 11:00:57 | INFO | train_inner | {"epoch": 38, "update": 37.117, "loss": "3.951", "nll_loss": "2.486", "ppl": "5.6", "wps": "69129.4", "ups": "19.27", "wpb": "3587.6", "bsz": "150.2", "num_updates": "40900", "lr": "0.00312729", "gnorm": "0.249", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2365"}
2023-12-10 11:01:02 | INFO | train_inner | {"epoch": 38, "update": 37.208, "loss": "3.988", "nll_loss": "2.527", "ppl": "5.77", "wps": "64473.6", "ups": "18.26", "wpb": "3530.2", "bsz": "134.9", "num_updates": "41000", "lr": "0.00312348", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2370"}
2023-12-10 11:01:08 | INFO | train_inner | {"epoch": 38, "update": 37.299, "loss": "4.028", "nll_loss": "2.574", "ppl": "5.95", "wps": "63341.2", "ups": "17.67", "wpb": "3585.6", "bsz": "135.9", "num_updates": "41100", "lr": "0.00311967", "gnorm": "0.254", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2376"}
2023-12-10 11:01:13 | INFO | train_inner | {"epoch": 38, "update": 37.389, "loss": "4.043", "nll_loss": "2.594", "ppl": "6.04", "wps": "70136.5", "ups": "19.34", "wpb": "3627.2", "bsz": "140.7", "num_updates": "41200", "lr": "0.00311588", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2381"}
2023-12-10 11:01:18 | INFO | train_inner | {"epoch": 38, "update": 37.48, "loss": "3.997", "nll_loss": "2.542", "ppl": "5.82", "wps": "70070.7", "ups": "19.47", "wpb": "3599.4", "bsz": "159.2", "num_updates": "41300", "lr": "0.00311211", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2386"}
2023-12-10 11:01:23 | INFO | train_inner | {"epoch": 38, "update": 37.571, "loss": "4.014", "nll_loss": "2.561", "ppl": "5.9", "wps": "71413.2", "ups": "19.9", "wpb": "3589", "bsz": "159.6", "num_updates": "41400", "lr": "0.00310835", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2391"}
2023-12-10 11:01:29 | INFO | train_inner | {"epoch": 38, "update": 37.662, "loss": "4.063", "nll_loss": "2.617", "ppl": "6.14", "wps": "65720.4", "ups": "18.42", "wpb": "3567.1", "bsz": "137", "num_updates": "41500", "lr": "0.0031046", "gnorm": "0.277", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2397"}
2023-12-10 11:01:34 | INFO | train_inner | {"epoch": 38, "update": 37.752, "loss": "4.054", "nll_loss": "2.606", "ppl": "6.09", "wps": "73909.6", "ups": "20.35", "wpb": "3632.1", "bsz": "148.4", "num_updates": "41600", "lr": "0.00310087", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2402"}
2023-12-10 11:01:38 | INFO | train_inner | {"epoch": 38, "update": 37.843, "loss": "4.023", "nll_loss": "2.576", "ppl": "5.96", "wps": "78413.9", "ups": "21.57", "wpb": "3634.8", "bsz": "163", "num_updates": "41700", "lr": "0.00309715", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2406"}
2023-12-10 11:01:43 | INFO | train_inner | {"epoch": 38, "update": 37.934, "loss": "4.091", "nll_loss": "2.65", "ppl": "6.28", "wps": "66917.2", "ups": "18.79", "wpb": "3562.1", "bsz": "139", "num_updates": "41800", "lr": "0.00309344", "gnorm": "0.276", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2412"}
2023-12-10 11:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:01:49 | INFO | valid | {"epoch": 38, "valid_loss": "4.425", "valid_nll_loss": "3.044", "valid_ppl": "8.25", "valid_wps": "130552", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "41873", "valid_best_loss": "4.409"}
2023-12-10 11:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 41873 updates
2023-12-10 11:01:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint38.pt
2023-12-10 11:01:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint38.pt
2023-12-10 11:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint38.pt (epoch 38 @ 41873 updates, score 4.425) (writing took 1.6284937649033964 seconds)
2023-12-10 11:01:51 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-12-10 11:01:51 | INFO | train | {"epoch": 38, "train_loss": "4.028", "train_nll_loss": "2.576", "train_ppl": "5.96", "train_wps": "64903.7", "train_ups": "18.11", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "41873", "train_lr": "0.00309074", "train_gnorm": "0.26", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2419"}
2023-12-10 11:01:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:01:51 | INFO | fairseq.trainer | begin training epoch 39
2023-12-10 11:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:01:52 | INFO | train_inner | {"epoch": 39, "update": 38.025, "loss": "4.055", "nll_loss": "2.607", "ppl": "6.09", "wps": "39046.2", "ups": "11.12", "wpb": "3512.6", "bsz": "136.7", "num_updates": "41900", "lr": "0.00308975", "gnorm": "0.261", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2421"}
2023-12-10 11:01:58 | INFO | train_inner | {"epoch": 39, "update": 38.115, "loss": "3.9", "nll_loss": "2.426", "ppl": "5.38", "wps": "68935.4", "ups": "19.23", "wpb": "3584.2", "bsz": "162.2", "num_updates": "42000", "lr": "0.00308607", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2426"}
2023-12-10 11:02:03 | INFO | train_inner | {"epoch": 39, "update": 38.206, "loss": "3.989", "nll_loss": "2.53", "ppl": "5.77", "wps": "67617.4", "ups": "18.9", "wpb": "3576.8", "bsz": "143.4", "num_updates": "42100", "lr": "0.0030824", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2431"}
2023-12-10 11:02:08 | INFO | train_inner | {"epoch": 39, "update": 38.297, "loss": "4.005", "nll_loss": "2.55", "ppl": "5.86", "wps": "66898.5", "ups": "18.56", "wpb": "3605.2", "bsz": "139.4", "num_updates": "42200", "lr": "0.00307875", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2436"}
2023-12-10 11:02:14 | INFO | train_inner | {"epoch": 39, "update": 38.387, "loss": "3.991", "nll_loss": "2.533", "ppl": "5.79", "wps": "65921.4", "ups": "18.35", "wpb": "3593.2", "bsz": "146", "num_updates": "42300", "lr": "0.0030751", "gnorm": "0.254", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2442"}
2023-12-10 11:02:19 | INFO | train_inner | {"epoch": 39, "update": 38.478, "loss": "4.009", "nll_loss": "2.553", "ppl": "5.87", "wps": "71971.6", "ups": "19.73", "wpb": "3647.9", "bsz": "140.4", "num_updates": "42400", "lr": "0.00307148", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2447"}
2023-12-10 11:02:24 | INFO | train_inner | {"epoch": 39, "update": 38.569, "loss": "4.009", "nll_loss": "2.554", "ppl": "5.87", "wps": "74269.7", "ups": "20.67", "wpb": "3592.2", "bsz": "154.1", "num_updates": "42500", "lr": "0.00306786", "gnorm": "0.273", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2452"}
2023-12-10 11:02:29 | INFO | train_inner | {"epoch": 39, "update": 38.66, "loss": "4.049", "nll_loss": "2.602", "ppl": "6.07", "wps": "68872.9", "ups": "19.11", "wpb": "3603.4", "bsz": "141.4", "num_updates": "42600", "lr": "0.00306426", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2457"}
2023-12-10 11:02:34 | INFO | train_inner | {"epoch": 39, "update": 38.75, "loss": "4.032", "nll_loss": "2.582", "ppl": "5.99", "wps": "64454.3", "ups": "18.33", "wpb": "3516.7", "bsz": "149.2", "num_updates": "42700", "lr": "0.00306067", "gnorm": "0.269", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2463"}
2023-12-10 11:02:39 | INFO | train_inner | {"epoch": 39, "update": 38.841, "loss": "4.074", "nll_loss": "2.632", "ppl": "6.2", "wps": "71814.5", "ups": "20.03", "wpb": "3585.2", "bsz": "146.2", "num_updates": "42800", "lr": "0.00305709", "gnorm": "0.28", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2468"}
2023-12-10 11:02:45 | INFO | train_inner | {"epoch": 39, "update": 38.932, "loss": "4.078", "nll_loss": "2.636", "ppl": "6.22", "wps": "65769.7", "ups": "18.45", "wpb": "3565.7", "bsz": "135.8", "num_updates": "42900", "lr": "0.00305352", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2473"}
2023-12-10 11:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:02:50 | INFO | valid | {"epoch": 39, "valid_loss": "4.413", "valid_nll_loss": "3.031", "valid_ppl": "8.17", "valid_wps": "131948", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "42975", "valid_best_loss": "4.409"}
2023-12-10 11:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 42975 updates
2023-12-10 11:02:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint39.pt
2023-12-10 11:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint39.pt
2023-12-10 11:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint39.pt (epoch 39 @ 42975 updates, score 4.413) (writing took 3.469611067790538 seconds)
2023-12-10 11:02:54 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-12-10 11:02:54 | INFO | train | {"epoch": 39, "train_loss": "4.017", "train_nll_loss": "2.564", "train_ppl": "5.91", "train_wps": "62795", "train_ups": "17.52", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "42975", "train_lr": "0.00305086", "train_gnorm": "0.262", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2482"}
2023-12-10 11:02:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:02:54 | INFO | fairseq.trainer | begin training epoch 40
2023-12-10 11:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:02:55 | INFO | train_inner | {"epoch": 40, "update": 39.023, "loss": "4.051", "nll_loss": "2.604", "ppl": "6.08", "wps": "34862.9", "ups": "9.76", "wpb": "3571.9", "bsz": "139.4", "num_updates": "43000", "lr": "0.00304997", "gnorm": "0.276", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2483"}
2023-12-10 11:03:00 | INFO | train_inner | {"epoch": 40, "update": 39.113, "loss": "3.919", "nll_loss": "2.448", "ppl": "5.46", "wps": "68740.4", "ups": "19.07", "wpb": "3604.4", "bsz": "150.2", "num_updates": "43100", "lr": "0.00304643", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2488"}
2023-12-10 11:03:06 | INFO | train_inner | {"epoch": 40, "update": 39.204, "loss": "3.951", "nll_loss": "2.485", "ppl": "5.6", "wps": "65589.2", "ups": "18.49", "wpb": "3546.9", "bsz": "138.5", "num_updates": "43200", "lr": "0.0030429", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2494"}
2023-12-10 11:03:11 | INFO | train_inner | {"epoch": 40, "update": 39.295, "loss": "3.931", "nll_loss": "2.466", "ppl": "5.52", "wps": "76139.3", "ups": "20.81", "wpb": "3658.9", "bsz": "166.4", "num_updates": "43300", "lr": "0.00303939", "gnorm": "0.245", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2499"}
2023-12-10 11:03:15 | INFO | train_inner | {"epoch": 40, "update": 39.386, "loss": "3.997", "nll_loss": "2.541", "ppl": "5.82", "wps": "71734.4", "ups": "20.18", "wpb": "3555.1", "bsz": "150.1", "num_updates": "43400", "lr": "0.00303588", "gnorm": "0.271", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2504"}
2023-12-10 11:03:21 | INFO | train_inner | {"epoch": 40, "update": 39.476, "loss": "4.039", "nll_loss": "2.589", "ppl": "6.02", "wps": "64683.2", "ups": "18.08", "wpb": "3577.8", "bsz": "141.8", "num_updates": "43500", "lr": "0.00303239", "gnorm": "0.27", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2509"}
2023-12-10 11:03:26 | INFO | train_inner | {"epoch": 40, "update": 39.567, "loss": "4.05", "nll_loss": "2.6", "ppl": "6.06", "wps": "69994.7", "ups": "19.58", "wpb": "3574.4", "bsz": "130.6", "num_updates": "43600", "lr": "0.00302891", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2514"}
2023-12-10 11:03:32 | INFO | train_inner | {"epoch": 40, "update": 39.658, "loss": "4.074", "nll_loss": "2.629", "ppl": "6.18", "wps": "61406.8", "ups": "17.51", "wpb": "3506.3", "bsz": "131.5", "num_updates": "43700", "lr": "0.00302545", "gnorm": "0.279", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2520"}
2023-12-10 11:03:36 | INFO | train_inner | {"epoch": 40, "update": 39.749, "loss": "4.002", "nll_loss": "2.548", "ppl": "5.85", "wps": "78486.5", "ups": "21.49", "wpb": "3652.1", "bsz": "151.3", "num_updates": "43800", "lr": "0.00302199", "gnorm": "0.254", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2525"}
2023-12-10 11:03:42 | INFO | train_inner | {"epoch": 40, "update": 39.839, "loss": "4.072", "nll_loss": "2.627", "ppl": "6.18", "wps": "60336.1", "ups": "17.13", "wpb": "3522.1", "bsz": "135.4", "num_updates": "43900", "lr": "0.00301855", "gnorm": "0.264", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2530"}
2023-12-10 11:03:47 | INFO | train_inner | {"epoch": 40, "update": 39.93, "loss": "4.036", "nll_loss": "2.59", "ppl": "6.02", "wps": "71872.9", "ups": "19.83", "wpb": "3624.7", "bsz": "152.9", "num_updates": "44000", "lr": "0.00301511", "gnorm": "0.255", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2535"}
2023-12-10 11:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:03:53 | INFO | valid | {"epoch": 40, "valid_loss": "4.417", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "130549", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "44077", "valid_best_loss": "4.409"}
2023-12-10 11:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 44077 updates
2023-12-10 11:03:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint40.pt
2023-12-10 11:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint40.pt
2023-12-10 11:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint40.pt (epoch 40 @ 44077 updates, score 4.417) (writing took 1.6615413227118552 seconds)
2023-12-10 11:03:54 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-12-10 11:03:54 | INFO | train | {"epoch": 40, "train_loss": "4.005", "train_nll_loss": "2.551", "train_ppl": "5.86", "train_wps": "65178.5", "train_ups": "18.19", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "44077", "train_lr": "0.00301248", "train_gnorm": "0.261", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "38.9", "train_wall": "2542"}
2023-12-10 11:03:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:03:54 | INFO | fairseq.trainer | begin training epoch 41
2023-12-10 11:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:03:56 | INFO | train_inner | {"epoch": 41, "update": 40.021, "loss": "3.997", "nll_loss": "2.542", "ppl": "5.82", "wps": "43193.3", "ups": "11.91", "wpb": "3627.8", "bsz": "150.6", "num_updates": "44100", "lr": "0.00301169", "gnorm": "0.265", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2544"}
2023-12-10 11:04:01 | INFO | train_inner | {"epoch": 41, "update": 40.112, "loss": "3.875", "nll_loss": "2.4", "ppl": "5.28", "wps": "75154.8", "ups": "20.66", "wpb": "3636.9", "bsz": "158.3", "num_updates": "44200", "lr": "0.00300828", "gnorm": "0.239", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2549"}
2023-12-10 11:04:06 | INFO | train_inner | {"epoch": 41, "update": 40.202, "loss": "3.937", "nll_loss": "2.47", "ppl": "5.54", "wps": "66270.9", "ups": "18.37", "wpb": "3607.2", "bsz": "145.8", "num_updates": "44300", "lr": "0.00300489", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2554"}
2023-12-10 11:04:11 | INFO | train_inner | {"epoch": 41, "update": 40.293, "loss": "4.003", "nll_loss": "2.547", "ppl": "5.84", "wps": "66621.3", "ups": "18.62", "wpb": "3577.3", "bsz": "136.2", "num_updates": "44400", "lr": "0.0030015", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2560"}
2023-12-10 11:04:17 | INFO | train_inner | {"epoch": 41, "update": 40.384, "loss": "3.978", "nll_loss": "2.518", "ppl": "5.73", "wps": "62484.3", "ups": "17.68", "wpb": "3533.2", "bsz": "139.7", "num_updates": "44500", "lr": "0.00299813", "gnorm": "0.264", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2565"}
2023-12-10 11:04:22 | INFO | train_inner | {"epoch": 41, "update": 40.475, "loss": "4.003", "nll_loss": "2.547", "ppl": "5.85", "wps": "69364.2", "ups": "19.45", "wpb": "3565.6", "bsz": "138.8", "num_updates": "44600", "lr": "0.00299476", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2570"}
2023-12-10 11:04:28 | INFO | train_inner | {"epoch": 41, "update": 40.565, "loss": "4.042", "nll_loss": "2.591", "ppl": "6.03", "wps": "60109.6", "ups": "16.96", "wpb": "3544.6", "bsz": "132.1", "num_updates": "44700", "lr": "0.00299141", "gnorm": "0.274", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2576"}
2023-12-10 11:04:33 | INFO | train_inner | {"epoch": 41, "update": 40.656, "loss": "3.997", "nll_loss": "2.543", "ppl": "5.83", "wps": "72329.8", "ups": "20.48", "wpb": "3532.1", "bsz": "155.9", "num_updates": "44800", "lr": "0.00298807", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2581"}
2023-12-10 11:04:38 | INFO | train_inner | {"epoch": 41, "update": 40.747, "loss": "4.039", "nll_loss": "2.59", "ppl": "6.02", "wps": "65466.1", "ups": "18.3", "wpb": "3578.1", "bsz": "140.5", "num_updates": "44900", "lr": "0.00298474", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2587"}
2023-12-10 11:04:44 | INFO | train_inner | {"epoch": 41, "update": 40.838, "loss": "4.034", "nll_loss": "2.587", "ppl": "6.01", "wps": "72340.1", "ups": "19.51", "wpb": "3708.3", "bsz": "151", "num_updates": "45000", "lr": "0.00298142", "gnorm": "0.248", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2592"}
2023-12-10 11:04:49 | INFO | train_inner | {"epoch": 41, "update": 40.928, "loss": "4.061", "nll_loss": "2.617", "ppl": "6.13", "wps": "66272.2", "ups": "18.57", "wpb": "3568.4", "bsz": "143.8", "num_updates": "45100", "lr": "0.00297812", "gnorm": "0.267", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2597"}
2023-12-10 11:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:04:55 | INFO | valid | {"epoch": 41, "valid_loss": "4.429", "valid_nll_loss": "3.053", "valid_ppl": "8.3", "valid_wps": "129040", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "45179", "valid_best_loss": "4.409"}
2023-12-10 11:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 45179 updates
2023-12-10 11:04:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint41.pt
2023-12-10 11:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint41.pt
2023-12-10 11:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint41.pt (epoch 41 @ 45179 updates, score 4.429) (writing took 1.5615713130682707 seconds)
2023-12-10 11:04:56 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-12-10 11:04:56 | INFO | train | {"epoch": 41, "train_loss": "3.998", "train_nll_loss": "2.542", "train_ppl": "5.82", "train_wps": "63767.7", "train_ups": "17.79", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "45179", "train_lr": "0.00297551", "train_gnorm": "0.26", "train_loss_scale": "64", "train_train_wall": "58", "train_gb_free": "38.9", "train_wall": "2604"}
2023-12-10 11:04:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:04:56 | INFO | fairseq.trainer | begin training epoch 42
2023-12-10 11:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:04:57 | INFO | train_inner | {"epoch": 42, "update": 41.019, "loss": "4.022", "nll_loss": "2.573", "ppl": "5.95", "wps": "41613.1", "ups": "11.7", "wpb": "3555.9", "bsz": "155.4", "num_updates": "45200", "lr": "0.00297482", "gnorm": "0.271", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2606"}
2023-12-10 11:05:02 | INFO | train_inner | {"epoch": 42, "update": 41.11, "loss": "3.882", "nll_loss": "2.407", "ppl": "5.3", "wps": "76740.4", "ups": "21.11", "wpb": "3635.9", "bsz": "144.8", "num_updates": "45300", "lr": "0.00297154", "gnorm": "0.233", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2610"}
2023-12-10 11:05:07 | INFO | train_inner | {"epoch": 42, "update": 41.201, "loss": "3.911", "nll_loss": "2.44", "ppl": "5.42", "wps": "68334.4", "ups": "19", "wpb": "3596.9", "bsz": "146.2", "num_updates": "45400", "lr": "0.00296826", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2616"}
2023-12-10 11:05:13 | INFO | train_inner | {"epoch": 42, "update": 41.291, "loss": "3.965", "nll_loss": "2.503", "ppl": "5.67", "wps": "70292", "ups": "19.44", "wpb": "3616.2", "bsz": "145.2", "num_updates": "45500", "lr": "0.002965", "gnorm": "0.264", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2621"}
2023-12-10 11:05:18 | INFO | train_inner | {"epoch": 42, "update": 41.382, "loss": "3.98", "nll_loss": "2.521", "ppl": "5.74", "wps": "66614.3", "ups": "18.83", "wpb": "3537.9", "bsz": "145.6", "num_updates": "45600", "lr": "0.00296174", "gnorm": "0.264", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2626"}
2023-12-10 11:05:23 | INFO | train_inner | {"epoch": 42, "update": 41.473, "loss": "3.99", "nll_loss": "2.533", "ppl": "5.79", "wps": "72468.8", "ups": "19.81", "wpb": "3657.8", "bsz": "144.2", "num_updates": "45700", "lr": "0.0029585", "gnorm": "0.267", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2631"}
2023-12-10 11:05:28 | INFO | train_inner | {"epoch": 42, "update": 41.564, "loss": "4.004", "nll_loss": "2.549", "ppl": "5.85", "wps": "68191", "ups": "19.3", "wpb": "3532.9", "bsz": "141.4", "num_updates": "45800", "lr": "0.00295527", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2636"}
2023-12-10 11:05:34 | INFO | train_inner | {"epoch": 42, "update": 41.654, "loss": "4.028", "nll_loss": "2.577", "ppl": "5.97", "wps": "59737.6", "ups": "17.01", "wpb": "3511", "bsz": "143.7", "num_updates": "45900", "lr": "0.00295205", "gnorm": "0.27", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2642"}
2023-12-10 11:05:40 | INFO | train_inner | {"epoch": 42, "update": 41.745, "loss": "4.071", "nll_loss": "2.625", "ppl": "6.17", "wps": "60501.5", "ups": "17.1", "wpb": "3537.2", "bsz": "130.5", "num_updates": "46000", "lr": "0.00294884", "gnorm": "0.274", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2648"}
2023-12-10 11:05:45 | INFO | train_inner | {"epoch": 42, "update": 41.836, "loss": "4.017", "nll_loss": "2.568", "ppl": "5.93", "wps": "71726.4", "ups": "19.82", "wpb": "3618.9", "bsz": "148.2", "num_updates": "46100", "lr": "0.00294564", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2653"}
2023-12-10 11:05:50 | INFO | train_inner | {"epoch": 42, "update": 41.926, "loss": "3.981", "nll_loss": "2.527", "ppl": "5.76", "wps": "73725.3", "ups": "20.45", "wpb": "3605.9", "bsz": "170.4", "num_updates": "46200", "lr": "0.00294245", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2658"}
2023-12-10 11:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:05:56 | INFO | valid | {"epoch": 42, "valid_loss": "4.429", "valid_nll_loss": "3.055", "valid_ppl": "8.31", "valid_wps": "132122", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "46281", "valid_best_loss": "4.409"}
2023-12-10 11:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 46281 updates
2023-12-10 11:05:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint42.pt
2023-12-10 11:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint42.pt
2023-12-10 11:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint42.pt (epoch 42 @ 46281 updates, score 4.429) (writing took 1.614044701680541 seconds)
2023-12-10 11:05:57 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-12-10 11:05:57 | INFO | train | {"epoch": 42, "train_loss": "3.989", "train_nll_loss": "2.532", "train_ppl": "5.79", "train_wps": "64807.7", "train_ups": "18.08", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "46281", "train_lr": "0.00293987", "train_gnorm": "0.26", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2665"}
2023-12-10 11:05:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:05:57 | INFO | fairseq.trainer | begin training epoch 43
2023-12-10 11:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:05:58 | INFO | train_inner | {"epoch": 43, "update": 42.017, "loss": "4.042", "nll_loss": "2.595", "ppl": "6.04", "wps": "41803.3", "ups": "11.83", "wpb": "3534.8", "bsz": "141.8", "num_updates": "46300", "lr": "0.00293927", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2666"}
2023-12-10 11:06:04 | INFO | train_inner | {"epoch": 43, "update": 42.108, "loss": "3.876", "nll_loss": "2.399", "ppl": "5.28", "wps": "69343.6", "ups": "19.18", "wpb": "3615.8", "bsz": "147.1", "num_updates": "46400", "lr": "0.0029361", "gnorm": "0.249", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2672"}
2023-12-10 11:06:09 | INFO | train_inner | {"epoch": 43, "update": 42.199, "loss": "3.903", "nll_loss": "2.431", "ppl": "5.39", "wps": "66139.9", "ups": "18.64", "wpb": "3548.4", "bsz": "157.8", "num_updates": "46500", "lr": "0.00293294", "gnorm": "0.266", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2677"}
2023-12-10 11:06:14 | INFO | train_inner | {"epoch": 43, "update": 42.289, "loss": "3.933", "nll_loss": "2.467", "ppl": "5.53", "wps": "67460.1", "ups": "18.79", "wpb": "3590", "bsz": "157", "num_updates": "46600", "lr": "0.00292979", "gnorm": "0.256", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2682"}
2023-12-10 11:06:19 | INFO | train_inner | {"epoch": 43, "update": 42.38, "loss": "3.963", "nll_loss": "2.503", "ppl": "5.67", "wps": "70305.2", "ups": "19.54", "wpb": "3597.9", "bsz": "144.7", "num_updates": "46700", "lr": "0.00292666", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2687"}
2023-12-10 11:06:24 | INFO | train_inner | {"epoch": 43, "update": 42.471, "loss": "3.998", "nll_loss": "2.541", "ppl": "5.82", "wps": "73042.8", "ups": "19.94", "wpb": "3662.6", "bsz": "139.8", "num_updates": "46800", "lr": "0.00292353", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2692"}
2023-12-10 11:06:30 | INFO | train_inner | {"epoch": 43, "update": 42.562, "loss": "4.018", "nll_loss": "2.566", "ppl": "5.92", "wps": "67565.2", "ups": "19.23", "wpb": "3514.2", "bsz": "142.8", "num_updates": "46900", "lr": "0.00292041", "gnorm": "0.266", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2698"}
2023-12-10 11:06:35 | INFO | train_inner | {"epoch": 43, "update": 42.652, "loss": "4.001", "nll_loss": "2.547", "ppl": "5.84", "wps": "68910.3", "ups": "19.39", "wpb": "3553.3", "bsz": "150", "num_updates": "47000", "lr": "0.0029173", "gnorm": "0.26", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2703"}
2023-12-10 11:06:41 | INFO | train_inner | {"epoch": 43, "update": 42.743, "loss": "4.008", "nll_loss": "2.554", "ppl": "5.87", "wps": "60791.9", "ups": "17.19", "wpb": "3536.3", "bsz": "139.2", "num_updates": "47100", "lr": "0.0029142", "gnorm": "0.273", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2709"}
2023-12-10 11:06:46 | INFO | train_inner | {"epoch": 43, "update": 42.834, "loss": "4.066", "nll_loss": "2.62", "ppl": "6.15", "wps": "67425.9", "ups": "18.58", "wpb": "3629.8", "bsz": "131.6", "num_updates": "47200", "lr": "0.00291111", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2714"}
2023-12-10 11:06:52 | INFO | train_inner | {"epoch": 43, "update": 42.925, "loss": "4.085", "nll_loss": "2.641", "ppl": "6.24", "wps": "58618.4", "ups": "16.6", "wpb": "3531.3", "bsz": "122.7", "num_updates": "47300", "lr": "0.00290803", "gnorm": "0.28", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2720"}
2023-12-10 11:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:06:57 | INFO | valid | {"epoch": 43, "valid_loss": "4.418", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "132526", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "47383", "valid_best_loss": "4.409"}
2023-12-10 11:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 47383 updates
2023-12-10 11:06:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint43.pt
2023-12-10 11:06:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint43.pt
2023-12-10 11:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint43.pt (epoch 43 @ 47383 updates, score 4.418) (writing took 1.7102104579098523 seconds)
2023-12-10 11:06:59 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-12-10 11:06:59 | INFO | train | {"epoch": 43, "train_loss": "3.98", "train_nll_loss": "2.522", "train_ppl": "5.74", "train_wps": "63876", "train_ups": "17.82", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "47383", "train_lr": "0.00290549", "train_gnorm": "0.261", "train_loss_scale": "64", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "2727"}
2023-12-10 11:06:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:06:59 | INFO | fairseq.trainer | begin training epoch 44
2023-12-10 11:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:07:00 | INFO | train_inner | {"epoch": 44, "update": 43.015, "loss": "3.943", "nll_loss": "2.483", "ppl": "5.59", "wps": "45428.8", "ups": "12.41", "wpb": "3661.2", "bsz": "165.4", "num_updates": "47400", "lr": "0.00290496", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2728"}
2023-12-10 11:07:05 | INFO | train_inner | {"epoch": 44, "update": 43.106, "loss": "3.881", "nll_loss": "2.407", "ppl": "5.31", "wps": "67328.6", "ups": "19.07", "wpb": "3530.9", "bsz": "162.1", "num_updates": "47500", "lr": "0.00290191", "gnorm": "0.257", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2733"}
2023-12-10 11:07:11 | INFO | train_inner | {"epoch": 44, "update": 43.197, "loss": "3.922", "nll_loss": "2.454", "ppl": "5.48", "wps": "66310.5", "ups": "18.32", "wpb": "3619.7", "bsz": "149.3", "num_updates": "47600", "lr": "0.00289886", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2739"}
2023-12-10 11:07:16 | INFO | train_inner | {"epoch": 44, "update": 43.288, "loss": "3.936", "nll_loss": "2.47", "ppl": "5.54", "wps": "68753.9", "ups": "19.24", "wpb": "3573.8", "bsz": "146.9", "num_updates": "47700", "lr": "0.00289581", "gnorm": "0.252", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2744"}
2023-12-10 11:07:21 | INFO | train_inner | {"epoch": 44, "update": 43.378, "loss": "3.975", "nll_loss": "2.515", "ppl": "5.72", "wps": "67928.5", "ups": "19.03", "wpb": "3568.9", "bsz": "141.3", "num_updates": "47800", "lr": "0.00289278", "gnorm": "0.27", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2749"}
2023-12-10 11:07:26 | INFO | train_inner | {"epoch": 44, "update": 43.469, "loss": "3.973", "nll_loss": "2.511", "ppl": "5.7", "wps": "67824", "ups": "19.05", "wpb": "3559.8", "bsz": "137.5", "num_updates": "47900", "lr": "0.00288976", "gnorm": "0.272", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2755"}
2023-12-10 11:07:32 | INFO | train_inner | {"epoch": 44, "update": 43.56, "loss": "3.944", "nll_loss": "2.481", "ppl": "5.58", "wps": "69617.8", "ups": "19.23", "wpb": "3620.1", "bsz": "149", "num_updates": "48000", "lr": "0.00288675", "gnorm": "0.253", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2760"}
2023-12-10 11:07:37 | INFO | train_inner | {"epoch": 44, "update": 43.651, "loss": "4.003", "nll_loss": "2.548", "ppl": "5.85", "wps": "70598", "ups": "19.59", "wpb": "3603.8", "bsz": "137.9", "num_updates": "48100", "lr": "0.00288375", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2765"}
2023-12-10 11:07:42 | INFO | train_inner | {"epoch": 44, "update": 43.741, "loss": "4.06", "nll_loss": "2.613", "ppl": "6.12", "wps": "67612.2", "ups": "18.73", "wpb": "3610", "bsz": "129.8", "num_updates": "48200", "lr": "0.00288076", "gnorm": "0.262", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2770"}
2023-12-10 11:07:48 | INFO | train_inner | {"epoch": 44, "update": 43.832, "loss": "4.042", "nll_loss": "2.593", "ppl": "6.03", "wps": "63648", "ups": "18", "wpb": "3535.2", "bsz": "127.7", "num_updates": "48300", "lr": "0.00287777", "gnorm": "0.269", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2776"}
2023-12-10 11:07:53 | INFO | train_inner | {"epoch": 44, "update": 43.923, "loss": "3.994", "nll_loss": "2.54", "ppl": "5.82", "wps": "68032.7", "ups": "19", "wpb": "3580.6", "bsz": "152.4", "num_updates": "48400", "lr": "0.0028748", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2781"}
2023-12-10 11:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:07:58 | INFO | valid | {"epoch": 44, "valid_loss": "4.436", "valid_nll_loss": "3.055", "valid_ppl": "8.31", "valid_wps": "129427", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "48485", "valid_best_loss": "4.409"}
2023-12-10 11:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 48485 updates
2023-12-10 11:07:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint44.pt
2023-12-10 11:07:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint44.pt
2023-12-10 11:08:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint44.pt (epoch 44 @ 48485 updates, score 4.436) (writing took 1.5931071788072586 seconds)
2023-12-10 11:08:00 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-12-10 11:08:00 | INFO | train | {"epoch": 44, "train_loss": "3.972", "train_nll_loss": "2.513", "train_ppl": "5.71", "train_wps": "64734", "train_ups": "18.06", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "48485", "train_lr": "0.00287228", "train_gnorm": "0.263", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2788"}
2023-12-10 11:08:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:08:00 | INFO | fairseq.trainer | begin training epoch 45
2023-12-10 11:08:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:08:01 | INFO | train_inner | {"epoch": 45, "update": 44.014, "loss": "3.945", "nll_loss": "2.486", "ppl": "5.6", "wps": "45006.8", "ups": "12.51", "wpb": "3599", "bsz": "169", "num_updates": "48500", "lr": "0.00287183", "gnorm": "0.28", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2789"}
2023-12-10 11:08:06 | INFO | train_inner | {"epoch": 45, "update": 44.104, "loss": "3.865", "nll_loss": "2.386", "ppl": "5.23", "wps": "65117.8", "ups": "17.99", "wpb": "3619.7", "bsz": "144.2", "num_updates": "48600", "lr": "0.00286888", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2795"}
2023-12-10 11:08:11 | INFO | train_inner | {"epoch": 45, "update": 44.195, "loss": "3.895", "nll_loss": "2.421", "ppl": "5.35", "wps": "73729.7", "ups": "20.59", "wpb": "3580.8", "bsz": "149.4", "num_updates": "48700", "lr": "0.00286593", "gnorm": "0.254", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2799"}
2023-12-10 11:08:16 | INFO | train_inner | {"epoch": 45, "update": 44.286, "loss": "3.929", "nll_loss": "2.461", "ppl": "5.51", "wps": "71031.6", "ups": "19.64", "wpb": "3616.9", "bsz": "143.1", "num_updates": "48800", "lr": "0.00286299", "gnorm": "0.251", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2804"}
2023-12-10 11:08:22 | INFO | train_inner | {"epoch": 45, "update": 44.377, "loss": "3.966", "nll_loss": "2.505", "ppl": "5.68", "wps": "67318.7", "ups": "18.96", "wpb": "3551", "bsz": "142.3", "num_updates": "48900", "lr": "0.00286006", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2810"}
2023-12-10 11:08:27 | INFO | train_inner | {"epoch": 45, "update": 44.467, "loss": "3.972", "nll_loss": "2.511", "ppl": "5.7", "wps": "63561.6", "ups": "17.9", "wpb": "3550.4", "bsz": "132.5", "num_updates": "49000", "lr": "0.00285714", "gnorm": "0.274", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2815"}
2023-12-10 11:08:32 | INFO | train_inner | {"epoch": 45, "update": 44.558, "loss": "3.974", "nll_loss": "2.516", "ppl": "5.72", "wps": "79132", "ups": "21.88", "wpb": "3616.4", "bsz": "149.3", "num_updates": "49100", "lr": "0.00285423", "gnorm": "0.256", "loss_scale": "64", "train_wall": "4", "gb_free": "38.9", "wall": "2820"}
2023-12-10 11:08:37 | INFO | train_inner | {"epoch": 45, "update": 44.649, "loss": "4.015", "nll_loss": "2.562", "ppl": "5.91", "wps": "67766.9", "ups": "19.12", "wpb": "3543.9", "bsz": "143.2", "num_updates": "49200", "lr": "0.00285133", "gnorm": "0.271", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2825"}
2023-12-10 11:08:42 | INFO | train_inner | {"epoch": 45, "update": 44.74, "loss": "4.013", "nll_loss": "2.562", "ppl": "5.91", "wps": "68544.4", "ups": "19.02", "wpb": "3603.8", "bsz": "149", "num_updates": "49300", "lr": "0.00284844", "gnorm": "0.269", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2830"}
2023-12-10 11:08:48 | INFO | train_inner | {"epoch": 45, "update": 44.83, "loss": "3.998", "nll_loss": "2.545", "ppl": "5.83", "wps": "67614.7", "ups": "18.68", "wpb": "3619.7", "bsz": "148.1", "num_updates": "49400", "lr": "0.00284555", "gnorm": "0.265", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2836"}
2023-12-10 11:08:53 | INFO | train_inner | {"epoch": 45, "update": 44.921, "loss": "4.011", "nll_loss": "2.561", "ppl": "5.9", "wps": "68060.4", "ups": "19.27", "wpb": "3532.1", "bsz": "145.2", "num_updates": "49500", "lr": "0.00284268", "gnorm": "0.263", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2841"}
2023-12-10 11:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:08:59 | INFO | valid | {"epoch": 45, "valid_loss": "4.423", "valid_nll_loss": "3.043", "valid_ppl": "8.24", "valid_wps": "131601", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "49587", "valid_best_loss": "4.409"}
2023-12-10 11:08:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 49587 updates
2023-12-10 11:08:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint45.pt
2023-12-10 11:09:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint45.pt
2023-12-10 11:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint45.pt (epoch 45 @ 49587 updates, score 4.423) (writing took 1.7785725421272218 seconds)
2023-12-10 11:09:01 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-12-10 11:09:01 | INFO | train | {"epoch": 45, "train_loss": "3.964", "train_nll_loss": "2.503", "train_ppl": "5.67", "train_wps": "65265", "train_ups": "18.21", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "49587", "train_lr": "0.00284018", "train_gnorm": "0.261", "train_loss_scale": "64", "train_train_wall": "56", "train_gb_free": "39", "train_wall": "2849"}
2023-12-10 11:09:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:09:01 | INFO | fairseq.trainer | begin training epoch 46
2023-12-10 11:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:09:01 | INFO | train_inner | {"epoch": 46, "update": 45.012, "loss": "3.989", "nll_loss": "2.535", "ppl": "5.79", "wps": "42714.1", "ups": "11.84", "wpb": "3607.2", "bsz": "149", "num_updates": "49600", "lr": "0.00283981", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2849"}
2023-12-10 11:09:06 | INFO | train_inner | {"epoch": 46, "update": 45.103, "loss": "3.84", "nll_loss": "2.358", "ppl": "5.13", "wps": "71918.6", "ups": "19.91", "wpb": "3612.7", "bsz": "154.8", "num_updates": "49700", "lr": "0.00283695", "gnorm": "0.249", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2854"}
2023-12-10 11:09:12 | INFO | train_inner | {"epoch": 46, "update": 45.193, "loss": "3.908", "nll_loss": "2.438", "ppl": "5.42", "wps": "65446.1", "ups": "18.17", "wpb": "3601.6", "bsz": "144.2", "num_updates": "49800", "lr": "0.0028341", "gnorm": "0.264", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2860"}
2023-12-10 11:09:16 | INFO | train_inner | {"epoch": 46, "update": 45.284, "loss": "3.912", "nll_loss": "2.443", "ppl": "5.44", "wps": "77800.6", "ups": "21.34", "wpb": "3645.4", "bsz": "146.6", "num_updates": "49900", "lr": "0.00283126", "gnorm": "0.247", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2865"}
2023-12-10 11:09:22 | INFO | train_inner | {"epoch": 46, "update": 45.375, "loss": "3.881", "nll_loss": "2.408", "ppl": "5.31", "wps": "70765.5", "ups": "19.64", "wpb": "3602.5", "bsz": "161.8", "num_updates": "50000", "lr": "0.00282843", "gnorm": "0.259", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2870"}
2023-12-10 11:09:27 | INFO | train_inner | {"epoch": 46, "update": 45.466, "loss": "3.999", "nll_loss": "2.542", "ppl": "5.82", "wps": "65699.4", "ups": "18.23", "wpb": "3604.7", "bsz": "130.6", "num_updates": "50100", "lr": "0.0028256", "gnorm": "0.263", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "2875"}
2023-12-10 11:09:32 | INFO | train_inner | {"epoch": 46, "update": 45.556, "loss": "3.979", "nll_loss": "2.52", "ppl": "5.74", "wps": "69178.6", "ups": "19.47", "wpb": "3552.7", "bsz": "146.3", "num_updates": "50200", "lr": "0.00282279", "gnorm": "0.258", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2880"}
2023-12-10 11:09:38 | INFO | train_inner | {"epoch": 46, "update": 45.647, "loss": "4.002", "nll_loss": "2.546", "ppl": "5.84", "wps": "65395.2", "ups": "18.27", "wpb": "3578.5", "bsz": "136.9", "num_updates": "50300", "lr": "0.00281998", "gnorm": "0.271", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2886"}
2023-12-10 11:09:43 | INFO | train_inner | {"epoch": 46, "update": 45.738, "loss": "3.971", "nll_loss": "2.513", "ppl": "5.71", "wps": "72754.5", "ups": "20.43", "wpb": "3560.7", "bsz": "146", "num_updates": "50400", "lr": "0.00281718", "gnorm": "0.272", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2891"}
2023-12-10 11:09:49 | INFO | train_inner | {"epoch": 46, "update": 45.828, "loss": "4.022", "nll_loss": "2.571", "ppl": "5.94", "wps": "57644.4", "ups": "16.44", "wpb": "3506.1", "bsz": "137", "num_updates": "50500", "lr": "0.00281439", "gnorm": "0.272", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2897"}
2023-12-10 11:09:54 | INFO | train_inner | {"epoch": 46, "update": 45.919, "loss": "4.023", "nll_loss": "2.573", "ppl": "5.95", "wps": "62884", "ups": "17.62", "wpb": "3568.4", "bsz": "141.4", "num_updates": "50600", "lr": "0.00281161", "gnorm": "0.269", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "2902"}
2023-12-10 11:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:10:00 | INFO | valid | {"epoch": 46, "valid_loss": "4.438", "valid_nll_loss": "3.069", "valid_ppl": "8.39", "valid_wps": "130619", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "50689", "valid_best_loss": "4.409"}
2023-12-10 11:10:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 50689 updates
2023-12-10 11:10:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint46.pt
2023-12-10 11:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint46.pt
2023-12-10 11:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint46.pt (epoch 46 @ 50689 updates, score 4.438) (writing took 1.7800334142521024 seconds)
2023-12-10 11:10:02 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-12-10 11:10:02 | INFO | train | {"epoch": 46, "train_loss": "3.955", "train_nll_loss": "2.494", "train_ppl": "5.63", "train_wps": "64291.4", "train_ups": "17.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "50689", "train_lr": "0.00280914", "train_gnorm": "0.261", "train_loss_scale": "64", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "2910"}
2023-12-10 11:10:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:10:02 | INFO | fairseq.trainer | begin training epoch 47
2023-12-10 11:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:10:02 | INFO | train_inner | {"epoch": 47, "update": 46.01, "loss": "3.966", "nll_loss": "2.51", "ppl": "5.7", "wps": "43762.8", "ups": "12.27", "wpb": "3567.2", "bsz": "157.5", "num_updates": "50700", "lr": "0.00280883", "gnorm": "0.255", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "2911"}
2023-12-10 11:10:08 | INFO | train_inner | {"epoch": 47, "update": 46.101, "loss": "3.844", "nll_loss": "2.363", "ppl": "5.15", "wps": "63748.4", "ups": "17.83", "wpb": "3576.1", "bsz": "155.2", "num_updates": "50800", "lr": "0.00280607", "gnorm": "0.269", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "2916"}
2023-12-10 11:10:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-10 11:10:13 | INFO | train_inner | {"epoch": 47, "update": 46.192, "loss": "3.895", "nll_loss": "2.424", "ppl": "5.37", "wps": "68824.4", "ups": "19.38", "wpb": "3550.6", "bsz": "150.2", "num_updates": "50900", "lr": "0.00280331", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2921"}
2023-12-10 11:10:18 | INFO | train_inner | {"epoch": 47, "update": 46.283, "loss": "3.887", "nll_loss": "2.415", "ppl": "5.33", "wps": "69424.7", "ups": "19.32", "wpb": "3594", "bsz": "154.1", "num_updates": "51000", "lr": "0.00280056", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2927"}
2023-12-10 11:10:24 | INFO | train_inner | {"epoch": 47, "update": 46.374, "loss": "3.997", "nll_loss": "2.538", "ppl": "5.81", "wps": "66697.3", "ups": "18.82", "wpb": "3543.2", "bsz": "127", "num_updates": "51100", "lr": "0.00279782", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2932"}
2023-12-10 11:10:29 | INFO | train_inner | {"epoch": 47, "update": 46.465, "loss": "3.979", "nll_loss": "2.52", "ppl": "5.74", "wps": "63783.3", "ups": "17.8", "wpb": "3583.8", "bsz": "136.2", "num_updates": "51200", "lr": "0.00279508", "gnorm": "0.268", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2937"}
2023-12-10 11:10:34 | INFO | train_inner | {"epoch": 47, "update": 46.555, "loss": "3.946", "nll_loss": "2.483", "ppl": "5.59", "wps": "70566.6", "ups": "19.51", "wpb": "3617.5", "bsz": "153.6", "num_updates": "51300", "lr": "0.00279236", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2943"}
2023-12-10 11:10:40 | INFO | train_inner | {"epoch": 47, "update": 46.646, "loss": "3.943", "nll_loss": "2.481", "ppl": "5.58", "wps": "65169.9", "ups": "18.39", "wpb": "3543.7", "bsz": "147.8", "num_updates": "51400", "lr": "0.00278964", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2948"}
2023-12-10 11:10:46 | INFO | train_inner | {"epoch": 47, "update": 46.737, "loss": "3.99", "nll_loss": "2.533", "ppl": "5.79", "wps": "63824.9", "ups": "17.62", "wpb": "3622.9", "bsz": "139.8", "num_updates": "51500", "lr": "0.00278693", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2954"}
2023-12-10 11:10:51 | INFO | train_inner | {"epoch": 47, "update": 46.828, "loss": "4.017", "nll_loss": "2.565", "ppl": "5.92", "wps": "65518.5", "ups": "18.25", "wpb": "3590.2", "bsz": "135", "num_updates": "51600", "lr": "0.00278423", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2959"}
2023-12-10 11:10:56 | INFO | train_inner | {"epoch": 47, "update": 46.918, "loss": "3.974", "nll_loss": "2.518", "ppl": "5.73", "wps": "71100.4", "ups": "19.56", "wpb": "3635.5", "bsz": "153.5", "num_updates": "51700", "lr": "0.00278154", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2964"}
2023-12-10 11:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:11:02 | INFO | valid | {"epoch": 47, "valid_loss": "4.426", "valid_nll_loss": "3.046", "valid_ppl": "8.26", "valid_wps": "131663", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "51790", "valid_best_loss": "4.409"}
2023-12-10 11:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 51790 updates
2023-12-10 11:11:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint47.pt
2023-12-10 11:11:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint47.pt
2023-12-10 11:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint47.pt (epoch 47 @ 51790 updates, score 4.426) (writing took 1.6843658541329205 seconds)
2023-12-10 11:11:04 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-12-10 11:11:04 | INFO | train | {"epoch": 47, "train_loss": "3.949", "train_nll_loss": "2.487", "train_ppl": "5.6", "train_wps": "63889.1", "train_ups": "17.83", "train_wpb": "3583.3", "train_bsz": "145.5", "train_num_updates": "51790", "train_lr": "0.00277912", "train_gnorm": "0.264", "train_loss_scale": "32", "train_train_wall": "58", "train_gb_free": "39", "train_wall": "2972"}
2023-12-10 11:11:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:11:04 | INFO | fairseq.trainer | begin training epoch 48
2023-12-10 11:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:11:04 | INFO | train_inner | {"epoch": 48, "update": 47.009, "loss": "3.979", "nll_loss": "2.523", "ppl": "5.75", "wps": "43795.3", "ups": "12.27", "wpb": "3568.8", "bsz": "144.2", "num_updates": "51800", "lr": "0.00277885", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2972"}
2023-12-10 11:11:10 | INFO | train_inner | {"epoch": 48, "update": 47.1, "loss": "3.839", "nll_loss": "2.357", "ppl": "5.12", "wps": "67753.6", "ups": "18.88", "wpb": "3589.6", "bsz": "144.9", "num_updates": "51900", "lr": "0.00277617", "gnorm": "0.246", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2978"}
2023-12-10 11:11:14 | INFO | train_inner | {"epoch": 48, "update": 47.191, "loss": "3.875", "nll_loss": "2.4", "ppl": "5.28", "wps": "73648.4", "ups": "20.59", "wpb": "3577", "bsz": "158.5", "num_updates": "52000", "lr": "0.0027735", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2983"}
2023-12-10 11:11:20 | INFO | train_inner | {"epoch": 48, "update": 47.281, "loss": "3.959", "nll_loss": "2.495", "ppl": "5.64", "wps": "64239", "ups": "17.75", "wpb": "3619.2", "bsz": "133.7", "num_updates": "52100", "lr": "0.00277084", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2988"}
2023-12-10 11:11:25 | INFO | train_inner | {"epoch": 48, "update": 47.372, "loss": "3.892", "nll_loss": "2.419", "ppl": "5.35", "wps": "74066.1", "ups": "20.53", "wpb": "3607.6", "bsz": "141.8", "num_updates": "52200", "lr": "0.00276818", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2993"}
2023-12-10 11:11:30 | INFO | train_inner | {"epoch": 48, "update": 47.463, "loss": "3.955", "nll_loss": "2.493", "ppl": "5.63", "wps": "70148", "ups": "19.71", "wpb": "3558.5", "bsz": "143.5", "num_updates": "52300", "lr": "0.00276553", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2998"}
2023-12-10 11:11:35 | INFO | train_inner | {"epoch": 48, "update": 47.554, "loss": "3.96", "nll_loss": "2.499", "ppl": "5.65", "wps": "67757.5", "ups": "18.65", "wpb": "3632.2", "bsz": "149.7", "num_updates": "52400", "lr": "0.00276289", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3004"}
2023-12-10 11:11:41 | INFO | train_inner | {"epoch": 48, "update": 47.644, "loss": "3.98", "nll_loss": "2.522", "ppl": "5.74", "wps": "66212.7", "ups": "18.16", "wpb": "3645.9", "bsz": "140.9", "num_updates": "52500", "lr": "0.00276026", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3009"}
2023-12-10 11:11:46 | INFO | train_inner | {"epoch": 48, "update": 47.735, "loss": "3.985", "nll_loss": "2.529", "ppl": "5.77", "wps": "69618.2", "ups": "19.4", "wpb": "3587.8", "bsz": "142", "num_updates": "52600", "lr": "0.00275764", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3014"}
2023-12-10 11:11:52 | INFO | train_inner | {"epoch": 48, "update": 47.826, "loss": "3.989", "nll_loss": "2.532", "ppl": "5.78", "wps": "60154", "ups": "17.27", "wpb": "3483.5", "bsz": "135", "num_updates": "52700", "lr": "0.00275502", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3020"}
2023-12-10 11:11:57 | INFO | train_inner | {"epoch": 48, "update": 47.917, "loss": "3.967", "nll_loss": "2.512", "ppl": "5.7", "wps": "68925.5", "ups": "19.57", "wpb": "3522.4", "bsz": "166.2", "num_updates": "52800", "lr": "0.00275241", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3025"}
2023-12-10 11:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:12:03 | INFO | valid | {"epoch": 48, "valid_loss": "4.437", "valid_nll_loss": "3.07", "valid_ppl": "8.4", "valid_wps": "134593", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "52892", "valid_best_loss": "4.409"}
2023-12-10 11:12:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 52892 updates
2023-12-10 11:12:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint48.pt
2023-12-10 11:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint48.pt
2023-12-10 11:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint48.pt (epoch 48 @ 52892 updates, score 4.437) (writing took 1.8242772659286857 seconds)
2023-12-10 11:12:05 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-12-10 11:12:05 | INFO | train | {"epoch": 48, "train_loss": "3.94", "train_nll_loss": "2.476", "train_ppl": "5.56", "train_wps": "64464.9", "train_ups": "17.99", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "52892", "train_lr": "0.00275001", "train_gnorm": "0.263", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3033"}
2023-12-10 11:12:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:12:05 | INFO | fairseq.trainer | begin training epoch 49
2023-12-10 11:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:12:05 | INFO | train_inner | {"epoch": 49, "update": 48.007, "loss": "3.936", "nll_loss": "2.472", "ppl": "5.55", "wps": "42325.6", "ups": "11.81", "wpb": "3584.4", "bsz": "144.5", "num_updates": "52900", "lr": "0.00274981", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3034"}
2023-12-10 11:12:11 | INFO | train_inner | {"epoch": 49, "update": 48.098, "loss": "3.878", "nll_loss": "2.4", "ppl": "5.28", "wps": "66146.4", "ups": "18.62", "wpb": "3553.1", "bsz": "132.5", "num_updates": "53000", "lr": "0.00274721", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3039"}
2023-12-10 11:12:16 | INFO | train_inner | {"epoch": 49, "update": 48.189, "loss": "3.87", "nll_loss": "2.395", "ppl": "5.26", "wps": "71142.9", "ups": "19.61", "wpb": "3627", "bsz": "153.3", "num_updates": "53100", "lr": "0.00274462", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3044"}
2023-12-10 11:12:21 | INFO | train_inner | {"epoch": 49, "update": 48.279, "loss": "3.9", "nll_loss": "2.427", "ppl": "5.38", "wps": "67238.1", "ups": "18.66", "wpb": "3603", "bsz": "138.6", "num_updates": "53200", "lr": "0.00274204", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3049"}
2023-12-10 11:12:26 | INFO | train_inner | {"epoch": 49, "update": 48.37, "loss": "3.965", "nll_loss": "2.504", "ppl": "5.67", "wps": "70965.7", "ups": "19.36", "wpb": "3666.4", "bsz": "138.3", "num_updates": "53300", "lr": "0.00273947", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3055"}
2023-12-10 11:12:32 | INFO | train_inner | {"epoch": 49, "update": 48.461, "loss": "3.958", "nll_loss": "2.496", "ppl": "5.64", "wps": "70208.3", "ups": "19.55", "wpb": "3591.1", "bsz": "144.6", "num_updates": "53400", "lr": "0.0027369", "gnorm": "0.274", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3060"}
2023-12-10 11:12:37 | INFO | train_inner | {"epoch": 49, "update": 48.552, "loss": "3.902", "nll_loss": "2.433", "ppl": "5.4", "wps": "68640.5", "ups": "19.37", "wpb": "3544.3", "bsz": "159.5", "num_updates": "53500", "lr": "0.00273434", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3065"}
2023-12-10 11:12:43 | INFO | train_inner | {"epoch": 49, "update": 48.642, "loss": "3.977", "nll_loss": "2.519", "ppl": "5.73", "wps": "59770", "ups": "16.96", "wpb": "3524.1", "bsz": "141.5", "num_updates": "53600", "lr": "0.00273179", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3071"}
2023-12-10 11:12:48 | INFO | train_inner | {"epoch": 49, "update": 48.733, "loss": "3.949", "nll_loss": "2.486", "ppl": "5.6", "wps": "66913.2", "ups": "18.98", "wpb": "3525.8", "bsz": "141.8", "num_updates": "53700", "lr": "0.00272925", "gnorm": "0.28", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3076"}
2023-12-10 11:12:54 | INFO | train_inner | {"epoch": 49, "update": 48.824, "loss": "3.943", "nll_loss": "2.48", "ppl": "5.58", "wps": "64013.8", "ups": "17.8", "wpb": "3596.4", "bsz": "148.6", "num_updates": "53800", "lr": "0.00272671", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3082"}
2023-12-10 11:12:59 | INFO | train_inner | {"epoch": 49, "update": 48.915, "loss": "3.996", "nll_loss": "2.541", "ppl": "5.82", "wps": "70932.2", "ups": "19.88", "wpb": "3568.2", "bsz": "139.4", "num_updates": "53900", "lr": "0.00272418", "gnorm": "0.281", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3087"}
2023-12-10 11:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:13:05 | INFO | valid | {"epoch": 49, "valid_loss": "4.454", "valid_nll_loss": "3.061", "valid_ppl": "8.35", "valid_wps": "131307", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "53994", "valid_best_loss": "4.409"}
2023-12-10 11:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 53994 updates
2023-12-10 11:13:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint49.pt
2023-12-10 11:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint49.pt
2023-12-10 11:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint49.pt (epoch 49 @ 53994 updates, score 4.454) (writing took 1.5829774686135352 seconds)
2023-12-10 11:13:06 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-12-10 11:13:06 | INFO | train | {"epoch": 49, "train_loss": "3.935", "train_nll_loss": "2.47", "train_ppl": "5.54", "train_wps": "64585.9", "train_ups": "18.02", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "53994", "train_lr": "0.00272181", "train_gnorm": "0.268", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3094"}
2023-12-10 11:13:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:13:06 | INFO | fairseq.trainer | begin training epoch 50
2023-12-10 11:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:13:07 | INFO | train_inner | {"epoch": 50, "update": 49.005, "loss": "3.954", "nll_loss": "2.496", "ppl": "5.64", "wps": "45470.7", "ups": "12.56", "wpb": "3621.4", "bsz": "159.5", "num_updates": "54000", "lr": "0.00272166", "gnorm": "0.259", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3095"}
2023-12-10 11:13:12 | INFO | train_inner | {"epoch": 50, "update": 49.096, "loss": "3.831", "nll_loss": "2.35", "ppl": "5.1", "wps": "71787.7", "ups": "19.82", "wpb": "3621.9", "bsz": "153.1", "num_updates": "54100", "lr": "0.00271914", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3100"}
2023-12-10 11:13:17 | INFO | train_inner | {"epoch": 50, "update": 49.187, "loss": "3.927", "nll_loss": "2.458", "ppl": "5.5", "wps": "62708.3", "ups": "17.64", "wpb": "3554.7", "bsz": "128.9", "num_updates": "54200", "lr": "0.00271663", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3105"}
2023-12-10 11:13:22 | INFO | train_inner | {"epoch": 50, "update": 49.278, "loss": "3.841", "nll_loss": "2.361", "ppl": "5.14", "wps": "72905.2", "ups": "20.43", "wpb": "3567.7", "bsz": "157", "num_updates": "54300", "lr": "0.00271413", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3110"}
2023-12-10 11:13:27 | INFO | train_inner | {"epoch": 50, "update": 49.368, "loss": "3.922", "nll_loss": "2.455", "ppl": "5.48", "wps": "71408.3", "ups": "20.04", "wpb": "3563.9", "bsz": "148.8", "num_updates": "54400", "lr": "0.00271163", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3115"}
2023-12-10 11:13:32 | INFO | train_inner | {"epoch": 50, "update": 49.459, "loss": "3.913", "nll_loss": "2.444", "ppl": "5.44", "wps": "68484.2", "ups": "19.04", "wpb": "3596.2", "bsz": "145.8", "num_updates": "54500", "lr": "0.00270914", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3120"}
2023-12-10 11:13:37 | INFO | train_inner | {"epoch": 50, "update": 49.55, "loss": "3.907", "nll_loss": "2.438", "ppl": "5.42", "wps": "69981.1", "ups": "19.59", "wpb": "3572.1", "bsz": "161.7", "num_updates": "54600", "lr": "0.00270666", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3126"}
2023-12-10 11:13:43 | INFO | train_inner | {"epoch": 50, "update": 49.641, "loss": "3.953", "nll_loss": "2.493", "ppl": "5.63", "wps": "64776.2", "ups": "17.76", "wpb": "3646.6", "bsz": "143.4", "num_updates": "54700", "lr": "0.00270418", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3131"}
2023-12-10 11:13:48 | INFO | train_inner | {"epoch": 50, "update": 49.731, "loss": "3.991", "nll_loss": "2.536", "ppl": "5.8", "wps": "69732.6", "ups": "19.35", "wpb": "3603.9", "bsz": "142.8", "num_updates": "54800", "lr": "0.00270172", "gnorm": "0.281", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3136"}
2023-12-10 11:13:54 | INFO | train_inner | {"epoch": 50, "update": 49.822, "loss": "3.957", "nll_loss": "2.497", "ppl": "5.64", "wps": "68450.5", "ups": "18.99", "wpb": "3603.7", "bsz": "145.5", "num_updates": "54900", "lr": "0.00269925", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3142"}
2023-12-10 11:13:59 | INFO | train_inner | {"epoch": 50, "update": 49.913, "loss": "3.941", "nll_loss": "2.478", "ppl": "5.57", "wps": "65006.2", "ups": "18.17", "wpb": "3577", "bsz": "147", "num_updates": "55000", "lr": "0.0026968", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3147"}
2023-12-10 11:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:14:06 | INFO | valid | {"epoch": 50, "valid_loss": "4.447", "valid_nll_loss": "3.063", "valid_ppl": "8.36", "valid_wps": "129488", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "55096", "valid_best_loss": "4.409"}
2023-12-10 11:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 55096 updates
2023-12-10 11:14:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint50.pt
2023-12-10 11:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint50.pt
2023-12-10 11:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint50.pt (epoch 50 @ 55096 updates, score 4.447) (writing took 1.683293404057622 seconds)
2023-12-10 11:14:07 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-12-10 11:14:07 | INFO | train | {"epoch": 50, "train_loss": "3.927", "train_nll_loss": "2.461", "train_ppl": "5.51", "train_wps": "64623.3", "train_ups": "18.03", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "55096", "train_lr": "0.00269445", "train_gnorm": "0.263", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3155"}
2023-12-10 11:14:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:14:07 | INFO | fairseq.trainer | begin training epoch 51
2023-12-10 11:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:14:08 | INFO | train_inner | {"epoch": 51, "update": 50.004, "loss": "4.021", "nll_loss": "2.571", "ppl": "5.94", "wps": "41024.5", "ups": "11.64", "wpb": "3523.8", "bsz": "125.5", "num_updates": "55100", "lr": "0.00269435", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3156"}
2023-12-10 11:14:13 | INFO | train_inner | {"epoch": 51, "update": 50.094, "loss": "3.866", "nll_loss": "2.388", "ppl": "5.24", "wps": "66958.5", "ups": "18.38", "wpb": "3643.7", "bsz": "136.2", "num_updates": "55200", "lr": "0.00269191", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3161"}
2023-12-10 11:14:18 | INFO | train_inner | {"epoch": 51, "update": 50.185, "loss": "3.842", "nll_loss": "2.362", "ppl": "5.14", "wps": "69514.6", "ups": "19.29", "wpb": "3604.1", "bsz": "150.5", "num_updates": "55300", "lr": "0.00268947", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3166"}
2023-12-10 11:14:23 | INFO | train_inner | {"epoch": 51, "update": 50.276, "loss": "3.867", "nll_loss": "2.392", "ppl": "5.25", "wps": "77406.1", "ups": "21.51", "wpb": "3598.3", "bsz": "156.8", "num_updates": "55400", "lr": "0.00268705", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3171"}
2023-12-10 11:14:28 | INFO | train_inner | {"epoch": 51, "update": 50.367, "loss": "3.852", "nll_loss": "2.373", "ppl": "5.18", "wps": "68158", "ups": "19.01", "wpb": "3585", "bsz": "152.8", "num_updates": "55500", "lr": "0.00268462", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3176"}
2023-12-10 11:14:33 | INFO | train_inner | {"epoch": 51, "update": 50.457, "loss": "3.922", "nll_loss": "2.455", "ppl": "5.48", "wps": "68496.6", "ups": "19.18", "wpb": "3570.6", "bsz": "148.8", "num_updates": "55600", "lr": "0.00268221", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3182"}
2023-12-10 11:14:38 | INFO | train_inner | {"epoch": 51, "update": 50.548, "loss": "3.925", "nll_loss": "2.459", "ppl": "5.5", "wps": "72329.5", "ups": "19.8", "wpb": "3653.6", "bsz": "144.5", "num_updates": "55700", "lr": "0.0026798", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3187"}
2023-12-10 11:14:43 | INFO | train_inner | {"epoch": 51, "update": 50.639, "loss": "3.943", "nll_loss": "2.48", "ppl": "5.58", "wps": "72759.8", "ups": "20.06", "wpb": "3627.8", "bsz": "148.2", "num_updates": "55800", "lr": "0.0026774", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3192"}
2023-12-10 11:14:49 | INFO | train_inner | {"epoch": 51, "update": 50.73, "loss": "3.957", "nll_loss": "2.495", "ppl": "5.64", "wps": "62087.5", "ups": "17.84", "wpb": "3480.3", "bsz": "141.3", "num_updates": "55900", "lr": "0.002675", "gnorm": "0.296", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3197"}
2023-12-10 11:14:54 | INFO | train_inner | {"epoch": 51, "update": 50.82, "loss": "3.989", "nll_loss": "2.534", "ppl": "5.79", "wps": "70726.7", "ups": "19.65", "wpb": "3599", "bsz": "140.6", "num_updates": "56000", "lr": "0.00267261", "gnorm": "0.278", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3202"}
2023-12-10 11:15:00 | INFO | train_inner | {"epoch": 51, "update": 50.911, "loss": "3.965", "nll_loss": "2.506", "ppl": "5.68", "wps": "58954.1", "ups": "16.74", "wpb": "3521.2", "bsz": "147.5", "num_updates": "56100", "lr": "0.00267023", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3208"}
2023-12-10 11:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:15:07 | INFO | valid | {"epoch": 51, "valid_loss": "4.455", "valid_nll_loss": "3.076", "valid_ppl": "8.43", "valid_wps": "131849", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "56198", "valid_best_loss": "4.409"}
2023-12-10 11:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 56198 updates
2023-12-10 11:15:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint51.pt
2023-12-10 11:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint51.pt
2023-12-10 11:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint51.pt (epoch 51 @ 56198 updates, score 4.455) (writing took 1.8933711959980428 seconds)
2023-12-10 11:15:09 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-12-10 11:15:09 | INFO | train | {"epoch": 51, "train_loss": "3.921", "train_nll_loss": "2.454", "train_ppl": "5.48", "train_wps": "64345.4", "train_ups": "17.96", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "56198", "train_lr": "0.0026679", "train_gnorm": "0.269", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3217"}
2023-12-10 11:15:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:15:09 | INFO | fairseq.trainer | begin training epoch 52
2023-12-10 11:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:15:09 | INFO | train_inner | {"epoch": 52, "update": 51.002, "loss": "4.006", "nll_loss": "2.553", "ppl": "5.87", "wps": "40670.8", "ups": "11.5", "wpb": "3535.4", "bsz": "134.3", "num_updates": "56200", "lr": "0.00266785", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3217"}
2023-12-10 11:15:14 | INFO | train_inner | {"epoch": 52, "update": 51.093, "loss": "3.835", "nll_loss": "2.352", "ppl": "5.11", "wps": "70996", "ups": "19.67", "wpb": "3608.9", "bsz": "145.4", "num_updates": "56300", "lr": "0.00266548", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3222"}
2023-12-10 11:15:19 | INFO | train_inner | {"epoch": 52, "update": 51.183, "loss": "3.831", "nll_loss": "2.35", "ppl": "5.1", "wps": "75118.7", "ups": "20.61", "wpb": "3645", "bsz": "159.8", "num_updates": "56400", "lr": "0.00266312", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3227"}
2023-12-10 11:15:24 | INFO | train_inner | {"epoch": 52, "update": 51.274, "loss": "3.858", "nll_loss": "2.383", "ppl": "5.22", "wps": "67294.6", "ups": "18.79", "wpb": "3582.3", "bsz": "169.6", "num_updates": "56500", "lr": "0.00266076", "gnorm": "0.279", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3232"}
2023-12-10 11:15:30 | INFO | train_inner | {"epoch": 52, "update": 51.365, "loss": "3.9", "nll_loss": "2.429", "ppl": "5.39", "wps": "61327.6", "ups": "17.31", "wpb": "3541.9", "bsz": "143.8", "num_updates": "56600", "lr": "0.00265841", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3238"}
2023-12-10 11:15:35 | INFO | train_inner | {"epoch": 52, "update": 51.456, "loss": "3.891", "nll_loss": "2.42", "ppl": "5.35", "wps": "69108.6", "ups": "19.4", "wpb": "3561.8", "bsz": "151.5", "num_updates": "56700", "lr": "0.00265606", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3243"}
2023-12-10 11:15:40 | INFO | train_inner | {"epoch": 52, "update": 51.546, "loss": "3.948", "nll_loss": "2.483", "ppl": "5.59", "wps": "71261.2", "ups": "20.25", "wpb": "3519", "bsz": "135.1", "num_updates": "56800", "lr": "0.00265372", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3248"}
2023-12-10 11:15:46 | INFO | train_inner | {"epoch": 52, "update": 51.637, "loss": "3.947", "nll_loss": "2.484", "ppl": "5.59", "wps": "64146.2", "ups": "17.8", "wpb": "3604.2", "bsz": "135.4", "num_updates": "56900", "lr": "0.00265139", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3254"}
2023-12-10 11:15:51 | INFO | train_inner | {"epoch": 52, "update": 51.728, "loss": "3.963", "nll_loss": "2.503", "ppl": "5.67", "wps": "68956.1", "ups": "19.41", "wpb": "3551.9", "bsz": "136.6", "num_updates": "57000", "lr": "0.00264906", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3259"}
2023-12-10 11:15:56 | INFO | train_inner | {"epoch": 52, "update": 51.819, "loss": "3.99", "nll_loss": "2.534", "ppl": "5.79", "wps": "65257.5", "ups": "18.02", "wpb": "3621.8", "bsz": "127.9", "num_updates": "57100", "lr": "0.00264674", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3264"}
2023-12-10 11:16:01 | INFO | train_inner | {"epoch": 52, "update": 51.909, "loss": "3.969", "nll_loss": "2.511", "ppl": "5.7", "wps": "67402.7", "ups": "18.93", "wpb": "3560.6", "bsz": "144.6", "num_updates": "57200", "lr": "0.00264443", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3270"}
2023-12-10 11:16:07 | INFO | train_inner | {"epoch": 52, "update": 52.0, "loss": "3.936", "nll_loss": "2.473", "ppl": "5.55", "wps": "70027.6", "ups": "19.38", "wpb": "3614.3", "bsz": "148.5", "num_updates": "57300", "lr": "0.00264212", "gnorm": "0.272", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3275"}
2023-12-10 11:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:16:08 | INFO | valid | {"epoch": 52, "valid_loss": "4.443", "valid_nll_loss": "3.075", "valid_ppl": "8.43", "valid_wps": "131719", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "57300", "valid_best_loss": "4.409"}
2023-12-10 11:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 57300 updates
2023-12-10 11:16:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint52.pt
2023-12-10 11:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint52.pt
2023-12-10 11:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint52.pt (epoch 52 @ 57300 updates, score 4.443) (writing took 1.5623671668581665 seconds)
2023-12-10 11:16:10 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-12-10 11:16:10 | INFO | train | {"epoch": 52, "train_loss": "3.915", "train_nll_loss": "2.447", "train_ppl": "5.45", "train_wps": "64705.8", "train_ups": "18.06", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "57300", "train_lr": "0.00264212", "train_gnorm": "0.266", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3278"}
2023-12-10 11:16:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:16:10 | INFO | fairseq.trainer | begin training epoch 53
2023-12-10 11:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:16:15 | INFO | train_inner | {"epoch": 53, "update": 52.091, "loss": "3.851", "nll_loss": "2.371", "ppl": "5.17", "wps": "42733.3", "ups": "11.95", "wpb": "3576.9", "bsz": "135.8", "num_updates": "57400", "lr": "0.00263982", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3283"}
2023-12-10 11:16:20 | INFO | train_inner | {"epoch": 53, "update": 52.181, "loss": "3.795", "nll_loss": "2.309", "ppl": "4.95", "wps": "74513.8", "ups": "20.66", "wpb": "3606.7", "bsz": "164.9", "num_updates": "57500", "lr": "0.00263752", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3288"}
2023-12-10 11:16:25 | INFO | train_inner | {"epoch": 53, "update": 52.272, "loss": "3.83", "nll_loss": "2.349", "ppl": "5.1", "wps": "73106.9", "ups": "20.7", "wpb": "3531", "bsz": "160.4", "num_updates": "57600", "lr": "0.00263523", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3293"}
2023-12-10 11:16:30 | INFO | train_inner | {"epoch": 53, "update": 52.363, "loss": "3.856", "nll_loss": "2.379", "ppl": "5.2", "wps": "70474.4", "ups": "19.4", "wpb": "3633", "bsz": "154.3", "num_updates": "57700", "lr": "0.00263295", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3298"}
2023-12-10 11:16:35 | INFO | train_inner | {"epoch": 53, "update": 52.454, "loss": "3.904", "nll_loss": "2.435", "ppl": "5.41", "wps": "70297.1", "ups": "19.56", "wpb": "3594.3", "bsz": "146.6", "num_updates": "57800", "lr": "0.00263067", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3303"}
2023-12-10 11:16:40 | INFO | train_inner | {"epoch": 53, "update": 52.544, "loss": "3.904", "nll_loss": "2.436", "ppl": "5.41", "wps": "71526.2", "ups": "20.2", "wpb": "3541", "bsz": "154.2", "num_updates": "57900", "lr": "0.0026284", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3308"}
2023-12-10 11:16:46 | INFO | train_inner | {"epoch": 53, "update": 52.635, "loss": "3.985", "nll_loss": "2.525", "ppl": "5.76", "wps": "60431.2", "ups": "16.88", "wpb": "3579.2", "bsz": "123.6", "num_updates": "58000", "lr": "0.00262613", "gnorm": "0.288", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3314"}
2023-12-10 11:16:51 | INFO | train_inner | {"epoch": 53, "update": 52.726, "loss": "3.917", "nll_loss": "2.452", "ppl": "5.47", "wps": "72435.7", "ups": "20.03", "wpb": "3615.6", "bsz": "148.1", "num_updates": "58100", "lr": "0.00262387", "gnorm": "0.255", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3319"}
2023-12-10 11:16:56 | INFO | train_inner | {"epoch": 53, "update": 52.817, "loss": "3.966", "nll_loss": "2.508", "ppl": "5.69", "wps": "71276.1", "ups": "19.89", "wpb": "3584.1", "bsz": "140.4", "num_updates": "58200", "lr": "0.00262161", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3324"}
2023-12-10 11:17:01 | INFO | train_inner | {"epoch": 53, "update": 52.907, "loss": "3.974", "nll_loss": "2.516", "ppl": "5.72", "wps": "68341.7", "ups": "18.77", "wpb": "3640.7", "bsz": "142.1", "num_updates": "58300", "lr": "0.00261936", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3329"}
2023-12-10 11:17:07 | INFO | train_inner | {"epoch": 53, "update": 52.998, "loss": "4.001", "nll_loss": "2.547", "ppl": "5.84", "wps": "58554.7", "ups": "16.67", "wpb": "3512.3", "bsz": "130.2", "num_updates": "58400", "lr": "0.00261712", "gnorm": "0.283", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3335"}
2023-12-10 11:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:17:09 | INFO | valid | {"epoch": 53, "valid_loss": "4.433", "valid_nll_loss": "3.049", "valid_ppl": "8.28", "valid_wps": "132393", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "58402", "valid_best_loss": "4.409"}
2023-12-10 11:17:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 58402 updates
2023-12-10 11:17:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint53.pt
2023-12-10 11:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint53.pt
2023-12-10 11:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint53.pt (epoch 53 @ 58402 updates, score 4.433) (writing took 1.6783321341499686 seconds)
2023-12-10 11:17:10 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-12-10 11:17:10 | INFO | train | {"epoch": 53, "train_loss": "3.908", "train_nll_loss": "2.439", "train_ppl": "5.42", "train_wps": "65000.1", "train_ups": "18.14", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "58402", "train_lr": "0.00261707", "train_gnorm": "0.267", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3339"}
2023-12-10 11:17:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:17:10 | INFO | fairseq.trainer | begin training epoch 54
2023-12-10 11:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:17:15 | INFO | train_inner | {"epoch": 54, "update": 53.089, "loss": "3.823", "nll_loss": "2.337", "ppl": "5.05", "wps": "43271.7", "ups": "12.16", "wpb": "3558.9", "bsz": "144", "num_updates": "58500", "lr": "0.00261488", "gnorm": "0.25", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3344"}
2023-12-10 11:17:21 | INFO | train_inner | {"epoch": 54, "update": 53.18, "loss": "3.87", "nll_loss": "2.394", "ppl": "5.26", "wps": "66357.2", "ups": "18.29", "wpb": "3628.6", "bsz": "141.2", "num_updates": "58600", "lr": "0.00261265", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3349"}
2023-12-10 11:17:26 | INFO | train_inner | {"epoch": 54, "update": 53.27, "loss": "3.826", "nll_loss": "2.343", "ppl": "5.07", "wps": "69410.6", "ups": "19.34", "wpb": "3589.3", "bsz": "150.6", "num_updates": "58700", "lr": "0.00261042", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3354"}
2023-12-10 11:17:31 | INFO | train_inner | {"epoch": 54, "update": 53.361, "loss": "3.871", "nll_loss": "2.398", "ppl": "5.27", "wps": "75472.1", "ups": "20.44", "wpb": "3692.4", "bsz": "155.4", "num_updates": "58800", "lr": "0.0026082", "gnorm": "0.248", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3359"}
2023-12-10 11:17:36 | INFO | train_inner | {"epoch": 54, "update": 53.452, "loss": "3.91", "nll_loss": "2.439", "ppl": "5.42", "wps": "67007.6", "ups": "18.9", "wpb": "3544.8", "bsz": "134.8", "num_updates": "58900", "lr": "0.00260599", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3364"}
2023-12-10 11:17:41 | INFO | train_inner | {"epoch": 54, "update": 53.543, "loss": "3.88", "nll_loss": "2.408", "ppl": "5.31", "wps": "70469.4", "ups": "19.35", "wpb": "3642.3", "bsz": "159", "num_updates": "59000", "lr": "0.00260378", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3370"}
2023-12-10 11:17:47 | INFO | train_inner | {"epoch": 54, "update": 53.633, "loss": "3.919", "nll_loss": "2.451", "ppl": "5.47", "wps": "69091.5", "ups": "19.2", "wpb": "3598.6", "bsz": "142.2", "num_updates": "59100", "lr": "0.00260157", "gnorm": "0.267", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3375"}
2023-12-10 11:17:52 | INFO | train_inner | {"epoch": 54, "update": 53.724, "loss": "3.939", "nll_loss": "2.479", "ppl": "5.58", "wps": "72024.6", "ups": "20.26", "wpb": "3555.1", "bsz": "156.1", "num_updates": "59200", "lr": "0.00259938", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3380"}
2023-12-10 11:17:57 | INFO | train_inner | {"epoch": 54, "update": 53.815, "loss": "3.962", "nll_loss": "2.503", "ppl": "5.67", "wps": "59397.8", "ups": "16.97", "wpb": "3500.1", "bsz": "138.2", "num_updates": "59300", "lr": "0.00259718", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3386"}
2023-12-10 11:18:03 | INFO | train_inner | {"epoch": 54, "update": 53.906, "loss": "3.936", "nll_loss": "2.473", "ppl": "5.55", "wps": "66256", "ups": "18.56", "wpb": "3570.4", "bsz": "149.8", "num_updates": "59400", "lr": "0.002595", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3391"}
2023-12-10 11:18:08 | INFO | train_inner | {"epoch": 54, "update": 53.996, "loss": "3.978", "nll_loss": "2.519", "ppl": "5.73", "wps": "62919.8", "ups": "17.73", "wpb": "3549.2", "bsz": "125.5", "num_updates": "59500", "lr": "0.00259281", "gnorm": "0.28", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3397"}
2023-12-10 11:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:18:10 | INFO | valid | {"epoch": 54, "valid_loss": "4.449", "valid_nll_loss": "3.086", "valid_ppl": "8.49", "valid_wps": "129622", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "59504", "valid_best_loss": "4.409"}
2023-12-10 11:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 59504 updates
2023-12-10 11:18:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint54.pt
2023-12-10 11:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint54.pt
2023-12-10 11:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint54.pt (epoch 54 @ 59504 updates, score 4.449) (writing took 1.818914477713406 seconds)
2023-12-10 11:18:12 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-12-10 11:18:12 | INFO | train | {"epoch": 54, "train_loss": "3.9", "train_nll_loss": "2.43", "train_ppl": "5.39", "train_wps": "64128.5", "train_ups": "17.9", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "59504", "train_lr": "0.00259273", "train_gnorm": "0.265", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "39", "train_wall": "3400"}
2023-12-10 11:18:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-10 11:18:12 | INFO | fairseq.trainer | begin training epoch 55
2023-12-10 11:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-10 11:18:17 | INFO | train_inner | {"epoch": 55, "update": 54.087, "loss": "3.768", "nll_loss": "2.277", "ppl": "4.85", "wps": "42336.1", "ups": "12.06", "wpb": "3509.7", "bsz": "159.8", "num_updates": "59600", "lr": "0.00259064", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3405"}
2023-12-10 11:18:22 | INFO | train_inner | {"epoch": 55, "update": 54.178, "loss": "3.853", "nll_loss": "2.372", "ppl": "5.18", "wps": "69248.9", "ups": "19.63", "wpb": "3527.7", "bsz": "137.2", "num_updates": "59700", "lr": "0.00258847", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3410"}
2023-12-10 11:18:27 | INFO | train_inner | {"epoch": 55, "update": 54.269, "loss": "3.858", "nll_loss": "2.382", "ppl": "5.21", "wps": "70868.9", "ups": "19.66", "wpb": "3605.6", "bsz": "154.1", "num_updates": "59800", "lr": "0.0025863", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3415"}
2023-12-10 11:18:32 | INFO | train_inner | {"epoch": 55, "update": 54.359, "loss": "3.863", "nll_loss": "2.386", "ppl": "5.23", "wps": "68897.3", "ups": "19.1", "wpb": "3606.6", "bsz": "145.4", "num_updates": "59900", "lr": "0.00258414", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3420"}
2023-12-10 11:18:38 | INFO | train_inner | {"epoch": 55, "update": 54.45, "loss": "3.883", "nll_loss": "2.411", "ppl": "5.32", "wps": "67611.2", "ups": "18.56", "wpb": "3642.5", "bsz": "160.6", "num_updates": "60000", "lr": "0.00258199", "gnorm": "0.269", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3426"}
2023-12-10 11:18:43 | INFO | train_inner | {"epoch": 55, "update": 54.541, "loss": "3.943", "nll_loss": "2.483", "ppl": "5.59", "wps": "71199.7", "ups": "19.84", "wpb": "3588.7", "bsz": "145.6", "num_updates": "60100", "lr": "0.00257984", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3431"}
2023-12-10 11:18:48 | INFO | train_inner | {"epoch": 55, "update": 54.632, "loss": "3.908", "nll_loss": "2.439", "ppl": "5.42", "wps": "64649", "ups": "18.34", "wpb": "3525.8", "bsz": "138.6", "num_updates": "60200", "lr": "0.0025777", "gnorm": "0.271", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3436"}
2023-12-10 11:18:53 | INFO | train_inner | {"epoch": 55, "update": 54.722, "loss": "3.913", "nll_loss": "2.445", "ppl": "5.44", "wps": "67985.5", "ups": "18.95", "wpb": "3588.2", "bsz": "142.1", "num_updates": "60300", "lr": "0.00257556", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3441"}
2023-12-10 11:18:59 | INFO | train_inner | {"epoch": 55, "update": 54.813, "loss": "3.934", "nll_loss": "2.468", "ppl": "5.53", "wps": "64618.1", "ups": "17.89", "wpb": "3611", "bsz": "138.2", "num_updates": "60400", "lr": "0.00257343", "gnorm": "0.268", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3447"}
2023-12-10 11:19:04 | INFO | train_inner | {"epoch": 55, "update": 54.904, "loss": "3.94", "nll_loss": "2.477", "ppl": "5.57", "wps": "69571.3", "ups": "19.23", "wpb": "3618.7", "bsz": "142.2", "num_updates": "60500", "lr": "0.0025713", "gnorm": "0.275", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3452"}
2023-12-10 11:19:10 | INFO | train_inner | {"epoch": 55, "update": 54.995, "loss": "3.966", "nll_loss": "2.509", "ppl": "5.69", "wps": "64172.6", "ups": "17.81", "wpb": "3602.6", "bsz": "139", "num_updates": "60600", "lr": "0.00256917", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3458"}
2023-12-10 11:19:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-10 11:19:12 | INFO | valid | {"epoch": 55, "valid_loss": "4.435", "valid_nll_loss": "3.06", "valid_ppl": "8.34", "valid_wps": "131991", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "60606", "valid_best_loss": "4.409"}
2023-12-10 11:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 60606 updates
2023-12-10 11:19:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint55.pt
2023-12-10 11:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/nlpdata1/home/jprado/etc/experiments/nlp_experiments/checkpoints/checkpoint55.pt
2023-12-10 11:19:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint55.pt (epoch 55 @ 60606 updates, score 4.435) (writing took 1.499952896963805 seconds)
2023-12-10 11:19:13 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-12-10 11:19:13 | INFO | train | {"epoch": 55, "train_loss": "3.895", "train_nll_loss": "2.424", "train_ppl": "5.37", "train_wps": "64666.2", "train_ups": "18.05", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "60606", "train_lr": "0.00256905", "train_gnorm": "0.267", "train_loss_scale": "32", "train_train_wall": "57", "train_gb_free": "38.9", "train_wall": "3461"}
2023-12-10 11:19:13 | INFO | fairseq_cli.train | done training in 3461.0 seconds
