2023-12-13 21:27:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-12-13 21:27:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 94628, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': True, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/jprado/experiments/fairseq_dadaptation_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 55, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoint_d0_1e-0_94628', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=94628, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=True, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/home/jprado/experiments/fairseq_dadaptation_module', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='dadapt-adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_d0_1e-0_94628', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='lstm_wiseman_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=94628, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=True, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/home/jprado/experiments/fairseq_dadaptation_module', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='dadapt-adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_d0_1e-0_94628', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='dadapt-adam'), 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.01]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-12-13 21:27:57 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2023-12-13 21:27:57 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2023-12-13 21:27:57 | INFO | fairseq_cli.train | LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 256, padding_idx=1)
    (lstm): LSTM(256, 256)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 256, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(512, 256)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=256, out_features=256, bias=False)
      (output_proj): Linear(in_features=512, out_features=256, bias=False)
    )
  )
)
2023-12-13 21:27:57 | INFO | fairseq_cli.train | task: TranslationTask
2023-12-13 21:27:57 | INFO | fairseq_cli.train | model: LSTMModel
2023-12-13 21:27:57 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-12-13 21:27:57 | INFO | fairseq_cli.train | num. shared model params: 5,474,304 (num. trained: 5,474,304)
2023-12-13 21:27:57 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-12-13 21:27:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2023-12-13 21:27:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2023-12-13 21:27:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2023-12-13 21:27:59 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias
2023-12-13 21:27:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 21:27:59 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.392 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-12-13 21:27:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 21:27:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-12-13 21:27:59 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-12-13 21:27:59 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoint_d0_1e-0_94628/checkpoint_last.pt
2023-12-13 21:27:59 | INFO | fairseq.trainer | No existing checkpoint found checkpoint_d0_1e-0_94628/checkpoint_last.pt
2023-12-13 21:27:59 | INFO | fairseq.trainer | loading train data for epoch 1
2023-12-13 21:27:59 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2023-12-13 21:27:59 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2023-12-13 21:27:59 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Using decoupled weight decay
2023-12-13 21:27:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:27:59 | INFO | fairseq.trainer | begin training epoch 1
2023-12-13 21:27:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:28:06 | INFO | train_inner | {"epoch": 1, "update": 0.091, "loss": "11.629", "nll_loss": "11.454", "ppl": "2804.7", "wps": "59698.3", "ups": "16.56", "wpb": "3589.2", "bsz": "151.6", "num_updates": "100", "lr": "0.00025", "gnorm": "0.569", "loss_scale": "128", "train_wall": "6", "gb_free": "38.9", "wall": "6"}
2023-12-13 21:28:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-12-13 21:28:12 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "9.93", "nll_loss": "9.445", "ppl": "696.79", "wps": "58788.3", "ups": "16.62", "wpb": "3536.5", "bsz": "137.1", "num_updates": "200", "lr": "0.0005", "gnorm": "0.744", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "12"}
2023-12-13 21:28:18 | INFO | train_inner | {"epoch": 1, "update": 0.273, "loss": "9.709", "nll_loss": "9.198", "ppl": "587.23", "wps": "56979.2", "ups": "15.95", "wpb": "3572.2", "bsz": "135.4", "num_updates": "300", "lr": "0.00075", "gnorm": "0.794", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "19"}
2023-12-13 21:28:23 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "9.347", "nll_loss": "8.785", "ppl": "441.26", "wps": "65057", "ups": "17.82", "wpb": "3650", "bsz": "148.6", "num_updates": "400", "lr": "0.001", "gnorm": "0.692", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "24"}
2023-12-13 21:28:29 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "8.976", "nll_loss": "8.353", "ppl": "326.9", "wps": "60010.3", "ups": "16.8", "wpb": "3572.9", "bsz": "138.2", "num_updates": "500", "lr": "0.00125", "gnorm": "0.618", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "30"}
2023-12-13 21:28:36 | INFO | train_inner | {"epoch": 1, "update": 0.545, "loss": "8.604", "nll_loss": "7.918", "ppl": "241.82", "wps": "57247.3", "ups": "16.03", "wpb": "3571.7", "bsz": "137.5", "num_updates": "600", "lr": "0.0015", "gnorm": "0.486", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "37"}
2023-12-13 21:28:41 | INFO | train_inner | {"epoch": 1, "update": 0.636, "loss": "8.318", "nll_loss": "7.586", "ppl": "192.2", "wps": "61755.4", "ups": "17.24", "wpb": "3581.9", "bsz": "148.2", "num_updates": "700", "lr": "0.00175", "gnorm": "0.481", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "42"}
2023-12-13 21:28:47 | INFO | train_inner | {"epoch": 1, "update": 0.727, "loss": "7.925", "nll_loss": "7.13", "ppl": "140.09", "wps": "64573.1", "ups": "17.78", "wpb": "3631.8", "bsz": "151.3", "num_updates": "800", "lr": "0.002", "gnorm": "0.481", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "48"}
2023-12-13 21:28:53 | INFO | train_inner | {"epoch": 1, "update": 0.818, "loss": "7.63", "nll_loss": "6.786", "ppl": "110.35", "wps": "58301", "ups": "16.45", "wpb": "3543.9", "bsz": "141.1", "num_updates": "900", "lr": "0.00225", "gnorm": "0.48", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "54"}
2023-12-13 21:28:59 | INFO | train_inner | {"epoch": 1, "update": 0.908, "loss": "7.221", "nll_loss": "6.311", "ppl": "79.39", "wps": "62243.3", "ups": "17.26", "wpb": "3607.1", "bsz": "148.8", "num_updates": "1000", "lr": "0.0025", "gnorm": "0.469", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "60"}
2023-12-13 21:29:05 | INFO | train_inner | {"epoch": 1, "update": 0.999, "loss": "6.934", "nll_loss": "5.971", "ppl": "62.71", "wps": "61936.9", "ups": "17.37", "wpb": "3565.9", "bsz": "155.3", "num_updates": "1100", "lr": "0.00275", "gnorm": "0.493", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "66"}
2023-12-13 21:29:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:29:06 | INFO | valid | {"epoch": 1, "valid_loss": "6.705", "valid_nll_loss": "5.708", "valid_ppl": "52.26", "valid_wps": "129542", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "1101"}
2023-12-13 21:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1101 updates
2023-12-13 21:29:06 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint1.pt
2023-12-13 21:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint1.pt
2023-12-13 21:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint1.pt (epoch 1 @ 1101 updates, score 6.705) (writing took 0.15351162385195494 seconds)
2023-12-13 21:29:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-12-13 21:29:06 | INFO | train | {"epoch": 1, "train_loss": "8.745", "train_nll_loss": "8.083", "train_ppl": "271.1", "train_wps": "59007.1", "train_ups": "16.46", "train_wpb": "3584.1", "train_bsz": "144.8", "train_num_updates": "1101", "train_lr": "0.0027525", "train_gnorm": "0.573", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "67"}
2023-12-13 21:29:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:29:07 | INFO | fairseq.trainer | begin training epoch 2
2023-12-13 21:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:29:13 | INFO | train_inner | {"epoch": 2, "update": 1.09, "loss": "6.682", "nll_loss": "5.671", "ppl": "50.95", "wps": "44712.9", "ups": "12.67", "wpb": "3527.8", "bsz": "145.8", "num_updates": "1200", "lr": "0.003", "gnorm": "0.473", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "73"}
2023-12-13 21:29:18 | INFO | train_inner | {"epoch": 2, "update": 1.181, "loss": "6.533", "nll_loss": "5.492", "ppl": "44.99", "wps": "63615.5", "ups": "17.37", "wpb": "3663.4", "bsz": "128.6", "num_updates": "1300", "lr": "0.00325", "gnorm": "0.438", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "79"}
2023-12-13 21:29:24 | INFO | train_inner | {"epoch": 2, "update": 1.271, "loss": "6.28", "nll_loss": "5.193", "ppl": "36.57", "wps": "62374.3", "ups": "17.55", "wpb": "3554.5", "bsz": "152.7", "num_updates": "1400", "lr": "0.0035", "gnorm": "0.438", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "85"}
2023-12-13 21:29:30 | INFO | train_inner | {"epoch": 2, "update": 1.362, "loss": "6.149", "nll_loss": "5.035", "ppl": "32.8", "wps": "61993.4", "ups": "17.16", "wpb": "3612.1", "bsz": "150.2", "num_updates": "1500", "lr": "0.00375", "gnorm": "0.434", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "91"}
2023-12-13 21:29:36 | INFO | train_inner | {"epoch": 2, "update": 1.453, "loss": "6.087", "nll_loss": "4.96", "ppl": "31.12", "wps": "61407.5", "ups": "16.99", "wpb": "3614.4", "bsz": "131.6", "num_updates": "1600", "lr": "0.004", "gnorm": "0.405", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "97"}
2023-12-13 21:29:42 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "5.961", "nll_loss": "4.813", "ppl": "28.11", "wps": "57257.6", "ups": "16.11", "wpb": "3554.7", "bsz": "139.1", "num_updates": "1700", "lr": "0.00425", "gnorm": "0.408", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "103"}
2023-12-13 21:29:48 | INFO | train_inner | {"epoch": 2, "update": 1.634, "loss": "5.845", "nll_loss": "4.677", "ppl": "25.58", "wps": "59490.4", "ups": "16.95", "wpb": "3509.8", "bsz": "150.6", "num_updates": "1800", "lr": "0.0045", "gnorm": "0.395", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "109"}
2023-12-13 21:29:54 | INFO | train_inner | {"epoch": 2, "update": 1.725, "loss": "5.779", "nll_loss": "4.602", "ppl": "24.28", "wps": "61248.5", "ups": "17.26", "wpb": "3547.7", "bsz": "148.2", "num_updates": "1900", "lr": "0.00475", "gnorm": "0.373", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "115"}
2023-12-13 21:29:59 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "5.698", "nll_loss": "4.504", "ppl": "22.69", "wps": "64967.8", "ups": "17.75", "wpb": "3659.6", "bsz": "149", "num_updates": "2000", "lr": "0.005", "gnorm": "0.36", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "120"}
2023-12-13 21:30:05 | INFO | train_inner | {"epoch": 2, "update": 1.907, "loss": "5.636", "nll_loss": "4.434", "ppl": "21.62", "wps": "64419.6", "ups": "18.06", "wpb": "3567.8", "bsz": "155", "num_updates": "2100", "lr": "0.00525", "gnorm": "0.372", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "126"}
2023-12-13 21:30:11 | INFO | train_inner | {"epoch": 2, "update": 1.997, "loss": "5.621", "nll_loss": "4.416", "ppl": "21.34", "wps": "62839.1", "ups": "17.43", "wpb": "3605.8", "bsz": "144.2", "num_updates": "2200", "lr": "0.0055", "gnorm": "0.339", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "131"}
2023-12-13 21:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:30:12 | INFO | valid | {"epoch": 2, "valid_loss": "5.407", "valid_nll_loss": "4.179", "valid_ppl": "18.12", "valid_wps": "123849", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "2203", "valid_best_loss": "5.407"}
2023-12-13 21:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2203 updates
2023-12-13 21:30:12 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint2.pt
2023-12-13 21:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint2.pt
2023-12-13 21:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint2.pt (epoch 2 @ 2203 updates, score 5.407) (writing took 0.21150494646281004 seconds)
2023-12-13 21:30:12 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-12-13 21:30:12 | INFO | train | {"epoch": 2, "train_loss": "6.021", "train_nll_loss": "4.886", "train_ppl": "29.58", "train_wps": "59883.1", "train_ups": "16.71", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "2203", "train_lr": "0.0055075", "train_gnorm": "0.403", "train_loss_scale": "64", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "133"}
2023-12-13 21:30:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:30:12 | INFO | fairseq.trainer | begin training epoch 3
2023-12-13 21:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:30:19 | INFO | train_inner | {"epoch": 3, "update": 2.088, "loss": "5.507", "nll_loss": "4.282", "ppl": "19.46", "wps": "45276", "ups": "12.57", "wpb": "3600.8", "bsz": "146.6", "num_updates": "2300", "lr": "0.00575", "gnorm": "0.347", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "139"}
2023-12-13 21:30:24 | INFO | train_inner | {"epoch": 3, "update": 2.179, "loss": "5.512", "nll_loss": "4.282", "ppl": "19.46", "wps": "64043.9", "ups": "17.71", "wpb": "3616", "bsz": "146.8", "num_updates": "2400", "lr": "0.006", "gnorm": "0.344", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "145"}
2023-12-13 21:30:30 | INFO | train_inner | {"epoch": 3, "update": 2.27, "loss": "5.479", "nll_loss": "4.25", "ppl": "19.03", "wps": "62306.5", "ups": "17.69", "wpb": "3522.6", "bsz": "151.4", "num_updates": "2500", "lr": "0.00625", "gnorm": "0.338", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "151"}
2023-12-13 21:30:36 | INFO | train_inner | {"epoch": 3, "update": 2.36, "loss": "5.519", "nll_loss": "4.296", "ppl": "19.65", "wps": "59625.1", "ups": "16.68", "wpb": "3574.8", "bsz": "141.1", "num_updates": "2600", "lr": "0.0065", "gnorm": "0.33", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "157"}
2023-12-13 21:30:41 | INFO | train_inner | {"epoch": 3, "update": 2.451, "loss": "5.401", "nll_loss": "4.159", "ppl": "17.87", "wps": "64850.4", "ups": "18.01", "wpb": "3601.6", "bsz": "160.9", "num_updates": "2700", "lr": "0.00675", "gnorm": "0.315", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "162"}
2023-12-13 21:30:47 | INFO | train_inner | {"epoch": 3, "update": 2.542, "loss": "5.436", "nll_loss": "4.195", "ppl": "18.32", "wps": "60578.1", "ups": "17.23", "wpb": "3515.7", "bsz": "154.2", "num_updates": "2800", "lr": "0.007", "gnorm": "0.347", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "168"}
2023-12-13 21:30:53 | INFO | train_inner | {"epoch": 3, "update": 2.632, "loss": "5.491", "nll_loss": "4.259", "ppl": "19.14", "wps": "62341.1", "ups": "17.39", "wpb": "3584.7", "bsz": "136.9", "num_updates": "2900", "lr": "0.00725", "gnorm": "0.343", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "174"}
2023-12-13 21:30:59 | INFO | train_inner | {"epoch": 3, "update": 2.723, "loss": "5.442", "nll_loss": "4.203", "ppl": "18.42", "wps": "59024.3", "ups": "16.3", "wpb": "3620.9", "bsz": "141.7", "num_updates": "3000", "lr": "0.0075", "gnorm": "0.312", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "180"}
2023-12-13 21:31:05 | INFO | train_inner | {"epoch": 3, "update": 2.814, "loss": "5.4", "nll_loss": "4.153", "ppl": "17.79", "wps": "63480.3", "ups": "17.55", "wpb": "3616.2", "bsz": "145.8", "num_updates": "3100", "lr": "0.00775", "gnorm": "0.313", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "186"}
2023-12-13 21:31:11 | INFO | train_inner | {"epoch": 3, "update": 2.905, "loss": "5.431", "nll_loss": "4.188", "ppl": "18.22", "wps": "55242.8", "ups": "15.55", "wpb": "3552.6", "bsz": "132.6", "num_updates": "3200", "lr": "0.008", "gnorm": "0.32", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "192"}
2023-12-13 21:31:17 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "5.408", "nll_loss": "4.161", "ppl": "17.89", "wps": "65210.2", "ups": "18.06", "wpb": "3611.6", "bsz": "146.5", "num_updates": "3300", "lr": "0.00825", "gnorm": "0.313", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "198"}
2023-12-13 21:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:31:18 | INFO | valid | {"epoch": 3, "valid_loss": "5.178", "valid_nll_loss": "3.959", "valid_ppl": "15.55", "valid_wps": "126843", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "3305", "valid_best_loss": "5.178"}
2023-12-13 21:31:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3305 updates
2023-12-13 21:31:18 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint3.pt
2023-12-13 21:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint3.pt
2023-12-13 21:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint3.pt (epoch 3 @ 3305 updates, score 5.178) (writing took 0.20389369502663612 seconds)
2023-12-13 21:31:19 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-12-13 21:31:19 | INFO | train | {"epoch": 3, "train_loss": "5.459", "train_nll_loss": "4.223", "train_ppl": "18.67", "train_wps": "59568.6", "train_ups": "16.62", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "3305", "train_lr": "0.0082625", "train_gnorm": "0.329", "train_loss_scale": "64", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "200"}
2023-12-13 21:31:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:31:19 | INFO | fairseq.trainer | begin training epoch 4
2023-12-13 21:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:31:24 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "5.281", "nll_loss": "4.009", "ppl": "16.1", "wps": "51005.1", "ups": "13.92", "wpb": "3663.9", "bsz": "149", "num_updates": "3400", "lr": "0.0085", "gnorm": "0.305", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "205"}
2023-12-13 21:31:30 | INFO | train_inner | {"epoch": 4, "update": 3.177, "loss": "5.34", "nll_loss": "4.075", "ppl": "16.85", "wps": "56671.9", "ups": "15.99", "wpb": "3545.2", "bsz": "146.5", "num_updates": "3500", "lr": "0.00875", "gnorm": "0.327", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "211"}
2023-12-13 21:31:36 | INFO | train_inner | {"epoch": 4, "update": 3.268, "loss": "5.344", "nll_loss": "4.082", "ppl": "16.93", "wps": "61162.6", "ups": "16.92", "wpb": "3614.8", "bsz": "137.3", "num_updates": "3600", "lr": "0.009", "gnorm": "0.307", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "217"}
2023-12-13 21:31:42 | INFO | train_inner | {"epoch": 4, "update": 3.358, "loss": "5.321", "nll_loss": "4.055", "ppl": "16.62", "wps": "62780.9", "ups": "17.35", "wpb": "3617.6", "bsz": "151.3", "num_updates": "3700", "lr": "0.00925", "gnorm": "0.312", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "223"}
2023-12-13 21:31:48 | INFO | train_inner | {"epoch": 4, "update": 3.449, "loss": "5.356", "nll_loss": "4.094", "ppl": "17.08", "wps": "63440.3", "ups": "17.77", "wpb": "3571.1", "bsz": "147.5", "num_updates": "3800", "lr": "0.0095", "gnorm": "0.313", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "228"}
2023-12-13 21:31:54 | INFO | train_inner | {"epoch": 4, "update": 3.54, "loss": "5.442", "nll_loss": "4.193", "ppl": "18.29", "wps": "56935.8", "ups": "16", "wpb": "3557.8", "bsz": "128.2", "num_updates": "3900", "lr": "0.00975", "gnorm": "0.306", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "235"}
2023-12-13 21:32:00 | INFO | train_inner | {"epoch": 4, "update": 3.631, "loss": "5.43", "nll_loss": "4.176", "ppl": "18.07", "wps": "55341.3", "ups": "15.43", "wpb": "3585.6", "bsz": "134.6", "num_updates": "4000", "lr": "0.01", "gnorm": "0.323", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "241"}
2023-12-13 21:32:06 | INFO | train_inner | {"epoch": 4, "update": 3.721, "loss": "5.389", "nll_loss": "4.125", "ppl": "17.44", "wps": "59887.3", "ups": "16.74", "wpb": "3577.2", "bsz": "153.8", "num_updates": "4100", "lr": "0.0098773", "gnorm": "0.338", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "247"}
2023-12-13 21:32:11 | INFO | train_inner | {"epoch": 4, "update": 3.812, "loss": "5.26", "nll_loss": "3.983", "ppl": "15.81", "wps": "68389", "ups": "19.07", "wpb": "3586.6", "bsz": "171", "num_updates": "4200", "lr": "0.009759", "gnorm": "0.307", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "252"}
2023-12-13 21:32:17 | INFO | train_inner | {"epoch": 4, "update": 3.903, "loss": "5.342", "nll_loss": "4.075", "ppl": "16.86", "wps": "61714", "ups": "17.34", "wpb": "3559.4", "bsz": "148.2", "num_updates": "4300", "lr": "0.00964486", "gnorm": "0.309", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "258"}
2023-12-13 21:32:23 | INFO | train_inner | {"epoch": 4, "update": 3.994, "loss": "5.4", "nll_loss": "4.145", "ppl": "17.69", "wps": "59655.2", "ups": "16.8", "wpb": "3550.2", "bsz": "131.9", "num_updates": "4400", "lr": "0.00953463", "gnorm": "0.3", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "264"}
2023-12-13 21:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:32:25 | INFO | valid | {"epoch": 4, "valid_loss": "5.107", "valid_nll_loss": "3.862", "valid_ppl": "14.54", "valid_wps": "123505", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "4407", "valid_best_loss": "5.107"}
2023-12-13 21:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4407 updates
2023-12-13 21:32:25 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint4.pt
2023-12-13 21:32:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint4.pt
2023-12-13 21:32:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint4.pt (epoch 4 @ 4407 updates, score 5.107) (writing took 0.20819830149412155 seconds)
2023-12-13 21:32:25 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-12-13 21:32:25 | INFO | train | {"epoch": 4, "train_loss": "5.354", "train_nll_loss": "4.091", "train_ppl": "17.04", "train_wps": "59306.5", "train_ups": "16.55", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "4407", "train_lr": "0.00952705", "train_gnorm": "0.313", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "266"}
2023-12-13 21:32:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:32:25 | INFO | fairseq.trainer | begin training epoch 5
2023-12-13 21:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:32:31 | INFO | train_inner | {"epoch": 5, "update": 4.084, "loss": "5.203", "nll_loss": "3.912", "ppl": "15.05", "wps": "48813.2", "ups": "13.62", "wpb": "3583.4", "bsz": "149.1", "num_updates": "4500", "lr": "0.00942809", "gnorm": "0.313", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "271"}
2023-12-13 21:32:37 | INFO | train_inner | {"epoch": 5, "update": 4.175, "loss": "5.287", "nll_loss": "4.013", "ppl": "16.14", "wps": "57165.9", "ups": "15.97", "wpb": "3579.2", "bsz": "131.6", "num_updates": "4600", "lr": "0.00932505", "gnorm": "0.305", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "278"}
2023-12-13 21:32:43 | INFO | train_inner | {"epoch": 5, "update": 4.266, "loss": "5.188", "nll_loss": "3.895", "ppl": "14.88", "wps": "61752.6", "ups": "17.02", "wpb": "3629.2", "bsz": "150.1", "num_updates": "4700", "lr": "0.00922531", "gnorm": "0.307", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "284"}
2023-12-13 21:32:49 | INFO | train_inner | {"epoch": 5, "update": 4.357, "loss": "5.204", "nll_loss": "3.922", "ppl": "15.16", "wps": "59297.3", "ups": "16.48", "wpb": "3597.2", "bsz": "139.8", "num_updates": "4800", "lr": "0.00912871", "gnorm": "0.284", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "290"}
2023-12-13 21:32:55 | INFO | train_inner | {"epoch": 5, "update": 4.447, "loss": "5.223", "nll_loss": "3.943", "ppl": "15.38", "wps": "56963.4", "ups": "16.02", "wpb": "3555.9", "bsz": "137.9", "num_updates": "4900", "lr": "0.00903508", "gnorm": "0.307", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "296"}
2023-12-13 21:33:00 | INFO | train_inner | {"epoch": 5, "update": 4.538, "loss": "5.201", "nll_loss": "3.919", "ppl": "15.13", "wps": "66228.9", "ups": "18.56", "wpb": "3567.8", "bsz": "143.4", "num_updates": "5000", "lr": "0.00894427", "gnorm": "0.293", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "301"}
2023-12-13 21:33:06 | INFO | train_inner | {"epoch": 5, "update": 4.629, "loss": "5.187", "nll_loss": "3.903", "ppl": "14.96", "wps": "64840.2", "ups": "18.11", "wpb": "3581.2", "bsz": "147.1", "num_updates": "5100", "lr": "0.00885615", "gnorm": "0.287", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "307"}
2023-12-13 21:33:12 | INFO | train_inner | {"epoch": 5, "update": 4.72, "loss": "5.156", "nll_loss": "3.865", "ppl": "14.57", "wps": "56409.4", "ups": "15.8", "wpb": "3570.6", "bsz": "143.8", "num_updates": "5200", "lr": "0.00877058", "gnorm": "0.306", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "313"}
2023-12-13 21:33:18 | INFO | train_inner | {"epoch": 5, "update": 4.81, "loss": "5.151", "nll_loss": "3.86", "ppl": "14.52", "wps": "65862.3", "ups": "18.31", "wpb": "3596.7", "bsz": "157.2", "num_updates": "5300", "lr": "0.00868744", "gnorm": "0.301", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "319"}
2023-12-13 21:33:24 | INFO | train_inner | {"epoch": 5, "update": 4.901, "loss": "5.187", "nll_loss": "3.904", "ppl": "14.97", "wps": "58116.2", "ups": "16.37", "wpb": "3549.2", "bsz": "133", "num_updates": "5400", "lr": "0.00860663", "gnorm": "0.293", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "325"}
2023-12-13 21:33:29 | INFO | train_inner | {"epoch": 5, "update": 4.992, "loss": "5.084", "nll_loss": "3.787", "ppl": "13.81", "wps": "66226.3", "ups": "18.44", "wpb": "3592", "bsz": "164.3", "num_updates": "5500", "lr": "0.00852803", "gnorm": "0.283", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "330"}
2023-12-13 21:33:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:33:31 | INFO | valid | {"epoch": 5, "valid_loss": "4.893", "valid_nll_loss": "3.603", "valid_ppl": "12.15", "valid_wps": "127932", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "5509", "valid_best_loss": "4.893"}
2023-12-13 21:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5509 updates
2023-12-13 21:33:31 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint5.pt
2023-12-13 21:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint5.pt
2023-12-13 21:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint5.pt (epoch 5 @ 5509 updates, score 4.893) (writing took 0.21241109631955624 seconds)
2023-12-13 21:33:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-12-13 21:33:31 | INFO | train | {"epoch": 5, "train_loss": "5.186", "train_nll_loss": "3.899", "train_ppl": "14.92", "train_wps": "59848.8", "train_ups": "16.7", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "5509", "train_lr": "0.00852106", "train_gnorm": "0.298", "train_loss_scale": "64", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "332"}
2023-12-13 21:33:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:33:31 | INFO | fairseq.trainer | begin training epoch 6
2023-12-13 21:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:33:37 | INFO | train_inner | {"epoch": 6, "update": 5.083, "loss": "5.007", "nll_loss": "3.696", "ppl": "12.96", "wps": "47864.8", "ups": "13.27", "wpb": "3608.1", "bsz": "144.7", "num_updates": "5600", "lr": "0.00845154", "gnorm": "0.279", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "338"}
2023-12-13 21:33:43 | INFO | train_inner | {"epoch": 6, "update": 5.173, "loss": "5.059", "nll_loss": "3.754", "ppl": "13.49", "wps": "59607.6", "ups": "16.61", "wpb": "3588.4", "bsz": "140.6", "num_updates": "5700", "lr": "0.00837708", "gnorm": "0.291", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "344"}
2023-12-13 21:33:48 | INFO | train_inner | {"epoch": 6, "update": 5.264, "loss": "4.969", "nll_loss": "3.652", "ppl": "12.57", "wps": "67219.9", "ups": "18.44", "wpb": "3644.8", "bsz": "154.6", "num_updates": "5800", "lr": "0.00830455", "gnorm": "0.277", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "349"}
2023-12-13 21:33:54 | INFO | train_inner | {"epoch": 6, "update": 5.355, "loss": "5.135", "nll_loss": "3.844", "ppl": "14.36", "wps": "61261.3", "ups": "17.09", "wpb": "3585.1", "bsz": "130.1", "num_updates": "5900", "lr": "0.00823387", "gnorm": "0.292", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "355"}
2023-12-13 21:34:00 | INFO | train_inner | {"epoch": 6, "update": 5.446, "loss": "5.105", "nll_loss": "3.81", "ppl": "14.03", "wps": "56605", "ups": "16.14", "wpb": "3506.8", "bsz": "125.4", "num_updates": "6000", "lr": "0.00816497", "gnorm": "0.282", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "361"}
2023-12-13 21:34:06 | INFO | train_inner | {"epoch": 6, "update": 5.536, "loss": "5.017", "nll_loss": "3.712", "ppl": "13.11", "wps": "60158.2", "ups": "16.9", "wpb": "3559.3", "bsz": "141.8", "num_updates": "6100", "lr": "0.00809776", "gnorm": "0.282", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "367"}
2023-12-13 21:34:13 | INFO | train_inner | {"epoch": 6, "update": 5.627, "loss": "5.036", "nll_loss": "3.734", "ppl": "13.3", "wps": "56374.1", "ups": "15.67", "wpb": "3597", "bsz": "150.1", "num_updates": "6200", "lr": "0.00803219", "gnorm": "0.285", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "373"}
2023-12-13 21:34:18 | INFO | train_inner | {"epoch": 6, "update": 5.718, "loss": "5.014", "nll_loss": "3.712", "ppl": "13.1", "wps": "61608.6", "ups": "17.28", "wpb": "3565.7", "bsz": "149", "num_updates": "6300", "lr": "0.00796819", "gnorm": "0.286", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "379"}
2023-12-13 21:34:24 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "4.961", "nll_loss": "3.651", "ppl": "12.56", "wps": "67980.1", "ups": "18.74", "wpb": "3628.2", "bsz": "164.6", "num_updates": "6400", "lr": "0.00790569", "gnorm": "0.283", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "385"}
2023-12-13 21:34:29 | INFO | train_inner | {"epoch": 6, "update": 5.899, "loss": "4.995", "nll_loss": "3.689", "ppl": "12.89", "wps": "63527.7", "ups": "17.89", "wpb": "3550.8", "bsz": "145.8", "num_updates": "6500", "lr": "0.00784465", "gnorm": "0.276", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "390"}
2023-12-13 21:34:35 | INFO | train_inner | {"epoch": 6, "update": 5.99, "loss": "4.994", "nll_loss": "3.69", "ppl": "12.91", "wps": "59044.5", "ups": "16.48", "wpb": "3583.4", "bsz": "151.3", "num_updates": "6600", "lr": "0.00778499", "gnorm": "0.283", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "396"}
2023-12-13 21:34:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:34:37 | INFO | valid | {"epoch": 6, "valid_loss": "4.835", "valid_nll_loss": "3.498", "valid_ppl": "11.3", "valid_wps": "127029", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "6611", "valid_best_loss": "4.835"}
2023-12-13 21:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6611 updates
2023-12-13 21:34:37 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint6.pt
2023-12-13 21:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint6.pt
2023-12-13 21:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint6.pt (epoch 6 @ 6611 updates, score 4.835) (writing took 0.2088126689195633 seconds)
2023-12-13 21:34:38 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-12-13 21:34:38 | INFO | train | {"epoch": 6, "train_loss": "5.025", "train_nll_loss": "3.721", "train_ppl": "13.19", "train_wps": "59556.1", "train_ups": "16.62", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "6611", "train_lr": "0.00777851", "train_gnorm": "0.284", "train_loss_scale": "64", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "398"}
2023-12-13 21:34:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:34:38 | INFO | fairseq.trainer | begin training epoch 7
2023-12-13 21:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:34:44 | INFO | train_inner | {"epoch": 7, "update": 6.081, "loss": "4.963", "nll_loss": "3.648", "ppl": "12.54", "wps": "41422.7", "ups": "11.71", "wpb": "3537.1", "bsz": "129.9", "num_updates": "6700", "lr": "0.00772667", "gnorm": "0.281", "loss_scale": "64", "train_wall": "7", "gb_free": "38.9", "wall": "405"}
2023-12-13 21:34:49 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "4.828", "nll_loss": "3.495", "ppl": "11.27", "wps": "65769", "ups": "18.04", "wpb": "3645.8", "bsz": "158.2", "num_updates": "6800", "lr": "0.00766965", "gnorm": "0.268", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "410"}
2023-12-13 21:34:55 | INFO | train_inner | {"epoch": 7, "update": 6.262, "loss": "4.92", "nll_loss": "3.602", "ppl": "12.14", "wps": "63968.4", "ups": "17.86", "wpb": "3581.2", "bsz": "142.5", "num_updates": "6900", "lr": "0.00761387", "gnorm": "0.276", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "416"}
2023-12-13 21:35:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-13 21:35:01 | INFO | train_inner | {"epoch": 7, "update": 6.354, "loss": "4.89", "nll_loss": "3.569", "ppl": "11.86", "wps": "60532.5", "ups": "16.81", "wpb": "3601.2", "bsz": "154.7", "num_updates": "7000", "lr": "0.00755929", "gnorm": "0.28", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "422"}
2023-12-13 21:35:07 | INFO | train_inner | {"epoch": 7, "update": 6.445, "loss": "4.914", "nll_loss": "3.598", "ppl": "12.11", "wps": "60811.8", "ups": "17.08", "wpb": "3560.7", "bsz": "145.8", "num_updates": "7100", "lr": "0.00750587", "gnorm": "0.276", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "428"}
2023-12-13 21:35:12 | INFO | train_inner | {"epoch": 7, "update": 6.535, "loss": "4.828", "nll_loss": "3.497", "ppl": "11.29", "wps": "66885.6", "ups": "18.45", "wpb": "3624.3", "bsz": "171.4", "num_updates": "7200", "lr": "0.00745356", "gnorm": "0.282", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "433"}
2023-12-13 21:35:18 | INFO | train_inner | {"epoch": 7, "update": 6.626, "loss": "4.92", "nll_loss": "3.607", "ppl": "12.19", "wps": "64579", "ups": "18.24", "wpb": "3540.2", "bsz": "147.8", "num_updates": "7300", "lr": "0.00740233", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "439"}
2023-12-13 21:35:24 | INFO | train_inner | {"epoch": 7, "update": 6.717, "loss": "4.986", "nll_loss": "3.68", "ppl": "12.81", "wps": "58765.8", "ups": "16.28", "wpb": "3610.6", "bsz": "126.6", "num_updates": "7400", "lr": "0.00735215", "gnorm": "0.279", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "445"}
2023-12-13 21:35:30 | INFO | train_inner | {"epoch": 7, "update": 6.808, "loss": "4.908", "nll_loss": "3.592", "ppl": "12.05", "wps": "58800.4", "ups": "16.54", "wpb": "3555.8", "bsz": "148.4", "num_updates": "7500", "lr": "0.00730297", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "451"}
2023-12-13 21:35:36 | INFO | train_inner | {"epoch": 7, "update": 6.898, "loss": "4.982", "nll_loss": "3.678", "ppl": "12.8", "wps": "59517.7", "ups": "16.67", "wpb": "3571.1", "bsz": "128.6", "num_updates": "7600", "lr": "0.00725476", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "457"}
2023-12-13 21:35:41 | INFO | train_inner | {"epoch": 7, "update": 6.989, "loss": "4.892", "nll_loss": "3.576", "ppl": "11.92", "wps": "64815", "ups": "17.97", "wpb": "3607.6", "bsz": "146.4", "num_updates": "7700", "lr": "0.0072075", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "462"}
2023-12-13 21:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:35:43 | INFO | valid | {"epoch": 7, "valid_loss": "4.698", "valid_nll_loss": "3.38", "valid_ppl": "10.41", "valid_wps": "127566", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "7712", "valid_best_loss": "4.698"}
2023-12-13 21:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7712 updates
2023-12-13 21:35:43 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint7.pt
2023-12-13 21:35:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint7.pt
2023-12-13 21:35:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint7.pt (epoch 7 @ 7712 updates, score 4.698) (writing took 0.20936458185315132 seconds)
2023-12-13 21:35:44 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-12-13 21:35:44 | INFO | train | {"epoch": 7, "train_loss": "4.909", "train_nll_loss": "3.591", "train_ppl": "12.05", "train_wps": "59712", "train_ups": "16.65", "train_wpb": "3585.5", "train_bsz": "145.5", "train_num_updates": "7712", "train_lr": "0.00720189", "train_gnorm": "0.272", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "465"}
2023-12-13 21:35:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:35:44 | INFO | fairseq.trainer | begin training epoch 8
2023-12-13 21:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:35:49 | INFO | train_inner | {"epoch": 8, "update": 7.08, "loss": "4.736", "nll_loss": "3.393", "ppl": "10.5", "wps": "50504.7", "ups": "14.05", "wpb": "3595.6", "bsz": "144.6", "num_updates": "7800", "lr": "0.00716115", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "469"}
2023-12-13 21:35:54 | INFO | train_inner | {"epoch": 8, "update": 7.171, "loss": "4.722", "nll_loss": "3.377", "ppl": "10.39", "wps": "66026.9", "ups": "18.12", "wpb": "3644.8", "bsz": "161", "num_updates": "7900", "lr": "0.00711568", "gnorm": "0.279", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "475"}
2023-12-13 21:36:00 | INFO | train_inner | {"epoch": 8, "update": 7.261, "loss": "4.837", "nll_loss": "3.509", "ppl": "11.39", "wps": "58133.8", "ups": "16.19", "wpb": "3589.9", "bsz": "140.1", "num_updates": "8000", "lr": "0.00707107", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "481"}
2023-12-13 21:36:06 | INFO | train_inner | {"epoch": 8, "update": 7.352, "loss": "4.879", "nll_loss": "3.559", "ppl": "11.79", "wps": "61644.2", "ups": "17.29", "wpb": "3566.2", "bsz": "128.7", "num_updates": "8100", "lr": "0.00702728", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "487"}
2023-12-13 21:36:12 | INFO | train_inner | {"epoch": 8, "update": 7.443, "loss": "4.891", "nll_loss": "3.572", "ppl": "11.89", "wps": "59142.7", "ups": "16.46", "wpb": "3592.8", "bsz": "125.6", "num_updates": "8200", "lr": "0.0069843", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "493"}
2023-12-13 21:36:18 | INFO | train_inner | {"epoch": 8, "update": 7.534, "loss": "4.831", "nll_loss": "3.505", "ppl": "11.36", "wps": "60605.3", "ups": "16.89", "wpb": "3587.8", "bsz": "143.4", "num_updates": "8300", "lr": "0.0069421", "gnorm": "0.264", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "499"}
2023-12-13 21:36:24 | INFO | train_inner | {"epoch": 8, "update": 7.624, "loss": "4.82", "nll_loss": "3.493", "ppl": "11.26", "wps": "63174.8", "ups": "17.43", "wpb": "3625.2", "bsz": "141.8", "num_updates": "8400", "lr": "0.00690066", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "505"}
2023-12-13 21:36:29 | INFO | train_inner | {"epoch": 8, "update": 7.715, "loss": "4.756", "nll_loss": "3.419", "ppl": "10.7", "wps": "70580.4", "ups": "19.32", "wpb": "3653.2", "bsz": "163.2", "num_updates": "8500", "lr": "0.00685994", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "510"}
2023-12-13 21:36:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-12-13 21:36:35 | INFO | train_inner | {"epoch": 8, "update": 7.807, "loss": "4.805", "nll_loss": "3.477", "ppl": "11.13", "wps": "62431.6", "ups": "17.28", "wpb": "3613.6", "bsz": "157.5", "num_updates": "8600", "lr": "0.00681994", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "516"}
2023-12-13 21:36:41 | INFO | train_inner | {"epoch": 8, "update": 7.897, "loss": "4.89", "nll_loss": "3.574", "ppl": "11.91", "wps": "52095.1", "ups": "14.97", "wpb": "3480", "bsz": "141.8", "num_updates": "8700", "lr": "0.00678064", "gnorm": "0.289", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "522"}
2023-12-13 21:36:47 | INFO | train_inner | {"epoch": 8, "update": 7.988, "loss": "4.796", "nll_loss": "3.469", "ppl": "11.08", "wps": "64630.7", "ups": "18.41", "wpb": "3511.1", "bsz": "155.1", "num_updates": "8800", "lr": "0.006742", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "528"}
2023-12-13 21:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:36:49 | INFO | valid | {"epoch": 8, "valid_loss": "4.683", "valid_nll_loss": "3.376", "valid_ppl": "10.38", "valid_wps": "127162", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "8813", "valid_best_loss": "4.683"}
2023-12-13 21:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8813 updates
2023-12-13 21:36:49 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint8.pt
2023-12-13 21:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint8.pt
2023-12-13 21:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint8.pt (epoch 8 @ 8813 updates, score 4.683) (writing took 0.2065351903438568 seconds)
2023-12-13 21:36:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-12-13 21:36:49 | INFO | train | {"epoch": 8, "train_loss": "4.815", "train_nll_loss": "3.487", "train_ppl": "11.21", "train_wps": "60202", "train_ups": "16.8", "train_wpb": "3583.9", "train_bsz": "145.5", "train_num_updates": "8813", "train_lr": "0.00673702", "train_gnorm": "0.27", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "530"}
2023-12-13 21:36:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:36:49 | INFO | fairseq.trainer | begin training epoch 9
2023-12-13 21:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:36:55 | INFO | train_inner | {"epoch": 9, "update": 8.079, "loss": "4.716", "nll_loss": "3.372", "ppl": "10.35", "wps": "45030", "ups": "12.92", "wpb": "3485.2", "bsz": "143.6", "num_updates": "8900", "lr": "0.00670402", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "535"}
2023-12-13 21:37:00 | INFO | train_inner | {"epoch": 9, "update": 8.17, "loss": "4.713", "nll_loss": "3.368", "ppl": "10.32", "wps": "63800.7", "ups": "18.02", "wpb": "3540.9", "bsz": "151.2", "num_updates": "9000", "lr": "0.00666667", "gnorm": "0.269", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "541"}
2023-12-13 21:37:06 | INFO | train_inner | {"epoch": 9, "update": 8.26, "loss": "4.762", "nll_loss": "3.424", "ppl": "10.73", "wps": "58791.9", "ups": "16.5", "wpb": "3562.6", "bsz": "141.7", "num_updates": "9100", "lr": "0.00662994", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "547"}
2023-12-13 21:37:12 | INFO | train_inner | {"epoch": 9, "update": 8.351, "loss": "4.724", "nll_loss": "3.383", "ppl": "10.43", "wps": "59853.4", "ups": "16.64", "wpb": "3596.6", "bsz": "150.6", "num_updates": "9200", "lr": "0.0065938", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "553"}
2023-12-13 21:37:18 | INFO | train_inner | {"epoch": 9, "update": 8.442, "loss": "4.754", "nll_loss": "3.418", "ppl": "10.69", "wps": "61052.9", "ups": "17.08", "wpb": "3575.2", "bsz": "141", "num_updates": "9300", "lr": "0.00655826", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "559"}
2023-12-13 21:37:24 | INFO | train_inner | {"epoch": 9, "update": 8.533, "loss": "4.803", "nll_loss": "3.475", "ppl": "11.12", "wps": "56654.8", "ups": "15.82", "wpb": "3580.2", "bsz": "133.8", "num_updates": "9400", "lr": "0.00652328", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "565"}
2023-12-13 21:37:31 | INFO | train_inner | {"epoch": 9, "update": 8.623, "loss": "4.797", "nll_loss": "3.467", "ppl": "11.06", "wps": "57296.7", "ups": "15.87", "wpb": "3609.7", "bsz": "138.2", "num_updates": "9500", "lr": "0.00648886", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "572"}
2023-12-13 21:37:36 | INFO | train_inner | {"epoch": 9, "update": 8.714, "loss": "4.709", "nll_loss": "3.368", "ppl": "10.33", "wps": "69217.9", "ups": "18.74", "wpb": "3694.5", "bsz": "160.2", "num_updates": "9600", "lr": "0.00645497", "gnorm": "0.264", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "577"}
2023-12-13 21:37:42 | INFO | train_inner | {"epoch": 9, "update": 8.805, "loss": "4.746", "nll_loss": "3.411", "ppl": "10.64", "wps": "62506.7", "ups": "17.54", "wpb": "3564.3", "bsz": "154", "num_updates": "9700", "lr": "0.00642161", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "583"}
2023-12-13 21:37:47 | INFO | train_inner | {"epoch": 9, "update": 8.896, "loss": "4.725", "nll_loss": "3.385", "ppl": "10.45", "wps": "71475", "ups": "19.46", "wpb": "3672.6", "bsz": "157.9", "num_updates": "9800", "lr": "0.00638877", "gnorm": "0.26", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "588"}
2023-12-13 21:37:53 | INFO | train_inner | {"epoch": 9, "update": 8.986, "loss": "4.789", "nll_loss": "3.462", "ppl": "11.02", "wps": "56495.6", "ups": "15.89", "wpb": "3556", "bsz": "131.8", "num_updates": "9900", "lr": "0.00635642", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "594"}
2023-12-13 21:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:37:56 | INFO | valid | {"epoch": 9, "valid_loss": "4.644", "valid_nll_loss": "3.318", "valid_ppl": "9.97", "valid_wps": "128761", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "9915", "valid_best_loss": "4.644"}
2023-12-13 21:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9915 updates
2023-12-13 21:37:56 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint9.pt
2023-12-13 21:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint9.pt
2023-12-13 21:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint9.pt (epoch 9 @ 9915 updates, score 4.644) (writing took 0.2076519886031747 seconds)
2023-12-13 21:37:56 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-12-13 21:37:56 | INFO | train | {"epoch": 9, "train_loss": "4.75", "train_nll_loss": "3.413", "train_ppl": "10.65", "train_wps": "59256.4", "train_ups": "16.54", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "9915", "train_lr": "0.00635161", "train_gnorm": "0.266", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "597"}
2023-12-13 21:37:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:37:56 | INFO | fairseq.trainer | begin training epoch 10
2023-12-13 21:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:38:01 | INFO | train_inner | {"epoch": 10, "update": 9.077, "loss": "4.654", "nll_loss": "3.302", "ppl": "9.87", "wps": "44510.9", "ups": "12.52", "wpb": "3555.7", "bsz": "140.7", "num_updates": "10000", "lr": "0.00632456", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "602"}
2023-12-13 21:38:07 | INFO | train_inner | {"epoch": 10, "update": 9.168, "loss": "4.598", "nll_loss": "3.237", "ppl": "9.43", "wps": "62296.9", "ups": "17.29", "wpb": "3604", "bsz": "163.3", "num_updates": "10100", "lr": "0.00629317", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "608"}
2023-12-13 21:38:13 | INFO | train_inner | {"epoch": 10, "update": 9.259, "loss": "4.649", "nll_loss": "3.298", "ppl": "9.84", "wps": "61827.4", "ups": "17.25", "wpb": "3583.2", "bsz": "144", "num_updates": "10200", "lr": "0.00626224", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "614"}
2023-12-13 21:38:19 | INFO | train_inner | {"epoch": 10, "update": 9.349, "loss": "4.695", "nll_loss": "3.352", "ppl": "10.21", "wps": "61270.2", "ups": "17.12", "wpb": "3579.7", "bsz": "141.4", "num_updates": "10300", "lr": "0.00623177", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "619"}
2023-12-13 21:38:24 | INFO | train_inner | {"epoch": 10, "update": 9.44, "loss": "4.702", "nll_loss": "3.361", "ppl": "10.28", "wps": "64593.1", "ups": "17.62", "wpb": "3665.9", "bsz": "141", "num_updates": "10400", "lr": "0.00620174", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "625"}
2023-12-13 21:38:30 | INFO | train_inner | {"epoch": 10, "update": 9.531, "loss": "4.655", "nll_loss": "3.308", "ppl": "9.9", "wps": "66679.3", "ups": "18.78", "wpb": "3550.3", "bsz": "166.3", "num_updates": "10500", "lr": "0.00617213", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "630"}
2023-12-13 21:38:35 | INFO | train_inner | {"epoch": 10, "update": 9.622, "loss": "4.749", "nll_loss": "3.416", "ppl": "10.67", "wps": "63124.4", "ups": "17.56", "wpb": "3595", "bsz": "137", "num_updates": "10600", "lr": "0.00614295", "gnorm": "0.261", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "636"}
2023-12-13 21:38:41 | INFO | train_inner | {"epoch": 10, "update": 9.712, "loss": "4.752", "nll_loss": "3.419", "ppl": "10.7", "wps": "56675", "ups": "16.17", "wpb": "3506", "bsz": "137.3", "num_updates": "10700", "lr": "0.00611418", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "642"}
2023-12-13 21:38:47 | INFO | train_inner | {"epoch": 10, "update": 9.803, "loss": "4.671", "nll_loss": "3.327", "ppl": "10.04", "wps": "63439.8", "ups": "17.79", "wpb": "3566", "bsz": "152.6", "num_updates": "10800", "lr": "0.00608581", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "648"}
2023-12-13 21:38:53 | INFO | train_inner | {"epoch": 10, "update": 9.894, "loss": "4.778", "nll_loss": "3.453", "ppl": "10.95", "wps": "62840.5", "ups": "17.42", "wpb": "3606.8", "bsz": "141.6", "num_updates": "10900", "lr": "0.00605783", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "654"}
2023-12-13 21:38:59 | INFO | train_inner | {"epoch": 10, "update": 9.985, "loss": "4.738", "nll_loss": "3.403", "ppl": "10.58", "wps": "62061.2", "ups": "17.28", "wpb": "3591.2", "bsz": "135.4", "num_updates": "11000", "lr": "0.00603023", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "659"}
2023-12-13 21:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:39:01 | INFO | valid | {"epoch": 10, "valid_loss": "4.621", "valid_nll_loss": "3.317", "valid_ppl": "9.97", "valid_wps": "127327", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "11017", "valid_best_loss": "4.621"}
2023-12-13 21:39:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11017 updates
2023-12-13 21:39:01 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint10.pt
2023-12-13 21:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint10.pt
2023-12-13 21:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint10.pt (epoch 10 @ 11017 updates, score 4.621) (writing took 0.2102453839033842 seconds)
2023-12-13 21:39:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-12-13 21:39:01 | INFO | train | {"epoch": 10, "train_loss": "4.695", "train_nll_loss": "3.352", "train_ppl": "10.21", "train_wps": "60353", "train_ups": "16.84", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "11017", "train_lr": "0.00602557", "train_gnorm": "0.265", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "662"}
2023-12-13 21:39:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:39:01 | INFO | fairseq.trainer | begin training epoch 11
2023-12-13 21:39:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:39:07 | INFO | train_inner | {"epoch": 11, "update": 10.075, "loss": "4.628", "nll_loss": "3.275", "ppl": "9.68", "wps": "44850.5", "ups": "12.49", "wpb": "3589.9", "bsz": "143.8", "num_updates": "11100", "lr": "0.006003", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "667"}
2023-12-13 21:39:13 | INFO | train_inner | {"epoch": 11, "update": 10.166, "loss": "4.598", "nll_loss": "3.241", "ppl": "9.45", "wps": "53358.7", "ups": "15.12", "wpb": "3528.7", "bsz": "147.3", "num_updates": "11200", "lr": "0.00597614", "gnorm": "0.263", "loss_scale": "16", "train_wall": "7", "gb_free": "39", "wall": "674"}
2023-12-13 21:39:19 | INFO | train_inner | {"epoch": 11, "update": 10.257, "loss": "4.597", "nll_loss": "3.239", "ppl": "9.44", "wps": "64106.7", "ups": "17.79", "wpb": "3604", "bsz": "144.2", "num_updates": "11300", "lr": "0.00594964", "gnorm": "0.247", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "680"}
2023-12-13 21:39:24 | INFO | train_inner | {"epoch": 11, "update": 10.348, "loss": "4.611", "nll_loss": "3.258", "ppl": "9.57", "wps": "64707.6", "ups": "17.91", "wpb": "3612.2", "bsz": "154.8", "num_updates": "11400", "lr": "0.00592349", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "685"}
2023-12-13 21:39:30 | INFO | train_inner | {"epoch": 11, "update": 10.438, "loss": "4.603", "nll_loss": "3.251", "ppl": "9.52", "wps": "62380.7", "ups": "17.39", "wpb": "3586.5", "bsz": "163", "num_updates": "11500", "lr": "0.00589768", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "691"}
2023-12-13 21:39:36 | INFO | train_inner | {"epoch": 11, "update": 10.529, "loss": "4.664", "nll_loss": "3.32", "ppl": "9.98", "wps": "59990.7", "ups": "16.89", "wpb": "3552.6", "bsz": "138.8", "num_updates": "11600", "lr": "0.0058722", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "697"}
2023-12-13 21:39:42 | INFO | train_inner | {"epoch": 11, "update": 10.62, "loss": "4.702", "nll_loss": "3.362", "ppl": "10.28", "wps": "62591.3", "ups": "17.48", "wpb": "3580.9", "bsz": "130.4", "num_updates": "11700", "lr": "0.00584705", "gnorm": "0.261", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "703"}
2023-12-13 21:39:48 | INFO | train_inner | {"epoch": 11, "update": 10.711, "loss": "4.667", "nll_loss": "3.323", "ppl": "10.01", "wps": "62019.4", "ups": "17.27", "wpb": "3591.6", "bsz": "142.8", "num_updates": "11800", "lr": "0.00582223", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "708"}
2023-12-13 21:39:54 | INFO | train_inner | {"epoch": 11, "update": 10.801, "loss": "4.661", "nll_loss": "3.317", "ppl": "9.96", "wps": "59729", "ups": "16.73", "wpb": "3571.1", "bsz": "144.7", "num_updates": "11900", "lr": "0.00579771", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "714"}
2023-12-13 21:39:59 | INFO | train_inner | {"epoch": 11, "update": 10.892, "loss": "4.696", "nll_loss": "3.358", "ppl": "10.25", "wps": "61730.3", "ups": "17", "wpb": "3631.8", "bsz": "139.8", "num_updates": "12000", "lr": "0.0057735", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "720"}
2023-12-13 21:40:05 | INFO | train_inner | {"epoch": 11, "update": 10.983, "loss": "4.679", "nll_loss": "3.337", "ppl": "10.11", "wps": "63356.3", "ups": "17.91", "wpb": "3536.9", "bsz": "149", "num_updates": "12100", "lr": "0.0057496", "gnorm": "0.274", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "726"}
2023-12-13 21:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:40:07 | INFO | valid | {"epoch": 11, "valid_loss": "4.528", "valid_nll_loss": "3.192", "valid_ppl": "9.14", "valid_wps": "130100", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "12119", "valid_best_loss": "4.528"}
2023-12-13 21:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12119 updates
2023-12-13 21:40:07 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint11.pt
2023-12-13 21:40:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint11.pt
2023-12-13 21:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint11.pt (epoch 11 @ 12119 updates, score 4.528) (writing took 0.2075942838564515 seconds)
2023-12-13 21:40:08 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-12-13 21:40:08 | INFO | train | {"epoch": 11, "train_loss": "4.644", "train_nll_loss": "3.296", "train_ppl": "9.82", "train_wps": "59482.2", "train_ups": "16.6", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "12119", "train_lr": "0.00574509", "train_gnorm": "0.263", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "729"}
2023-12-13 21:40:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:40:08 | INFO | fairseq.trainer | begin training epoch 12
2023-12-13 21:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:40:13 | INFO | train_inner | {"epoch": 12, "update": 11.074, "loss": "4.544", "nll_loss": "3.18", "ppl": "9.06", "wps": "46706", "ups": "12.95", "wpb": "3606.8", "bsz": "141.6", "num_updates": "12200", "lr": "0.00572598", "gnorm": "0.245", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "734"}
2023-12-13 21:40:19 | INFO | train_inner | {"epoch": 12, "update": 11.164, "loss": "4.565", "nll_loss": "3.202", "ppl": "9.2", "wps": "55065.4", "ups": "15.41", "wpb": "3573.3", "bsz": "142.6", "num_updates": "12300", "lr": "0.00570266", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "740"}
2023-12-13 21:40:25 | INFO | train_inner | {"epoch": 12, "update": 11.255, "loss": "4.528", "nll_loss": "3.161", "ppl": "8.95", "wps": "64263.9", "ups": "17.76", "wpb": "3619.3", "bsz": "157.7", "num_updates": "12400", "lr": "0.00567962", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "746"}
2023-12-13 21:40:31 | INFO | train_inner | {"epoch": 12, "update": 11.346, "loss": "4.6", "nll_loss": "3.245", "ppl": "9.48", "wps": "57201.5", "ups": "15.87", "wpb": "3603.7", "bsz": "142.2", "num_updates": "12500", "lr": "0.00565685", "gnorm": "0.257", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "752"}
2023-12-13 21:40:37 | INFO | train_inner | {"epoch": 12, "update": 11.436, "loss": "4.575", "nll_loss": "3.216", "ppl": "9.29", "wps": "59613.5", "ups": "16.47", "wpb": "3620.1", "bsz": "144.2", "num_updates": "12600", "lr": "0.00563436", "gnorm": "0.257", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "758"}
2023-12-13 21:40:43 | INFO | train_inner | {"epoch": 12, "update": 11.527, "loss": "4.624", "nll_loss": "3.272", "ppl": "9.66", "wps": "61741.1", "ups": "17.28", "wpb": "3573.2", "bsz": "141.5", "num_updates": "12700", "lr": "0.00561214", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "764"}
2023-12-13 21:40:49 | INFO | train_inner | {"epoch": 12, "update": 11.618, "loss": "4.589", "nll_loss": "3.235", "ppl": "9.42", "wps": "61021.6", "ups": "17.04", "wpb": "3581.6", "bsz": "152.6", "num_updates": "12800", "lr": "0.00559017", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "770"}
2023-12-13 21:40:55 | INFO | train_inner | {"epoch": 12, "update": 11.709, "loss": "4.656", "nll_loss": "3.313", "ppl": "9.94", "wps": "61147.9", "ups": "17.13", "wpb": "3569", "bsz": "141.7", "num_updates": "12900", "lr": "0.00556846", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "776"}
2023-12-13 21:41:01 | INFO | train_inner | {"epoch": 12, "update": 11.799, "loss": "4.676", "nll_loss": "3.335", "ppl": "10.09", "wps": "58558", "ups": "16.56", "wpb": "3535.9", "bsz": "132.1", "num_updates": "13000", "lr": "0.005547", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "782"}
2023-12-13 21:41:06 | INFO | train_inner | {"epoch": 12, "update": 11.89, "loss": "4.621", "nll_loss": "3.273", "ppl": "9.67", "wps": "63602.1", "ups": "17.85", "wpb": "3563.8", "bsz": "152.4", "num_updates": "13100", "lr": "0.00552579", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "787"}
2023-12-13 21:41:12 | INFO | train_inner | {"epoch": 12, "update": 11.981, "loss": "4.639", "nll_loss": "3.293", "ppl": "9.8", "wps": "62591.5", "ups": "17.53", "wpb": "3570.1", "bsz": "144.5", "num_updates": "13200", "lr": "0.00550482", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "793"}
2023-12-13 21:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:41:15 | INFO | valid | {"epoch": 12, "valid_loss": "4.517", "valid_nll_loss": "3.162", "valid_ppl": "8.95", "valid_wps": "128667", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "13221", "valid_best_loss": "4.517"}
2023-12-13 21:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13221 updates
2023-12-13 21:41:15 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint12.pt
2023-12-13 21:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint12.pt
2023-12-13 21:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint12.pt (epoch 12 @ 13221 updates, score 4.517) (writing took 0.21100650541484356 seconds)
2023-12-13 21:41:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-12-13 21:41:15 | INFO | train | {"epoch": 12, "train_loss": "4.599", "train_nll_loss": "3.245", "train_ppl": "9.48", "train_wps": "58881.6", "train_ups": "16.43", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "13221", "train_lr": "0.00550045", "train_gnorm": "0.261", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "796"}
2023-12-13 21:41:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:41:15 | INFO | fairseq.trainer | begin training epoch 13
2023-12-13 21:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:41:20 | INFO | train_inner | {"epoch": 13, "update": 12.072, "loss": "4.556", "nll_loss": "3.195", "ppl": "9.16", "wps": "44081.5", "ups": "12.26", "wpb": "3596", "bsz": "128.7", "num_updates": "13300", "lr": "0.00548408", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "801"}
2023-12-13 21:41:26 | INFO | train_inner | {"epoch": 13, "update": 12.162, "loss": "4.51", "nll_loss": "3.143", "ppl": "8.83", "wps": "68651.2", "ups": "19", "wpb": "3614.1", "bsz": "146", "num_updates": "13400", "lr": "0.00546358", "gnorm": "0.25", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "806"}
2023-12-13 21:41:31 | INFO | train_inner | {"epoch": 13, "update": 12.253, "loss": "4.482", "nll_loss": "3.111", "ppl": "8.64", "wps": "62522.9", "ups": "17.47", "wpb": "3578.7", "bsz": "160.9", "num_updates": "13500", "lr": "0.00544331", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "812"}
2023-12-13 21:41:37 | INFO | train_inner | {"epoch": 13, "update": 12.344, "loss": "4.602", "nll_loss": "3.248", "ppl": "9.5", "wps": "61495.9", "ups": "16.92", "wpb": "3634.2", "bsz": "140.4", "num_updates": "13600", "lr": "0.00542326", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "818"}
2023-12-13 21:41:43 | INFO | train_inner | {"epoch": 13, "update": 12.435, "loss": "4.506", "nll_loss": "3.139", "ppl": "8.81", "wps": "63846.1", "ups": "17.85", "wpb": "3576.6", "bsz": "165", "num_updates": "13700", "lr": "0.00540343", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "824"}
2023-12-13 21:41:48 | INFO | train_inner | {"epoch": 13, "update": 12.525, "loss": "4.56", "nll_loss": "3.201", "ppl": "9.2", "wps": "65540.9", "ups": "18.16", "wpb": "3609.9", "bsz": "149.8", "num_updates": "13800", "lr": "0.00538382", "gnorm": "0.255", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "829"}
2023-12-13 21:41:54 | INFO | train_inner | {"epoch": 13, "update": 12.616, "loss": "4.577", "nll_loss": "3.224", "ppl": "9.34", "wps": "63680.9", "ups": "17.4", "wpb": "3659.5", "bsz": "147.3", "num_updates": "13900", "lr": "0.00536442", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "835"}
2023-12-13 21:42:00 | INFO | train_inner | {"epoch": 13, "update": 12.707, "loss": "4.578", "nll_loss": "3.221", "ppl": "9.32", "wps": "63682.1", "ups": "17.7", "wpb": "3597.1", "bsz": "148.2", "num_updates": "14000", "lr": "0.00534522", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "841"}
2023-12-13 21:42:06 | INFO | train_inner | {"epoch": 13, "update": 12.798, "loss": "4.575", "nll_loss": "3.22", "ppl": "9.32", "wps": "59292.4", "ups": "16.59", "wpb": "3574.3", "bsz": "142.2", "num_updates": "14100", "lr": "0.00532624", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "847"}
2023-12-13 21:42:12 | INFO | train_inner | {"epoch": 13, "update": 12.888, "loss": "4.622", "nll_loss": "3.275", "ppl": "9.68", "wps": "59994.1", "ups": "16.97", "wpb": "3535.8", "bsz": "135.4", "num_updates": "14200", "lr": "0.00530745", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "852"}
2023-12-13 21:42:18 | INFO | train_inner | {"epoch": 13, "update": 12.979, "loss": "4.636", "nll_loss": "3.29", "ppl": "9.78", "wps": "58116.2", "ups": "16.66", "wpb": "3487.9", "bsz": "138.6", "num_updates": "14300", "lr": "0.00528886", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "858"}
2023-12-13 21:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:42:20 | INFO | valid | {"epoch": 13, "valid_loss": "4.499", "valid_nll_loss": "3.158", "valid_ppl": "8.93", "valid_wps": "124512", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "14323", "valid_best_loss": "4.499"}
2023-12-13 21:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14323 updates
2023-12-13 21:42:20 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint13.pt
2023-12-13 21:42:21 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint13.pt
2023-12-13 21:42:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint13.pt (epoch 13 @ 14323 updates, score 4.499) (writing took 0.20987730287015438 seconds)
2023-12-13 21:42:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-12-13 21:42:21 | INFO | train | {"epoch": 13, "train_loss": "4.564", "train_nll_loss": "3.206", "train_ppl": "9.23", "train_wps": "59931.4", "train_ups": "16.72", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "14323", "train_lr": "0.00528461", "train_gnorm": "0.265", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "862"}
2023-12-13 21:42:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:42:21 | INFO | fairseq.trainer | begin training epoch 14
2023-12-13 21:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:42:25 | INFO | train_inner | {"epoch": 14, "update": 13.07, "loss": "4.47", "nll_loss": "3.099", "ppl": "8.57", "wps": "47026.5", "ups": "13.14", "wpb": "3579.7", "bsz": "142.5", "num_updates": "14400", "lr": "0.00527046", "gnorm": "0.244", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "866"}
2023-12-13 21:42:31 | INFO | train_inner | {"epoch": 14, "update": 13.161, "loss": "4.455", "nll_loss": "3.079", "ppl": "8.45", "wps": "64979", "ups": "18.06", "wpb": "3597", "bsz": "154.1", "num_updates": "14500", "lr": "0.00525226", "gnorm": "0.257", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "872"}
2023-12-13 21:42:37 | INFO | train_inner | {"epoch": 14, "update": 13.251, "loss": "4.495", "nll_loss": "3.127", "ppl": "8.74", "wps": "60838.7", "ups": "16.85", "wpb": "3610.7", "bsz": "142.7", "num_updates": "14600", "lr": "0.00523424", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "878"}
2023-12-13 21:42:43 | INFO | train_inner | {"epoch": 14, "update": 13.342, "loss": "4.539", "nll_loss": "3.18", "ppl": "9.06", "wps": "59848.8", "ups": "16.76", "wpb": "3570.2", "bsz": "151", "num_updates": "14700", "lr": "0.00521641", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "884"}
2023-12-13 21:42:49 | INFO | train_inner | {"epoch": 14, "update": 13.433, "loss": "4.513", "nll_loss": "3.149", "ppl": "8.87", "wps": "59885.6", "ups": "16.76", "wpb": "3574.1", "bsz": "146.1", "num_updates": "14800", "lr": "0.00519875", "gnorm": "0.25", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "890"}
2023-12-13 21:42:55 | INFO | train_inner | {"epoch": 14, "update": 13.524, "loss": "4.574", "nll_loss": "3.218", "ppl": "9.31", "wps": "56682.5", "ups": "16.21", "wpb": "3496.7", "bsz": "138.2", "num_updates": "14900", "lr": "0.00518128", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "896"}
2023-12-13 21:43:01 | INFO | train_inner | {"epoch": 14, "update": 13.614, "loss": "4.577", "nll_loss": "3.221", "ppl": "9.33", "wps": "58041.3", "ups": "16.13", "wpb": "3597.5", "bsz": "135.7", "num_updates": "15000", "lr": "0.00516398", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "902"}
2023-12-13 21:43:06 | INFO | train_inner | {"epoch": 14, "update": 13.705, "loss": "4.488", "nll_loss": "3.123", "ppl": "8.71", "wps": "74930.5", "ups": "20.85", "wpb": "3594.3", "bsz": "160.2", "num_updates": "15100", "lr": "0.00514685", "gnorm": "0.247", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "907"}
2023-12-13 21:43:11 | INFO | train_inner | {"epoch": 14, "update": 13.796, "loss": "4.545", "nll_loss": "3.189", "ppl": "9.12", "wps": "68653.9", "ups": "19.04", "wpb": "3604.9", "bsz": "151.4", "num_updates": "15200", "lr": "0.00512989", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "912"}
2023-12-13 21:43:17 | INFO | train_inner | {"epoch": 14, "update": 13.887, "loss": "4.579", "nll_loss": "3.226", "ppl": "9.36", "wps": "59212.5", "ups": "16.43", "wpb": "3603.9", "bsz": "140.2", "num_updates": "15300", "lr": "0.0051131", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "918"}
2023-12-13 21:43:23 | INFO | train_inner | {"epoch": 14, "update": 13.977, "loss": "4.55", "nll_loss": "3.193", "ppl": "9.15", "wps": "63863", "ups": "17.89", "wpb": "3568.8", "bsz": "149.2", "num_updates": "15400", "lr": "0.00509647", "gnorm": "0.286", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "924"}
2023-12-13 21:43:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:43:26 | INFO | valid | {"epoch": 14, "valid_loss": "4.472", "valid_nll_loss": "3.133", "valid_ppl": "8.78", "valid_wps": "127589", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "15425", "valid_best_loss": "4.472"}
2023-12-13 21:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15425 updates
2023-12-13 21:43:26 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint14.pt
2023-12-13 21:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint14.pt
2023-12-13 21:43:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint14.pt (epoch 14 @ 15425 updates, score 4.472) (writing took 0.21354537922888994 seconds)
2023-12-13 21:43:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-12-13 21:43:26 | INFO | train | {"epoch": 14, "train_loss": "4.529", "train_nll_loss": "3.167", "train_ppl": "8.98", "train_wps": "60352.5", "train_ups": "16.84", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "15425", "train_lr": "0.00509234", "train_gnorm": "0.265", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "927"}
2023-12-13 21:43:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:43:26 | INFO | fairseq.trainer | begin training epoch 15
2023-12-13 21:43:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:43:30 | INFO | train_inner | {"epoch": 15, "update": 14.068, "loss": "4.49", "nll_loss": "3.121", "ppl": "8.7", "wps": "46095.2", "ups": "12.88", "wpb": "3577.9", "bsz": "130.5", "num_updates": "15500", "lr": "0.00508001", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "931"}
2023-12-13 21:43:36 | INFO | train_inner | {"epoch": 15, "update": 14.159, "loss": "4.407", "nll_loss": "3.024", "ppl": "8.14", "wps": "59357.5", "ups": "16.67", "wpb": "3561.7", "bsz": "153", "num_updates": "15600", "lr": "0.0050637", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "937"}
2023-12-13 21:43:42 | INFO | train_inner | {"epoch": 15, "update": 14.25, "loss": "4.404", "nll_loss": "3.023", "ppl": "8.13", "wps": "67726.2", "ups": "18.64", "wpb": "3633.5", "bsz": "157.8", "num_updates": "15700", "lr": "0.00504754", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "39.1", "wall": "943"}
2023-12-13 21:43:48 | INFO | train_inner | {"epoch": 15, "update": 14.34, "loss": "4.557", "nll_loss": "3.197", "ppl": "9.17", "wps": "55055.3", "ups": "15.38", "wpb": "3579.4", "bsz": "131.9", "num_updates": "15800", "lr": "0.00503155", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "949"}
2023-12-13 21:43:54 | INFO | train_inner | {"epoch": 15, "update": 14.431, "loss": "4.428", "nll_loss": "3.054", "ppl": "8.3", "wps": "62784.8", "ups": "17.44", "wpb": "3599.7", "bsz": "167.8", "num_updates": "15900", "lr": "0.0050157", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "955"}
2023-12-13 21:44:00 | INFO | train_inner | {"epoch": 15, "update": 14.522, "loss": "4.6", "nll_loss": "3.25", "ppl": "9.51", "wps": "56580.4", "ups": "15.74", "wpb": "3595.8", "bsz": "117.2", "num_updates": "16000", "lr": "0.005", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "961"}
2023-12-13 21:44:06 | INFO | train_inner | {"epoch": 15, "update": 14.613, "loss": "4.484", "nll_loss": "3.117", "ppl": "8.68", "wps": "62424.3", "ups": "17.5", "wpb": "3567.4", "bsz": "150.7", "num_updates": "16100", "lr": "0.00498445", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "967"}
2023-12-13 21:44:11 | INFO | train_inner | {"epoch": 15, "update": 14.703, "loss": "4.477", "nll_loss": "3.112", "ppl": "8.64", "wps": "73925.1", "ups": "20.35", "wpb": "3633.5", "bsz": "165.2", "num_updates": "16200", "lr": "0.00496904", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "972"}
2023-12-13 21:44:17 | INFO | train_inner | {"epoch": 15, "update": 14.794, "loss": "4.593", "nll_loss": "3.245", "ppl": "9.48", "wps": "61147.8", "ups": "17.35", "wpb": "3524.7", "bsz": "135.4", "num_updates": "16300", "lr": "0.00495377", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "978"}
2023-12-13 21:44:23 | INFO | train_inner | {"epoch": 15, "update": 14.885, "loss": "4.552", "nll_loss": "3.196", "ppl": "9.17", "wps": "57278.8", "ups": "16.23", "wpb": "3529.6", "bsz": "142.6", "num_updates": "16400", "lr": "0.00493865", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "984"}
2023-12-13 21:44:29 | INFO | train_inner | {"epoch": 15, "update": 14.975, "loss": "4.536", "nll_loss": "3.178", "ppl": "9.05", "wps": "60890.3", "ups": "16.86", "wpb": "3612.1", "bsz": "139.5", "num_updates": "16500", "lr": "0.00492366", "gnorm": "0.258", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "990"}
2023-12-13 21:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:44:32 | INFO | valid | {"epoch": 15, "valid_loss": "4.464", "valid_nll_loss": "3.105", "valid_ppl": "8.6", "valid_wps": "127175", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "16527", "valid_best_loss": "4.464"}
2023-12-13 21:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16527 updates
2023-12-13 21:44:32 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint15.pt
2023-12-13 21:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint15.pt
2023-12-13 21:44:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint15.pt (epoch 15 @ 16527 updates, score 4.464) (writing took 0.20716434717178345 seconds)
2023-12-13 21:44:32 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-12-13 21:44:32 | INFO | train | {"epoch": 15, "train_loss": "4.5", "train_nll_loss": "3.135", "train_ppl": "8.79", "train_wps": "59911", "train_ups": "16.72", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "16527", "train_lr": "0.00491964", "train_gnorm": "0.263", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "993"}
2023-12-13 21:44:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:44:32 | INFO | fairseq.trainer | begin training epoch 16
2023-12-13 21:44:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:44:36 | INFO | train_inner | {"epoch": 16, "update": 15.066, "loss": "4.352", "nll_loss": "2.966", "ppl": "7.82", "wps": "54299", "ups": "15.11", "wpb": "3594.7", "bsz": "168.1", "num_updates": "16600", "lr": "0.00490881", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "996"}
2023-12-13 21:44:43 | INFO | train_inner | {"epoch": 16, "update": 15.157, "loss": "4.513", "nll_loss": "3.147", "ppl": "8.86", "wps": "50297.7", "ups": "14.41", "wpb": "3490", "bsz": "125.8", "num_updates": "16700", "lr": "0.00489409", "gnorm": "0.282", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "1003"}
2023-12-13 21:44:48 | INFO | train_inner | {"epoch": 16, "update": 15.248, "loss": "4.442", "nll_loss": "3.064", "ppl": "8.36", "wps": "59611.2", "ups": "16.84", "wpb": "3540.7", "bsz": "143.5", "num_updates": "16800", "lr": "0.0048795", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1009"}
2023-12-13 21:44:54 | INFO | train_inner | {"epoch": 16, "update": 15.338, "loss": "4.4", "nll_loss": "3.019", "ppl": "8.11", "wps": "65035.4", "ups": "17.9", "wpb": "3633.5", "bsz": "161.3", "num_updates": "16900", "lr": "0.00486504", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1015"}
2023-12-13 21:45:00 | INFO | train_inner | {"epoch": 16, "update": 15.429, "loss": "4.497", "nll_loss": "3.133", "ppl": "8.77", "wps": "60620.4", "ups": "16.89", "wpb": "3589.7", "bsz": "139.3", "num_updates": "17000", "lr": "0.00485071", "gnorm": "0.261", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1021"}
2023-12-13 21:45:06 | INFO | train_inner | {"epoch": 16, "update": 15.52, "loss": "4.532", "nll_loss": "3.172", "ppl": "9.01", "wps": "58140.7", "ups": "16.42", "wpb": "3540.2", "bsz": "130", "num_updates": "17100", "lr": "0.00483651", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1027"}
2023-12-13 21:45:12 | INFO | train_inner | {"epoch": 16, "update": 15.611, "loss": "4.525", "nll_loss": "3.164", "ppl": "8.97", "wps": "61797.4", "ups": "17.11", "wpb": "3610.8", "bsz": "135", "num_updates": "17200", "lr": "0.00482243", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1033"}
2023-12-13 21:45:17 | INFO | train_inner | {"epoch": 16, "update": 15.701, "loss": "4.468", "nll_loss": "3.101", "ppl": "8.58", "wps": "68442.4", "ups": "18.67", "wpb": "3665", "bsz": "155.2", "num_updates": "17300", "lr": "0.00480847", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1038"}
2023-12-13 21:45:23 | INFO | train_inner | {"epoch": 16, "update": 15.792, "loss": "4.5", "nll_loss": "3.137", "ppl": "8.8", "wps": "64112.5", "ups": "17.85", "wpb": "3592", "bsz": "152.4", "num_updates": "17400", "lr": "0.00479463", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1044"}
2023-12-13 21:45:29 | INFO | train_inner | {"epoch": 16, "update": 15.883, "loss": "4.56", "nll_loss": "3.208", "ppl": "9.24", "wps": "59291.9", "ups": "16.83", "wpb": "3522.4", "bsz": "146.4", "num_updates": "17500", "lr": "0.00478091", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1050"}
2023-12-13 21:45:34 | INFO | train_inner | {"epoch": 16, "update": 15.974, "loss": "4.506", "nll_loss": "3.146", "ppl": "8.85", "wps": "65590.1", "ups": "18.14", "wpb": "3615.5", "bsz": "143.6", "num_updates": "17600", "lr": "0.00476731", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1055"}
2023-12-13 21:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:45:38 | INFO | valid | {"epoch": 16, "valid_loss": "4.45", "valid_nll_loss": "3.106", "valid_ppl": "8.61", "valid_wps": "126963", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "17629", "valid_best_loss": "4.45"}
2023-12-13 21:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17629 updates
2023-12-13 21:45:38 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint16.pt
2023-12-13 21:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint16.pt
2023-12-13 21:45:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint16.pt (epoch 16 @ 17629 updates, score 4.45) (writing took 0.21388773433864117 seconds)
2023-12-13 21:45:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-12-13 21:45:38 | INFO | train | {"epoch": 16, "train_loss": "4.48", "train_nll_loss": "3.113", "train_ppl": "8.65", "train_wps": "59977", "train_ups": "16.74", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "17629", "train_lr": "0.00476339", "train_gnorm": "0.267", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1059"}
2023-12-13 21:45:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:45:38 | INFO | fairseq.trainer | begin training epoch 17
2023-12-13 21:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:45:42 | INFO | train_inner | {"epoch": 17, "update": 16.064, "loss": "4.401", "nll_loss": "3.021", "ppl": "8.12", "wps": "48570.3", "ups": "13.36", "wpb": "3634.7", "bsz": "151.4", "num_updates": "17700", "lr": "0.00475383", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1063"}
2023-12-13 21:45:48 | INFO | train_inner | {"epoch": 17, "update": 16.155, "loss": "4.477", "nll_loss": "3.105", "ppl": "8.61", "wps": "55777.6", "ups": "15.4", "wpb": "3621.9", "bsz": "112.6", "num_updates": "17800", "lr": "0.00474045", "gnorm": "0.261", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1069"}
2023-12-13 21:45:54 | INFO | train_inner | {"epoch": 17, "update": 16.246, "loss": "4.402", "nll_loss": "3.022", "ppl": "8.12", "wps": "59933", "ups": "16.74", "wpb": "3581.1", "bsz": "152.6", "num_updates": "17900", "lr": "0.00472719", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1075"}
2023-12-13 21:46:00 | INFO | train_inner | {"epoch": 17, "update": 16.337, "loss": "4.452", "nll_loss": "3.08", "ppl": "8.46", "wps": "57277", "ups": "16.22", "wpb": "3530.7", "bsz": "139.1", "num_updates": "18000", "lr": "0.00471405", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1081"}
2023-12-13 21:46:06 | INFO | train_inner | {"epoch": 17, "update": 16.427, "loss": "4.455", "nll_loss": "3.083", "ppl": "8.47", "wps": "59702.5", "ups": "16.64", "wpb": "3587.8", "bsz": "141.4", "num_updates": "18100", "lr": "0.004701", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1087"}
2023-12-13 21:46:13 | INFO | train_inner | {"epoch": 17, "update": 16.518, "loss": "4.509", "nll_loss": "3.146", "ppl": "8.85", "wps": "58623", "ups": "16.43", "wpb": "3567.2", "bsz": "135.6", "num_updates": "18200", "lr": "0.00468807", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1093"}
2023-12-13 21:46:18 | INFO | train_inner | {"epoch": 17, "update": 16.609, "loss": "4.404", "nll_loss": "3.028", "ppl": "8.16", "wps": "68395.9", "ups": "18.76", "wpb": "3645.8", "bsz": "164", "num_updates": "18300", "lr": "0.00467525", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1099"}
2023-12-13 21:46:24 | INFO | train_inner | {"epoch": 17, "update": 16.7, "loss": "4.492", "nll_loss": "3.129", "ppl": "8.75", "wps": "60985", "ups": "16.97", "wpb": "3594.4", "bsz": "133.8", "num_updates": "18400", "lr": "0.00466252", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1105"}
2023-12-13 21:46:29 | INFO | train_inner | {"epoch": 17, "update": 16.79, "loss": "4.405", "nll_loss": "3.029", "ppl": "8.16", "wps": "65365.7", "ups": "18.53", "wpb": "3527.9", "bsz": "167.2", "num_updates": "18500", "lr": "0.00464991", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1110"}
2023-12-13 21:46:35 | INFO | train_inner | {"epoch": 17, "update": 16.881, "loss": "4.47", "nll_loss": "3.106", "ppl": "8.61", "wps": "65847.3", "ups": "18.42", "wpb": "3575", "bsz": "155.3", "num_updates": "18600", "lr": "0.00463739", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1115"}
2023-12-13 21:46:40 | INFO | train_inner | {"epoch": 17, "update": 16.972, "loss": "4.507", "nll_loss": "3.147", "ppl": "8.86", "wps": "63577.1", "ups": "17.83", "wpb": "3564.9", "bsz": "144", "num_updates": "18700", "lr": "0.00462497", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1121"}
2023-12-13 21:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:46:43 | INFO | valid | {"epoch": 17, "valid_loss": "4.43", "valid_nll_loss": "3.083", "valid_ppl": "8.47", "valid_wps": "128347", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "18731", "valid_best_loss": "4.43"}
2023-12-13 21:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18731 updates
2023-12-13 21:46:43 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint17.pt
2023-12-13 21:46:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint17.pt
2023-12-13 21:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint17.pt (epoch 17 @ 18731 updates, score 4.43) (writing took 0.20971453189849854 seconds)
2023-12-13 21:46:44 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-12-13 21:46:44 | INFO | train | {"epoch": 17, "train_loss": "4.452", "train_nll_loss": "3.081", "train_ppl": "8.46", "train_wps": "60163.1", "train_ups": "16.79", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "18731", "train_lr": "0.00462114", "train_gnorm": "0.263", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1124"}
2023-12-13 21:46:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:46:44 | INFO | fairseq.trainer | begin training epoch 18
2023-12-13 21:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:46:48 | INFO | train_inner | {"epoch": 18, "update": 17.063, "loss": "4.364", "nll_loss": "2.979", "ppl": "7.89", "wps": "46821.5", "ups": "13.21", "wpb": "3544.1", "bsz": "147", "num_updates": "18800", "lr": "0.00461266", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1129"}
2023-12-13 21:46:54 | INFO | train_inner | {"epoch": 18, "update": 17.153, "loss": "4.384", "nll_loss": "3.001", "ppl": "8.01", "wps": "56686.8", "ups": "15.94", "wpb": "3555.6", "bsz": "139.6", "num_updates": "18900", "lr": "0.00460044", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1135"}
2023-12-13 21:46:59 | INFO | train_inner | {"epoch": 18, "update": 17.244, "loss": "4.277", "nll_loss": "2.883", "ppl": "7.38", "wps": "76055.9", "ups": "20.77", "wpb": "3661.2", "bsz": "187", "num_updates": "19000", "lr": "0.00458831", "gnorm": "0.249", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1140"}
2023-12-13 21:47:05 | INFO | train_inner | {"epoch": 18, "update": 17.335, "loss": "4.461", "nll_loss": "3.091", "ppl": "8.52", "wps": "55641.6", "ups": "15.62", "wpb": "3562.5", "bsz": "135", "num_updates": "19100", "lr": "0.00457629", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1146"}
2023-12-13 21:47:11 | INFO | train_inner | {"epoch": 18, "update": 17.426, "loss": "4.458", "nll_loss": "3.087", "ppl": "8.5", "wps": "59683.9", "ups": "16.58", "wpb": "3600.3", "bsz": "130.4", "num_updates": "19200", "lr": "0.00456435", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1152"}
2023-12-13 21:47:17 | INFO | train_inner | {"epoch": 18, "update": 17.516, "loss": "4.431", "nll_loss": "3.06", "ppl": "8.34", "wps": "61644.2", "ups": "17.18", "wpb": "3588.8", "bsz": "151.3", "num_updates": "19300", "lr": "0.00455251", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1158"}
2023-12-13 21:47:23 | INFO | train_inner | {"epoch": 18, "update": 17.607, "loss": "4.456", "nll_loss": "3.087", "ppl": "8.5", "wps": "64797.4", "ups": "18.02", "wpb": "3595.9", "bsz": "142.1", "num_updates": "19400", "lr": "0.00454077", "gnorm": "0.263", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1164"}
2023-12-13 21:47:28 | INFO | train_inner | {"epoch": 18, "update": 17.698, "loss": "4.435", "nll_loss": "3.064", "ppl": "8.36", "wps": "63169", "ups": "17.32", "wpb": "3648.1", "bsz": "148.6", "num_updates": "19500", "lr": "0.00452911", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1169"}
2023-12-13 21:47:34 | INFO | train_inner | {"epoch": 18, "update": 17.789, "loss": "4.486", "nll_loss": "3.12", "ppl": "8.69", "wps": "57993.7", "ups": "16.51", "wpb": "3513.3", "bsz": "130.7", "num_updates": "19600", "lr": "0.00451754", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1175"}
2023-12-13 21:47:40 | INFO | train_inner | {"epoch": 18, "update": 17.879, "loss": "4.491", "nll_loss": "3.13", "ppl": "8.76", "wps": "59959.9", "ups": "16.96", "wpb": "3535.9", "bsz": "146.4", "num_updates": "19700", "lr": "0.00450606", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1181"}
2023-12-13 21:47:46 | INFO | train_inner | {"epoch": 18, "update": 17.97, "loss": "4.468", "nll_loss": "3.104", "ppl": "8.6", "wps": "60677.8", "ups": "16.71", "wpb": "3630.6", "bsz": "142.3", "num_updates": "19800", "lr": "0.00449467", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1187"}
2023-12-13 21:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:47:50 | INFO | valid | {"epoch": 18, "valid_loss": "4.417", "valid_nll_loss": "3.067", "valid_ppl": "8.38", "valid_wps": "124402", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "19833", "valid_best_loss": "4.417"}
2023-12-13 21:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19833 updates
2023-12-13 21:47:50 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint18.pt
2023-12-13 21:47:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint18.pt
2023-12-13 21:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint18.pt (epoch 18 @ 19833 updates, score 4.417) (writing took 0.2476479997858405 seconds)
2023-12-13 21:47:50 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-12-13 21:47:50 | INFO | train | {"epoch": 18, "train_loss": "4.427", "train_nll_loss": "3.054", "train_ppl": "8.3", "train_wps": "59436.9", "train_ups": "16.59", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "19833", "train_lr": "0.00449092", "train_gnorm": "0.265", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1191"}
2023-12-13 21:47:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:47:50 | INFO | fairseq.trainer | begin training epoch 19
2023-12-13 21:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:47:55 | INFO | train_inner | {"epoch": 19, "update": 18.061, "loss": "4.418", "nll_loss": "3.041", "ppl": "8.23", "wps": "42413.8", "ups": "12.02", "wpb": "3527.3", "bsz": "124.8", "num_updates": "19900", "lr": "0.00448336", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1196"}
2023-12-13 21:48:01 | INFO | train_inner | {"epoch": 19, "update": 18.152, "loss": "4.379", "nll_loss": "2.995", "ppl": "7.97", "wps": "55172.9", "ups": "15.7", "wpb": "3515.2", "bsz": "133.8", "num_updates": "20000", "lr": "0.00447214", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1202"}
2023-12-13 21:48:07 | INFO | train_inner | {"epoch": 19, "update": 18.242, "loss": "4.344", "nll_loss": "2.955", "ppl": "7.75", "wps": "62583.4", "ups": "17.39", "wpb": "3599.5", "bsz": "140.2", "num_updates": "20100", "lr": "0.004461", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1208"}
2023-12-13 21:48:12 | INFO | train_inner | {"epoch": 19, "update": 18.333, "loss": "4.347", "nll_loss": "2.963", "ppl": "7.8", "wps": "74562.2", "ups": "20.56", "wpb": "3626.3", "bsz": "161.4", "num_updates": "20200", "lr": "0.00444994", "gnorm": "0.256", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1213"}
2023-12-13 21:48:17 | INFO | train_inner | {"epoch": 19, "update": 18.424, "loss": "4.447", "nll_loss": "3.078", "ppl": "8.44", "wps": "64802.3", "ups": "18.06", "wpb": "3587.9", "bsz": "142.2", "num_updates": "20300", "lr": "0.00443897", "gnorm": "0.268", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1218"}
2023-12-13 21:48:23 | INFO | train_inner | {"epoch": 19, "update": 18.515, "loss": "4.426", "nll_loss": "3.053", "ppl": "8.3", "wps": "64642.6", "ups": "17.66", "wpb": "3661", "bsz": "149.6", "num_updates": "20400", "lr": "0.00442807", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1224"}
2023-12-13 21:48:29 | INFO | train_inner | {"epoch": 19, "update": 18.605, "loss": "4.406", "nll_loss": "3.031", "ppl": "8.18", "wps": "62769.1", "ups": "17.33", "wpb": "3622.2", "bsz": "151.7", "num_updates": "20500", "lr": "0.00441726", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1229"}
2023-12-13 21:48:35 | INFO | train_inner | {"epoch": 19, "update": 18.696, "loss": "4.462", "nll_loss": "3.097", "ppl": "8.56", "wps": "55626.2", "ups": "15.76", "wpb": "3529.2", "bsz": "139", "num_updates": "20600", "lr": "0.00440653", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1236"}
2023-12-13 21:48:42 | INFO | train_inner | {"epoch": 19, "update": 18.787, "loss": "4.48", "nll_loss": "3.114", "ppl": "8.66", "wps": "52998.9", "ups": "15.08", "wpb": "3513.4", "bsz": "137", "num_updates": "20700", "lr": "0.00439587", "gnorm": "0.298", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "1242"}
2023-12-13 21:48:47 | INFO | train_inner | {"epoch": 19, "update": 18.877, "loss": "4.407", "nll_loss": "3.033", "ppl": "8.18", "wps": "63606.9", "ups": "17.65", "wpb": "3603.8", "bsz": "156.9", "num_updates": "20800", "lr": "0.00438529", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1248"}
2023-12-13 21:48:52 | INFO | train_inner | {"epoch": 19, "update": 18.968, "loss": "4.385", "nll_loss": "3.009", "ppl": "8.05", "wps": "69846.6", "ups": "19.24", "wpb": "3629.4", "bsz": "157.3", "num_updates": "20900", "lr": "0.00437479", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1253"}
2023-12-13 21:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:48:56 | INFO | valid | {"epoch": 19, "valid_loss": "4.421", "valid_nll_loss": "3.076", "valid_ppl": "8.44", "valid_wps": "127254", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "20935", "valid_best_loss": "4.417"}
2023-12-13 21:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20935 updates
2023-12-13 21:48:56 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint19.pt
2023-12-13 21:48:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint19.pt
2023-12-13 21:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint19.pt (epoch 19 @ 20935 updates, score 4.421) (writing took 0.14847095776349306 seconds)
2023-12-13 21:48:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-12-13 21:48:56 | INFO | train | {"epoch": 19, "train_loss": "4.407", "train_nll_loss": "3.031", "train_ppl": "8.17", "train_wps": "59798", "train_ups": "16.69", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "20935", "train_lr": "0.00437113", "train_gnorm": "0.266", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1257"}
2023-12-13 21:48:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:48:56 | INFO | fairseq.trainer | begin training epoch 20
2023-12-13 21:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:49:00 | INFO | train_inner | {"epoch": 20, "update": 19.059, "loss": "4.348", "nll_loss": "2.964", "ppl": "7.8", "wps": "46854.8", "ups": "13.17", "wpb": "3558.8", "bsz": "147.5", "num_updates": "21000", "lr": "0.00436436", "gnorm": "0.26", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1261"}
2023-12-13 21:49:06 | INFO | train_inner | {"epoch": 20, "update": 19.15, "loss": "4.302", "nll_loss": "2.908", "ppl": "7.51", "wps": "65033.3", "ups": "17.88", "wpb": "3636.3", "bsz": "146.8", "num_updates": "21100", "lr": "0.004354", "gnorm": "0.254", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1267"}
2023-12-13 21:49:12 | INFO | train_inner | {"epoch": 20, "update": 19.24, "loss": "4.378", "nll_loss": "2.996", "ppl": "7.98", "wps": "58754.6", "ups": "16.64", "wpb": "3531.2", "bsz": "138.7", "num_updates": "21200", "lr": "0.00434372", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1273"}
2023-12-13 21:49:17 | INFO | train_inner | {"epoch": 20, "update": 19.331, "loss": "4.345", "nll_loss": "2.96", "ppl": "7.78", "wps": "63011.8", "ups": "17.34", "wpb": "3633.6", "bsz": "148.6", "num_updates": "21300", "lr": "0.00433351", "gnorm": "0.253", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1278"}
2023-12-13 21:49:23 | INFO | train_inner | {"epoch": 20, "update": 19.422, "loss": "4.359", "nll_loss": "2.976", "ppl": "7.87", "wps": "62994.3", "ups": "17.37", "wpb": "3625.9", "bsz": "144", "num_updates": "21400", "lr": "0.00432338", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1284"}
2023-12-13 21:49:29 | INFO | train_inner | {"epoch": 20, "update": 19.513, "loss": "4.387", "nll_loss": "3.01", "ppl": "8.06", "wps": "65900.3", "ups": "18.18", "wpb": "3624.8", "bsz": "149.4", "num_updates": "21500", "lr": "0.00431331", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1290"}
2023-12-13 21:49:34 | INFO | train_inner | {"epoch": 20, "update": 19.603, "loss": "4.406", "nll_loss": "3.031", "ppl": "8.18", "wps": "61958", "ups": "17.7", "wpb": "3501", "bsz": "146.6", "num_updates": "21600", "lr": "0.00430331", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1295"}
2023-12-13 21:49:40 | INFO | train_inner | {"epoch": 20, "update": 19.694, "loss": "4.403", "nll_loss": "3.028", "ppl": "8.16", "wps": "63618.3", "ups": "17.49", "wpb": "3637.7", "bsz": "154.4", "num_updates": "21700", "lr": "0.00429339", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1301"}
2023-12-13 21:49:46 | INFO | train_inner | {"epoch": 20, "update": 19.785, "loss": "4.397", "nll_loss": "3.021", "ppl": "8.12", "wps": "64681.3", "ups": "17.83", "wpb": "3627.8", "bsz": "143.4", "num_updates": "21800", "lr": "0.00428353", "gnorm": "0.25", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1307"}
2023-12-13 21:49:52 | INFO | train_inner | {"epoch": 20, "update": 19.876, "loss": "4.45", "nll_loss": "3.083", "ppl": "8.48", "wps": "59789.7", "ups": "17.03", "wpb": "3509.8", "bsz": "145.7", "num_updates": "21900", "lr": "0.00427374", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1312"}
2023-12-13 21:49:57 | INFO | train_inner | {"epoch": 20, "update": 19.966, "loss": "4.416", "nll_loss": "3.043", "ppl": "8.24", "wps": "62683", "ups": "17.5", "wpb": "3582", "bsz": "150.2", "num_updates": "22000", "lr": "0.00426401", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1318"}
2023-12-13 21:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:50:01 | INFO | valid | {"epoch": 20, "valid_loss": "4.408", "valid_nll_loss": "3.055", "valid_ppl": "8.31", "valid_wps": "129653", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "22037", "valid_best_loss": "4.408"}
2023-12-13 21:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 22037 updates
2023-12-13 21:50:01 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint20.pt
2023-12-13 21:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint20.pt
2023-12-13 21:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint20.pt (epoch 20 @ 22037 updates, score 4.408) (writing took 0.21678343880921602 seconds)
2023-12-13 21:50:01 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-12-13 21:50:01 | INFO | train | {"epoch": 20, "train_loss": "4.386", "train_nll_loss": "3.008", "train_ppl": "8.04", "train_wps": "60334.7", "train_ups": "16.84", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "22037", "train_lr": "0.00426043", "train_gnorm": "0.265", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1322"}
2023-12-13 21:50:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:50:02 | INFO | fairseq.trainer | begin training epoch 21
2023-12-13 21:50:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:50:05 | INFO | train_inner | {"epoch": 21, "update": 20.057, "loss": "4.414", "nll_loss": "3.038", "ppl": "8.21", "wps": "44030.8", "ups": "12.37", "wpb": "3559.9", "bsz": "127.2", "num_updates": "22100", "lr": "0.00425436", "gnorm": "0.3", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1326"}
2023-12-13 21:50:11 | INFO | train_inner | {"epoch": 21, "update": 20.148, "loss": "4.249", "nll_loss": "2.848", "ppl": "7.2", "wps": "68034.6", "ups": "18.88", "wpb": "3602.7", "bsz": "154.5", "num_updates": "22200", "lr": "0.00424476", "gnorm": "0.256", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1331"}
2023-12-13 21:50:16 | INFO | train_inner | {"epoch": 21, "update": 20.239, "loss": "4.356", "nll_loss": "2.973", "ppl": "7.85", "wps": "64829.9", "ups": "17.93", "wpb": "3616.2", "bsz": "146.4", "num_updates": "22300", "lr": "0.00423524", "gnorm": "0.263", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1337"}
2023-12-13 21:50:22 | INFO | train_inner | {"epoch": 21, "update": 20.329, "loss": "4.339", "nll_loss": "2.954", "ppl": "7.75", "wps": "66559.2", "ups": "18.52", "wpb": "3593.1", "bsz": "152.1", "num_updates": "22400", "lr": "0.00422577", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1342"}
2023-12-13 21:50:28 | INFO | train_inner | {"epoch": 21, "update": 20.42, "loss": "4.38", "nll_loss": "2.999", "ppl": "8", "wps": "60248.4", "ups": "16.77", "wpb": "3592.1", "bsz": "137.4", "num_updates": "22500", "lr": "0.00421637", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1348"}
2023-12-13 21:50:33 | INFO | train_inner | {"epoch": 21, "update": 20.511, "loss": "4.381", "nll_loss": "3.001", "ppl": "8.01", "wps": "62587.7", "ups": "17.58", "wpb": "3559.7", "bsz": "144", "num_updates": "22600", "lr": "0.00420703", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1354"}
2023-12-13 21:50:39 | INFO | train_inner | {"epoch": 21, "update": 20.602, "loss": "4.412", "nll_loss": "3.037", "ppl": "8.21", "wps": "59642.5", "ups": "16.66", "wpb": "3580.6", "bsz": "134.6", "num_updates": "22700", "lr": "0.00419775", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1360"}
2023-12-13 21:50:45 | INFO | train_inner | {"epoch": 21, "update": 20.692, "loss": "4.421", "nll_loss": "3.048", "ppl": "8.27", "wps": "61814.1", "ups": "17.25", "wpb": "3582.7", "bsz": "135", "num_updates": "22800", "lr": "0.00418854", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1366"}
2023-12-13 21:50:51 | INFO | train_inner | {"epoch": 21, "update": 20.783, "loss": "4.324", "nll_loss": "2.94", "ppl": "7.67", "wps": "65901.5", "ups": "18.34", "wpb": "3593.6", "bsz": "167.1", "num_updates": "22900", "lr": "0.00417938", "gnorm": "0.26", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1371"}
2023-12-13 21:50:57 | INFO | train_inner | {"epoch": 21, "update": 20.874, "loss": "4.41", "nll_loss": "3.038", "ppl": "8.21", "wps": "59793.1", "ups": "16.53", "wpb": "3617.3", "bsz": "144.9", "num_updates": "23000", "lr": "0.00417029", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1377"}
2023-12-13 21:51:03 | INFO | train_inner | {"epoch": 21, "update": 20.965, "loss": "4.439", "nll_loss": "3.072", "ppl": "8.41", "wps": "54271.3", "ups": "15.42", "wpb": "3520.2", "bsz": "141.6", "num_updates": "23100", "lr": "0.00416125", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1384"}
2023-12-13 21:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:51:07 | INFO | valid | {"epoch": 21, "valid_loss": "4.401", "valid_nll_loss": "3.048", "valid_ppl": "8.27", "valid_wps": "123068", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "23139", "valid_best_loss": "4.401"}
2023-12-13 21:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 23139 updates
2023-12-13 21:51:07 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint21.pt
2023-12-13 21:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint21.pt
2023-12-13 21:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint21.pt (epoch 21 @ 23139 updates, score 4.401) (writing took 0.22273851186037064 seconds)
2023-12-13 21:51:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-12-13 21:51:07 | INFO | train | {"epoch": 21, "train_loss": "4.369", "train_nll_loss": "2.989", "train_ppl": "7.94", "train_wps": "60039.2", "train_ups": "16.75", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "23139", "train_lr": "0.00415774", "train_gnorm": "0.269", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1388"}
2023-12-13 21:51:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:51:07 | INFO | fairseq.trainer | begin training epoch 22
2023-12-13 21:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:51:11 | INFO | train_inner | {"epoch": 22, "update": 21.055, "loss": "4.324", "nll_loss": "2.935", "ppl": "7.65", "wps": "40659.7", "ups": "11.95", "wpb": "3401.9", "bsz": "141.6", "num_updates": "23200", "lr": "0.00415227", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1392"}
2023-12-13 21:51:17 | INFO | train_inner | {"epoch": 22, "update": 21.146, "loss": "4.273", "nll_loss": "2.877", "ppl": "7.34", "wps": "65305.4", "ups": "18.29", "wpb": "3570.7", "bsz": "155.8", "num_updates": "23300", "lr": "0.00414335", "gnorm": "0.268", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1398"}
2023-12-13 21:51:23 | INFO | train_inner | {"epoch": 22, "update": 21.237, "loss": "4.298", "nll_loss": "2.904", "ppl": "7.49", "wps": "59813.4", "ups": "16.92", "wpb": "3535.3", "bsz": "139.8", "num_updates": "23400", "lr": "0.00413449", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1404"}
2023-12-13 21:51:28 | INFO | train_inner | {"epoch": 22, "update": 21.328, "loss": "4.272", "nll_loss": "2.877", "ppl": "7.34", "wps": "65311.7", "ups": "17.93", "wpb": "3641.9", "bsz": "157.5", "num_updates": "23500", "lr": "0.00412568", "gnorm": "0.26", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1409"}
2023-12-13 21:51:34 | INFO | train_inner | {"epoch": 22, "update": 21.418, "loss": "4.357", "nll_loss": "2.975", "ppl": "7.86", "wps": "59573.9", "ups": "16.44", "wpb": "3622.6", "bsz": "147.1", "num_updates": "23600", "lr": "0.00411693", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1415"}
2023-12-13 21:51:40 | INFO | train_inner | {"epoch": 22, "update": 21.509, "loss": "4.335", "nll_loss": "2.95", "ppl": "7.73", "wps": "67783.2", "ups": "18.63", "wpb": "3638.7", "bsz": "144.9", "num_updates": "23700", "lr": "0.00410824", "gnorm": "0.267", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1421"}
2023-12-13 21:51:46 | INFO | train_inner | {"epoch": 22, "update": 21.6, "loss": "4.45", "nll_loss": "3.083", "ppl": "8.47", "wps": "56078", "ups": "16.12", "wpb": "3479.4", "bsz": "127.3", "num_updates": "23800", "lr": "0.0040996", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1427"}
2023-12-13 21:51:52 | INFO | train_inner | {"epoch": 22, "update": 21.691, "loss": "4.362", "nll_loss": "2.982", "ppl": "7.9", "wps": "65249.8", "ups": "18.04", "wpb": "3616.1", "bsz": "153.4", "num_updates": "23900", "lr": "0.00409101", "gnorm": "0.266", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1432"}
2023-12-13 21:51:57 | INFO | train_inner | {"epoch": 22, "update": 21.781, "loss": "4.354", "nll_loss": "2.974", "ppl": "7.86", "wps": "66974.1", "ups": "18.37", "wpb": "3645.8", "bsz": "152.1", "num_updates": "24000", "lr": "0.00408248", "gnorm": "0.257", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1438"}
2023-12-13 21:52:03 | INFO | train_inner | {"epoch": 22, "update": 21.872, "loss": "4.397", "nll_loss": "3.024", "ppl": "8.14", "wps": "61492.8", "ups": "16.95", "wpb": "3627.5", "bsz": "143.8", "num_updates": "24100", "lr": "0.004074", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1444"}
2023-12-13 21:52:09 | INFO | train_inner | {"epoch": 22, "update": 21.963, "loss": "4.447", "nll_loss": "3.081", "ppl": "8.46", "wps": "58417.9", "ups": "16.37", "wpb": "3567.6", "bsz": "137.4", "num_updates": "24200", "lr": "0.00406558", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1450"}
2023-12-13 21:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:52:13 | INFO | valid | {"epoch": 22, "valid_loss": "4.383", "valid_nll_loss": "3.038", "valid_ppl": "8.21", "valid_wps": "125262", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "24241", "valid_best_loss": "4.383"}
2023-12-13 21:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 24241 updates
2023-12-13 21:52:13 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint22.pt
2023-12-13 21:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint22.pt
2023-12-13 21:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint22.pt (epoch 22 @ 24241 updates, score 4.383) (writing took 0.21473494451493025 seconds)
2023-12-13 21:52:13 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-12-13 21:52:13 | INFO | train | {"epoch": 22, "train_loss": "4.35", "train_nll_loss": "2.968", "train_ppl": "7.82", "train_wps": "60017.5", "train_ups": "16.75", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "24241", "train_lr": "0.00406214", "train_gnorm": "0.268", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "1454"}
2023-12-13 21:52:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:52:13 | INFO | fairseq.trainer | begin training epoch 23
2023-12-13 21:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:52:16 | INFO | train_inner | {"epoch": 23, "update": 22.054, "loss": "4.228", "nll_loss": "2.828", "ppl": "7.1", "wps": "52802.6", "ups": "14.62", "wpb": "3611.1", "bsz": "168.2", "num_updates": "24300", "lr": "0.0040572", "gnorm": "0.248", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1457"}
2023-12-13 21:52:21 | INFO | train_inner | {"epoch": 23, "update": 22.144, "loss": "4.237", "nll_loss": "2.837", "ppl": "7.14", "wps": "66875.3", "ups": "18.44", "wpb": "3627.4", "bsz": "155.7", "num_updates": "24400", "lr": "0.00404888", "gnorm": "0.263", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1462"}
2023-12-13 21:52:27 | INFO | train_inner | {"epoch": 23, "update": 22.235, "loss": "4.293", "nll_loss": "2.899", "ppl": "7.46", "wps": "60021.6", "ups": "16.82", "wpb": "3567.8", "bsz": "146.3", "num_updates": "24500", "lr": "0.00404061", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1468"}
2023-12-13 21:52:34 | INFO | train_inner | {"epoch": 23, "update": 22.326, "loss": "4.359", "nll_loss": "2.977", "ppl": "7.87", "wps": "57411.2", "ups": "15.92", "wpb": "3605.2", "bsz": "139.4", "num_updates": "24600", "lr": "0.00403239", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1474"}
2023-12-13 21:52:39 | INFO | train_inner | {"epoch": 23, "update": 22.417, "loss": "4.332", "nll_loss": "2.945", "ppl": "7.7", "wps": "59814.7", "ups": "16.77", "wpb": "3567.4", "bsz": "140.1", "num_updates": "24700", "lr": "0.00402422", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1480"}
2023-12-13 21:52:45 | INFO | train_inner | {"epoch": 23, "update": 22.507, "loss": "4.323", "nll_loss": "2.936", "ppl": "7.65", "wps": "64666.6", "ups": "17.83", "wpb": "3626.8", "bsz": "144.6", "num_updates": "24800", "lr": "0.0040161", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1486"}
2023-12-13 21:52:51 | INFO | train_inner | {"epoch": 23, "update": 22.598, "loss": "4.416", "nll_loss": "3.043", "ppl": "8.24", "wps": "62825.3", "ups": "17.65", "wpb": "3560.4", "bsz": "143", "num_updates": "24900", "lr": "0.00400802", "gnorm": "0.327", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1492"}
2023-12-13 21:52:57 | INFO | train_inner | {"epoch": 23, "update": 22.689, "loss": "4.388", "nll_loss": "3.015", "ppl": "8.08", "wps": "58734.8", "ups": "16.6", "wpb": "3538.8", "bsz": "134.5", "num_updates": "25000", "lr": "0.004", "gnorm": "0.263", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1498"}
2023-12-13 21:53:02 | INFO | train_inner | {"epoch": 23, "update": 22.779, "loss": "4.361", "nll_loss": "2.981", "ppl": "7.89", "wps": "64275.4", "ups": "17.86", "wpb": "3598.6", "bsz": "149", "num_updates": "25100", "lr": "0.00399202", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1503"}
2023-12-13 21:53:08 | INFO | train_inner | {"epoch": 23, "update": 22.87, "loss": "4.427", "nll_loss": "3.058", "ppl": "8.33", "wps": "58110.4", "ups": "16.4", "wpb": "3543.5", "bsz": "133.8", "num_updates": "25200", "lr": "0.0039841", "gnorm": "0.287", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1509"}
2023-12-13 21:53:14 | INFO | train_inner | {"epoch": 23, "update": 22.961, "loss": "4.396", "nll_loss": "3.021", "ppl": "8.12", "wps": "63070.4", "ups": "17.56", "wpb": "3590.9", "bsz": "140.2", "num_updates": "25300", "lr": "0.00397621", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1515"}
2023-12-13 21:53:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:53:18 | INFO | valid | {"epoch": 23, "valid_loss": "4.397", "valid_nll_loss": "3.044", "valid_ppl": "8.24", "valid_wps": "129359", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "25343", "valid_best_loss": "4.383"}
2023-12-13 21:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 25343 updates
2023-12-13 21:53:18 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint23.pt
2023-12-13 21:53:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint23.pt
2023-12-13 21:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint23.pt (epoch 23 @ 25343 updates, score 4.397) (writing took 0.147972134873271 seconds)
2023-12-13 21:53:18 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-12-13 21:53:18 | INFO | train | {"epoch": 23, "train_loss": "4.339", "train_nll_loss": "2.956", "train_ppl": "7.76", "train_wps": "60702.9", "train_ups": "16.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "25343", "train_lr": "0.00397284", "train_gnorm": "0.273", "train_loss_scale": "32", "train_train_wall": "62", "train_gb_free": "38.9", "train_wall": "1519"}
2023-12-13 21:53:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:53:18 | INFO | fairseq.trainer | begin training epoch 24
2023-12-13 21:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:53:22 | INFO | train_inner | {"epoch": 24, "update": 23.052, "loss": "4.268", "nll_loss": "2.873", "ppl": "7.33", "wps": "46513", "ups": "13.08", "wpb": "3555.1", "bsz": "155", "num_updates": "25400", "lr": "0.00396838", "gnorm": "0.274", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1523"}
2023-12-13 21:53:28 | INFO | train_inner | {"epoch": 24, "update": 23.142, "loss": "4.286", "nll_loss": "2.892", "ppl": "7.42", "wps": "56593.7", "ups": "15.77", "wpb": "3587.8", "bsz": "135.4", "num_updates": "25500", "lr": "0.00396059", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1529"}
2023-12-13 21:53:34 | INFO | train_inner | {"epoch": 24, "update": 23.233, "loss": "4.325", "nll_loss": "2.936", "ppl": "7.65", "wps": "57314.7", "ups": "16.07", "wpb": "3565.9", "bsz": "137", "num_updates": "25600", "lr": "0.00395285", "gnorm": "0.279", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1535"}
2023-12-13 21:53:40 | INFO | train_inner | {"epoch": 24, "update": 23.324, "loss": "4.303", "nll_loss": "2.914", "ppl": "7.53", "wps": "60790.8", "ups": "16.74", "wpb": "3631.9", "bsz": "139.8", "num_updates": "25700", "lr": "0.00394515", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1541"}
2023-12-13 21:53:46 | INFO | train_inner | {"epoch": 24, "update": 23.415, "loss": "4.274", "nll_loss": "2.881", "ppl": "7.37", "wps": "66720.9", "ups": "18.64", "wpb": "3579.6", "bsz": "157.5", "num_updates": "25800", "lr": "0.0039375", "gnorm": "0.265", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1547"}
2023-12-13 21:53:51 | INFO | train_inner | {"epoch": 24, "update": 23.505, "loss": "4.283", "nll_loss": "2.893", "ppl": "7.43", "wps": "64394", "ups": "18.08", "wpb": "3561.5", "bsz": "159.5", "num_updates": "25900", "lr": "0.00392989", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "1552"}
2023-12-13 21:53:58 | INFO | train_inner | {"epoch": 24, "update": 23.596, "loss": "4.309", "nll_loss": "2.921", "ppl": "7.57", "wps": "55167.5", "ups": "15.56", "wpb": "3544.8", "bsz": "150.1", "num_updates": "26000", "lr": "0.00392232", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1559"}
2023-12-13 21:54:03 | INFO | train_inner | {"epoch": 24, "update": 23.687, "loss": "4.362", "nll_loss": "2.983", "ppl": "7.9", "wps": "64399.7", "ups": "18.15", "wpb": "3547.7", "bsz": "140.2", "num_updates": "26100", "lr": "0.0039148", "gnorm": "0.27", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1564"}
2023-12-13 21:54:10 | INFO | train_inner | {"epoch": 24, "update": 23.778, "loss": "4.369", "nll_loss": "2.992", "ppl": "7.95", "wps": "54765.2", "ups": "15.27", "wpb": "3585.8", "bsz": "140.8", "num_updates": "26200", "lr": "0.00390732", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1571"}
2023-12-13 21:54:15 | INFO | train_inner | {"epoch": 24, "update": 23.868, "loss": "4.359", "nll_loss": "2.981", "ppl": "7.89", "wps": "65514.2", "ups": "18.07", "wpb": "3625.6", "bsz": "144.9", "num_updates": "26300", "lr": "0.00389989", "gnorm": "0.264", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1576"}
2023-12-13 21:54:21 | INFO | train_inner | {"epoch": 24, "update": 23.959, "loss": "4.351", "nll_loss": "2.973", "ppl": "7.85", "wps": "63177.5", "ups": "17.26", "wpb": "3660.5", "bsz": "150.6", "num_updates": "26400", "lr": "0.00389249", "gnorm": "0.261", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1582"}
2023-12-13 21:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:54:25 | INFO | valid | {"epoch": 24, "valid_loss": "4.366", "valid_nll_loss": "3.009", "valid_ppl": "8.05", "valid_wps": "128694", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "26445", "valid_best_loss": "4.366"}
2023-12-13 21:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 26445 updates
2023-12-13 21:54:25 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint24.pt
2023-12-13 21:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint24.pt
2023-12-13 21:54:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint24.pt (epoch 24 @ 26445 updates, score 4.366) (writing took 0.21388635225594044 seconds)
2023-12-13 21:54:26 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-12-13 21:54:26 | INFO | train | {"epoch": 24, "train_loss": "4.323", "train_nll_loss": "2.937", "train_ppl": "7.66", "train_wps": "58523.3", "train_ups": "16.33", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "26445", "train_lr": "0.00388918", "train_gnorm": "0.269", "train_loss_scale": "32", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "1586"}
2023-12-13 21:54:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:54:26 | INFO | fairseq.trainer | begin training epoch 25
2023-12-13 21:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:54:29 | INFO | train_inner | {"epoch": 25, "update": 24.05, "loss": "4.303", "nll_loss": "2.913", "ppl": "7.53", "wps": "44060.4", "ups": "12.37", "wpb": "3562", "bsz": "136.3", "num_updates": "26500", "lr": "0.00388514", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1590"}
2023-12-13 21:54:35 | INFO | train_inner | {"epoch": 25, "update": 24.141, "loss": "4.213", "nll_loss": "2.81", "ppl": "7.01", "wps": "64949", "ups": "18.06", "wpb": "3596.4", "bsz": "149.8", "num_updates": "26600", "lr": "0.00387783", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1596"}
2023-12-13 21:54:40 | INFO | train_inner | {"epoch": 25, "update": 24.231, "loss": "4.248", "nll_loss": "2.85", "ppl": "7.21", "wps": "68708.5", "ups": "19.09", "wpb": "3598.5", "bsz": "155.5", "num_updates": "26700", "lr": "0.00387056", "gnorm": "0.274", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1601"}
2023-12-13 21:54:46 | INFO | train_inner | {"epoch": 25, "update": 24.322, "loss": "4.258", "nll_loss": "2.862", "ppl": "7.27", "wps": "57377.2", "ups": "16.22", "wpb": "3537.8", "bsz": "143.8", "num_updates": "26800", "lr": "0.00386334", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1607"}
2023-12-13 21:54:52 | INFO | train_inner | {"epoch": 25, "update": 24.413, "loss": "4.316", "nll_loss": "2.929", "ppl": "7.62", "wps": "62790", "ups": "17.42", "wpb": "3603.9", "bsz": "135.4", "num_updates": "26900", "lr": "0.00385615", "gnorm": "0.264", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1613"}
2023-12-13 21:54:58 | INFO | train_inner | {"epoch": 25, "update": 24.504, "loss": "4.327", "nll_loss": "2.94", "ppl": "7.67", "wps": "57534.9", "ups": "16.16", "wpb": "3560.4", "bsz": "148.6", "num_updates": "27000", "lr": "0.003849", "gnorm": "0.275", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1619"}
2023-12-13 21:55:04 | INFO | train_inner | {"epoch": 25, "update": 24.594, "loss": "4.322", "nll_loss": "2.937", "ppl": "7.66", "wps": "60093.2", "ups": "16.86", "wpb": "3563.5", "bsz": "145.2", "num_updates": "27100", "lr": "0.00384189", "gnorm": "0.281", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1625"}
2023-12-13 21:55:10 | INFO | train_inner | {"epoch": 25, "update": 24.685, "loss": "4.39", "nll_loss": "3.015", "ppl": "8.09", "wps": "60809.7", "ups": "17.22", "wpb": "3531.9", "bsz": "137.4", "num_updates": "27200", "lr": "0.00383482", "gnorm": "0.275", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1631"}
2023-12-13 21:55:16 | INFO | train_inner | {"epoch": 25, "update": 24.776, "loss": "4.343", "nll_loss": "2.962", "ppl": "7.79", "wps": "58617.4", "ups": "16.24", "wpb": "3608.5", "bsz": "142", "num_updates": "27300", "lr": "0.0038278", "gnorm": "0.276", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1637"}
2023-12-13 21:55:22 | INFO | train_inner | {"epoch": 25, "update": 24.867, "loss": "4.324", "nll_loss": "2.941", "ppl": "7.68", "wps": "61175", "ups": "16.9", "wpb": "3620.4", "bsz": "149.9", "num_updates": "27400", "lr": "0.0038208", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1643"}
2023-12-13 21:55:27 | INFO | train_inner | {"epoch": 25, "update": 24.957, "loss": "4.397", "nll_loss": "3.026", "ppl": "8.15", "wps": "64627.6", "ups": "17.98", "wpb": "3595.3", "bsz": "136.9", "num_updates": "27500", "lr": "0.00381385", "gnorm": "0.274", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1648"}
2023-12-13 21:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:55:31 | INFO | valid | {"epoch": 25, "valid_loss": "4.359", "valid_nll_loss": "2.99", "valid_ppl": "7.94", "valid_wps": "127402", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "27547", "valid_best_loss": "4.359"}
2023-12-13 21:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 27547 updates
2023-12-13 21:55:31 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint25.pt
2023-12-13 21:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint25.pt
2023-12-13 21:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint25.pt (epoch 25 @ 27547 updates, score 4.359) (writing took 0.2146046031266451 seconds)
2023-12-13 21:55:32 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-12-13 21:55:32 | INFO | train | {"epoch": 25, "train_loss": "4.305", "train_nll_loss": "2.917", "train_ppl": "7.55", "train_wps": "59874.8", "train_ups": "16.71", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "27547", "train_lr": "0.0038106", "train_gnorm": "0.271", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "1652"}
2023-12-13 21:55:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:55:32 | INFO | fairseq.trainer | begin training epoch 26
2023-12-13 21:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:55:35 | INFO | train_inner | {"epoch": 26, "update": 25.048, "loss": "4.224", "nll_loss": "2.825", "ppl": "7.09", "wps": "50004.2", "ups": "14.02", "wpb": "3566.5", "bsz": "163.4", "num_updates": "27600", "lr": "0.00380693", "gnorm": "0.261", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1655"}
2023-12-13 21:55:40 | INFO | train_inner | {"epoch": 26, "update": 25.139, "loss": "4.182", "nll_loss": "2.775", "ppl": "6.85", "wps": "69387.8", "ups": "19.11", "wpb": "3630.5", "bsz": "160.5", "num_updates": "27700", "lr": "0.00380006", "gnorm": "0.253", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1661"}
2023-12-13 21:55:45 | INFO | train_inner | {"epoch": 26, "update": 25.23, "loss": "4.242", "nll_loss": "2.844", "ppl": "7.18", "wps": "66588", "ups": "18.55", "wpb": "3589", "bsz": "151.4", "num_updates": "27800", "lr": "0.00379322", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1666"}
2023-12-13 21:55:50 | INFO | train_inner | {"epoch": 26, "update": 25.32, "loss": "4.236", "nll_loss": "2.838", "ppl": "7.15", "wps": "69194.1", "ups": "18.96", "wpb": "3649.4", "bsz": "147.1", "num_updates": "27900", "lr": "0.00378641", "gnorm": "0.262", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1671"}
2023-12-13 21:55:56 | INFO | train_inner | {"epoch": 26, "update": 25.411, "loss": "4.249", "nll_loss": "2.852", "ppl": "7.22", "wps": "64494.9", "ups": "17.52", "wpb": "3680.4", "bsz": "154.5", "num_updates": "28000", "lr": "0.00377964", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1677"}
2023-12-13 21:56:03 | INFO | train_inner | {"epoch": 26, "update": 25.502, "loss": "4.334", "nll_loss": "2.948", "ppl": "7.72", "wps": "54966.4", "ups": "15.47", "wpb": "3553.4", "bsz": "131.5", "num_updates": "28100", "lr": "0.00377291", "gnorm": "0.283", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1683"}
2023-12-13 21:56:08 | INFO | train_inner | {"epoch": 26, "update": 25.593, "loss": "4.267", "nll_loss": "2.875", "ppl": "7.34", "wps": "61581", "ups": "17.36", "wpb": "3547.4", "bsz": "160.2", "num_updates": "28200", "lr": "0.00376622", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1689"}
2023-12-13 21:56:15 | INFO | train_inner | {"epoch": 26, "update": 25.683, "loss": "4.384", "nll_loss": "3.008", "ppl": "8.04", "wps": "56690.1", "ups": "16.12", "wpb": "3516.5", "bsz": "133.3", "num_updates": "28300", "lr": "0.00375956", "gnorm": "0.29", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1695"}
2023-12-13 21:56:21 | INFO | train_inner | {"epoch": 26, "update": 25.774, "loss": "4.33", "nll_loss": "2.947", "ppl": "7.71", "wps": "57265.5", "ups": "16.1", "wpb": "3557.6", "bsz": "143.6", "num_updates": "28400", "lr": "0.00375293", "gnorm": "0.274", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1702"}
2023-12-13 21:56:27 | INFO | train_inner | {"epoch": 26, "update": 25.865, "loss": "4.373", "nll_loss": "2.998", "ppl": "7.99", "wps": "56752.3", "ups": "15.97", "wpb": "3554", "bsz": "142.1", "num_updates": "28500", "lr": "0.00374634", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1708"}
2023-12-13 21:56:33 | INFO | train_inner | {"epoch": 26, "update": 25.956, "loss": "4.378", "nll_loss": "3.004", "ppl": "8.02", "wps": "63646.3", "ups": "17.82", "wpb": "3570.8", "bsz": "135.1", "num_updates": "28600", "lr": "0.00373979", "gnorm": "0.264", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1714"}
2023-12-13 21:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:56:37 | INFO | valid | {"epoch": 26, "valid_loss": "4.354", "valid_nll_loss": "3.008", "valid_ppl": "8.04", "valid_wps": "128416", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "28649", "valid_best_loss": "4.354"}
2023-12-13 21:56:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 28649 updates
2023-12-13 21:56:37 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint26.pt
2023-12-13 21:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint26.pt
2023-12-13 21:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint26.pt (epoch 26 @ 28649 updates, score 4.354) (writing took 0.2167291482910514 seconds)
2023-12-13 21:56:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-12-13 21:56:37 | INFO | train | {"epoch": 26, "train_loss": "4.294", "train_nll_loss": "2.904", "train_ppl": "7.49", "train_wps": "59894.4", "train_ups": "16.71", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "28649", "train_lr": "0.00373659", "train_gnorm": "0.272", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "1718"}
2023-12-13 21:56:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:56:38 | INFO | fairseq.trainer | begin training epoch 27
2023-12-13 21:56:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:56:41 | INFO | train_inner | {"epoch": 27, "update": 26.046, "loss": "4.304", "nll_loss": "2.914", "ppl": "7.53", "wps": "44667.3", "ups": "12.54", "wpb": "3560.7", "bsz": "125.7", "num_updates": "28700", "lr": "0.00373327", "gnorm": "0.28", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1721"}
2023-12-13 21:56:47 | INFO | train_inner | {"epoch": 27, "update": 26.137, "loss": "4.172", "nll_loss": "2.762", "ppl": "6.78", "wps": "59261", "ups": "16.41", "wpb": "3611.7", "bsz": "145.7", "num_updates": "28800", "lr": "0.00372678", "gnorm": "0.268", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1728"}
2023-12-13 21:56:52 | INFO | train_inner | {"epoch": 27, "update": 26.228, "loss": "4.22", "nll_loss": "2.819", "ppl": "7.06", "wps": "64796.5", "ups": "18.08", "wpb": "3584.1", "bsz": "146.5", "num_updates": "28900", "lr": "0.00372033", "gnorm": "0.263", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "1733"}
2023-12-13 21:56:58 | INFO | train_inner | {"epoch": 27, "update": 26.319, "loss": "4.213", "nll_loss": "2.812", "ppl": "7.02", "wps": "61381.6", "ups": "17.31", "wpb": "3546.7", "bsz": "157.2", "num_updates": "29000", "lr": "0.00371391", "gnorm": "0.275", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1739"}
2023-12-13 21:57:04 | INFO | train_inner | {"epoch": 27, "update": 26.409, "loss": "4.294", "nll_loss": "2.903", "ppl": "7.48", "wps": "58506.3", "ups": "16.23", "wpb": "3603.8", "bsz": "136.8", "num_updates": "29100", "lr": "0.00370752", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1745"}
2023-12-13 21:57:10 | INFO | train_inner | {"epoch": 27, "update": 26.5, "loss": "4.25", "nll_loss": "2.853", "ppl": "7.22", "wps": "63973.8", "ups": "17.52", "wpb": "3651.2", "bsz": "158", "num_updates": "29200", "lr": "0.00370117", "gnorm": "0.274", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1751"}
2023-12-13 21:57:16 | INFO | train_inner | {"epoch": 27, "update": 26.591, "loss": "4.315", "nll_loss": "2.93", "ppl": "7.62", "wps": "59551.7", "ups": "16.65", "wpb": "3576.1", "bsz": "147.1", "num_updates": "29300", "lr": "0.00369484", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1757"}
2023-12-13 21:57:22 | INFO | train_inner | {"epoch": 27, "update": 26.681, "loss": "4.332", "nll_loss": "2.949", "ppl": "7.72", "wps": "59410.6", "ups": "16.52", "wpb": "3596.6", "bsz": "139.5", "num_updates": "29400", "lr": "0.00368856", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "1763"}
2023-12-13 21:57:28 | INFO | train_inner | {"epoch": 27, "update": 26.772, "loss": "4.351", "nll_loss": "2.973", "ppl": "7.85", "wps": "57279.6", "ups": "16.2", "wpb": "3534.8", "bsz": "138.1", "num_updates": "29500", "lr": "0.0036823", "gnorm": "0.285", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "1769"}
2023-12-13 21:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-12-13 21:57:34 | INFO | train_inner | {"epoch": 27, "update": 26.864, "loss": "4.314", "nll_loss": "2.929", "ppl": "7.62", "wps": "63735.7", "ups": "17.74", "wpb": "3593.2", "bsz": "144.6", "num_updates": "29600", "lr": "0.00367607", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1775"}
2023-12-13 21:57:39 | INFO | train_inner | {"epoch": 27, "update": 26.955, "loss": "4.346", "nll_loss": "2.968", "ppl": "7.82", "wps": "65580.6", "ups": "18.37", "wpb": "3569.5", "bsz": "143", "num_updates": "29700", "lr": "0.00366988", "gnorm": "0.274", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1780"}
2023-12-13 21:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:57:43 | INFO | valid | {"epoch": 27, "valid_loss": "4.355", "valid_nll_loss": "2.98", "valid_ppl": "7.89", "valid_wps": "130898", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "29750", "valid_best_loss": "4.354"}
2023-12-13 21:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 29750 updates
2023-12-13 21:57:43 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint27.pt
2023-12-13 21:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint27.pt
2023-12-13 21:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint27.pt (epoch 27 @ 29750 updates, score 4.355) (writing took 0.15060701686888933 seconds)
2023-12-13 21:57:43 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-12-13 21:57:43 | INFO | train | {"epoch": 27, "train_loss": "4.279", "train_nll_loss": "2.888", "train_ppl": "7.4", "train_wps": "59926.2", "train_ups": "16.72", "train_wpb": "3584.3", "train_bsz": "145.5", "train_num_updates": "29750", "train_lr": "0.00366679", "train_gnorm": "0.272", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1784"}
2023-12-13 21:57:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:57:43 | INFO | fairseq.trainer | begin training epoch 28
2023-12-13 21:57:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:57:46 | INFO | train_inner | {"epoch": 28, "update": 27.045, "loss": "4.238", "nll_loss": "2.841", "ppl": "7.17", "wps": "49760.6", "ups": "13.91", "wpb": "3576.1", "bsz": "147.2", "num_updates": "29800", "lr": "0.00366372", "gnorm": "0.267", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1787"}
2023-12-13 21:57:52 | INFO | train_inner | {"epoch": 28, "update": 27.136, "loss": "4.134", "nll_loss": "2.719", "ppl": "6.59", "wps": "67704.4", "ups": "18.76", "wpb": "3608.3", "bsz": "155.6", "num_updates": "29900", "lr": "0.00365758", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1793"}
2023-12-13 21:57:58 | INFO | train_inner | {"epoch": 28, "update": 27.227, "loss": "4.211", "nll_loss": "2.807", "ppl": "7", "wps": "62492.2", "ups": "17.18", "wpb": "3637.9", "bsz": "154.1", "num_updates": "30000", "lr": "0.00365148", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1798"}
2023-12-13 21:58:03 | INFO | train_inner | {"epoch": 28, "update": 27.318, "loss": "4.213", "nll_loss": "2.812", "ppl": "7.02", "wps": "65999.8", "ups": "18.31", "wpb": "3604.4", "bsz": "152.6", "num_updates": "30100", "lr": "0.00364541", "gnorm": "0.265", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1804"}
2023-12-13 21:58:09 | INFO | train_inner | {"epoch": 28, "update": 27.408, "loss": "4.252", "nll_loss": "2.854", "ppl": "7.23", "wps": "60070.4", "ups": "16.87", "wpb": "3560.9", "bsz": "145.8", "num_updates": "30200", "lr": "0.00363937", "gnorm": "0.309", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1810"}
2023-12-13 21:58:15 | INFO | train_inner | {"epoch": 28, "update": 27.499, "loss": "4.322", "nll_loss": "2.938", "ppl": "7.67", "wps": "61240.4", "ups": "17.06", "wpb": "3590.8", "bsz": "139.4", "num_updates": "30300", "lr": "0.00363336", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1816"}
2023-12-13 21:58:21 | INFO | train_inner | {"epoch": 28, "update": 27.59, "loss": "4.362", "nll_loss": "2.983", "ppl": "7.91", "wps": "55868.3", "ups": "15.41", "wpb": "3625.9", "bsz": "124.9", "num_updates": "30400", "lr": "0.00362738", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "39.1", "wall": "1822"}
2023-12-13 21:58:28 | INFO | train_inner | {"epoch": 28, "update": 27.681, "loss": "4.353", "nll_loss": "2.973", "ppl": "7.85", "wps": "56772.7", "ups": "16.05", "wpb": "3537.8", "bsz": "134", "num_updates": "30500", "lr": "0.00362143", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1828"}
2023-12-13 21:58:33 | INFO | train_inner | {"epoch": 28, "update": 27.771, "loss": "4.257", "nll_loss": "2.865", "ppl": "7.28", "wps": "65197.4", "ups": "18.03", "wpb": "3615.5", "bsz": "155.4", "num_updates": "30600", "lr": "0.00361551", "gnorm": "0.273", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1834"}
2023-12-13 21:58:39 | INFO | train_inner | {"epoch": 28, "update": 27.862, "loss": "4.279", "nll_loss": "2.89", "ppl": "7.41", "wps": "59330.5", "ups": "16.61", "wpb": "3572.9", "bsz": "156", "num_updates": "30700", "lr": "0.00360961", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1840"}
2023-12-13 21:58:45 | INFO | train_inner | {"epoch": 28, "update": 27.953, "loss": "4.338", "nll_loss": "2.959", "ppl": "7.78", "wps": "61289.2", "ups": "17.45", "wpb": "3511.4", "bsz": "141", "num_updates": "30800", "lr": "0.00360375", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1846"}
2023-12-13 21:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:58:49 | INFO | valid | {"epoch": 28, "valid_loss": "4.352", "valid_nll_loss": "3.006", "valid_ppl": "8.03", "valid_wps": "128801", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "30852", "valid_best_loss": "4.352"}
2023-12-13 21:58:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 30852 updates
2023-12-13 21:58:49 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint28.pt
2023-12-13 21:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint28.pt
2023-12-13 21:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint28.pt (epoch 28 @ 30852 updates, score 4.352) (writing took 0.21502059418708086 seconds)
2023-12-13 21:58:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-12-13 21:58:49 | INFO | train | {"epoch": 28, "train_loss": "4.269", "train_nll_loss": "2.877", "train_ppl": "7.34", "train_wps": "59764", "train_ups": "16.68", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "30852", "train_lr": "0.00360071", "train_gnorm": "0.277", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1850"}
2023-12-13 21:58:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:58:49 | INFO | fairseq.trainer | begin training epoch 29
2023-12-13 21:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:58:52 | INFO | train_inner | {"epoch": 29, "update": 28.044, "loss": "4.187", "nll_loss": "2.781", "ppl": "6.87", "wps": "50979.3", "ups": "14.04", "wpb": "3630.7", "bsz": "152.8", "num_updates": "30900", "lr": "0.00359791", "gnorm": "0.257", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1853"}
2023-12-13 21:58:58 | INFO | train_inner | {"epoch": 29, "update": 28.134, "loss": "4.161", "nll_loss": "2.751", "ppl": "6.73", "wps": "64009.4", "ups": "17.9", "wpb": "3575.9", "bsz": "150.7", "num_updates": "31000", "lr": "0.00359211", "gnorm": "0.267", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1858"}
2023-12-13 21:59:03 | INFO | train_inner | {"epoch": 29, "update": 28.225, "loss": "4.246", "nll_loss": "2.848", "ppl": "7.2", "wps": "59599.1", "ups": "16.78", "wpb": "3551", "bsz": "141.3", "num_updates": "31100", "lr": "0.00358633", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1864"}
2023-12-13 21:59:09 | INFO | train_inner | {"epoch": 29, "update": 28.316, "loss": "4.223", "nll_loss": "2.823", "ppl": "7.08", "wps": "64969.6", "ups": "18.06", "wpb": "3597.9", "bsz": "152.6", "num_updates": "31200", "lr": "0.00358057", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1870"}
2023-12-13 21:59:15 | INFO | train_inner | {"epoch": 29, "update": 28.407, "loss": "4.262", "nll_loss": "2.87", "ppl": "7.31", "wps": "65685.7", "ups": "18.09", "wpb": "3631.1", "bsz": "144.8", "num_updates": "31300", "lr": "0.00357485", "gnorm": "0.281", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1875"}
2023-12-13 21:59:21 | INFO | train_inner | {"epoch": 29, "update": 28.497, "loss": "4.293", "nll_loss": "2.904", "ppl": "7.49", "wps": "60527.8", "ups": "16.76", "wpb": "3611.7", "bsz": "137.3", "num_updates": "31400", "lr": "0.00356915", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1881"}
2023-12-13 21:59:26 | INFO | train_inner | {"epoch": 29, "update": 28.588, "loss": "4.272", "nll_loss": "2.882", "ppl": "7.37", "wps": "63894.6", "ups": "18.01", "wpb": "3548.3", "bsz": "152.9", "num_updates": "31500", "lr": "0.00356348", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1887"}
2023-12-13 21:59:32 | INFO | train_inner | {"epoch": 29, "update": 28.679, "loss": "4.276", "nll_loss": "2.886", "ppl": "7.39", "wps": "62710", "ups": "17.56", "wpb": "3571.1", "bsz": "143", "num_updates": "31600", "lr": "0.00355784", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1893"}
2023-12-13 21:59:37 | INFO | train_inner | {"epoch": 29, "update": 28.77, "loss": "4.238", "nll_loss": "2.843", "ppl": "7.18", "wps": "65759", "ups": "18.25", "wpb": "3603.3", "bsz": "162.1", "num_updates": "31700", "lr": "0.00355222", "gnorm": "0.275", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1898"}
2023-12-13 21:59:43 | INFO | train_inner | {"epoch": 29, "update": 28.86, "loss": "4.31", "nll_loss": "2.926", "ppl": "7.6", "wps": "57283.4", "ups": "16.1", "wpb": "3558.2", "bsz": "137.5", "num_updates": "31800", "lr": "0.00354663", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1904"}
2023-12-13 21:59:49 | INFO | train_inner | {"epoch": 29, "update": 28.951, "loss": "4.366", "nll_loss": "2.99", "ppl": "7.94", "wps": "58218.7", "ups": "16.56", "wpb": "3516.3", "bsz": "125.5", "num_updates": "31900", "lr": "0.00354107", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1910"}
2023-12-13 21:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 21:59:54 | INFO | valid | {"epoch": 29, "valid_loss": "4.34", "valid_nll_loss": "2.986", "valid_ppl": "7.92", "valid_wps": "128616", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "31954", "valid_best_loss": "4.34"}
2023-12-13 21:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 31954 updates
2023-12-13 21:59:54 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint29.pt
2023-12-13 21:59:54 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint29.pt
2023-12-13 21:59:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint29.pt (epoch 29 @ 31954 updates, score 4.34) (writing took 0.2181728035211563 seconds)
2023-12-13 21:59:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-12-13 21:59:54 | INFO | train | {"epoch": 29, "train_loss": "4.257", "train_nll_loss": "2.863", "train_ppl": "7.28", "train_wps": "60668.1", "train_ups": "16.93", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "31954", "train_lr": "0.00353808", "train_gnorm": "0.275", "train_loss_scale": "16", "train_train_wall": "62", "train_gb_free": "38.9", "train_wall": "1915"}
2023-12-13 21:59:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 21:59:55 | INFO | fairseq.trainer | begin training epoch 30
2023-12-13 21:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 21:59:57 | INFO | train_inner | {"epoch": 30, "update": 29.042, "loss": "4.23", "nll_loss": "2.832", "ppl": "7.12", "wps": "45977.1", "ups": "12.8", "wpb": "3593", "bsz": "141.5", "num_updates": "32000", "lr": "0.00353553", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1918"}
2023-12-13 22:00:03 | INFO | train_inner | {"epoch": 30, "update": 29.132, "loss": "4.156", "nll_loss": "2.747", "ppl": "6.71", "wps": "66977.3", "ups": "18.48", "wpb": "3623.6", "bsz": "151.8", "num_updates": "32100", "lr": "0.00353002", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1924"}
2023-12-13 22:00:09 | INFO | train_inner | {"epoch": 30, "update": 29.223, "loss": "4.212", "nll_loss": "2.809", "ppl": "7.01", "wps": "60568.6", "ups": "17.12", "wpb": "3537.9", "bsz": "144", "num_updates": "32200", "lr": "0.00352454", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1929"}
2023-12-13 22:00:14 | INFO | train_inner | {"epoch": 30, "update": 29.314, "loss": "4.187", "nll_loss": "2.783", "ppl": "6.88", "wps": "64331.3", "ups": "18.2", "wpb": "3535.2", "bsz": "163.4", "num_updates": "32300", "lr": "0.00351908", "gnorm": "0.28", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1935"}
2023-12-13 22:00:20 | INFO | train_inner | {"epoch": 30, "update": 29.405, "loss": "4.213", "nll_loss": "2.814", "ppl": "7.03", "wps": "62973.4", "ups": "17.33", "wpb": "3634.6", "bsz": "159.5", "num_updates": "32400", "lr": "0.00351364", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1941"}
2023-12-13 22:00:26 | INFO | train_inner | {"epoch": 30, "update": 29.495, "loss": "4.331", "nll_loss": "2.947", "ppl": "7.71", "wps": "54571.9", "ups": "15.45", "wpb": "3531.5", "bsz": "125.2", "num_updates": "32500", "lr": "0.00350823", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1947"}
2023-12-13 22:00:33 | INFO | train_inner | {"epoch": 30, "update": 29.586, "loss": "4.299", "nll_loss": "2.912", "ppl": "7.53", "wps": "54679.5", "ups": "15.23", "wpb": "3590.5", "bsz": "129.2", "num_updates": "32600", "lr": "0.00350285", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1954"}
2023-12-13 22:00:39 | INFO | train_inner | {"epoch": 30, "update": 29.677, "loss": "4.282", "nll_loss": "2.892", "ppl": "7.42", "wps": "56845", "ups": "15.91", "wpb": "3573.6", "bsz": "143.8", "num_updates": "32700", "lr": "0.00349749", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1960"}
2023-12-13 22:00:45 | INFO | train_inner | {"epoch": 30, "update": 29.768, "loss": "4.263", "nll_loss": "2.873", "ppl": "7.33", "wps": "66670", "ups": "18.36", "wpb": "3632.2", "bsz": "147.6", "num_updates": "32800", "lr": "0.00349215", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1965"}
2023-12-13 22:00:50 | INFO | train_inner | {"epoch": 30, "update": 29.858, "loss": "4.3", "nll_loss": "2.913", "ppl": "7.53", "wps": "62608.8", "ups": "17.52", "wpb": "3572.9", "bsz": "131.6", "num_updates": "32900", "lr": "0.00348684", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1971"}
2023-12-13 22:00:56 | INFO | train_inner | {"epoch": 30, "update": 29.949, "loss": "4.284", "nll_loss": "2.897", "ppl": "7.45", "wps": "66207.6", "ups": "18.41", "wpb": "3596.9", "bsz": "154.6", "num_updates": "33000", "lr": "0.00348155", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1977"}
2023-12-13 22:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:01:00 | INFO | valid | {"epoch": 30, "valid_loss": "4.337", "valid_nll_loss": "2.977", "valid_ppl": "7.87", "valid_wps": "129387", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "33056", "valid_best_loss": "4.337"}
2023-12-13 22:01:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 33056 updates
2023-12-13 22:01:00 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint30.pt
2023-12-13 22:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint30.pt
2023-12-13 22:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint30.pt (epoch 30 @ 33056 updates, score 4.337) (writing took 0.21197121497243643 seconds)
2023-12-13 22:01:00 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-12-13 22:01:00 | INFO | train | {"epoch": 30, "train_loss": "4.249", "train_nll_loss": "2.855", "train_ppl": "7.23", "train_wps": "59941", "train_ups": "16.73", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "33056", "train_lr": "0.0034786", "train_gnorm": "0.279", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "1981"}
2023-12-13 22:01:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:01:00 | INFO | fairseq.trainer | begin training epoch 31
2023-12-13 22:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:01:03 | INFO | train_inner | {"epoch": 31, "update": 30.04, "loss": "4.194", "nll_loss": "2.792", "ppl": "6.92", "wps": "52356", "ups": "14.39", "wpb": "3637.1", "bsz": "156.4", "num_updates": "33100", "lr": "0.00347629", "gnorm": "0.272", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1984"}
2023-12-13 22:01:09 | INFO | train_inner | {"epoch": 31, "update": 30.131, "loss": "4.148", "nll_loss": "2.737", "ppl": "6.67", "wps": "59799.1", "ups": "16.84", "wpb": "3550.8", "bsz": "153.8", "num_updates": "33200", "lr": "0.00347105", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1989"}
2023-12-13 22:01:14 | INFO | train_inner | {"epoch": 31, "update": 30.221, "loss": "4.161", "nll_loss": "2.751", "ppl": "6.73", "wps": "65553.9", "ups": "18.11", "wpb": "3620.5", "bsz": "151", "num_updates": "33300", "lr": "0.00346583", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1995"}
2023-12-13 22:01:20 | INFO | train_inner | {"epoch": 31, "update": 30.312, "loss": "4.247", "nll_loss": "2.85", "ppl": "7.21", "wps": "57684.6", "ups": "16.22", "wpb": "3556.3", "bsz": "131.2", "num_updates": "33400", "lr": "0.00346064", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2001"}
2023-12-13 22:01:26 | INFO | train_inner | {"epoch": 31, "update": 30.403, "loss": "4.237", "nll_loss": "2.839", "ppl": "7.15", "wps": "60751", "ups": "17.04", "wpb": "3564.9", "bsz": "138.1", "num_updates": "33500", "lr": "0.00345547", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2007"}
2023-12-13 22:01:32 | INFO | train_inner | {"epoch": 31, "update": 30.494, "loss": "4.248", "nll_loss": "2.853", "ppl": "7.23", "wps": "57690.2", "ups": "16.15", "wpb": "3571.6", "bsz": "140.5", "num_updates": "33600", "lr": "0.00345033", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2013"}
2023-12-13 22:01:38 | INFO | train_inner | {"epoch": 31, "update": 30.584, "loss": "4.267", "nll_loss": "2.876", "ppl": "7.34", "wps": "62690.7", "ups": "17.26", "wpb": "3633.2", "bsz": "149.7", "num_updates": "33700", "lr": "0.0034452", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2019"}
2023-12-13 22:01:44 | INFO | train_inner | {"epoch": 31, "update": 30.675, "loss": "4.308", "nll_loss": "2.922", "ppl": "7.58", "wps": "57517", "ups": "15.84", "wpb": "3631.9", "bsz": "121.6", "num_updates": "33800", "lr": "0.0034401", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2025"}
2023-12-13 22:01:50 | INFO | train_inner | {"epoch": 31, "update": 30.766, "loss": "4.245", "nll_loss": "2.853", "ppl": "7.22", "wps": "64846", "ups": "18.23", "wpb": "3557.8", "bsz": "159.5", "num_updates": "33900", "lr": "0.00343503", "gnorm": "0.286", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2031"}
2023-12-13 22:01:56 | INFO | train_inner | {"epoch": 31, "update": 30.857, "loss": "4.258", "nll_loss": "2.866", "ppl": "7.29", "wps": "57831.7", "ups": "16.09", "wpb": "3594.1", "bsz": "144.2", "num_updates": "34000", "lr": "0.00342997", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2037"}
2023-12-13 22:02:02 | INFO | train_inner | {"epoch": 31, "update": 30.947, "loss": "4.244", "nll_loss": "2.854", "ppl": "7.23", "wps": "65975.2", "ups": "18.38", "wpb": "3589.1", "bsz": "162.4", "num_updates": "34100", "lr": "0.00342494", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2042"}
2023-12-13 22:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:02:07 | INFO | valid | {"epoch": 31, "valid_loss": "4.339", "valid_nll_loss": "2.983", "valid_ppl": "7.9", "valid_wps": "127469", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "34158", "valid_best_loss": "4.337"}
2023-12-13 22:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 34158 updates
2023-12-13 22:02:07 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint31.pt
2023-12-13 22:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint31.pt
2023-12-13 22:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint31.pt (epoch 31 @ 34158 updates, score 4.339) (writing took 0.153255813755095 seconds)
2023-12-13 22:02:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-12-13 22:02:07 | INFO | train | {"epoch": 31, "train_loss": "4.235", "train_nll_loss": "2.839", "train_ppl": "7.15", "train_wps": "59517.8", "train_ups": "16.61", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "34158", "train_lr": "0.00342203", "train_gnorm": "0.277", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "2048"}
2023-12-13 22:02:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:02:07 | INFO | fairseq.trainer | begin training epoch 32
2023-12-13 22:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:02:09 | INFO | train_inner | {"epoch": 32, "update": 31.038, "loss": "4.249", "nll_loss": "2.857", "ppl": "7.25", "wps": "46562.3", "ups": "13.21", "wpb": "3524.6", "bsz": "144.7", "num_updates": "34200", "lr": "0.00341993", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2050"}
2023-12-13 22:02:15 | INFO | train_inner | {"epoch": 32, "update": 31.129, "loss": "4.15", "nll_loss": "2.737", "ppl": "6.67", "wps": "58746.1", "ups": "16.53", "wpb": "3554", "bsz": "137.8", "num_updates": "34300", "lr": "0.00341494", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2056"}
2023-12-13 22:02:21 | INFO | train_inner | {"epoch": 32, "update": 31.22, "loss": "4.141", "nll_loss": "2.73", "ppl": "6.64", "wps": "57506.3", "ups": "16.23", "wpb": "3543.3", "bsz": "155", "num_updates": "34400", "lr": "0.00340997", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2062"}
2023-12-13 22:02:27 | INFO | train_inner | {"epoch": 32, "update": 31.31, "loss": "4.223", "nll_loss": "2.823", "ppl": "7.08", "wps": "64181.1", "ups": "17.92", "wpb": "3581.5", "bsz": "146.4", "num_updates": "34500", "lr": "0.00340503", "gnorm": "0.282", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2068"}
2023-12-13 22:02:33 | INFO | train_inner | {"epoch": 32, "update": 31.401, "loss": "4.201", "nll_loss": "2.799", "ppl": "6.96", "wps": "62576.6", "ups": "17.4", "wpb": "3597.1", "bsz": "149.6", "num_updates": "34600", "lr": "0.0034001", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2074"}
2023-12-13 22:02:38 | INFO | train_inner | {"epoch": 32, "update": 31.492, "loss": "4.215", "nll_loss": "2.816", "ppl": "7.04", "wps": "62724.8", "ups": "17.73", "wpb": "3538.6", "bsz": "149", "num_updates": "34700", "lr": "0.0033952", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2079"}
2023-12-13 22:02:45 | INFO | train_inner | {"epoch": 32, "update": 31.583, "loss": "4.279", "nll_loss": "2.888", "ppl": "7.4", "wps": "55525.3", "ups": "15.75", "wpb": "3524.6", "bsz": "132", "num_updates": "34800", "lr": "0.00339032", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2086"}
2023-12-13 22:02:50 | INFO | train_inner | {"epoch": 32, "update": 31.673, "loss": "4.202", "nll_loss": "2.802", "ppl": "6.97", "wps": "71222.9", "ups": "19.27", "wpb": "3697", "bsz": "154.6", "num_updates": "34900", "lr": "0.00338546", "gnorm": "0.264", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2091"}
2023-12-13 22:02:56 | INFO | train_inner | {"epoch": 32, "update": 31.764, "loss": "4.283", "nll_loss": "2.896", "ppl": "7.44", "wps": "62221.4", "ups": "17.44", "wpb": "3567", "bsz": "137.6", "num_updates": "35000", "lr": "0.00338062", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2097"}
2023-12-13 22:03:02 | INFO | train_inner | {"epoch": 32, "update": 31.855, "loss": "4.27", "nll_loss": "2.881", "ppl": "7.37", "wps": "61827.7", "ups": "17.07", "wpb": "3622.8", "bsz": "141.6", "num_updates": "35100", "lr": "0.0033758", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2102"}
2023-12-13 22:03:07 | INFO | train_inner | {"epoch": 32, "update": 31.946, "loss": "4.27", "nll_loss": "2.882", "ppl": "7.37", "wps": "61527.7", "ups": "17.35", "wpb": "3547", "bsz": "146.3", "num_updates": "35200", "lr": "0.003371", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2108"}
2023-12-13 22:03:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:03:12 | INFO | valid | {"epoch": 32, "valid_loss": "4.321", "valid_nll_loss": "2.966", "valid_ppl": "7.81", "valid_wps": "129494", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "35260", "valid_best_loss": "4.321"}
2023-12-13 22:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 35260 updates
2023-12-13 22:03:12 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint32.pt
2023-12-13 22:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint32.pt
2023-12-13 22:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint32.pt (epoch 32 @ 35260 updates, score 4.321) (writing took 0.21299785654991865 seconds)
2023-12-13 22:03:12 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-12-13 22:03:12 | INFO | train | {"epoch": 32, "train_loss": "4.225", "train_nll_loss": "2.828", "train_ppl": "7.1", "train_wps": "60250", "train_ups": "16.81", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "35260", "train_lr": "0.00336813", "train_gnorm": "0.277", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2113"}
2023-12-13 22:03:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:03:12 | INFO | fairseq.trainer | begin training epoch 33
2023-12-13 22:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:03:15 | INFO | train_inner | {"epoch": 33, "update": 32.036, "loss": "4.194", "nll_loss": "2.793", "ppl": "6.93", "wps": "48157.1", "ups": "13.32", "wpb": "3616.5", "bsz": "155", "num_updates": "35300", "lr": "0.00336622", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2116"}
2023-12-13 22:03:21 | INFO | train_inner | {"epoch": 33, "update": 32.127, "loss": "4.188", "nll_loss": "2.782", "ppl": "6.88", "wps": "59413", "ups": "16.6", "wpb": "3579", "bsz": "129.2", "num_updates": "35400", "lr": "0.00336146", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2122"}
2023-12-13 22:03:26 | INFO | train_inner | {"epoch": 33, "update": 32.218, "loss": "4.158", "nll_loss": "2.748", "ppl": "6.72", "wps": "65231.4", "ups": "18.15", "wpb": "3594.9", "bsz": "150.7", "num_updates": "35500", "lr": "0.00335673", "gnorm": "0.274", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2127"}
2023-12-13 22:03:33 | INFO | train_inner | {"epoch": 33, "update": 32.309, "loss": "4.178", "nll_loss": "2.772", "ppl": "6.83", "wps": "56668.3", "ups": "16.02", "wpb": "3537.8", "bsz": "138.9", "num_updates": "35600", "lr": "0.00335201", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2133"}
2023-12-13 22:03:39 | INFO | train_inner | {"epoch": 33, "update": 32.399, "loss": "4.213", "nll_loss": "2.813", "ppl": "7.03", "wps": "57128.1", "ups": "15.7", "wpb": "3638.6", "bsz": "140.5", "num_updates": "35700", "lr": "0.00334731", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2140"}
2023-12-13 22:03:45 | INFO | train_inner | {"epoch": 33, "update": 32.49, "loss": "4.198", "nll_loss": "2.797", "ppl": "6.95", "wps": "61585.2", "ups": "17.04", "wpb": "3613.7", "bsz": "147.1", "num_updates": "35800", "lr": "0.00334263", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2146"}
2023-12-13 22:03:51 | INFO | train_inner | {"epoch": 33, "update": 32.581, "loss": "4.215", "nll_loss": "2.816", "ppl": "7.04", "wps": "58614.9", "ups": "16.64", "wpb": "3521.6", "bsz": "147.8", "num_updates": "35900", "lr": "0.00333797", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2152"}
2023-12-13 22:03:56 | INFO | train_inner | {"epoch": 33, "update": 32.672, "loss": "4.212", "nll_loss": "2.814", "ppl": "7.03", "wps": "66290.5", "ups": "18.35", "wpb": "3613.5", "bsz": "158.3", "num_updates": "36000", "lr": "0.00333333", "gnorm": "0.28", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2157"}
2023-12-13 22:04:02 | INFO | train_inner | {"epoch": 33, "update": 32.762, "loss": "4.228", "nll_loss": "2.833", "ppl": "7.12", "wps": "65219.6", "ups": "17.74", "wpb": "3676.6", "bsz": "153.6", "num_updates": "36100", "lr": "0.00332871", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2163"}
2023-12-13 22:04:08 | INFO | train_inner | {"epoch": 33, "update": 32.853, "loss": "4.273", "nll_loss": "2.884", "ppl": "7.38", "wps": "59886.2", "ups": "16.88", "wpb": "3547.2", "bsz": "146.6", "num_updates": "36200", "lr": "0.00332411", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2169"}
2023-12-13 22:04:14 | INFO | train_inner | {"epoch": 33, "update": 32.944, "loss": "4.29", "nll_loss": "2.907", "ppl": "7.5", "wps": "60733.7", "ups": "17.07", "wpb": "3557.6", "bsz": "146", "num_updates": "36300", "lr": "0.00331953", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2175"}
2023-12-13 22:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:04:19 | INFO | valid | {"epoch": 33, "valid_loss": "4.321", "valid_nll_loss": "2.961", "valid_ppl": "7.79", "valid_wps": "127338", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "36362", "valid_best_loss": "4.321"}
2023-12-13 22:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 36362 updates
2023-12-13 22:04:19 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint33.pt
2023-12-13 22:04:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint33.pt
2023-12-13 22:04:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint33.pt (epoch 33 @ 36362 updates, score 4.321) (writing took 0.21336223371326923 seconds)
2023-12-13 22:04:19 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-12-13 22:04:19 | INFO | train | {"epoch": 33, "train_loss": "4.214", "train_nll_loss": "2.815", "train_ppl": "7.04", "train_wps": "58839.8", "train_ups": "16.42", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "36362", "train_lr": "0.0033167", "train_gnorm": "0.28", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "2180"}
2023-12-13 22:04:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:04:19 | INFO | fairseq.trainer | begin training epoch 34
2023-12-13 22:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:04:22 | INFO | train_inner | {"epoch": 34, "update": 33.034, "loss": "4.222", "nll_loss": "2.826", "ppl": "7.09", "wps": "42907.2", "ups": "12.1", "wpb": "3545.8", "bsz": "140.3", "num_updates": "36400", "lr": "0.00331497", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2183"}
2023-12-13 22:04:28 | INFO | train_inner | {"epoch": 34, "update": 33.125, "loss": "4.077", "nll_loss": "2.656", "ppl": "6.3", "wps": "64732.5", "ups": "17.9", "wpb": "3617.3", "bsz": "150.9", "num_updates": "36500", "lr": "0.00331042", "gnorm": "0.267", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2188"}
2023-12-13 22:04:33 | INFO | train_inner | {"epoch": 34, "update": 33.216, "loss": "4.177", "nll_loss": "2.771", "ppl": "6.82", "wps": "60046.7", "ups": "16.86", "wpb": "3560.6", "bsz": "141.3", "num_updates": "36600", "lr": "0.0033059", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2194"}
2023-12-13 22:04:39 | INFO | train_inner | {"epoch": 34, "update": 33.307, "loss": "4.174", "nll_loss": "2.768", "ppl": "6.81", "wps": "62407.4", "ups": "17.15", "wpb": "3638.5", "bsz": "150.2", "num_updates": "36700", "lr": "0.00330139", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2200"}
2023-12-13 22:04:45 | INFO | train_inner | {"epoch": 34, "update": 33.397, "loss": "4.206", "nll_loss": "2.805", "ppl": "6.99", "wps": "58753.7", "ups": "16.23", "wpb": "3619.3", "bsz": "138.8", "num_updates": "36800", "lr": "0.0032969", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2206"}
2023-12-13 22:04:52 | INFO | train_inner | {"epoch": 34, "update": 33.488, "loss": "4.214", "nll_loss": "2.815", "ppl": "7.04", "wps": "58991.8", "ups": "16.53", "wpb": "3569.4", "bsz": "141.9", "num_updates": "36900", "lr": "0.00329243", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2212"}
2023-12-13 22:04:57 | INFO | train_inner | {"epoch": 34, "update": 33.579, "loss": "4.205", "nll_loss": "2.807", "ppl": "7", "wps": "64734.9", "ups": "18.09", "wpb": "3577.7", "bsz": "153.1", "num_updates": "37000", "lr": "0.00328798", "gnorm": "0.276", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2218"}
2023-12-13 22:05:03 | INFO | train_inner | {"epoch": 34, "update": 33.67, "loss": "4.209", "nll_loss": "2.81", "ppl": "7.01", "wps": "64592.9", "ups": "18.23", "wpb": "3542.7", "bsz": "149.1", "num_updates": "37100", "lr": "0.00328355", "gnorm": "0.297", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2223"}
2023-12-13 22:05:08 | INFO | train_inner | {"epoch": 34, "update": 33.76, "loss": "4.202", "nll_loss": "2.803", "ppl": "6.98", "wps": "64143", "ups": "17.74", "wpb": "3615.3", "bsz": "154.6", "num_updates": "37200", "lr": "0.00327913", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2229"}
2023-12-13 22:05:15 | INFO | train_inner | {"epoch": 34, "update": 33.851, "loss": "4.324", "nll_loss": "2.944", "ppl": "7.69", "wps": "53487.7", "ups": "15.22", "wpb": "3515", "bsz": "128.1", "num_updates": "37300", "lr": "0.00327473", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2236"}
2023-12-13 22:05:21 | INFO | train_inner | {"epoch": 34, "update": 33.942, "loss": "4.253", "nll_loss": "2.862", "ppl": "7.27", "wps": "62217.3", "ups": "17.13", "wpb": "3631.9", "bsz": "148.9", "num_updates": "37400", "lr": "0.00327035", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2241"}
2023-12-13 22:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:05:26 | INFO | valid | {"epoch": 34, "valid_loss": "4.321", "valid_nll_loss": "2.956", "valid_ppl": "7.76", "valid_wps": "120553", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "37464", "valid_best_loss": "4.321"}
2023-12-13 22:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 37464 updates
2023-12-13 22:05:26 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint34.pt
2023-12-13 22:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint34.pt
2023-12-13 22:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint34.pt (epoch 34 @ 37464 updates, score 4.321) (writing took 0.21926522813737392 seconds)
2023-12-13 22:05:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-12-13 22:05:26 | INFO | train | {"epoch": 34, "train_loss": "4.206", "train_nll_loss": "2.806", "train_ppl": "7", "train_wps": "59112.5", "train_ups": "16.5", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "37464", "train_lr": "0.00326756", "train_gnorm": "0.282", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "2247"}
2023-12-13 22:05:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:05:26 | INFO | fairseq.trainer | begin training epoch 35
2023-12-13 22:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:05:28 | INFO | train_inner | {"epoch": 35, "update": 34.033, "loss": "4.24", "nll_loss": "2.847", "ppl": "7.2", "wps": "45307.4", "ups": "12.77", "wpb": "3548.8", "bsz": "138", "num_updates": "37500", "lr": "0.00326599", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2249"}
2023-12-13 22:05:34 | INFO | train_inner | {"epoch": 35, "update": 34.123, "loss": "4.145", "nll_loss": "2.731", "ppl": "6.64", "wps": "59404.5", "ups": "16.64", "wpb": "3569", "bsz": "130.1", "num_updates": "37600", "lr": "0.00326164", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2255"}
2023-12-13 22:05:40 | INFO | train_inner | {"epoch": 35, "update": 34.214, "loss": "4.114", "nll_loss": "2.698", "ppl": "6.49", "wps": "61572.6", "ups": "17.35", "wpb": "3549.8", "bsz": "146.6", "num_updates": "37700", "lr": "0.00325731", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2261"}
2023-12-13 22:05:46 | INFO | train_inner | {"epoch": 35, "update": 34.305, "loss": "4.158", "nll_loss": "2.751", "ppl": "6.73", "wps": "63706.9", "ups": "17.58", "wpb": "3623.1", "bsz": "158.3", "num_updates": "37800", "lr": "0.003253", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2267"}
2023-12-13 22:05:52 | INFO | train_inner | {"epoch": 35, "update": 34.396, "loss": "4.194", "nll_loss": "2.793", "ppl": "6.93", "wps": "57812.1", "ups": "16.14", "wpb": "3582.4", "bsz": "148.4", "num_updates": "37900", "lr": "0.00324871", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2273"}
2023-12-13 22:05:58 | INFO | train_inner | {"epoch": 35, "update": 34.486, "loss": "4.208", "nll_loss": "2.807", "ppl": "7", "wps": "58576.5", "ups": "16.35", "wpb": "3582.4", "bsz": "136.6", "num_updates": "38000", "lr": "0.00324443", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2279"}
2023-12-13 22:06:04 | INFO | train_inner | {"epoch": 35, "update": 34.577, "loss": "4.205", "nll_loss": "2.807", "ppl": "7", "wps": "65210.8", "ups": "18.5", "wpb": "3525.5", "bsz": "154", "num_updates": "38100", "lr": "0.00324017", "gnorm": "0.279", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "2284"}
2023-12-13 22:06:09 | INFO | train_inner | {"epoch": 35, "update": 34.668, "loss": "4.193", "nll_loss": "2.792", "ppl": "6.93", "wps": "64303.4", "ups": "17.77", "wpb": "3619", "bsz": "152.1", "num_updates": "38200", "lr": "0.00323592", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2290"}
2023-12-13 22:06:15 | INFO | train_inner | {"epoch": 35, "update": 34.759, "loss": "4.247", "nll_loss": "2.853", "ppl": "7.23", "wps": "57776", "ups": "16.27", "wpb": "3551.3", "bsz": "138.9", "num_updates": "38300", "lr": "0.0032317", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2296"}
2023-12-13 22:06:21 | INFO | train_inner | {"epoch": 35, "update": 34.849, "loss": "4.277", "nll_loss": "2.888", "ppl": "7.4", "wps": "58912", "ups": "16.47", "wpb": "3577.5", "bsz": "133.7", "num_updates": "38400", "lr": "0.00322749", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2302"}
2023-12-13 22:06:27 | INFO | train_inner | {"epoch": 35, "update": 34.94, "loss": "4.221", "nll_loss": "2.825", "ppl": "7.09", "wps": "68449.4", "ups": "18.8", "wpb": "3640.1", "bsz": "150.5", "num_updates": "38500", "lr": "0.00322329", "gnorm": "0.283", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2308"}
2023-12-13 22:06:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:06:32 | INFO | valid | {"epoch": 35, "valid_loss": "4.322", "valid_nll_loss": "2.974", "valid_ppl": "7.86", "valid_wps": "125058", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "38566", "valid_best_loss": "4.321"}
2023-12-13 22:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 38566 updates
2023-12-13 22:06:32 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint35.pt
2023-12-13 22:06:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint35.pt
2023-12-13 22:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint35.pt (epoch 35 @ 38566 updates, score 4.322) (writing took 0.17363610956817865 seconds)
2023-12-13 22:06:32 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-12-13 22:06:32 | INFO | train | {"epoch": 35, "train_loss": "4.196", "train_nll_loss": "2.795", "train_ppl": "6.94", "train_wps": "59956.3", "train_ups": "16.73", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "38566", "train_lr": "0.00322053", "train_gnorm": "0.283", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2313"}
2023-12-13 22:06:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:06:32 | INFO | fairseq.trainer | begin training epoch 36
2023-12-13 22:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:06:34 | INFO | train_inner | {"epoch": 36, "update": 35.031, "loss": "4.201", "nll_loss": "2.801", "ppl": "6.97", "wps": "47803.5", "ups": "13.24", "wpb": "3610.3", "bsz": "145.2", "num_updates": "38600", "lr": "0.00321911", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2315"}
2023-12-13 22:06:41 | INFO | train_inner | {"epoch": 36, "update": 35.122, "loss": "4.077", "nll_loss": "2.654", "ppl": "6.29", "wps": "55144.4", "ups": "15.57", "wpb": "3542.1", "bsz": "150.3", "num_updates": "38700", "lr": "0.00321495", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2322"}
2023-12-13 22:06:46 | INFO | train_inner | {"epoch": 36, "update": 35.212, "loss": "4.063", "nll_loss": "2.64", "ppl": "6.23", "wps": "61644", "ups": "17.32", "wpb": "3558.5", "bsz": "159", "num_updates": "38800", "lr": "0.00321081", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2327"}
2023-12-13 22:06:52 | INFO | train_inner | {"epoch": 36, "update": 35.303, "loss": "4.151", "nll_loss": "2.741", "ppl": "6.68", "wps": "62701.9", "ups": "17.05", "wpb": "3676.6", "bsz": "146.9", "num_updates": "38900", "lr": "0.00320668", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2333"}
2023-12-13 22:06:58 | INFO | train_inner | {"epoch": 36, "update": 35.394, "loss": "4.128", "nll_loss": "2.717", "ppl": "6.58", "wps": "69770.6", "ups": "19.15", "wpb": "3642.9", "bsz": "156.2", "num_updates": "39000", "lr": "0.00320256", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2338"}
2023-12-13 22:07:03 | INFO | train_inner | {"epoch": 36, "update": 35.485, "loss": "4.159", "nll_loss": "2.752", "ppl": "6.74", "wps": "62999.4", "ups": "17.75", "wpb": "3549.6", "bsz": "152.5", "num_updates": "39100", "lr": "0.00319847", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2344"}
2023-12-13 22:07:09 | INFO | train_inner | {"epoch": 36, "update": 35.575, "loss": "4.268", "nll_loss": "2.876", "ppl": "7.34", "wps": "56476.6", "ups": "16.13", "wpb": "3501.2", "bsz": "127.7", "num_updates": "39200", "lr": "0.00319438", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2350"}
2023-12-13 22:07:16 | INFO | train_inner | {"epoch": 36, "update": 35.666, "loss": "4.255", "nll_loss": "2.863", "ppl": "7.27", "wps": "57211.7", "ups": "16", "wpb": "3576.5", "bsz": "129.1", "num_updates": "39300", "lr": "0.00319032", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2357"}
2023-12-13 22:07:22 | INFO | train_inner | {"epoch": 36, "update": 35.757, "loss": "4.268", "nll_loss": "2.877", "ppl": "7.35", "wps": "54481", "ups": "15.22", "wpb": "3578.4", "bsz": "132.8", "num_updates": "39400", "lr": "0.00318626", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2363"}
2023-12-13 22:07:27 | INFO | train_inner | {"epoch": 36, "update": 35.848, "loss": "4.198", "nll_loss": "2.801", "ppl": "6.97", "wps": "68413.9", "ups": "19.13", "wpb": "3575.4", "bsz": "165", "num_updates": "39500", "lr": "0.00318223", "gnorm": "0.287", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2368"}
2023-12-13 22:07:34 | INFO | train_inner | {"epoch": 36, "update": 35.938, "loss": "4.311", "nll_loss": "2.929", "ppl": "7.62", "wps": "56445.6", "ups": "15.82", "wpb": "3567.7", "bsz": "130.7", "num_updates": "39600", "lr": "0.00317821", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2375"}
2023-12-13 22:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:07:39 | INFO | valid | {"epoch": 36, "valid_loss": "4.336", "valid_nll_loss": "2.959", "valid_ppl": "7.78", "valid_wps": "128008", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "39668", "valid_best_loss": "4.321"}
2023-12-13 22:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 39668 updates
2023-12-13 22:07:39 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint36.pt
2023-12-13 22:07:39 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint36.pt
2023-12-13 22:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint36.pt (epoch 36 @ 39668 updates, score 4.336) (writing took 0.15015175007283688 seconds)
2023-12-13 22:07:39 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-12-13 22:07:39 | INFO | train | {"epoch": 36, "train_loss": "4.187", "train_nll_loss": "2.785", "train_ppl": "6.89", "train_wps": "58609.4", "train_ups": "16.35", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "39668", "train_lr": "0.00317548", "train_gnorm": "0.284", "train_loss_scale": "16", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "2380"}
2023-12-13 22:07:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:07:39 | INFO | fairseq.trainer | begin training epoch 37
2023-12-13 22:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:07:41 | INFO | train_inner | {"epoch": 37, "update": 36.029, "loss": "4.173", "nll_loss": "2.77", "ppl": "6.82", "wps": "48738.9", "ups": "13.39", "wpb": "3638.8", "bsz": "151.7", "num_updates": "39700", "lr": "0.0031742", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2382"}
2023-12-13 22:07:47 | INFO | train_inner | {"epoch": 37, "update": 36.12, "loss": "4.099", "nll_loss": "2.68", "ppl": "6.41", "wps": "60977.3", "ups": "17.17", "wpb": "3550.8", "bsz": "140.1", "num_updates": "39800", "lr": "0.00317021", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2388"}
2023-12-13 22:07:53 | INFO | train_inner | {"epoch": 37, "update": 36.211, "loss": "4.106", "nll_loss": "2.69", "ppl": "6.45", "wps": "59705", "ups": "16.57", "wpb": "3602.3", "bsz": "153.4", "num_updates": "39900", "lr": "0.00316624", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2394"}
2023-12-13 22:07:59 | INFO | train_inner | {"epoch": 37, "update": 36.301, "loss": "4.108", "nll_loss": "2.693", "ppl": "6.46", "wps": "61075.2", "ups": "17.13", "wpb": "3565.2", "bsz": "154.1", "num_updates": "40000", "lr": "0.00316228", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2400"}
2023-12-13 22:08:05 | INFO | train_inner | {"epoch": 37, "update": 36.392, "loss": "4.192", "nll_loss": "2.79", "ppl": "6.92", "wps": "58867.9", "ups": "16.65", "wpb": "3535.6", "bsz": "134.2", "num_updates": "40100", "lr": "0.00315833", "gnorm": "0.295", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2406"}
2023-12-13 22:08:11 | INFO | train_inner | {"epoch": 37, "update": 36.483, "loss": "4.249", "nll_loss": "2.855", "ppl": "7.23", "wps": "56972.7", "ups": "16.17", "wpb": "3523.3", "bsz": "131.7", "num_updates": "40200", "lr": "0.0031544", "gnorm": "0.306", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2412"}
2023-12-13 22:08:17 | INFO | train_inner | {"epoch": 37, "update": 36.574, "loss": "4.212", "nll_loss": "2.813", "ppl": "7.03", "wps": "61356.8", "ups": "16.99", "wpb": "3611.3", "bsz": "139.4", "num_updates": "40300", "lr": "0.00315049", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2418"}
2023-12-13 22:08:22 | INFO | train_inner | {"epoch": 37, "update": 36.664, "loss": "4.237", "nll_loss": "2.844", "ppl": "7.18", "wps": "65993.8", "ups": "18.62", "wpb": "3543.7", "bsz": "141", "num_updates": "40400", "lr": "0.00314658", "gnorm": "0.292", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2423"}
2023-12-13 22:08:28 | INFO | train_inner | {"epoch": 37, "update": 36.755, "loss": "4.18", "nll_loss": "2.779", "ppl": "6.87", "wps": "68271.4", "ups": "18.69", "wpb": "3653.3", "bsz": "167.1", "num_updates": "40500", "lr": "0.0031427", "gnorm": "0.283", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2429"}
2023-12-13 22:08:33 | INFO | train_inner | {"epoch": 37, "update": 36.846, "loss": "4.172", "nll_loss": "2.77", "ppl": "6.82", "wps": "67537.1", "ups": "18.72", "wpb": "3608.2", "bsz": "161.5", "num_updates": "40600", "lr": "0.00313882", "gnorm": "0.279", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2434"}
2023-12-13 22:08:39 | INFO | train_inner | {"epoch": 37, "update": 36.936, "loss": "4.213", "nll_loss": "2.817", "ppl": "7.05", "wps": "63839.8", "ups": "17.5", "wpb": "3648.3", "bsz": "147.8", "num_updates": "40700", "lr": "0.00313497", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2440"}
2023-12-13 22:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:08:45 | INFO | valid | {"epoch": 37, "valid_loss": "4.329", "valid_nll_loss": "2.976", "valid_ppl": "7.87", "valid_wps": "129787", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "40770", "valid_best_loss": "4.321"}
2023-12-13 22:08:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 40770 updates
2023-12-13 22:08:45 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint37.pt
2023-12-13 22:08:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint37.pt
2023-12-13 22:08:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint37.pt (epoch 37 @ 40770 updates, score 4.329) (writing took 0.15089593827724457 seconds)
2023-12-13 22:08:45 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-12-13 22:08:45 | INFO | train | {"epoch": 37, "train_loss": "4.181", "train_nll_loss": "2.778", "train_ppl": "6.86", "train_wps": "60174.7", "train_ups": "16.79", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "40770", "train_lr": "0.00313227", "train_gnorm": "0.288", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2446"}
2023-12-13 22:08:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:08:45 | INFO | fairseq.trainer | begin training epoch 38
2023-12-13 22:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:08:47 | INFO | train_inner | {"epoch": 38, "update": 37.027, "loss": "4.226", "nll_loss": "2.83", "ppl": "7.11", "wps": "44977.7", "ups": "12.6", "wpb": "3568.7", "bsz": "132.3", "num_updates": "40800", "lr": "0.00313112", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2448"}
2023-12-13 22:08:53 | INFO | train_inner | {"epoch": 38, "update": 37.118, "loss": "4.078", "nll_loss": "2.656", "ppl": "6.3", "wps": "61907.6", "ups": "17.35", "wpb": "3567.8", "bsz": "147", "num_updates": "40900", "lr": "0.00312729", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2453"}
2023-12-13 22:08:59 | INFO | train_inner | {"epoch": 38, "update": 37.209, "loss": "4.162", "nll_loss": "2.754", "ppl": "6.75", "wps": "52528.2", "ups": "14.72", "wpb": "3567.4", "bsz": "129", "num_updates": "41000", "lr": "0.00312348", "gnorm": "0.29", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2460"}
2023-12-13 22:09:04 | INFO | train_inner | {"epoch": 38, "update": 37.299, "loss": "4.13", "nll_loss": "2.719", "ppl": "6.58", "wps": "73254.8", "ups": "20.14", "wpb": "3636.6", "bsz": "153", "num_updates": "41100", "lr": "0.00311967", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2465"}
2023-12-13 22:09:09 | INFO | train_inner | {"epoch": 38, "update": 37.39, "loss": "4.091", "nll_loss": "2.675", "ppl": "6.39", "wps": "70766.5", "ups": "19.55", "wpb": "3620.6", "bsz": "170.6", "num_updates": "41200", "lr": "0.00311588", "gnorm": "0.285", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "2470"}
2023-12-13 22:09:15 | INFO | train_inner | {"epoch": 38, "update": 37.481, "loss": "4.202", "nll_loss": "2.803", "ppl": "6.98", "wps": "62100", "ups": "17.09", "wpb": "3632.7", "bsz": "136.6", "num_updates": "41300", "lr": "0.00311211", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2476"}
2023-12-13 22:09:21 | INFO | train_inner | {"epoch": 38, "update": 37.572, "loss": "4.159", "nll_loss": "2.753", "ppl": "6.74", "wps": "63694.6", "ups": "17.59", "wpb": "3621.4", "bsz": "152.7", "num_updates": "41400", "lr": "0.00310835", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2482"}
2023-12-13 22:09:27 | INFO | train_inner | {"epoch": 38, "update": 37.662, "loss": "4.211", "nll_loss": "2.813", "ppl": "7.03", "wps": "61070.6", "ups": "17.23", "wpb": "3544.2", "bsz": "140.3", "num_updates": "41500", "lr": "0.0031046", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2488"}
2023-12-13 22:09:33 | INFO | train_inner | {"epoch": 38, "update": 37.753, "loss": "4.252", "nll_loss": "2.861", "ppl": "7.26", "wps": "57053.6", "ups": "16.08", "wpb": "3548.7", "bsz": "130.1", "num_updates": "41600", "lr": "0.00310087", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2494"}
2023-12-13 22:09:39 | INFO | train_inner | {"epoch": 38, "update": 37.844, "loss": "4.22", "nll_loss": "2.824", "ppl": "7.08", "wps": "58522.7", "ups": "16.42", "wpb": "3564", "bsz": "138.6", "num_updates": "41700", "lr": "0.00309715", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2500"}
2023-12-13 22:09:45 | INFO | train_inner | {"epoch": 38, "update": 37.935, "loss": "4.235", "nll_loss": "2.843", "ppl": "7.18", "wps": "62318.9", "ups": "17.73", "wpb": "3514.1", "bsz": "150.1", "num_updates": "41800", "lr": "0.00309344", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2506"}
2023-12-13 22:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:09:50 | INFO | valid | {"epoch": 38, "valid_loss": "4.313", "valid_nll_loss": "2.936", "valid_ppl": "7.65", "valid_wps": "127671", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "41872", "valid_best_loss": "4.313"}
2023-12-13 22:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 41872 updates
2023-12-13 22:09:50 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint38.pt
2023-12-13 22:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint38.pt
2023-12-13 22:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint38.pt (epoch 38 @ 41872 updates, score 4.313) (writing took 0.20450013224035501 seconds)
2023-12-13 22:09:50 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-12-13 22:09:50 | INFO | train | {"epoch": 38, "train_loss": "4.172", "train_nll_loss": "2.767", "train_ppl": "6.81", "train_wps": "60674.5", "train_ups": "16.93", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "41872", "train_lr": "0.00309078", "train_gnorm": "0.285", "train_loss_scale": "16", "train_train_wall": "62", "train_gb_free": "38.9", "train_wall": "2511"}
2023-12-13 22:09:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:09:50 | INFO | fairseq.trainer | begin training epoch 39
2023-12-13 22:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:09:52 | INFO | train_inner | {"epoch": 39, "update": 38.025, "loss": "4.145", "nll_loss": "2.737", "ppl": "6.67", "wps": "51337.8", "ups": "14.1", "wpb": "3641.4", "bsz": "148.9", "num_updates": "41900", "lr": "0.00308975", "gnorm": "0.275", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2513"}
2023-12-13 22:09:57 | INFO | train_inner | {"epoch": 39, "update": 38.116, "loss": "4.025", "nll_loss": "2.598", "ppl": "6.05", "wps": "62843.9", "ups": "17.5", "wpb": "3591.6", "bsz": "158.1", "num_updates": "42000", "lr": "0.00308607", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2518"}
2023-12-13 22:10:03 | INFO | train_inner | {"epoch": 39, "update": 38.207, "loss": "4.096", "nll_loss": "2.678", "ppl": "6.4", "wps": "63868.8", "ups": "17.74", "wpb": "3599.3", "bsz": "148.2", "num_updates": "42100", "lr": "0.0030824", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2524"}
2023-12-13 22:10:09 | INFO | train_inner | {"epoch": 39, "update": 38.298, "loss": "4.111", "nll_loss": "2.697", "ppl": "6.49", "wps": "60845.1", "ups": "16.92", "wpb": "3596.6", "bsz": "147.4", "num_updates": "42200", "lr": "0.00307875", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2530"}
2023-12-13 22:10:15 | INFO | train_inner | {"epoch": 39, "update": 38.388, "loss": "4.176", "nll_loss": "2.772", "ppl": "6.83", "wps": "65198.3", "ups": "17.81", "wpb": "3661", "bsz": "140.2", "num_updates": "42300", "lr": "0.0030751", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2535"}
2023-12-13 22:10:21 | INFO | train_inner | {"epoch": 39, "update": 38.479, "loss": "4.238", "nll_loss": "2.843", "ppl": "7.17", "wps": "59663.1", "ups": "16.82", "wpb": "3547.2", "bsz": "127.8", "num_updates": "42400", "lr": "0.00307148", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2541"}
2023-12-13 22:10:26 | INFO | train_inner | {"epoch": 39, "update": 38.57, "loss": "4.173", "nll_loss": "2.768", "ppl": "6.81", "wps": "65934.1", "ups": "18.37", "wpb": "3590.1", "bsz": "144.4", "num_updates": "42500", "lr": "0.00306786", "gnorm": "0.28", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2547"}
2023-12-13 22:10:32 | INFO | train_inner | {"epoch": 39, "update": 38.661, "loss": "4.193", "nll_loss": "2.792", "ppl": "6.92", "wps": "60548.6", "ups": "16.9", "wpb": "3583.3", "bsz": "142.2", "num_updates": "42600", "lr": "0.00306426", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2553"}
2023-12-13 22:10:38 | INFO | train_inner | {"epoch": 39, "update": 38.751, "loss": "4.175", "nll_loss": "2.774", "ppl": "6.84", "wps": "62639", "ups": "17.54", "wpb": "3571.4", "bsz": "157.8", "num_updates": "42700", "lr": "0.00306067", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2559"}
2023-12-13 22:10:44 | INFO | train_inner | {"epoch": 39, "update": 38.842, "loss": "4.234", "nll_loss": "2.841", "ppl": "7.16", "wps": "56685.8", "ups": "16.27", "wpb": "3483.5", "bsz": "138.7", "num_updates": "42800", "lr": "0.00305709", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2565"}
2023-12-13 22:10:50 | INFO | train_inner | {"epoch": 39, "update": 38.933, "loss": "4.252", "nll_loss": "2.863", "ppl": "7.27", "wps": "62250", "ups": "17.51", "wpb": "3554.4", "bsz": "141.6", "num_updates": "42900", "lr": "0.00305352", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2570"}
2023-12-13 22:10:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:10:55 | INFO | valid | {"epoch": 39, "valid_loss": "4.305", "valid_nll_loss": "2.942", "valid_ppl": "7.68", "valid_wps": "125595", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "42974", "valid_best_loss": "4.305"}
2023-12-13 22:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 42974 updates
2023-12-13 22:10:55 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint39.pt
2023-12-13 22:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint39.pt
2023-12-13 22:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint39.pt (epoch 39 @ 42974 updates, score 4.305) (writing took 0.21236304007470608 seconds)
2023-12-13 22:10:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-12-13 22:10:55 | INFO | train | {"epoch": 39, "train_loss": "4.165", "train_nll_loss": "2.76", "train_ppl": "6.77", "train_wps": "60552.6", "train_ups": "16.9", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "42974", "train_lr": "0.00305089", "train_gnorm": "0.288", "train_loss_scale": "16", "train_train_wall": "62", "train_gb_free": "38.9", "train_wall": "2576"}
2023-12-13 22:10:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:10:55 | INFO | fairseq.trainer | begin training epoch 40
2023-12-13 22:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:10:57 | INFO | train_inner | {"epoch": 40, "update": 39.024, "loss": "4.166", "nll_loss": "2.763", "ppl": "6.79", "wps": "46564.2", "ups": "12.95", "wpb": "3596.2", "bsz": "149.4", "num_updates": "43000", "lr": "0.00304997", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2578"}
2023-12-13 22:11:02 | INFO | train_inner | {"epoch": 40, "update": 39.114, "loss": "3.989", "nll_loss": "2.556", "ppl": "5.88", "wps": "76490.9", "ups": "20.78", "wpb": "3680.6", "bsz": "179", "num_updates": "43100", "lr": "0.00304643", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2583"}
2023-12-13 22:11:08 | INFO | train_inner | {"epoch": 40, "update": 39.205, "loss": "4.082", "nll_loss": "2.663", "ppl": "6.34", "wps": "62424.5", "ups": "17.4", "wpb": "3587", "bsz": "147.6", "num_updates": "43200", "lr": "0.0030429", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2589"}
2023-12-13 22:11:13 | INFO | train_inner | {"epoch": 40, "update": 39.296, "loss": "4.133", "nll_loss": "2.722", "ppl": "6.6", "wps": "65312.9", "ups": "18.01", "wpb": "3626.4", "bsz": "140.2", "num_updates": "43300", "lr": "0.00303939", "gnorm": "0.281", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2594"}
2023-12-13 22:11:19 | INFO | train_inner | {"epoch": 40, "update": 39.387, "loss": "4.176", "nll_loss": "2.771", "ppl": "6.82", "wps": "58930", "ups": "16.86", "wpb": "3494.6", "bsz": "133.8", "num_updates": "43400", "lr": "0.00303588", "gnorm": "0.302", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2600"}
2023-12-13 22:11:25 | INFO | train_inner | {"epoch": 40, "update": 39.477, "loss": "4.161", "nll_loss": "2.756", "ppl": "6.76", "wps": "63350.1", "ups": "17.89", "wpb": "3540.7", "bsz": "141.4", "num_updates": "43500", "lr": "0.00303239", "gnorm": "0.283", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2606"}
2023-12-13 22:11:30 | INFO | train_inner | {"epoch": 40, "update": 39.568, "loss": "4.217", "nll_loss": "2.819", "ppl": "7.06", "wps": "65436.3", "ups": "18.11", "wpb": "3613.7", "bsz": "137.8", "num_updates": "43600", "lr": "0.00302891", "gnorm": "0.286", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2611"}
2023-12-13 22:11:36 | INFO | train_inner | {"epoch": 40, "update": 39.659, "loss": "4.134", "nll_loss": "2.727", "ppl": "6.62", "wps": "69664.9", "ups": "19.19", "wpb": "3630.8", "bsz": "154", "num_updates": "43700", "lr": "0.00302545", "gnorm": "0.276", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2616"}
2023-12-13 22:11:42 | INFO | train_inner | {"epoch": 40, "update": 39.75, "loss": "4.202", "nll_loss": "2.802", "ppl": "6.97", "wps": "58337.9", "ups": "16.35", "wpb": "3567.7", "bsz": "133.2", "num_updates": "43800", "lr": "0.00302199", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2623"}
2023-12-13 22:11:48 | INFO | train_inner | {"epoch": 40, "update": 39.84, "loss": "4.206", "nll_loss": "2.808", "ppl": "7", "wps": "60753.3", "ups": "16.86", "wpb": "3604", "bsz": "141.1", "num_updates": "43900", "lr": "0.00301855", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2629"}
2023-12-13 22:11:53 | INFO | train_inner | {"epoch": 40, "update": 39.931, "loss": "4.234", "nll_loss": "2.843", "ppl": "7.18", "wps": "65199.8", "ups": "18.21", "wpb": "3581.3", "bsz": "156.6", "num_updates": "44000", "lr": "0.00301511", "gnorm": "0.325", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2634"}
2023-12-13 22:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:11:59 | INFO | valid | {"epoch": 40, "valid_loss": "4.322", "valid_nll_loss": "2.959", "valid_ppl": "7.78", "valid_wps": "124644", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "44076", "valid_best_loss": "4.305"}
2023-12-13 22:11:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 44076 updates
2023-12-13 22:11:59 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint40.pt
2023-12-13 22:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint40.pt
2023-12-13 22:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint40.pt (epoch 40 @ 44076 updates, score 4.322) (writing took 0.14778759889304638 seconds)
2023-12-13 22:12:00 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-12-13 22:12:00 | INFO | train | {"epoch": 40, "train_loss": "4.157", "train_nll_loss": "2.751", "train_ppl": "6.73", "train_wps": "61533.4", "train_ups": "17.17", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "44076", "train_lr": "0.00301251", "train_gnorm": "0.29", "train_loss_scale": "16", "train_train_wall": "61", "train_gb_free": "39", "train_wall": "2640"}
2023-12-13 22:12:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:12:00 | INFO | fairseq.trainer | begin training epoch 41
2023-12-13 22:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:12:01 | INFO | train_inner | {"epoch": 41, "update": 40.022, "loss": "4.201", "nll_loss": "2.803", "ppl": "6.98", "wps": "44922.6", "ups": "12.81", "wpb": "3506.7", "bsz": "137.8", "num_updates": "44100", "lr": "0.00301169", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2642"}
2023-12-13 22:12:07 | INFO | train_inner | {"epoch": 41, "update": 40.113, "loss": "4.067", "nll_loss": "2.646", "ppl": "6.26", "wps": "63175.5", "ups": "17.66", "wpb": "3576.4", "bsz": "142.8", "num_updates": "44200", "lr": "0.00300828", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2647"}
2023-12-13 22:12:13 | INFO | train_inner | {"epoch": 41, "update": 40.203, "loss": "4.074", "nll_loss": "2.655", "ppl": "6.3", "wps": "59984.9", "ups": "16.67", "wpb": "3597.7", "bsz": "157.9", "num_updates": "44300", "lr": "0.00300489", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2653"}
2023-12-13 22:12:19 | INFO | train_inner | {"epoch": 41, "update": 40.294, "loss": "4.123", "nll_loss": "2.71", "ppl": "6.55", "wps": "56445.7", "ups": "15.77", "wpb": "3578.9", "bsz": "138.8", "num_updates": "44400", "lr": "0.0030015", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2660"}
2023-12-13 22:12:24 | INFO | train_inner | {"epoch": 41, "update": 40.385, "loss": "4.115", "nll_loss": "2.701", "ppl": "6.5", "wps": "68104.5", "ups": "18.9", "wpb": "3603.3", "bsz": "138.8", "num_updates": "44500", "lr": "0.00299813", "gnorm": "0.274", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2665"}
2023-12-13 22:12:30 | INFO | train_inner | {"epoch": 41, "update": 40.475, "loss": "4.136", "nll_loss": "2.726", "ppl": "6.62", "wps": "62408", "ups": "17.53", "wpb": "3561", "bsz": "148.2", "num_updates": "44600", "lr": "0.00299476", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2671"}
2023-12-13 22:12:36 | INFO | train_inner | {"epoch": 41, "update": 40.566, "loss": "4.185", "nll_loss": "2.783", "ppl": "6.88", "wps": "59632.2", "ups": "16.68", "wpb": "3575.1", "bsz": "146.2", "num_updates": "44700", "lr": "0.00299141", "gnorm": "0.295", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2677"}
2023-12-13 22:12:42 | INFO | train_inner | {"epoch": 41, "update": 40.657, "loss": "4.197", "nll_loss": "2.796", "ppl": "6.95", "wps": "55384.2", "ups": "15.57", "wpb": "3557.7", "bsz": "130", "num_updates": "44800", "lr": "0.00298807", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2683"}
2023-12-13 22:12:48 | INFO | train_inner | {"epoch": 41, "update": 40.748, "loss": "4.163", "nll_loss": "2.758", "ppl": "6.76", "wps": "65029.5", "ups": "17.91", "wpb": "3630.2", "bsz": "145", "num_updates": "44900", "lr": "0.00298474", "gnorm": "0.282", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2689"}
2023-12-13 22:12:54 | INFO | train_inner | {"epoch": 41, "update": 40.838, "loss": "4.153", "nll_loss": "2.749", "ppl": "6.72", "wps": "62870.3", "ups": "17.48", "wpb": "3596", "bsz": "158.4", "num_updates": "45000", "lr": "0.00298142", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2695"}
2023-12-13 22:13:00 | INFO | train_inner | {"epoch": 41, "update": 40.929, "loss": "4.216", "nll_loss": "2.823", "ppl": "7.07", "wps": "59953", "ups": "16.89", "wpb": "3550.3", "bsz": "151.7", "num_updates": "45100", "lr": "0.00297812", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2700"}
2023-12-13 22:13:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:13:06 | INFO | valid | {"epoch": 41, "valid_loss": "4.323", "valid_nll_loss": "2.956", "valid_ppl": "7.76", "valid_wps": "128766", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "45178", "valid_best_loss": "4.305"}
2023-12-13 22:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 45178 updates
2023-12-13 22:13:06 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint41.pt
2023-12-13 22:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint41.pt
2023-12-13 22:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint41.pt (epoch 41 @ 45178 updates, score 4.323) (writing took 0.1483808271586895 seconds)
2023-12-13 22:13:06 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-12-13 22:13:06 | INFO | train | {"epoch": 41, "train_loss": "4.147", "train_nll_loss": "2.74", "train_ppl": "6.68", "train_wps": "59250.9", "train_ups": "16.53", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "45178", "train_lr": "0.00297554", "train_gnorm": "0.29", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "2707"}
2023-12-13 22:13:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:13:06 | INFO | fairseq.trainer | begin training epoch 42
2023-12-13 22:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:13:08 | INFO | train_inner | {"epoch": 42, "update": 41.02, "loss": "4.177", "nll_loss": "2.774", "ppl": "6.84", "wps": "44736.3", "ups": "12.4", "wpb": "3608.4", "bsz": "141.3", "num_updates": "45200", "lr": "0.00297482", "gnorm": "0.302", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2709"}
2023-12-13 22:13:13 | INFO | train_inner | {"epoch": 42, "update": 41.111, "loss": "4.067", "nll_loss": "2.647", "ppl": "6.26", "wps": "61979.5", "ups": "17.4", "wpb": "3561.4", "bsz": "145.2", "num_updates": "45300", "lr": "0.00297154", "gnorm": "0.301", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2714"}
2023-12-13 22:13:19 | INFO | train_inner | {"epoch": 42, "update": 41.201, "loss": "4.091", "nll_loss": "2.674", "ppl": "6.38", "wps": "61999.4", "ups": "17.25", "wpb": "3593.5", "bsz": "147.3", "num_updates": "45400", "lr": "0.00296826", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2720"}
2023-12-13 22:13:25 | INFO | train_inner | {"epoch": 42, "update": 41.292, "loss": "4.104", "nll_loss": "2.688", "ppl": "6.44", "wps": "63099.4", "ups": "17.56", "wpb": "3593.5", "bsz": "140.4", "num_updates": "45500", "lr": "0.002965", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2726"}
2023-12-13 22:13:31 | INFO | train_inner | {"epoch": 42, "update": 41.383, "loss": "4.143", "nll_loss": "2.733", "ppl": "6.65", "wps": "62137.3", "ups": "17.08", "wpb": "3637.8", "bsz": "139", "num_updates": "45600", "lr": "0.00296174", "gnorm": "0.338", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2732"}
2023-12-13 22:13:37 | INFO | train_inner | {"epoch": 42, "update": 41.474, "loss": "4.152", "nll_loss": "2.744", "ppl": "6.7", "wps": "60562.5", "ups": "16.83", "wpb": "3598.1", "bsz": "135", "num_updates": "45700", "lr": "0.0029585", "gnorm": "0.3", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2738"}
2023-12-13 22:13:42 | INFO | train_inner | {"epoch": 42, "update": 41.564, "loss": "4.134", "nll_loss": "2.726", "ppl": "6.62", "wps": "64743.7", "ups": "18", "wpb": "3596.2", "bsz": "154.8", "num_updates": "45800", "lr": "0.00295527", "gnorm": "0.318", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2743"}
2023-12-13 22:13:48 | INFO | train_inner | {"epoch": 42, "update": 41.655, "loss": "4.101", "nll_loss": "2.691", "ppl": "6.46", "wps": "67995.9", "ups": "18.91", "wpb": "3595.6", "bsz": "181.4", "num_updates": "45900", "lr": "0.00295205", "gnorm": "0.279", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2748"}
2023-12-13 22:13:53 | INFO | train_inner | {"epoch": 42, "update": 41.746, "loss": "4.191", "nll_loss": "2.793", "ppl": "6.93", "wps": "64065.3", "ups": "17.86", "wpb": "3587.9", "bsz": "151.7", "num_updates": "46000", "lr": "0.00294884", "gnorm": "0.283", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2754"}
2023-12-13 22:13:59 | INFO | train_inner | {"epoch": 42, "update": 41.837, "loss": "4.213", "nll_loss": "2.816", "ppl": "7.04", "wps": "55665.4", "ups": "15.7", "wpb": "3546.3", "bsz": "125.8", "num_updates": "46100", "lr": "0.00294564", "gnorm": "0.296", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2760"}
2023-12-13 22:14:05 | INFO | train_inner | {"epoch": 42, "update": 41.927, "loss": "4.244", "nll_loss": "2.853", "ppl": "7.22", "wps": "59165.9", "ups": "16.88", "wpb": "3504.2", "bsz": "133.1", "num_updates": "46200", "lr": "0.00294245", "gnorm": "0.297", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2766"}
2023-12-13 22:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:14:12 | INFO | valid | {"epoch": 42, "valid_loss": "4.317", "valid_nll_loss": "2.939", "valid_ppl": "7.67", "valid_wps": "127695", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "46280", "valid_best_loss": "4.305"}
2023-12-13 22:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 46280 updates
2023-12-13 22:14:12 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint42.pt
2023-12-13 22:14:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint42.pt
2023-12-13 22:14:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint42.pt (epoch 42 @ 46280 updates, score 4.317) (writing took 0.14603498298674822 seconds)
2023-12-13 22:14:12 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-12-13 22:14:12 | INFO | train | {"epoch": 42, "train_loss": "4.146", "train_nll_loss": "2.738", "train_ppl": "6.67", "train_wps": "60320.9", "train_ups": "16.83", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "46280", "train_lr": "0.00293991", "train_gnorm": "0.299", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2773"}
2023-12-13 22:14:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:14:12 | INFO | fairseq.trainer | begin training epoch 43
2023-12-13 22:14:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:14:13 | INFO | train_inner | {"epoch": 43, "update": 42.018, "loss": "4.155", "nll_loss": "2.75", "ppl": "6.73", "wps": "49405.9", "ups": "13.65", "wpb": "3618.2", "bsz": "151.6", "num_updates": "46300", "lr": "0.00293927", "gnorm": "0.291", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2774"}
2023-12-13 22:14:19 | INFO | train_inner | {"epoch": 43, "update": 42.109, "loss": "4.08", "nll_loss": "2.66", "ppl": "6.32", "wps": "59294.2", "ups": "16.34", "wpb": "3629", "bsz": "139.4", "num_updates": "46400", "lr": "0.0029361", "gnorm": "0.278", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2780"}
2023-12-13 22:14:25 | INFO | train_inner | {"epoch": 43, "update": 42.2, "loss": "4.073", "nll_loss": "2.653", "ppl": "6.29", "wps": "60644.3", "ups": "16.86", "wpb": "3596.9", "bsz": "145.3", "num_updates": "46500", "lr": "0.00293294", "gnorm": "0.284", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2786"}
2023-12-13 22:14:31 | INFO | train_inner | {"epoch": 43, "update": 42.29, "loss": "4.09", "nll_loss": "2.674", "ppl": "6.38", "wps": "60434.7", "ups": "17.05", "wpb": "3543.7", "bsz": "151.4", "num_updates": "46600", "lr": "0.00292979", "gnorm": "0.294", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2792"}
2023-12-13 22:14:36 | INFO | train_inner | {"epoch": 43, "update": 42.381, "loss": "4.124", "nll_loss": "2.713", "ppl": "6.56", "wps": "63800.9", "ups": "17.78", "wpb": "3587.8", "bsz": "146.9", "num_updates": "46700", "lr": "0.00292666", "gnorm": "0.306", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2797"}
2023-12-13 22:14:42 | INFO | train_inner | {"epoch": 43, "update": 42.472, "loss": "4.106", "nll_loss": "2.694", "ppl": "6.47", "wps": "63028.6", "ups": "17.42", "wpb": "3618.4", "bsz": "156.2", "num_updates": "46800", "lr": "0.00292353", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2803"}
2023-12-13 22:14:48 | INFO | train_inner | {"epoch": 43, "update": 42.563, "loss": "4.192", "nll_loss": "2.791", "ppl": "6.92", "wps": "55579.2", "ups": "15.93", "wpb": "3488", "bsz": "130", "num_updates": "46900", "lr": "0.00292041", "gnorm": "0.341", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2809"}
2023-12-13 22:14:54 | INFO | train_inner | {"epoch": 43, "update": 42.653, "loss": "4.194", "nll_loss": "2.794", "ppl": "6.94", "wps": "59040.7", "ups": "16.59", "wpb": "3557.8", "bsz": "141", "num_updates": "47000", "lr": "0.0029173", "gnorm": "0.302", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2815"}
2023-12-13 22:15:00 | INFO | train_inner | {"epoch": 43, "update": 42.744, "loss": "4.167", "nll_loss": "2.765", "ppl": "6.8", "wps": "63540.6", "ups": "17.56", "wpb": "3619.4", "bsz": "146.8", "num_updates": "47100", "lr": "0.0029142", "gnorm": "0.293", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2821"}
2023-12-13 22:15:05 | INFO | train_inner | {"epoch": 43, "update": 42.835, "loss": "4.169", "nll_loss": "2.767", "ppl": "6.81", "wps": "69305.9", "ups": "19.35", "wpb": "3581.3", "bsz": "147.5", "num_updates": "47200", "lr": "0.00291111", "gnorm": "0.293", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2826"}
2023-12-13 22:15:11 | INFO | train_inner | {"epoch": 43, "update": 42.926, "loss": "4.161", "nll_loss": "2.759", "ppl": "6.77", "wps": "66867.7", "ups": "18.62", "wpb": "3591.7", "bsz": "154.1", "num_updates": "47300", "lr": "0.00290803", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2831"}
2023-12-13 22:15:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:15:17 | INFO | valid | {"epoch": 43, "valid_loss": "4.307", "valid_nll_loss": "2.945", "valid_ppl": "7.7", "valid_wps": "127903", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "47382", "valid_best_loss": "4.305"}
2023-12-13 22:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 47382 updates
2023-12-13 22:15:17 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint43.pt
2023-12-13 22:15:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint43.pt
2023-12-13 22:15:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint43.pt (epoch 43 @ 47382 updates, score 4.307) (writing took 0.14418250042945147 seconds)
2023-12-13 22:15:17 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-12-13 22:15:17 | INFO | train | {"epoch": 43, "train_loss": "4.137", "train_nll_loss": "2.729", "train_ppl": "6.63", "train_wps": "60574", "train_ups": "16.9", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "47382", "train_lr": "0.00290552", "train_gnorm": "0.296", "train_loss_scale": "32", "train_train_wall": "62", "train_gb_free": "39", "train_wall": "2838"}
2023-12-13 22:15:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:15:17 | INFO | fairseq.trainer | begin training epoch 44
2023-12-13 22:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:15:18 | INFO | train_inner | {"epoch": 44, "update": 43.016, "loss": "4.19", "nll_loss": "2.791", "ppl": "6.92", "wps": "49048.3", "ups": "13.71", "wpb": "3577.3", "bsz": "139.2", "num_updates": "47400", "lr": "0.00290496", "gnorm": "0.296", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2839"}
2023-12-13 22:15:24 | INFO | train_inner | {"epoch": 44, "update": 43.107, "loss": "4.05", "nll_loss": "2.625", "ppl": "6.17", "wps": "63446.1", "ups": "17.71", "wpb": "3582.6", "bsz": "143.4", "num_updates": "47500", "lr": "0.00290191", "gnorm": "0.288", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2844"}
2023-12-13 22:15:29 | INFO | train_inner | {"epoch": 44, "update": 43.198, "loss": "4.05", "nll_loss": "2.627", "ppl": "6.18", "wps": "67917.8", "ups": "18.63", "wpb": "3645.6", "bsz": "152.7", "num_updates": "47600", "lr": "0.00289886", "gnorm": "0.278", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "2850"}
2023-12-13 22:15:35 | INFO | train_inner | {"epoch": 44, "update": 43.289, "loss": "4.111", "nll_loss": "2.696", "ppl": "6.48", "wps": "59780.5", "ups": "16.53", "wpb": "3615.5", "bsz": "130.9", "num_updates": "47700", "lr": "0.00289581", "gnorm": "0.288", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2856"}
2023-12-13 22:15:40 | INFO | train_inner | {"epoch": 44, "update": 43.379, "loss": "4.078", "nll_loss": "2.66", "ppl": "6.32", "wps": "65674.8", "ups": "18.35", "wpb": "3578.4", "bsz": "154.6", "num_updates": "47800", "lr": "0.00289278", "gnorm": "0.293", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2861"}
2023-12-13 22:15:47 | INFO | train_inner | {"epoch": 44, "update": 43.47, "loss": "4.144", "nll_loss": "2.735", "ppl": "6.66", "wps": "57256.3", "ups": "16.29", "wpb": "3515.1", "bsz": "142.9", "num_updates": "47900", "lr": "0.00288976", "gnorm": "0.321", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2867"}
2023-12-13 22:15:52 | INFO | train_inner | {"epoch": 44, "update": 43.561, "loss": "4.117", "nll_loss": "2.707", "ppl": "6.53", "wps": "60200.2", "ups": "17.04", "wpb": "3533.5", "bsz": "155.1", "num_updates": "48000", "lr": "0.00288675", "gnorm": "0.291", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2873"}
2023-12-13 22:15:58 | INFO | train_inner | {"epoch": 44, "update": 43.652, "loss": "4.169", "nll_loss": "2.768", "ppl": "6.81", "wps": "62254.8", "ups": "17.2", "wpb": "3618.8", "bsz": "151.8", "num_updates": "48100", "lr": "0.00288375", "gnorm": "0.29", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2879"}
2023-12-13 22:16:05 | INFO | train_inner | {"epoch": 44, "update": 43.742, "loss": "4.182", "nll_loss": "2.78", "ppl": "6.87", "wps": "54813.9", "ups": "15.31", "wpb": "3580.9", "bsz": "127", "num_updates": "48200", "lr": "0.00288076", "gnorm": "0.288", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2886"}
2023-12-13 22:16:11 | INFO | train_inner | {"epoch": 44, "update": 43.833, "loss": "4.165", "nll_loss": "2.762", "ppl": "6.78", "wps": "59988.9", "ups": "16.74", "wpb": "3584.5", "bsz": "152.6", "num_updates": "48300", "lr": "0.00287777", "gnorm": "0.302", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2892"}
2023-12-13 22:16:16 | INFO | train_inner | {"epoch": 44, "update": 43.924, "loss": "4.155", "nll_loss": "2.752", "ppl": "6.74", "wps": "62416.2", "ups": "17.28", "wpb": "3612.2", "bsz": "153.4", "num_updates": "48400", "lr": "0.0028748", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2897"}
2023-12-13 22:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:16:23 | INFO | valid | {"epoch": 44, "valid_loss": "4.298", "valid_nll_loss": "2.938", "valid_ppl": "7.66", "valid_wps": "127351", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "48484", "valid_best_loss": "4.298"}
2023-12-13 22:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 48484 updates
2023-12-13 22:16:23 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint44.pt
2023-12-13 22:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint44.pt
2023-12-13 22:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint44.pt (epoch 44 @ 48484 updates, score 4.298) (writing took 0.2116371151059866 seconds)
2023-12-13 22:16:23 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-12-13 22:16:23 | INFO | train | {"epoch": 44, "train_loss": "4.13", "train_nll_loss": "2.721", "train_ppl": "6.59", "train_wps": "59544.1", "train_ups": "16.62", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "48484", "train_lr": "0.00287231", "train_gnorm": "0.294", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2904"}
2023-12-13 22:16:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:16:23 | INFO | fairseq.trainer | begin training epoch 45
2023-12-13 22:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:16:24 | INFO | train_inner | {"epoch": 45, "update": 44.015, "loss": "4.197", "nll_loss": "2.799", "ppl": "6.96", "wps": "46942.4", "ups": "13.34", "wpb": "3519.3", "bsz": "139.9", "num_updates": "48500", "lr": "0.00287183", "gnorm": "0.302", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2905"}
2023-12-13 22:16:30 | INFO | train_inner | {"epoch": 45, "update": 44.105, "loss": "4.042", "nll_loss": "2.616", "ppl": "6.13", "wps": "59979.2", "ups": "16.95", "wpb": "3537.7", "bsz": "135", "num_updates": "48600", "lr": "0.00286888", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2911"}
2023-12-13 22:16:35 | INFO | train_inner | {"epoch": 45, "update": 44.196, "loss": "4.043", "nll_loss": "2.619", "ppl": "6.14", "wps": "70779.3", "ups": "19.51", "wpb": "3627.6", "bsz": "153.7", "num_updates": "48700", "lr": "0.00286593", "gnorm": "0.284", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2916"}
2023-12-13 22:16:41 | INFO | train_inner | {"epoch": 45, "update": 44.287, "loss": "4.11", "nll_loss": "2.695", "ppl": "6.48", "wps": "57223.1", "ups": "15.97", "wpb": "3583.3", "bsz": "133.2", "num_updates": "48800", "lr": "0.00286299", "gnorm": "0.306", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2922"}
2023-12-13 22:16:48 | INFO | train_inner | {"epoch": 45, "update": 44.377, "loss": "4.178", "nll_loss": "2.775", "ppl": "6.84", "wps": "54296.4", "ups": "15.33", "wpb": "3542.6", "bsz": "128", "num_updates": "48900", "lr": "0.00286006", "gnorm": "0.311", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2929"}
2023-12-13 22:16:53 | INFO | train_inner | {"epoch": 45, "update": 44.468, "loss": "4.118", "nll_loss": "2.705", "ppl": "6.52", "wps": "64332.9", "ups": "17.7", "wpb": "3635", "bsz": "144.9", "num_updates": "49000", "lr": "0.00285714", "gnorm": "0.284", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2934"}
2023-12-13 22:16:59 | INFO | train_inner | {"epoch": 45, "update": 44.559, "loss": "4.137", "nll_loss": "2.729", "ppl": "6.63", "wps": "63415.6", "ups": "17.55", "wpb": "3613.1", "bsz": "152.4", "num_updates": "49100", "lr": "0.00285423", "gnorm": "0.296", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2940"}
2023-12-13 22:17:05 | INFO | train_inner | {"epoch": 45, "update": 44.65, "loss": "4.175", "nll_loss": "2.773", "ppl": "6.84", "wps": "61211.6", "ups": "17", "wpb": "3599.7", "bsz": "141.4", "num_updates": "49200", "lr": "0.00285133", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2946"}
2023-12-13 22:17:10 | INFO | train_inner | {"epoch": 45, "update": 44.74, "loss": "4.162", "nll_loss": "2.758", "ppl": "6.77", "wps": "65617.7", "ups": "18.37", "wpb": "3571.3", "bsz": "143.8", "num_updates": "49300", "lr": "0.00284844", "gnorm": "0.298", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2951"}
2023-12-13 22:17:16 | INFO | train_inner | {"epoch": 45, "update": 44.831, "loss": "4.14", "nll_loss": "2.735", "ppl": "6.66", "wps": "63991.9", "ups": "17.87", "wpb": "3580.6", "bsz": "156", "num_updates": "49400", "lr": "0.00284555", "gnorm": "0.288", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2957"}
2023-12-13 22:17:22 | INFO | train_inner | {"epoch": 45, "update": 44.922, "loss": "4.143", "nll_loss": "2.738", "ppl": "6.67", "wps": "59554.4", "ups": "16.64", "wpb": "3578", "bsz": "149.8", "num_updates": "49500", "lr": "0.00284268", "gnorm": "0.296", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2963"}
2023-12-13 22:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:17:29 | INFO | valid | {"epoch": 45, "valid_loss": "4.306", "valid_nll_loss": "2.924", "valid_ppl": "7.59", "valid_wps": "127796", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "49586", "valid_best_loss": "4.298"}
2023-12-13 22:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 49586 updates
2023-12-13 22:17:29 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint45.pt
2023-12-13 22:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint45.pt
2023-12-13 22:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint45.pt (epoch 45 @ 49586 updates, score 4.306) (writing took 0.14904269482940435 seconds)
2023-12-13 22:17:29 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-12-13 22:17:29 | INFO | train | {"epoch": 45, "train_loss": "4.123", "train_nll_loss": "2.713", "train_ppl": "6.56", "train_wps": "60067.4", "train_ups": "16.76", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "49586", "train_lr": "0.00284021", "train_gnorm": "0.295", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "2970"}
2023-12-13 22:17:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:17:29 | INFO | fairseq.trainer | begin training epoch 46
2023-12-13 22:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:17:30 | INFO | train_inner | {"epoch": 46, "update": 45.013, "loss": "4.105", "nll_loss": "2.694", "ppl": "6.47", "wps": "47433", "ups": "13.22", "wpb": "3589.1", "bsz": "157.2", "num_updates": "49600", "lr": "0.00283981", "gnorm": "0.298", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2971"}
2023-12-13 22:17:36 | INFO | train_inner | {"epoch": 46, "update": 45.103, "loss": "4.024", "nll_loss": "2.596", "ppl": "6.04", "wps": "61748.7", "ups": "16.82", "wpb": "3671.9", "bsz": "142.6", "num_updates": "49700", "lr": "0.00283695", "gnorm": "0.277", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2976"}
2023-12-13 22:17:42 | INFO | train_inner | {"epoch": 46, "update": 45.194, "loss": "4.078", "nll_loss": "2.659", "ppl": "6.32", "wps": "55425.5", "ups": "15.72", "wpb": "3525.4", "bsz": "136.2", "num_updates": "49800", "lr": "0.0028341", "gnorm": "0.295", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "2983"}
2023-12-13 22:17:47 | INFO | train_inner | {"epoch": 46, "update": 45.285, "loss": "4.031", "nll_loss": "2.607", "ppl": "6.09", "wps": "71363.5", "ups": "19.65", "wpb": "3631.6", "bsz": "167.4", "num_updates": "49900", "lr": "0.00283126", "gnorm": "0.282", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "2988"}
2023-12-13 22:17:53 | INFO | train_inner | {"epoch": 46, "update": 45.376, "loss": "4.08", "nll_loss": "2.663", "ppl": "6.34", "wps": "59194.5", "ups": "16.71", "wpb": "3541.6", "bsz": "153.3", "num_updates": "50000", "lr": "0.00282843", "gnorm": "0.307", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "2994"}
2023-12-13 22:17:59 | INFO | train_inner | {"epoch": 46, "update": 45.466, "loss": "4.088", "nll_loss": "2.673", "ppl": "6.38", "wps": "64850.4", "ups": "17.81", "wpb": "3641.9", "bsz": "157.3", "num_updates": "50100", "lr": "0.0028256", "gnorm": "0.291", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3000"}
2023-12-13 22:18:04 | INFO | train_inner | {"epoch": 46, "update": 45.557, "loss": "4.165", "nll_loss": "2.761", "ppl": "6.78", "wps": "62833.9", "ups": "17.64", "wpb": "3561.3", "bsz": "136.1", "num_updates": "50200", "lr": "0.00282279", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3005"}
2023-12-13 22:18:10 | INFO | train_inner | {"epoch": 46, "update": 45.648, "loss": "4.198", "nll_loss": "2.8", "ppl": "6.96", "wps": "58917.7", "ups": "16.48", "wpb": "3575.6", "bsz": "134.6", "num_updates": "50300", "lr": "0.00281998", "gnorm": "0.302", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3011"}
2023-12-13 22:18:16 | INFO | train_inner | {"epoch": 46, "update": 45.739, "loss": "4.098", "nll_loss": "2.686", "ppl": "6.44", "wps": "63363.6", "ups": "17.58", "wpb": "3604", "bsz": "158.4", "num_updates": "50400", "lr": "0.00281718", "gnorm": "0.287", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3017"}
2023-12-13 22:18:22 | INFO | train_inner | {"epoch": 46, "update": 45.829, "loss": "4.172", "nll_loss": "2.77", "ppl": "6.82", "wps": "60685.5", "ups": "17.16", "wpb": "3536.8", "bsz": "142.2", "num_updates": "50500", "lr": "0.00281439", "gnorm": "0.306", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3023"}
2023-12-13 22:18:28 | INFO | train_inner | {"epoch": 46, "update": 45.92, "loss": "4.195", "nll_loss": "2.797", "ppl": "6.95", "wps": "60188.6", "ups": "16.93", "wpb": "3554.2", "bsz": "136.4", "num_updates": "50600", "lr": "0.00281161", "gnorm": "0.303", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3029"}
2023-12-13 22:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:18:35 | INFO | valid | {"epoch": 46, "valid_loss": "4.296", "valid_nll_loss": "2.928", "valid_ppl": "7.61", "valid_wps": "124848", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "50688", "valid_best_loss": "4.296"}
2023-12-13 22:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 50688 updates
2023-12-13 22:18:35 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint46.pt
2023-12-13 22:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint46.pt
2023-12-13 22:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint46.pt (epoch 46 @ 50688 updates, score 4.296) (writing took 0.21455804724246264 seconds)
2023-12-13 22:18:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-12-13 22:18:35 | INFO | train | {"epoch": 46, "train_loss": "4.116", "train_nll_loss": "2.706", "train_ppl": "6.52", "train_wps": "59567.7", "train_ups": "16.62", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "50688", "train_lr": "0.00280917", "train_gnorm": "0.295", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "3036"}
2023-12-13 22:18:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:18:35 | INFO | fairseq.trainer | begin training epoch 47
2023-12-13 22:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:18:36 | INFO | train_inner | {"epoch": 47, "update": 46.011, "loss": "4.167", "nll_loss": "2.764", "ppl": "6.79", "wps": "44257.1", "ups": "12.34", "wpb": "3585.4", "bsz": "133.8", "num_updates": "50700", "lr": "0.00280883", "gnorm": "0.295", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3037"}
2023-12-13 22:18:42 | INFO | train_inner | {"epoch": 47, "update": 46.102, "loss": "4.036", "nll_loss": "2.607", "ppl": "6.09", "wps": "60053.3", "ups": "16.56", "wpb": "3625.7", "bsz": "128.6", "num_updates": "50800", "lr": "0.00280607", "gnorm": "0.305", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3043"}
2023-12-13 22:18:47 | INFO | train_inner | {"epoch": 47, "update": 46.192, "loss": "3.999", "nll_loss": "2.569", "ppl": "5.93", "wps": "67020.4", "ups": "18.56", "wpb": "3611", "bsz": "157.4", "num_updates": "50900", "lr": "0.00280331", "gnorm": "0.287", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3048"}
2023-12-13 22:18:54 | INFO | train_inner | {"epoch": 47, "update": 46.283, "loss": "4.065", "nll_loss": "2.643", "ppl": "6.25", "wps": "56482.2", "ups": "16.19", "wpb": "3488.7", "bsz": "146.9", "num_updates": "51000", "lr": "0.00280056", "gnorm": "0.31", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3054"}
2023-12-13 22:19:00 | INFO | train_inner | {"epoch": 47, "update": 46.374, "loss": "4.119", "nll_loss": "2.707", "ppl": "6.53", "wps": "57490.4", "ups": "16.13", "wpb": "3564.7", "bsz": "141.4", "num_updates": "51100", "lr": "0.00279782", "gnorm": "0.298", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3061"}
2023-12-13 22:19:06 | INFO | train_inner | {"epoch": 47, "update": 46.465, "loss": "4.103", "nll_loss": "2.689", "ppl": "6.45", "wps": "58659.8", "ups": "16.56", "wpb": "3541.5", "bsz": "144.6", "num_updates": "51200", "lr": "0.00279508", "gnorm": "0.305", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3067"}
2023-12-13 22:19:12 | INFO | train_inner | {"epoch": 47, "update": 46.555, "loss": "4.161", "nll_loss": "2.755", "ppl": "6.75", "wps": "57781.4", "ups": "16.2", "wpb": "3567.6", "bsz": "126", "num_updates": "51300", "lr": "0.00279236", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3073"}
2023-12-13 22:19:17 | INFO | train_inner | {"epoch": 47, "update": 46.646, "loss": "4.106", "nll_loss": "2.696", "ppl": "6.48", "wps": "77020.3", "ups": "21.01", "wpb": "3665.4", "bsz": "164.7", "num_updates": "51400", "lr": "0.00278964", "gnorm": "0.289", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3078"}
2023-12-13 22:19:23 | INFO | train_inner | {"epoch": 47, "update": 46.737, "loss": "4.158", "nll_loss": "2.753", "ppl": "6.74", "wps": "58482.5", "ups": "16.46", "wpb": "3553.4", "bsz": "132.4", "num_updates": "51500", "lr": "0.00278693", "gnorm": "0.303", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3084"}
2023-12-13 22:19:28 | INFO | train_inner | {"epoch": 47, "update": 46.828, "loss": "4.145", "nll_loss": "2.741", "ppl": "6.69", "wps": "62680.4", "ups": "17.75", "wpb": "3531.3", "bsz": "157.2", "num_updates": "51600", "lr": "0.00278423", "gnorm": "0.301", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3089"}
2023-12-13 22:19:34 | INFO | train_inner | {"epoch": 47, "update": 46.918, "loss": "4.149", "nll_loss": "2.747", "ppl": "6.71", "wps": "66342.2", "ups": "18.25", "wpb": "3635.1", "bsz": "157.4", "num_updates": "51700", "lr": "0.00278154", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3095"}
2023-12-13 22:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:19:41 | INFO | valid | {"epoch": 47, "valid_loss": "4.294", "valid_nll_loss": "2.926", "valid_ppl": "7.6", "valid_wps": "126598", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "51790", "valid_best_loss": "4.294"}
2023-12-13 22:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 51790 updates
2023-12-13 22:19:41 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint47.pt
2023-12-13 22:19:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint47.pt
2023-12-13 22:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint47.pt (epoch 47 @ 51790 updates, score 4.294) (writing took 0.21922357007861137 seconds)
2023-12-13 22:19:41 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-12-13 22:19:41 | INFO | train | {"epoch": 47, "train_loss": "4.109", "train_nll_loss": "2.697", "train_ppl": "6.48", "train_wps": "60261.7", "train_ups": "16.82", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "51790", "train_lr": "0.00277912", "train_gnorm": "0.298", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "3102"}
2023-12-13 22:19:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:19:41 | INFO | fairseq.trainer | begin training epoch 48
2023-12-13 22:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:19:41 | INFO | train_inner | {"epoch": 48, "update": 47.009, "loss": "4.182", "nll_loss": "2.784", "ppl": "6.89", "wps": "47972.1", "ups": "13.28", "wpb": "3611.6", "bsz": "140.2", "num_updates": "51800", "lr": "0.00277885", "gnorm": "0.298", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3102"}
2023-12-13 22:19:47 | INFO | train_inner | {"epoch": 48, "update": 47.1, "loss": "4.024", "nll_loss": "2.596", "ppl": "6.05", "wps": "62613.6", "ups": "17.52", "wpb": "3574.5", "bsz": "146.7", "num_updates": "51900", "lr": "0.00277617", "gnorm": "0.294", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3108"}
2023-12-13 22:19:53 | INFO | train_inner | {"epoch": 48, "update": 47.191, "loss": "4.019", "nll_loss": "2.591", "ppl": "6.03", "wps": "61431.3", "ups": "16.97", "wpb": "3619.8", "bsz": "142.3", "num_updates": "52000", "lr": "0.0027735", "gnorm": "0.291", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3114"}
2023-12-13 22:19:59 | INFO | train_inner | {"epoch": 48, "update": 47.281, "loss": "4.074", "nll_loss": "2.654", "ppl": "6.29", "wps": "61360.3", "ups": "17.12", "wpb": "3584.6", "bsz": "144.5", "num_updates": "52100", "lr": "0.00277084", "gnorm": "0.314", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3120"}
2023-12-13 22:20:04 | INFO | train_inner | {"epoch": 48, "update": 47.372, "loss": "4.087", "nll_loss": "2.671", "ppl": "6.37", "wps": "65534.6", "ups": "18.34", "wpb": "3574.1", "bsz": "147", "num_updates": "52200", "lr": "0.00276818", "gnorm": "0.294", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3125"}
2023-12-13 22:20:10 | INFO | train_inner | {"epoch": 48, "update": 47.463, "loss": "4.043", "nll_loss": "2.621", "ppl": "6.15", "wps": "62652.8", "ups": "17.56", "wpb": "3567.7", "bsz": "154.5", "num_updates": "52300", "lr": "0.00276553", "gnorm": "0.295", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3131"}
2023-12-13 22:20:16 | INFO | train_inner | {"epoch": 48, "update": 47.554, "loss": "4.168", "nll_loss": "2.766", "ppl": "6.8", "wps": "60224.9", "ups": "16.71", "wpb": "3604.4", "bsz": "138.7", "num_updates": "52400", "lr": "0.00276289", "gnorm": "0.303", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3137"}
2023-12-13 22:20:22 | INFO | train_inner | {"epoch": 48, "update": 47.644, "loss": "4.139", "nll_loss": "2.731", "ppl": "6.64", "wps": "60388.1", "ups": "17.16", "wpb": "3518.3", "bsz": "140.4", "num_updates": "52500", "lr": "0.00276026", "gnorm": "0.307", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3143"}
2023-12-13 22:20:27 | INFO | train_inner | {"epoch": 48, "update": 47.735, "loss": "4.121", "nll_loss": "2.713", "ppl": "6.56", "wps": "69597.1", "ups": "18.87", "wpb": "3688.5", "bsz": "152.4", "num_updates": "52600", "lr": "0.00275764", "gnorm": "0.295", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3148"}
2023-12-13 22:20:34 | INFO | train_inner | {"epoch": 48, "update": 47.826, "loss": "4.182", "nll_loss": "2.781", "ppl": "6.87", "wps": "55289.3", "ups": "15.57", "wpb": "3551.2", "bsz": "128.7", "num_updates": "52700", "lr": "0.00275502", "gnorm": "0.304", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3154"}
2023-12-13 22:20:39 | INFO | train_inner | {"epoch": 48, "update": 47.917, "loss": "4.137", "nll_loss": "2.733", "ppl": "6.65", "wps": "64858.8", "ups": "17.91", "wpb": "3622.3", "bsz": "155.7", "num_updates": "52800", "lr": "0.00275241", "gnorm": "0.285", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3160"}
2023-12-13 22:20:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:20:46 | INFO | valid | {"epoch": 48, "valid_loss": "4.319", "valid_nll_loss": "2.943", "valid_ppl": "7.69", "valid_wps": "126873", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "52892", "valid_best_loss": "4.294"}
2023-12-13 22:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 52892 updates
2023-12-13 22:20:46 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint48.pt
2023-12-13 22:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint48.pt
2023-12-13 22:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint48.pt (epoch 48 @ 52892 updates, score 4.319) (writing took 0.15283016208559275 seconds)
2023-12-13 22:20:46 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-12-13 22:20:46 | INFO | train | {"epoch": 48, "train_loss": "4.104", "train_nll_loss": "2.691", "train_ppl": "6.46", "train_wps": "60311", "train_ups": "16.83", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "52892", "train_lr": "0.00275001", "train_gnorm": "0.299", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "3167"}
2023-12-13 22:20:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:20:46 | INFO | fairseq.trainer | begin training epoch 49
2023-12-13 22:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:20:47 | INFO | train_inner | {"epoch": 49, "update": 48.007, "loss": "4.147", "nll_loss": "2.742", "ppl": "6.69", "wps": "44903.2", "ups": "12.75", "wpb": "3521.3", "bsz": "145", "num_updates": "52900", "lr": "0.00274981", "gnorm": "0.308", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3168"}
2023-12-13 22:20:53 | INFO | train_inner | {"epoch": 49, "update": 48.098, "loss": "3.999", "nll_loss": "2.564", "ppl": "5.91", "wps": "60362.2", "ups": "17.13", "wpb": "3524.8", "bsz": "137.1", "num_updates": "53000", "lr": "0.00274721", "gnorm": "0.297", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3174"}
2023-12-13 22:20:59 | INFO | train_inner | {"epoch": 49, "update": 48.189, "loss": "4.032", "nll_loss": "2.606", "ppl": "6.09", "wps": "61866.6", "ups": "16.87", "wpb": "3667.2", "bsz": "147.5", "num_updates": "53100", "lr": "0.00274462", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3180"}
2023-12-13 22:21:05 | INFO | train_inner | {"epoch": 49, "update": 48.279, "loss": "4.087", "nll_loss": "2.67", "ppl": "6.36", "wps": "60941.7", "ups": "17.02", "wpb": "3580.3", "bsz": "139.9", "num_updates": "53200", "lr": "0.00274204", "gnorm": "0.309", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3185"}
2023-12-13 22:21:10 | INFO | train_inner | {"epoch": 49, "update": 48.37, "loss": "4.044", "nll_loss": "2.624", "ppl": "6.16", "wps": "71760.8", "ups": "20.24", "wpb": "3545.9", "bsz": "165", "num_updates": "53300", "lr": "0.00273947", "gnorm": "0.287", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3190"}
2023-12-13 22:21:16 | INFO | train_inner | {"epoch": 49, "update": 48.461, "loss": "4.131", "nll_loss": "2.722", "ppl": "6.6", "wps": "58342.9", "ups": "16.48", "wpb": "3539.3", "bsz": "142.9", "num_updates": "53400", "lr": "0.0027369", "gnorm": "0.31", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3196"}
2023-12-13 22:21:22 | INFO | train_inner | {"epoch": 49, "update": 48.552, "loss": "4.103", "nll_loss": "2.691", "ppl": "6.46", "wps": "60983.6", "ups": "16.87", "wpb": "3615.5", "bsz": "149.7", "num_updates": "53500", "lr": "0.00273434", "gnorm": "0.291", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3202"}
2023-12-13 22:21:27 | INFO | train_inner | {"epoch": 49, "update": 48.642, "loss": "4.106", "nll_loss": "2.693", "ppl": "6.47", "wps": "64697.9", "ups": "18.07", "wpb": "3580.8", "bsz": "147.9", "num_updates": "53600", "lr": "0.00273179", "gnorm": "0.3", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3208"}
2023-12-13 22:21:33 | INFO | train_inner | {"epoch": 49, "update": 48.733, "loss": "4.104", "nll_loss": "2.693", "ppl": "6.47", "wps": "59502.7", "ups": "16.64", "wpb": "3576.2", "bsz": "151.8", "num_updates": "53700", "lr": "0.00272925", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3214"}
2023-12-13 22:21:39 | INFO | train_inner | {"epoch": 49, "update": 48.824, "loss": "4.154", "nll_loss": "2.749", "ppl": "6.72", "wps": "61861.1", "ups": "17.49", "wpb": "3536.1", "bsz": "145.8", "num_updates": "53800", "lr": "0.00272671", "gnorm": "0.312", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3220"}
2023-12-13 22:21:45 | INFO | train_inner | {"epoch": 49, "update": 48.915, "loss": "4.187", "nll_loss": "2.789", "ppl": "6.91", "wps": "58368.6", "ups": "16.32", "wpb": "3577.5", "bsz": "131.8", "num_updates": "53900", "lr": "0.00272418", "gnorm": "0.3", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3226"}
2023-12-13 22:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:21:52 | INFO | valid | {"epoch": 49, "valid_loss": "4.295", "valid_nll_loss": "2.931", "valid_ppl": "7.63", "valid_wps": "119718", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "53994", "valid_best_loss": "4.294"}
2023-12-13 22:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 53994 updates
2023-12-13 22:21:52 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint49.pt
2023-12-13 22:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint49.pt
2023-12-13 22:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint49.pt (epoch 49 @ 53994 updates, score 4.295) (writing took 0.1505167055875063 seconds)
2023-12-13 22:21:52 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-12-13 22:21:52 | INFO | train | {"epoch": 49, "train_loss": "4.099", "train_nll_loss": "2.686", "train_ppl": "6.43", "train_wps": "60131.7", "train_ups": "16.78", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "53994", "train_lr": "0.00272181", "train_gnorm": "0.3", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "3233"}
2023-12-13 22:21:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:21:52 | INFO | fairseq.trainer | begin training epoch 50
2023-12-13 22:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:21:52 | INFO | train_inner | {"epoch": 50, "update": 49.005, "loss": "4.137", "nll_loss": "2.732", "ppl": "6.64", "wps": "49637", "ups": "13.57", "wpb": "3658.2", "bsz": "146.2", "num_updates": "54000", "lr": "0.00272166", "gnorm": "0.305", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3233"}
2023-12-13 22:21:59 | INFO | train_inner | {"epoch": 50, "update": 49.096, "loss": "4.01", "nll_loss": "2.579", "ppl": "5.98", "wps": "57397.1", "ups": "16.09", "wpb": "3566.9", "bsz": "134.7", "num_updates": "54100", "lr": "0.00271914", "gnorm": "0.286", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3239"}
2023-12-13 22:22:04 | INFO | train_inner | {"epoch": 50, "update": 49.187, "loss": "3.986", "nll_loss": "2.554", "ppl": "5.87", "wps": "63940", "ups": "17.72", "wpb": "3607.5", "bsz": "153", "num_updates": "54200", "lr": "0.00271663", "gnorm": "0.292", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3245"}
2023-12-13 22:22:10 | INFO | train_inner | {"epoch": 50, "update": 49.278, "loss": "4.045", "nll_loss": "2.623", "ppl": "6.16", "wps": "65322.8", "ups": "18.09", "wpb": "3611.5", "bsz": "155.5", "num_updates": "54300", "lr": "0.00271413", "gnorm": "0.293", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3251"}
2023-12-13 22:22:16 | INFO | train_inner | {"epoch": 50, "update": 49.368, "loss": "4.154", "nll_loss": "2.746", "ppl": "6.71", "wps": "54197.7", "ups": "15.22", "wpb": "3561.8", "bsz": "121.6", "num_updates": "54400", "lr": "0.00271163", "gnorm": "0.309", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3257"}
2023-12-13 22:22:22 | INFO | train_inner | {"epoch": 50, "update": 49.459, "loss": "4.115", "nll_loss": "2.704", "ppl": "6.52", "wps": "63699", "ups": "17.81", "wpb": "3576.8", "bsz": "138.3", "num_updates": "54500", "lr": "0.00270914", "gnorm": "0.31", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3263"}
2023-12-13 22:22:27 | INFO | train_inner | {"epoch": 50, "update": 49.55, "loss": "4.027", "nll_loss": "2.604", "ppl": "6.08", "wps": "72659.7", "ups": "19.87", "wpb": "3656.9", "bsz": "169.8", "num_updates": "54600", "lr": "0.00270666", "gnorm": "0.29", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3268"}
2023-12-13 22:22:32 | INFO | train_inner | {"epoch": 50, "update": 49.641, "loss": "4.077", "nll_loss": "2.662", "ppl": "6.33", "wps": "64250.1", "ups": "18.12", "wpb": "3545.4", "bsz": "156.2", "num_updates": "54700", "lr": "0.00270418", "gnorm": "0.298", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3273"}
2023-12-13 22:22:38 | INFO | train_inner | {"epoch": 50, "update": 49.731, "loss": "4.121", "nll_loss": "2.714", "ppl": "6.56", "wps": "62270.3", "ups": "17.18", "wpb": "3625.2", "bsz": "147", "num_updates": "54800", "lr": "0.00270172", "gnorm": "0.314", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3279"}
2023-12-13 22:22:45 | INFO | train_inner | {"epoch": 50, "update": 49.822, "loss": "4.149", "nll_loss": "2.743", "ppl": "6.7", "wps": "54676.5", "ups": "15.65", "wpb": "3493.5", "bsz": "136.9", "num_updates": "54900", "lr": "0.00269925", "gnorm": "0.321", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3285"}
2023-12-13 22:22:51 | INFO | train_inner | {"epoch": 50, "update": 49.913, "loss": "4.184", "nll_loss": "2.785", "ppl": "6.89", "wps": "60413.4", "ups": "16.86", "wpb": "3584", "bsz": "133.4", "num_updates": "55000", "lr": "0.0026968", "gnorm": "0.301", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3291"}
2023-12-13 22:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:22:57 | INFO | valid | {"epoch": 50, "valid_loss": "4.284", "valid_nll_loss": "2.927", "valid_ppl": "7.61", "valid_wps": "126447", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "55096", "valid_best_loss": "4.284"}
2023-12-13 22:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 55096 updates
2023-12-13 22:22:57 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint50.pt
2023-12-13 22:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint50.pt
2023-12-13 22:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint50.pt (epoch 50 @ 55096 updates, score 4.284) (writing took 0.21558843087404966 seconds)
2023-12-13 22:22:58 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-12-13 22:22:58 | INFO | train | {"epoch": 50, "train_loss": "4.092", "train_nll_loss": "2.677", "train_ppl": "6.4", "train_wps": "60009.3", "train_ups": "16.75", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "55096", "train_lr": "0.00269445", "train_gnorm": "0.301", "train_loss_scale": "32", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "3299"}
2023-12-13 22:22:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:22:58 | INFO | fairseq.trainer | begin training epoch 51
2023-12-13 22:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:22:58 | INFO | train_inner | {"epoch": 51, "update": 50.004, "loss": "4.145", "nll_loss": "2.742", "ppl": "6.69", "wps": "47882.8", "ups": "13.31", "wpb": "3597.4", "bsz": "150.6", "num_updates": "55100", "lr": "0.00269435", "gnorm": "0.292", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3299"}
2023-12-13 22:23:04 | INFO | train_inner | {"epoch": 51, "update": 50.094, "loss": "4.016", "nll_loss": "2.587", "ppl": "6.01", "wps": "58202.4", "ups": "16.29", "wpb": "3571.9", "bsz": "140.3", "num_updates": "55200", "lr": "0.00269191", "gnorm": "0.298", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3305"}
2023-12-13 22:23:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-12-13 22:23:11 | INFO | train_inner | {"epoch": 51, "update": 50.186, "loss": "4.054", "nll_loss": "2.631", "ppl": "6.2", "wps": "55518.1", "ups": "15.48", "wpb": "3585.8", "bsz": "135.7", "num_updates": "55300", "lr": "0.00268947", "gnorm": "0.309", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3312"}
2023-12-13 22:23:16 | INFO | train_inner | {"epoch": 51, "update": 50.277, "loss": "3.99", "nll_loss": "2.559", "ppl": "5.89", "wps": "66984.6", "ups": "18.7", "wpb": "3581.6", "bsz": "159.1", "num_updates": "55400", "lr": "0.00268705", "gnorm": "0.29", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3317"}
2023-12-13 22:23:22 | INFO | train_inner | {"epoch": 51, "update": 50.368, "loss": "4.051", "nll_loss": "2.63", "ppl": "6.19", "wps": "65633.8", "ups": "18.18", "wpb": "3610.6", "bsz": "147.1", "num_updates": "55500", "lr": "0.00268462", "gnorm": "0.294", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3322"}
2023-12-13 22:23:27 | INFO | train_inner | {"epoch": 51, "update": 50.458, "loss": "4.089", "nll_loss": "2.675", "ppl": "6.39", "wps": "62738.5", "ups": "17.82", "wpb": "3520.1", "bsz": "147.4", "num_updates": "55600", "lr": "0.00268221", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3328"}
2023-12-13 22:23:33 | INFO | train_inner | {"epoch": 51, "update": 50.549, "loss": "4.076", "nll_loss": "2.66", "ppl": "6.32", "wps": "63583", "ups": "17.69", "wpb": "3594.3", "bsz": "152.4", "num_updates": "55700", "lr": "0.0026798", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3334"}
2023-12-13 22:23:39 | INFO | train_inner | {"epoch": 51, "update": 50.64, "loss": "4.125", "nll_loss": "2.716", "ppl": "6.57", "wps": "60703.6", "ups": "16.87", "wpb": "3599", "bsz": "144.9", "num_updates": "55800", "lr": "0.0026774", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3340"}
2023-12-13 22:23:45 | INFO | train_inner | {"epoch": 51, "update": 50.73, "loss": "4.133", "nll_loss": "2.726", "ppl": "6.62", "wps": "61440.2", "ups": "17.09", "wpb": "3594.8", "bsz": "145.3", "num_updates": "55900", "lr": "0.002675", "gnorm": "0.354", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3345"}
2023-12-13 22:23:51 | INFO | train_inner | {"epoch": 51, "update": 50.821, "loss": "4.128", "nll_loss": "2.72", "ppl": "6.59", "wps": "59390.4", "ups": "16.47", "wpb": "3605", "bsz": "140.1", "num_updates": "56000", "lr": "0.00267261", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3352"}
2023-12-13 22:23:56 | INFO | train_inner | {"epoch": 51, "update": 50.912, "loss": "4.137", "nll_loss": "2.733", "ppl": "6.65", "wps": "63995", "ups": "17.88", "wpb": "3578.4", "bsz": "155.2", "num_updates": "56100", "lr": "0.00267023", "gnorm": "0.296", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3357"}
2023-12-13 22:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:24:04 | INFO | valid | {"epoch": 51, "valid_loss": "4.295", "valid_nll_loss": "2.918", "valid_ppl": "7.56", "valid_wps": "127331", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "56197", "valid_best_loss": "4.284"}
2023-12-13 22:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 56197 updates
2023-12-13 22:24:04 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint51.pt
2023-12-13 22:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint51.pt
2023-12-13 22:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint51.pt (epoch 51 @ 56197 updates, score 4.295) (writing took 0.14696599077433348 seconds)
2023-12-13 22:24:04 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-12-13 22:24:04 | INFO | train | {"epoch": 51, "train_loss": "4.087", "train_nll_loss": "2.673", "train_ppl": "6.38", "train_wps": "59834.4", "train_ups": "16.69", "train_wpb": "3584.3", "train_bsz": "145.5", "train_num_updates": "56197", "train_lr": "0.00266792", "train_gnorm": "0.304", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "38.9", "train_wall": "3365"}
2023-12-13 22:24:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:24:04 | INFO | fairseq.trainer | begin training epoch 52
2023-12-13 22:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:24:04 | INFO | train_inner | {"epoch": 52, "update": 51.003, "loss": "4.172", "nll_loss": "2.772", "ppl": "6.83", "wps": "45891.8", "ups": "12.79", "wpb": "3588.9", "bsz": "130.8", "num_updates": "56200", "lr": "0.00266785", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3365"}
2023-12-13 22:24:11 | INFO | train_inner | {"epoch": 52, "update": 51.093, "loss": "4.004", "nll_loss": "2.575", "ppl": "5.96", "wps": "53228.9", "ups": "15.14", "wpb": "3516.5", "bsz": "145", "num_updates": "56300", "lr": "0.00266548", "gnorm": "0.33", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "3372"}
2023-12-13 22:24:16 | INFO | train_inner | {"epoch": 52, "update": 51.184, "loss": "3.995", "nll_loss": "2.563", "ppl": "5.91", "wps": "62136.8", "ups": "17.4", "wpb": "3572.1", "bsz": "146.6", "num_updates": "56400", "lr": "0.00266312", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3377"}
2023-12-13 22:24:22 | INFO | train_inner | {"epoch": 52, "update": 51.275, "loss": "4.048", "nll_loss": "2.625", "ppl": "6.17", "wps": "61213.2", "ups": "16.96", "wpb": "3608.8", "bsz": "140.6", "num_updates": "56500", "lr": "0.00266076", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3383"}
2023-12-13 22:24:28 | INFO | train_inner | {"epoch": 52, "update": 51.366, "loss": "4.073", "nll_loss": "2.654", "ppl": "6.3", "wps": "64932.6", "ups": "17.89", "wpb": "3628.8", "bsz": "143.8", "num_updates": "56600", "lr": "0.00265841", "gnorm": "0.31", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3389"}
2023-12-13 22:24:33 | INFO | train_inner | {"epoch": 52, "update": 51.456, "loss": "4.092", "nll_loss": "2.678", "ppl": "6.4", "wps": "64852.2", "ups": "17.85", "wpb": "3634", "bsz": "146.4", "num_updates": "56700", "lr": "0.00265606", "gnorm": "0.306", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3394"}
2023-12-13 22:24:39 | INFO | train_inner | {"epoch": 52, "update": 51.547, "loss": "4.083", "nll_loss": "2.668", "ppl": "6.36", "wps": "61263.2", "ups": "17.3", "wpb": "3542", "bsz": "143.8", "num_updates": "56800", "lr": "0.00265372", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3400"}
2023-12-13 22:24:46 | INFO | train_inner | {"epoch": 52, "update": 51.638, "loss": "4.126", "nll_loss": "2.718", "ppl": "6.58", "wps": "52320", "ups": "14.69", "wpb": "3562", "bsz": "143.9", "num_updates": "56900", "lr": "0.00265139", "gnorm": "0.31", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "3407"}
2023-12-13 22:24:52 | INFO | train_inner | {"epoch": 52, "update": 51.729, "loss": "4.076", "nll_loss": "2.66", "ppl": "6.32", "wps": "58542.2", "ups": "16.18", "wpb": "3617.4", "bsz": "147.4", "num_updates": "57000", "lr": "0.00264906", "gnorm": "0.295", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3413"}
2023-12-13 22:24:58 | INFO | train_inner | {"epoch": 52, "update": 51.819, "loss": "4.147", "nll_loss": "2.742", "ppl": "6.69", "wps": "60845.7", "ups": "16.98", "wpb": "3584.2", "bsz": "142.9", "num_updates": "57100", "lr": "0.00264674", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3419"}
2023-12-13 22:25:04 | INFO | train_inner | {"epoch": 52, "update": 51.91, "loss": "4.148", "nll_loss": "2.745", "ppl": "6.7", "wps": "63757.4", "ups": "17.72", "wpb": "3598.5", "bsz": "147.3", "num_updates": "57200", "lr": "0.00264443", "gnorm": "0.315", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3425"}
2023-12-13 22:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:25:11 | INFO | valid | {"epoch": 52, "valid_loss": "4.293", "valid_nll_loss": "2.911", "valid_ppl": "7.52", "valid_wps": "122741", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "57299", "valid_best_loss": "4.284"}
2023-12-13 22:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 57299 updates
2023-12-13 22:25:11 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint52.pt
2023-12-13 22:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint52.pt
2023-12-13 22:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint52.pt (epoch 52 @ 57299 updates, score 4.293) (writing took 0.16108108218759298 seconds)
2023-12-13 22:25:11 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-12-13 22:25:11 | INFO | train | {"epoch": 52, "train_loss": "4.083", "train_nll_loss": "2.667", "train_ppl": "6.35", "train_wps": "58230.3", "train_ups": "16.25", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "57299", "train_lr": "0.00264214", "train_gnorm": "0.306", "train_loss_scale": "16", "train_train_wall": "65", "train_gb_free": "39", "train_wall": "3432"}
2023-12-13 22:25:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:25:12 | INFO | fairseq.trainer | begin training epoch 53
2023-12-13 22:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:25:12 | INFO | train_inner | {"epoch": 53, "update": 52.001, "loss": "4.111", "nll_loss": "2.701", "ppl": "6.5", "wps": "45454.9", "ups": "12.77", "wpb": "3560.8", "bsz": "153.8", "num_updates": "57300", "lr": "0.00264212", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3432"}
2023-12-13 22:25:17 | INFO | train_inner | {"epoch": 53, "update": 52.092, "loss": "3.983", "nll_loss": "2.55", "ppl": "5.86", "wps": "60453.8", "ups": "17.28", "wpb": "3498.5", "bsz": "144.6", "num_updates": "57400", "lr": "0.00263982", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3438"}
2023-12-13 22:25:23 | INFO | train_inner | {"epoch": 53, "update": 52.182, "loss": "4.031", "nll_loss": "2.605", "ppl": "6.09", "wps": "59948.6", "ups": "16.53", "wpb": "3625.9", "bsz": "148.7", "num_updates": "57500", "lr": "0.00263752", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3444"}
2023-12-13 22:25:29 | INFO | train_inner | {"epoch": 53, "update": 52.273, "loss": "4.04", "nll_loss": "2.617", "ppl": "6.13", "wps": "60572.9", "ups": "16.86", "wpb": "3591.9", "bsz": "140.9", "num_updates": "57600", "lr": "0.00263523", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3450"}
2023-12-13 22:25:36 | INFO | train_inner | {"epoch": 53, "update": 52.364, "loss": "4.061", "nll_loss": "2.641", "ppl": "6.24", "wps": "55493.4", "ups": "15.48", "wpb": "3585", "bsz": "142.8", "num_updates": "57700", "lr": "0.00263295", "gnorm": "0.32", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3457"}
2023-12-13 22:25:42 | INFO | train_inner | {"epoch": 53, "update": 52.455, "loss": "4.082", "nll_loss": "2.665", "ppl": "6.34", "wps": "58382.4", "ups": "16.44", "wpb": "3552", "bsz": "135", "num_updates": "57800", "lr": "0.00263067", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3463"}
2023-12-13 22:25:47 | INFO | train_inner | {"epoch": 53, "update": 52.545, "loss": "4.035", "nll_loss": "2.613", "ppl": "6.12", "wps": "67128", "ups": "18.63", "wpb": "3604.1", "bsz": "160.6", "num_updates": "57900", "lr": "0.0026284", "gnorm": "0.295", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3468"}
2023-12-13 22:25:54 | INFO | train_inner | {"epoch": 53, "update": 52.636, "loss": "4.128", "nll_loss": "2.721", "ppl": "6.59", "wps": "56591.4", "ups": "15.88", "wpb": "3564", "bsz": "146.6", "num_updates": "58000", "lr": "0.00262613", "gnorm": "0.316", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3474"}
2023-12-13 22:25:59 | INFO | train_inner | {"epoch": 53, "update": 52.727, "loss": "4.109", "nll_loss": "2.698", "ppl": "6.49", "wps": "65252.1", "ups": "18.06", "wpb": "3612.9", "bsz": "141.2", "num_updates": "58100", "lr": "0.00262387", "gnorm": "0.308", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3480"}
2023-12-13 22:26:06 | INFO | train_inner | {"epoch": 53, "update": 52.818, "loss": "4.142", "nll_loss": "2.736", "ppl": "6.66", "wps": "55728.1", "ups": "15.66", "wpb": "3559.5", "bsz": "132", "num_updates": "58200", "lr": "0.00262161", "gnorm": "0.308", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3486"}
2023-12-13 22:26:11 | INFO | train_inner | {"epoch": 53, "update": 52.908, "loss": "4.1", "nll_loss": "2.691", "ppl": "6.46", "wps": "66922.9", "ups": "18.56", "wpb": "3605.8", "bsz": "160.9", "num_updates": "58300", "lr": "0.00261936", "gnorm": "0.3", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3492"}
2023-12-13 22:26:16 | INFO | train_inner | {"epoch": 53, "update": 52.999, "loss": "4.153", "nll_loss": "2.751", "ppl": "6.73", "wps": "66194.1", "ups": "18.32", "wpb": "3613.6", "bsz": "145.1", "num_updates": "58400", "lr": "0.00261712", "gnorm": "0.295", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3497"}
2023-12-13 22:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:26:18 | INFO | valid | {"epoch": 53, "valid_loss": "4.275", "valid_nll_loss": "2.922", "valid_ppl": "7.58", "valid_wps": "123700", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "58401", "valid_best_loss": "4.275"}
2023-12-13 22:26:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 58401 updates
2023-12-13 22:26:18 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint53.pt
2023-12-13 22:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint53.pt
2023-12-13 22:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint53.pt (epoch 53 @ 58401 updates, score 4.275) (writing took 0.21618868317455053 seconds)
2023-12-13 22:26:18 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-12-13 22:26:18 | INFO | train | {"epoch": 53, "train_loss": "4.078", "train_nll_loss": "2.662", "train_ppl": "6.33", "train_wps": "59260.3", "train_ups": "16.54", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "58401", "train_lr": "0.0026171", "train_gnorm": "0.304", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "3499"}
2023-12-13 22:26:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:26:18 | INFO | fairseq.trainer | begin training epoch 54
2023-12-13 22:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:26:24 | INFO | train_inner | {"epoch": 54, "update": 53.09, "loss": "3.943", "nll_loss": "2.505", "ppl": "5.68", "wps": "47192.9", "ups": "13.18", "wpb": "3581.7", "bsz": "153.3", "num_updates": "58500", "lr": "0.00261488", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3505"}
2023-12-13 22:26:31 | INFO | train_inner | {"epoch": 54, "update": 53.181, "loss": "4.035", "nll_loss": "2.611", "ppl": "6.11", "wps": "53620.9", "ups": "15.26", "wpb": "3512.8", "bsz": "131.7", "num_updates": "58600", "lr": "0.00261265", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3511"}
2023-12-13 22:26:36 | INFO | train_inner | {"epoch": 54, "update": 53.271, "loss": "4.051", "nll_loss": "2.63", "ppl": "6.19", "wps": "60722.7", "ups": "16.97", "wpb": "3577.5", "bsz": "146.6", "num_updates": "58700", "lr": "0.00261042", "gnorm": "0.318", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3517"}
2023-12-13 22:26:42 | INFO | train_inner | {"epoch": 54, "update": 53.362, "loss": "4.01", "nll_loss": "2.584", "ppl": "6", "wps": "65033.5", "ups": "18", "wpb": "3612.2", "bsz": "157.4", "num_updates": "58800", "lr": "0.0026082", "gnorm": "0.298", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3523"}
2023-12-13 22:26:48 | INFO | train_inner | {"epoch": 54, "update": 53.453, "loss": "4.102", "nll_loss": "2.689", "ppl": "6.45", "wps": "55315.5", "ups": "15.71", "wpb": "3520.1", "bsz": "139.6", "num_updates": "58900", "lr": "0.00260599", "gnorm": "0.314", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3529"}
2023-12-13 22:26:54 | INFO | train_inner | {"epoch": 54, "update": 53.544, "loss": "4.118", "nll_loss": "2.707", "ppl": "6.53", "wps": "64828.7", "ups": "18.08", "wpb": "3585", "bsz": "135.5", "num_updates": "59000", "lr": "0.00260378", "gnorm": "0.307", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3535"}
2023-12-13 22:26:59 | INFO | train_inner | {"epoch": 54, "update": 53.634, "loss": "4.098", "nll_loss": "2.685", "ppl": "6.43", "wps": "66329.9", "ups": "18.42", "wpb": "3601.5", "bsz": "139.1", "num_updates": "59100", "lr": "0.00260157", "gnorm": "0.304", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3540"}
2023-12-13 22:27:05 | INFO | train_inner | {"epoch": 54, "update": 53.725, "loss": "4.098", "nll_loss": "2.687", "ppl": "6.44", "wps": "60993.5", "ups": "16.98", "wpb": "3592.6", "bsz": "146.6", "num_updates": "59200", "lr": "0.00259938", "gnorm": "0.305", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3546"}
2023-12-13 22:27:11 | INFO | train_inner | {"epoch": 54, "update": 53.816, "loss": "4.133", "nll_loss": "2.726", "ppl": "6.62", "wps": "61363.2", "ups": "16.85", "wpb": "3641", "bsz": "143.4", "num_updates": "59300", "lr": "0.00259718", "gnorm": "0.3", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3552"}
2023-12-13 22:27:17 | INFO | train_inner | {"epoch": 54, "update": 53.907, "loss": "4.101", "nll_loss": "2.691", "ppl": "6.46", "wps": "64681.4", "ups": "17.89", "wpb": "3614.8", "bsz": "147.8", "num_updates": "59400", "lr": "0.002595", "gnorm": "0.306", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3558"}
2023-12-13 22:27:22 | INFO | train_inner | {"epoch": 54, "update": 53.997, "loss": "4.079", "nll_loss": "2.666", "ppl": "6.34", "wps": "64525.3", "ups": "17.98", "wpb": "3589.2", "bsz": "161.7", "num_updates": "59500", "lr": "0.00259281", "gnorm": "0.311", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3563"}
2023-12-13 22:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:27:24 | INFO | valid | {"epoch": 54, "valid_loss": "4.302", "valid_nll_loss": "2.945", "valid_ppl": "7.7", "valid_wps": "126183", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "59503", "valid_best_loss": "4.275"}
2023-12-13 22:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 59503 updates
2023-12-13 22:27:24 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint54.pt
2023-12-13 22:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint54.pt
2023-12-13 22:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint54.pt (epoch 54 @ 59503 updates, score 4.302) (writing took 0.16252474673092365 seconds)
2023-12-13 22:27:24 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-12-13 22:27:24 | INFO | train | {"epoch": 54, "train_loss": "4.071", "train_nll_loss": "2.654", "train_ppl": "6.29", "train_wps": "59880.3", "train_ups": "16.71", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "59503", "train_lr": "0.00259275", "train_gnorm": "0.305", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "3565"}
2023-12-13 22:27:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:27:24 | INFO | fairseq.trainer | begin training epoch 55
2023-12-13 22:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:27:30 | INFO | train_inner | {"epoch": 55, "update": 54.088, "loss": "3.987", "nll_loss": "2.555", "ppl": "5.88", "wps": "44298.6", "ups": "12.57", "wpb": "3524.2", "bsz": "143", "num_updates": "59600", "lr": "0.00259064", "gnorm": "0.316", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3571"}
2023-12-13 22:27:36 | INFO | train_inner | {"epoch": 55, "update": 54.179, "loss": "4.029", "nll_loss": "2.605", "ppl": "6.09", "wps": "60101.7", "ups": "16.59", "wpb": "3623.4", "bsz": "145.2", "num_updates": "59700", "lr": "0.00258847", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3577"}
2023-12-13 22:27:42 | INFO | train_inner | {"epoch": 55, "update": 54.27, "loss": "4.018", "nll_loss": "2.592", "ppl": "6.03", "wps": "62108.4", "ups": "17.46", "wpb": "3558.2", "bsz": "146.5", "num_updates": "59800", "lr": "0.0025863", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3583"}
2023-12-13 22:27:48 | INFO | train_inner | {"epoch": 55, "update": 54.36, "loss": "4.057", "nll_loss": "2.637", "ppl": "6.22", "wps": "60961.8", "ups": "17.12", "wpb": "3561.1", "bsz": "143.2", "num_updates": "59900", "lr": "0.00258414", "gnorm": "0.308", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3589"}
2023-12-13 22:27:54 | INFO | train_inner | {"epoch": 55, "update": 54.451, "loss": "4.083", "nll_loss": "2.667", "ppl": "6.35", "wps": "56969.2", "ups": "16.05", "wpb": "3549.3", "bsz": "136.4", "num_updates": "60000", "lr": "0.00258199", "gnorm": "0.311", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3595"}
2023-12-13 22:28:00 | INFO | train_inner | {"epoch": 55, "update": 54.542, "loss": "4.077", "nll_loss": "2.662", "ppl": "6.33", "wps": "61470.3", "ups": "17.26", "wpb": "3561.4", "bsz": "148.4", "num_updates": "60100", "lr": "0.00257984", "gnorm": "0.314", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3601"}
2023-12-13 22:28:06 | INFO | train_inner | {"epoch": 55, "update": 54.632, "loss": "4.107", "nll_loss": "2.695", "ppl": "6.48", "wps": "62931.7", "ups": "17.41", "wpb": "3615.2", "bsz": "139", "num_updates": "60200", "lr": "0.0025777", "gnorm": "0.308", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3606"}
2023-12-13 22:28:11 | INFO | train_inner | {"epoch": 55, "update": 54.723, "loss": "4.059", "nll_loss": "2.642", "ppl": "6.24", "wps": "64393.1", "ups": "17.78", "wpb": "3622.4", "bsz": "157.5", "num_updates": "60300", "lr": "0.00257556", "gnorm": "0.309", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3612"}
2023-12-13 22:28:17 | INFO | train_inner | {"epoch": 55, "update": 54.814, "loss": "4.114", "nll_loss": "2.704", "ppl": "6.52", "wps": "57453.9", "ups": "16.05", "wpb": "3579.2", "bsz": "137.7", "num_updates": "60400", "lr": "0.00257343", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3618"}
2023-12-13 22:28:23 | INFO | train_inner | {"epoch": 55, "update": 54.905, "loss": "4.106", "nll_loss": "2.696", "ppl": "6.48", "wps": "61748.7", "ups": "16.95", "wpb": "3642.2", "bsz": "147.8", "num_updates": "60500", "lr": "0.0025713", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3624"}
2023-12-13 22:28:29 | INFO | train_inner | {"epoch": 55, "update": 54.995, "loss": "4.097", "nll_loss": "2.687", "ppl": "6.44", "wps": "61742.7", "ups": "17.28", "wpb": "3572.1", "bsz": "150.5", "num_updates": "60600", "lr": "0.00256917", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3630"}
2023-12-13 22:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:28:31 | INFO | valid | {"epoch": 55, "valid_loss": "4.281", "valid_nll_loss": "2.916", "valid_ppl": "7.55", "valid_wps": "126738", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "60605", "valid_best_loss": "4.275"}
2023-12-13 22:28:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 60605 updates
2023-12-13 22:28:31 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint55.pt
2023-12-13 22:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_94628/checkpoint55.pt
2023-12-13 22:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_94628/checkpoint55.pt (epoch 55 @ 60605 updates, score 4.281) (writing took 0.14954021014273167 seconds)
2023-12-13 22:28:31 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-12-13 22:28:31 | INFO | train | {"epoch": 55, "train_loss": "4.065", "train_nll_loss": "2.648", "train_ppl": "6.27", "train_wps": "59026.8", "train_ups": "16.47", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "60605", "train_lr": "0.00256907", "train_gnorm": "0.307", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "3632"}
2023-12-13 22:28:31 | INFO | fairseq_cli.train | done training in 3631.8 seconds
