2023-12-13 22:28:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-12-13 22:28:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 84903, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': True, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/home/jprado/experiments/fairseq_dadaptation_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 55, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.01], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoint_d0_1e-0_84903', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=84903, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=True, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/home/jprado/experiments/fairseq_dadaptation_module', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='dadapt-adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_d0_1e-0_84903', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='lstm_wiseman_iwslt_de_en'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': Namespace(no_progress_bar=False, log_interval=100, log_format='json', log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=84903, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=True, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='/home/jprado/experiments/fairseq_dadaptation_module', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='dadapt-adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=4096, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=4096, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='lstm_wiseman_iwslt_de_en', max_epoch=55, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.01], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoint_d0_1e-0_84903', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, share_decoder_input_output_embed=True, share_all_embeddings=False, data='data-bin/iwslt14.tokenized.de-en', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, warmup_updates=4000, warmup_init_lr=-1, pad=1, eos=2, unk=3, dropout=0.3, no_seed_provided=False, encoder_embed_dim=256, encoder_dropout_in=0, encoder_dropout_out=0, decoder_embed_dim=256, decoder_out_embed_dim=256, decoder_dropout_in=0, decoder_dropout_out=0.3, encoder_embed_path=None, encoder_freeze_embed=False, encoder_hidden_size=256, encoder_layers=1, encoder_bidirectional=False, decoder_embed_path=None, decoder_freeze_embed=False, decoder_hidden_size=256, decoder_layers=1, decoder_attention='1', adaptive_softmax_cutoff='10000,50000,200000', _name='dadapt-adam'), 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.01]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-12-13 22:28:46 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2023-12-13 22:28:46 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2023-12-13 22:28:46 | INFO | fairseq_cli.train | LSTMModel(
  (encoder): LSTMEncoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 256, padding_idx=1)
    (lstm): LSTM(256, 256)
  )
  (decoder): LSTMDecoder(
    (dropout_in_module): FairseqDropout()
    (dropout_out_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 256, padding_idx=1)
    (layers): ModuleList(
      (0): LSTMCell(512, 256)
    )
    (attention): AttentionLayer(
      (input_proj): Linear(in_features=256, out_features=256, bias=False)
      (output_proj): Linear(in_features=512, out_features=256, bias=False)
    )
  )
)
2023-12-13 22:28:46 | INFO | fairseq_cli.train | task: TranslationTask
2023-12-13 22:28:46 | INFO | fairseq_cli.train | model: LSTMModel
2023-12-13 22:28:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-12-13 22:28:46 | INFO | fairseq_cli.train | num. shared model params: 5,474,304 (num. trained: 5,474,304)
2023-12-13 22:28:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-12-13 22:28:46 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2023-12-13 22:28:46 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2023-12-13 22:28:46 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2023-12-13 22:28:48 | INFO | fairseq.trainer | detected shared parameter: decoder.attention.input_proj.bias <- decoder.attention.output_proj.bias
2023-12-13 22:28:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 22:28:48 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.392 GB ; name = NVIDIA A100-SXM4-40GB                   
2023-12-13 22:28:48 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2023-12-13 22:28:48 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2023-12-13 22:28:48 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-12-13 22:28:48 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoint_d0_1e-0_84903/checkpoint_last.pt
2023-12-13 22:28:48 | INFO | fairseq.trainer | No existing checkpoint found checkpoint_d0_1e-0_84903/checkpoint_last.pt
2023-12-13 22:28:48 | INFO | fairseq.trainer | loading train data for epoch 1
2023-12-13 22:28:48 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2023-12-13 22:28:48 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2023-12-13 22:28:48 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Using decoupled weight decay
2023-12-13 22:28:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:28:48 | INFO | fairseq.trainer | begin training epoch 1
2023-12-13 22:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-12-13 22:28:54 | INFO | train_inner | {"epoch": 1, "update": 0.092, "loss": "11.564", "nll_loss": "11.378", "ppl": "2660.94", "wps": "62809.8", "ups": "17.37", "wpb": "3617", "bsz": "137.6", "num_updates": "100", "lr": "0.00025", "gnorm": "0.55", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "6"}
2023-12-13 22:29:00 | INFO | train_inner | {"epoch": 1, "update": 0.182, "loss": "9.939", "nll_loss": "9.454", "ppl": "701.57", "wps": "57567.1", "ups": "16.12", "wpb": "3570.4", "bsz": "136.9", "num_updates": "200", "lr": "0.0005", "gnorm": "0.747", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "12"}
2023-12-13 22:29:06 | INFO | train_inner | {"epoch": 1, "update": 0.273, "loss": "9.753", "nll_loss": "9.245", "ppl": "606.85", "wps": "57422", "ups": "16.38", "wpb": "3506.1", "bsz": "133.1", "num_updates": "300", "lr": "0.00075", "gnorm": "0.836", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "19"}
2023-12-13 22:29:12 | INFO | train_inner | {"epoch": 1, "update": 0.364, "loss": "9.332", "nll_loss": "8.77", "ppl": "436.45", "wps": "61823.6", "ups": "17.27", "wpb": "3579.3", "bsz": "160.3", "num_updates": "400", "lr": "0.001", "gnorm": "0.73", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "24"}
2023-12-13 22:29:17 | INFO | train_inner | {"epoch": 1, "update": 0.455, "loss": "8.867", "nll_loss": "8.234", "ppl": "301.03", "wps": "69215", "ups": "19.12", "wpb": "3620.3", "bsz": "170.2", "num_updates": "500", "lr": "0.00125", "gnorm": "0.63", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "30"}
2023-12-13 22:29:24 | INFO | train_inner | {"epoch": 1, "update": 0.545, "loss": "8.631", "nll_loss": "7.951", "ppl": "247.51", "wps": "55997.2", "ups": "15.76", "wpb": "3553.2", "bsz": "133.3", "num_updates": "600", "lr": "0.0015", "gnorm": "0.539", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "36"}
2023-12-13 22:29:30 | INFO | train_inner | {"epoch": 1, "update": 0.636, "loss": "8.304", "nll_loss": "7.569", "ppl": "189.9", "wps": "60990.1", "ups": "17.05", "wpb": "3576.5", "bsz": "142.3", "num_updates": "700", "lr": "0.00175", "gnorm": "0.505", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "42"}
2023-12-13 22:29:36 | INFO | train_inner | {"epoch": 1, "update": 0.727, "loss": "8.007", "nll_loss": "7.223", "ppl": "149.38", "wps": "56980.8", "ups": "15.79", "wpb": "3608", "bsz": "137.4", "num_updates": "800", "lr": "0.002", "gnorm": "0.511", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "48"}
2023-12-13 22:29:42 | INFO | train_inner | {"epoch": 1, "update": 0.818, "loss": "7.599", "nll_loss": "6.75", "ppl": "107.67", "wps": "63599.8", "ups": "17.83", "wpb": "3567.5", "bsz": "151.5", "num_updates": "900", "lr": "0.00225", "gnorm": "0.509", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "54"}
2023-12-13 22:29:48 | INFO | train_inner | {"epoch": 1, "update": 0.908, "loss": "7.266", "nll_loss": "6.36", "ppl": "82.14", "wps": "58938", "ups": "16.37", "wpb": "3600.2", "bsz": "150.9", "num_updates": "1000", "lr": "0.0025", "gnorm": "0.52", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "60"}
2023-12-13 22:29:54 | INFO | train_inner | {"epoch": 1, "update": 0.999, "loss": "6.987", "nll_loss": "6.03", "ppl": "65.36", "wps": "61386.7", "ups": "16.95", "wpb": "3620.7", "bsz": "142.5", "num_updates": "1100", "lr": "0.00275", "gnorm": "0.456", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "66"}
2023-12-13 22:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:29:55 | INFO | valid | {"epoch": 1, "valid_loss": "6.951", "valid_nll_loss": "5.998", "valid_ppl": "63.92", "valid_wps": "129088", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "1101"}
2023-12-13 22:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1101 updates
2023-12-13 22:29:55 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint1.pt
2023-12-13 22:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint1.pt
2023-12-13 22:29:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint1.pt (epoch 1 @ 1101 updates, score 6.951) (writing took 0.15768620278686285 seconds)
2023-12-13 22:29:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-12-13 22:29:55 | INFO | train | {"epoch": 1, "train_loss": "8.747", "train_nll_loss": "8.084", "train_ppl": "271.39", "train_wps": "58880.8", "train_ups": "16.43", "train_wpb": "3583.6", "train_bsz": "145", "train_num_updates": "1101", "train_lr": "0.0027525", "train_gnorm": "0.594", "train_loss_scale": "64", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "67"}
2023-12-13 22:29:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:29:55 | INFO | fairseq.trainer | begin training epoch 2
2023-12-13 22:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:30:02 | INFO | train_inner | {"epoch": 2, "update": 1.09, "loss": "6.737", "nll_loss": "5.731", "ppl": "53.12", "wps": "44616.5", "ups": "12.28", "wpb": "3633.2", "bsz": "144.4", "num_updates": "1200", "lr": "0.003", "gnorm": "0.48", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "74"}
2023-12-13 22:30:07 | INFO | train_inner | {"epoch": 2, "update": 1.181, "loss": "6.448", "nll_loss": "5.391", "ppl": "41.97", "wps": "66277.2", "ups": "18.45", "wpb": "3592.6", "bsz": "155.7", "num_updates": "1300", "lr": "0.00325", "gnorm": "0.444", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "79"}
2023-12-13 22:30:12 | INFO | train_inner | {"epoch": 2, "update": 1.271, "loss": "6.224", "nll_loss": "5.127", "ppl": "34.94", "wps": "69641.2", "ups": "19.25", "wpb": "3617.7", "bsz": "158.9", "num_updates": "1400", "lr": "0.0035", "gnorm": "0.432", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "84"}
2023-12-13 22:30:19 | INFO | train_inner | {"epoch": 2, "update": 1.362, "loss": "6.237", "nll_loss": "5.137", "ppl": "35.19", "wps": "57544.6", "ups": "16.12", "wpb": "3568.9", "bsz": "134.1", "num_updates": "1500", "lr": "0.00375", "gnorm": "0.419", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "91"}
2023-12-13 22:30:24 | INFO | train_inner | {"epoch": 2, "update": 1.453, "loss": "6.031", "nll_loss": "4.895", "ppl": "29.75", "wps": "62361.6", "ups": "17.31", "wpb": "3603.6", "bsz": "148.9", "num_updates": "1600", "lr": "0.004", "gnorm": "0.415", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "96"}
2023-12-13 22:30:31 | INFO | train_inner | {"epoch": 2, "update": 1.544, "loss": "6.009", "nll_loss": "4.867", "ppl": "29.18", "wps": "57312.2", "ups": "15.93", "wpb": "3596.6", "bsz": "133.6", "num_updates": "1700", "lr": "0.00425", "gnorm": "0.407", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "103"}
2023-12-13 22:30:36 | INFO | train_inner | {"epoch": 2, "update": 1.634, "loss": "5.86", "nll_loss": "4.693", "ppl": "25.87", "wps": "61674.3", "ups": "17.27", "wpb": "3570.9", "bsz": "144.2", "num_updates": "1800", "lr": "0.0045", "gnorm": "0.378", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "109"}
2023-12-13 22:30:43 | INFO | train_inner | {"epoch": 2, "update": 1.725, "loss": "5.85", "nll_loss": "4.683", "ppl": "25.68", "wps": "56865.1", "ups": "16.29", "wpb": "3491.5", "bsz": "135.9", "num_updates": "1900", "lr": "0.00475", "gnorm": "0.379", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "115"}
2023-12-13 22:30:48 | INFO | train_inner | {"epoch": 2, "update": 1.816, "loss": "5.636", "nll_loss": "4.43", "ppl": "21.56", "wps": "62646.8", "ups": "17.48", "wpb": "3584", "bsz": "169", "num_updates": "2000", "lr": "0.005", "gnorm": "0.365", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "120"}
2023-12-13 22:30:54 | INFO | train_inner | {"epoch": 2, "update": 1.907, "loss": "5.705", "nll_loss": "4.513", "ppl": "22.82", "wps": "64348.4", "ups": "17.61", "wpb": "3653.6", "bsz": "141.6", "num_updates": "2100", "lr": "0.00525", "gnorm": "0.357", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "126"}
2023-12-13 22:31:00 | INFO | train_inner | {"epoch": 2, "update": 1.997, "loss": "5.677", "nll_loss": "4.482", "ppl": "22.35", "wps": "55805.7", "ups": "15.94", "wpb": "3501.4", "bsz": "132.5", "num_updates": "2200", "lr": "0.0055", "gnorm": "0.35", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "132"}
2023-12-13 22:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:31:02 | INFO | valid | {"epoch": 2, "valid_loss": "5.431", "valid_nll_loss": "4.214", "valid_ppl": "18.56", "valid_wps": "109410", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "2203", "valid_best_loss": "5.431"}
2023-12-13 22:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2203 updates
2023-12-13 22:31:02 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint2.pt
2023-12-13 22:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint2.pt
2023-12-13 22:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint2.pt (epoch 2 @ 2203 updates, score 5.431) (writing took 0.21717882715165615 seconds)
2023-12-13 22:31:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-12-13 22:31:02 | INFO | train | {"epoch": 2, "train_loss": "6.037", "train_nll_loss": "4.904", "train_ppl": "29.93", "train_wps": "59024.9", "train_ups": "16.47", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "2203", "train_lr": "0.0055075", "train_gnorm": "0.402", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "134"}
2023-12-13 22:31:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:31:02 | INFO | fairseq.trainer | begin training epoch 3
2023-12-13 22:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:31:09 | INFO | train_inner | {"epoch": 3, "update": 2.088, "loss": "5.517", "nll_loss": "4.292", "ppl": "19.59", "wps": "42578.1", "ups": "11.94", "wpb": "3566.6", "bsz": "136.7", "num_updates": "2300", "lr": "0.00575", "gnorm": "0.341", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "141"}
2023-12-13 22:31:15 | INFO | train_inner | {"epoch": 3, "update": 2.179, "loss": "5.496", "nll_loss": "4.27", "ppl": "19.29", "wps": "59235.1", "ups": "16.57", "wpb": "3573.9", "bsz": "149.9", "num_updates": "2400", "lr": "0.006", "gnorm": "0.344", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "147"}
2023-12-13 22:31:20 | INFO | train_inner | {"epoch": 3, "update": 2.27, "loss": "5.481", "nll_loss": "4.251", "ppl": "19.05", "wps": "66502.8", "ups": "18.7", "wpb": "3555.7", "bsz": "150.2", "num_updates": "2500", "lr": "0.00625", "gnorm": "0.329", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "152"}
2023-12-13 22:31:26 | INFO | train_inner | {"epoch": 3, "update": 2.36, "loss": "5.529", "nll_loss": "4.305", "ppl": "19.76", "wps": "55216.3", "ups": "15.38", "wpb": "3591", "bsz": "135.1", "num_updates": "2600", "lr": "0.0065", "gnorm": "0.326", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "159"}
2023-12-13 22:31:33 | INFO | train_inner | {"epoch": 3, "update": 2.451, "loss": "5.469", "nll_loss": "4.236", "ppl": "18.84", "wps": "60005", "ups": "16.53", "wpb": "3629.4", "bsz": "141.9", "num_updates": "2700", "lr": "0.00675", "gnorm": "0.324", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "165"}
2023-12-13 22:31:38 | INFO | train_inner | {"epoch": 3, "update": 2.542, "loss": "5.422", "nll_loss": "4.18", "ppl": "18.13", "wps": "68023.1", "ups": "18.91", "wpb": "3596.8", "bsz": "154.1", "num_updates": "2800", "lr": "0.007", "gnorm": "0.319", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "170"}
2023-12-13 22:31:44 | INFO | train_inner | {"epoch": 3, "update": 2.632, "loss": "5.399", "nll_loss": "4.156", "ppl": "17.82", "wps": "62867.3", "ups": "17.38", "wpb": "3617.5", "bsz": "149.4", "num_updates": "2900", "lr": "0.00725", "gnorm": "0.307", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "176"}
2023-12-13 22:31:49 | INFO | train_inner | {"epoch": 3, "update": 2.723, "loss": "5.437", "nll_loss": "4.195", "ppl": "18.32", "wps": "60417.8", "ups": "17.04", "wpb": "3545.3", "bsz": "145.3", "num_updates": "3000", "lr": "0.0075", "gnorm": "0.318", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "182"}
2023-12-13 22:31:55 | INFO | train_inner | {"epoch": 3, "update": 2.814, "loss": "5.371", "nll_loss": "4.12", "ppl": "17.39", "wps": "62620.9", "ups": "17.41", "wpb": "3597.1", "bsz": "149.7", "num_updates": "3100", "lr": "0.00775", "gnorm": "0.304", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "187"}
2023-12-13 22:32:01 | INFO | train_inner | {"epoch": 3, "update": 2.905, "loss": "5.397", "nll_loss": "4.149", "ppl": "17.74", "wps": "59378.8", "ups": "16.47", "wpb": "3605.9", "bsz": "143", "num_updates": "3200", "lr": "0.008", "gnorm": "0.307", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "193"}
2023-12-13 22:32:07 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "5.409", "nll_loss": "4.161", "ppl": "17.89", "wps": "59114.7", "ups": "16.66", "wpb": "3548.6", "bsz": "144.4", "num_updates": "3300", "lr": "0.00825", "gnorm": "0.319", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "199"}
2023-12-13 22:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:32:09 | INFO | valid | {"epoch": 3, "valid_loss": "5.181", "valid_nll_loss": "3.921", "valid_ppl": "15.15", "valid_wps": "125170", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "3305", "valid_best_loss": "5.181"}
2023-12-13 22:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3305 updates
2023-12-13 22:32:09 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint3.pt
2023-12-13 22:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint3.pt
2023-12-13 22:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint3.pt (epoch 3 @ 3305 updates, score 5.181) (writing took 0.21265453472733498 seconds)
2023-12-13 22:32:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-12-13 22:32:09 | INFO | train | {"epoch": 3, "train_loss": "5.447", "train_nll_loss": "4.21", "train_ppl": "18.5", "train_wps": "58938.7", "train_ups": "16.45", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "3305", "train_lr": "0.0082625", "train_gnorm": "0.322", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "201"}
2023-12-13 22:32:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:32:09 | INFO | fairseq.trainer | begin training epoch 4
2023-12-13 22:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:32:15 | INFO | train_inner | {"epoch": 4, "update": 3.086, "loss": "5.312", "nll_loss": "4.046", "ppl": "16.52", "wps": "45473.3", "ups": "12.89", "wpb": "3528.1", "bsz": "133.4", "num_updates": "3400", "lr": "0.0085", "gnorm": "0.298", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "207"}
2023-12-13 22:32:21 | INFO | train_inner | {"epoch": 4, "update": 3.177, "loss": "5.338", "nll_loss": "4.075", "ppl": "16.86", "wps": "65925.7", "ups": "18.17", "wpb": "3628.2", "bsz": "145.2", "num_updates": "3500", "lr": "0.00875", "gnorm": "0.312", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "213"}
2023-12-13 22:32:27 | INFO | train_inner | {"epoch": 4, "update": 3.268, "loss": "5.399", "nll_loss": "4.141", "ppl": "17.64", "wps": "53219.7", "ups": "15.04", "wpb": "3539.2", "bsz": "134.2", "num_updates": "3600", "lr": "0.009", "gnorm": "0.323", "loss_scale": "64", "train_wall": "7", "gb_free": "38.9", "wall": "219"}
2023-12-13 22:32:33 | INFO | train_inner | {"epoch": 4, "update": 3.358, "loss": "5.367", "nll_loss": "4.107", "ppl": "17.23", "wps": "58886.3", "ups": "16.38", "wpb": "3594.8", "bsz": "147.3", "num_updates": "3700", "lr": "0.00925", "gnorm": "0.31", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "225"}
2023-12-13 22:32:40 | INFO | train_inner | {"epoch": 4, "update": 3.449, "loss": "5.382", "nll_loss": "4.122", "ppl": "17.41", "wps": "54534.2", "ups": "15.55", "wpb": "3507.4", "bsz": "145.4", "num_updates": "3800", "lr": "0.0095", "gnorm": "0.319", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "232"}
2023-12-13 22:32:45 | INFO | train_inner | {"epoch": 4, "update": 3.54, "loss": "5.269", "nll_loss": "3.991", "ppl": "15.9", "wps": "70145.6", "ups": "19.35", "wpb": "3625.9", "bsz": "172.8", "num_updates": "3900", "lr": "0.00975", "gnorm": "0.321", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "237"}
2023-12-13 22:32:50 | INFO | train_inner | {"epoch": 4, "update": 3.631, "loss": "5.397", "nll_loss": "4.14", "ppl": "17.63", "wps": "65087.4", "ups": "18.1", "wpb": "3595.8", "bsz": "139.8", "num_updates": "4000", "lr": "0.01", "gnorm": "0.303", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "243"}
2023-12-13 22:32:57 | INFO | train_inner | {"epoch": 4, "update": 3.721, "loss": "5.377", "nll_loss": "4.115", "ppl": "17.32", "wps": "58024.1", "ups": "16.21", "wpb": "3579.2", "bsz": "144.8", "num_updates": "4100", "lr": "0.0098773", "gnorm": "0.308", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "249"}
2023-12-13 22:33:03 | INFO | train_inner | {"epoch": 4, "update": 3.812, "loss": "5.353", "nll_loss": "4.09", "ppl": "17.03", "wps": "60244.5", "ups": "16.71", "wpb": "3605.7", "bsz": "148.4", "num_updates": "4200", "lr": "0.009759", "gnorm": "0.305", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "255"}
2023-12-13 22:33:08 | INFO | train_inner | {"epoch": 4, "update": 3.903, "loss": "5.331", "nll_loss": "4.064", "ppl": "16.73", "wps": "63342.6", "ups": "17.66", "wpb": "3587.1", "bsz": "149.8", "num_updates": "4300", "lr": "0.00964486", "gnorm": "0.296", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "260"}
2023-12-13 22:33:14 | INFO | train_inner | {"epoch": 4, "update": 3.994, "loss": "5.385", "nll_loss": "4.128", "ppl": "17.49", "wps": "62634.7", "ups": "17.33", "wpb": "3613.2", "bsz": "140.3", "num_updates": "4400", "lr": "0.00953463", "gnorm": "0.308", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "266"}
2023-12-13 22:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:33:16 | INFO | valid | {"epoch": 4, "valid_loss": "5.065", "valid_nll_loss": "3.79", "valid_ppl": "13.83", "valid_wps": "126544", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "4407", "valid_best_loss": "5.065"}
2023-12-13 22:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4407 updates
2023-12-13 22:33:16 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint4.pt
2023-12-13 22:33:16 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint4.pt
2023-12-13 22:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint4.pt (epoch 4 @ 4407 updates, score 5.065) (writing took 0.2141721760854125 seconds)
2023-12-13 22:33:16 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-12-13 22:33:16 | INFO | train | {"epoch": 4, "train_loss": "5.355", "train_nll_loss": "4.092", "train_ppl": "17.05", "train_wps": "59102.9", "train_ups": "16.49", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "4407", "train_lr": "0.00952705", "train_gnorm": "0.309", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "268"}
2023-12-13 22:33:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:33:16 | INFO | fairseq.trainer | begin training epoch 5
2023-12-13 22:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:33:22 | INFO | train_inner | {"epoch": 5, "update": 4.084, "loss": "5.139", "nll_loss": "3.839", "ppl": "14.31", "wps": "46796.3", "ups": "13.02", "wpb": "3595", "bsz": "149.2", "num_updates": "4500", "lr": "0.00942809", "gnorm": "0.288", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "274"}
2023-12-13 22:33:28 | INFO | train_inner | {"epoch": 5, "update": 4.175, "loss": "5.295", "nll_loss": "4.02", "ppl": "16.22", "wps": "58354.7", "ups": "16.26", "wpb": "3588.8", "bsz": "131", "num_updates": "4600", "lr": "0.00932505", "gnorm": "0.301", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "280"}
2023-12-13 22:33:34 | INFO | train_inner | {"epoch": 5, "update": 4.266, "loss": "5.234", "nll_loss": "3.952", "ppl": "15.48", "wps": "59693.6", "ups": "16.48", "wpb": "3621.9", "bsz": "136.1", "num_updates": "4700", "lr": "0.00922531", "gnorm": "0.298", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "286"}
2023-12-13 22:33:40 | INFO | train_inner | {"epoch": 5, "update": 4.357, "loss": "5.206", "nll_loss": "3.922", "ppl": "15.16", "wps": "58723.7", "ups": "16.34", "wpb": "3593.8", "bsz": "144", "num_updates": "4800", "lr": "0.00912871", "gnorm": "0.287", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "292"}
2023-12-13 22:33:46 | INFO | train_inner | {"epoch": 5, "update": 4.447, "loss": "5.21", "nll_loss": "3.926", "ppl": "15.2", "wps": "63138.7", "ups": "17.76", "wpb": "3555.7", "bsz": "144.2", "num_updates": "4900", "lr": "0.00903508", "gnorm": "0.297", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "298"}
2023-12-13 22:33:52 | INFO | train_inner | {"epoch": 5, "update": 4.538, "loss": "5.18", "nll_loss": "3.895", "ppl": "14.88", "wps": "60325.2", "ups": "16.77", "wpb": "3597.6", "bsz": "150", "num_updates": "5000", "lr": "0.00894427", "gnorm": "0.287", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "304"}
2023-12-13 22:33:57 | INFO | train_inner | {"epoch": 5, "update": 4.629, "loss": "5.102", "nll_loss": "3.805", "ppl": "13.98", "wps": "69869.8", "ups": "19.19", "wpb": "3641", "bsz": "169.2", "num_updates": "5100", "lr": "0.00885615", "gnorm": "0.284", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "309"}
2023-12-13 22:34:03 | INFO | train_inner | {"epoch": 5, "update": 4.72, "loss": "5.143", "nll_loss": "3.854", "ppl": "14.46", "wps": "63129.9", "ups": "17.55", "wpb": "3597.9", "bsz": "148.3", "num_updates": "5200", "lr": "0.00877058", "gnorm": "0.286", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "315"}
2023-12-13 22:34:09 | INFO | train_inner | {"epoch": 5, "update": 4.81, "loss": "5.234", "nll_loss": "3.959", "ppl": "15.55", "wps": "57203.6", "ups": "16.16", "wpb": "3540.7", "bsz": "138.9", "num_updates": "5300", "lr": "0.00868744", "gnorm": "0.289", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "321"}
2023-12-13 22:34:15 | INFO | train_inner | {"epoch": 5, "update": 4.901, "loss": "5.161", "nll_loss": "3.873", "ppl": "14.65", "wps": "60430.4", "ups": "16.93", "wpb": "3569.1", "bsz": "150.2", "num_updates": "5400", "lr": "0.00860663", "gnorm": "0.288", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "327"}
2023-12-13 22:34:21 | INFO | train_inner | {"epoch": 5, "update": 4.992, "loss": "5.218", "nll_loss": "3.939", "ppl": "15.34", "wps": "53034.8", "ups": "15.09", "wpb": "3513.5", "bsz": "134.8", "num_updates": "5500", "lr": "0.00852803", "gnorm": "0.298", "loss_scale": "64", "train_wall": "7", "gb_free": "38.9", "wall": "333"}
2023-12-13 22:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:34:23 | INFO | valid | {"epoch": 5, "valid_loss": "4.902", "valid_nll_loss": "3.63", "valid_ppl": "12.38", "valid_wps": "124188", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "5509", "valid_best_loss": "4.902"}
2023-12-13 22:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5509 updates
2023-12-13 22:34:23 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint5.pt
2023-12-13 22:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint5.pt
2023-12-13 22:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint5.pt (epoch 5 @ 5509 updates, score 4.902) (writing took 0.2304176166653633 seconds)
2023-12-13 22:34:23 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-12-13 22:34:23 | INFO | train | {"epoch": 5, "train_loss": "5.19", "train_nll_loss": "3.905", "train_ppl": "14.98", "train_wps": "58635.4", "train_ups": "16.36", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "5509", "train_lr": "0.00852106", "train_gnorm": "0.291", "train_loss_scale": "64", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "336"}
2023-12-13 22:34:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:34:24 | INFO | fairseq.trainer | begin training epoch 6
2023-12-13 22:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:34:29 | INFO | train_inner | {"epoch": 6, "update": 5.083, "loss": "5.086", "nll_loss": "3.789", "ppl": "13.82", "wps": "44334.5", "ups": "12.32", "wpb": "3598.8", "bsz": "132.8", "num_updates": "5600", "lr": "0.00845154", "gnorm": "0.276", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "341"}
2023-12-13 22:34:36 | INFO | train_inner | {"epoch": 6, "update": 5.173, "loss": "5.038", "nll_loss": "3.732", "ppl": "13.29", "wps": "54907.1", "ups": "15.25", "wpb": "3600.5", "bsz": "138.9", "num_updates": "5700", "lr": "0.00837708", "gnorm": "0.277", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "348"}
2023-12-13 22:34:42 | INFO | train_inner | {"epoch": 6, "update": 5.264, "loss": "5.018", "nll_loss": "3.709", "ppl": "13.08", "wps": "63737.9", "ups": "17.7", "wpb": "3600.1", "bsz": "144.7", "num_updates": "5800", "lr": "0.00830455", "gnorm": "0.276", "loss_scale": "64", "train_wall": "6", "gb_free": "39", "wall": "354"}
2023-12-13 22:34:47 | INFO | train_inner | {"epoch": 6, "update": 5.355, "loss": "5.044", "nll_loss": "3.742", "ppl": "13.38", "wps": "62072.9", "ups": "17.35", "wpb": "3578.4", "bsz": "148", "num_updates": "5900", "lr": "0.00823387", "gnorm": "0.278", "loss_scale": "64", "train_wall": "6", "gb_free": "38.9", "wall": "359"}
2023-12-13 22:34:53 | INFO | train_inner | {"epoch": 6, "update": 5.446, "loss": "5.032", "nll_loss": "3.728", "ppl": "13.25", "wps": "64603.1", "ups": "18.01", "wpb": "3587.5", "bsz": "145.7", "num_updates": "6000", "lr": "0.00816497", "gnorm": "0.276", "loss_scale": "64", "train_wall": "5", "gb_free": "39", "wall": "365"}
2023-12-13 22:34:58 | INFO | train_inner | {"epoch": 6, "update": 5.536, "loss": "4.973", "nll_loss": "3.662", "ppl": "12.66", "wps": "64816", "ups": "18", "wpb": "3600.2", "bsz": "161.2", "num_updates": "6100", "lr": "0.00809776", "gnorm": "0.275", "loss_scale": "64", "train_wall": "5", "gb_free": "38.9", "wall": "371"}
2023-12-13 22:35:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-12-13 22:35:04 | INFO | train_inner | {"epoch": 6, "update": 5.628, "loss": "4.995", "nll_loss": "3.689", "ppl": "12.9", "wps": "59492", "ups": "16.66", "wpb": "3570", "bsz": "155.4", "num_updates": "6200", "lr": "0.00803219", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "377"}
2023-12-13 22:35:11 | INFO | train_inner | {"epoch": 6, "update": 5.719, "loss": "5.076", "nll_loss": "3.778", "ppl": "13.72", "wps": "54380.1", "ups": "15", "wpb": "3625.7", "bsz": "131.7", "num_updates": "6300", "lr": "0.00796819", "gnorm": "0.286", "loss_scale": "32", "train_wall": "7", "gb_free": "38.9", "wall": "383"}
2023-12-13 22:35:17 | INFO | train_inner | {"epoch": 6, "update": 5.809, "loss": "5.037", "nll_loss": "3.736", "ppl": "13.33", "wps": "59512.1", "ups": "16.64", "wpb": "3576.8", "bsz": "146.9", "num_updates": "6400", "lr": "0.00790569", "gnorm": "0.29", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "389"}
2023-12-13 22:35:23 | INFO | train_inner | {"epoch": 6, "update": 5.9, "loss": "5.024", "nll_loss": "3.724", "ppl": "13.21", "wps": "58510.7", "ups": "16.57", "wpb": "3532.1", "bsz": "141.6", "num_updates": "6500", "lr": "0.00784465", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "395"}
2023-12-13 22:35:29 | INFO | train_inner | {"epoch": 6, "update": 5.991, "loss": "4.973", "nll_loss": "3.665", "ppl": "12.68", "wps": "65057.6", "ups": "18.11", "wpb": "3591.9", "bsz": "155.4", "num_updates": "6600", "lr": "0.00778499", "gnorm": "0.278", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "401"}
2023-12-13 22:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:35:31 | INFO | valid | {"epoch": 6, "valid_loss": "4.8", "valid_nll_loss": "3.466", "valid_ppl": "11.05", "valid_wps": "124192", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "6610", "valid_best_loss": "4.8"}
2023-12-13 22:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6610 updates
2023-12-13 22:35:31 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint6.pt
2023-12-13 22:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint6.pt
2023-12-13 22:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint6.pt (epoch 6 @ 6610 updates, score 4.8) (writing took 0.22081792913377285 seconds)
2023-12-13 22:35:31 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-12-13 22:35:31 | INFO | train | {"epoch": 6, "train_loss": "5.026", "train_nll_loss": "3.722", "train_ppl": "13.2", "train_wps": "58438.3", "train_ups": "16.3", "train_wpb": "3585.4", "train_bsz": "145.5", "train_num_updates": "6610", "train_lr": "0.0077791", "train_gnorm": "0.277", "train_loss_scale": "32", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "403"}
2023-12-13 22:35:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:35:31 | INFO | fairseq.trainer | begin training epoch 7
2023-12-13 22:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:35:36 | INFO | train_inner | {"epoch": 7, "update": 6.082, "loss": "4.809", "nll_loss": "3.474", "ppl": "11.11", "wps": "51014.9", "ups": "14.11", "wpb": "3614.4", "bsz": "158.3", "num_updates": "6700", "lr": "0.00772667", "gnorm": "0.258", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "408"}
2023-12-13 22:35:42 | INFO | train_inner | {"epoch": 7, "update": 6.172, "loss": "4.92", "nll_loss": "3.599", "ppl": "12.12", "wps": "55904.9", "ups": "16.06", "wpb": "3480.2", "bsz": "142.3", "num_updates": "6800", "lr": "0.00766965", "gnorm": "0.287", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "414"}
2023-12-13 22:35:48 | INFO | train_inner | {"epoch": 7, "update": 6.263, "loss": "4.922", "nll_loss": "3.606", "ppl": "12.17", "wps": "58188.5", "ups": "16.58", "wpb": "3509.6", "bsz": "148", "num_updates": "6900", "lr": "0.00761387", "gnorm": "0.269", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "420"}
2023-12-13 22:35:54 | INFO | train_inner | {"epoch": 7, "update": 6.354, "loss": "4.85", "nll_loss": "3.52", "ppl": "11.47", "wps": "63106.8", "ups": "17.37", "wpb": "3632.9", "bsz": "158.2", "num_updates": "7000", "lr": "0.00755929", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "426"}
2023-12-13 22:36:00 | INFO | train_inner | {"epoch": 7, "update": 6.445, "loss": "4.91", "nll_loss": "3.594", "ppl": "12.07", "wps": "63012.6", "ups": "17.39", "wpb": "3622.8", "bsz": "148.6", "num_updates": "7100", "lr": "0.00750587", "gnorm": "0.279", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "432"}
2023-12-13 22:36:05 | INFO | train_inner | {"epoch": 7, "update": 6.535, "loss": "4.902", "nll_loss": "3.585", "ppl": "12", "wps": "64453.5", "ups": "17.58", "wpb": "3666.6", "bsz": "151.5", "num_updates": "7200", "lr": "0.00745356", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "437"}
2023-12-13 22:36:11 | INFO | train_inner | {"epoch": 7, "update": 6.626, "loss": "4.955", "nll_loss": "3.644", "ppl": "12.5", "wps": "57138.8", "ups": "16.2", "wpb": "3526.1", "bsz": "134.5", "num_updates": "7300", "lr": "0.00740233", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "444"}
2023-12-13 22:36:17 | INFO | train_inner | {"epoch": 7, "update": 6.717, "loss": "4.887", "nll_loss": "3.568", "ppl": "11.86", "wps": "63886.8", "ups": "17.89", "wpb": "3571.2", "bsz": "156.8", "num_updates": "7400", "lr": "0.00735215", "gnorm": "0.273", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "449"}
2023-12-13 22:36:23 | INFO | train_inner | {"epoch": 7, "update": 6.808, "loss": "4.918", "nll_loss": "3.606", "ppl": "12.18", "wps": "59787.6", "ups": "16.79", "wpb": "3560.8", "bsz": "146.2", "num_updates": "7500", "lr": "0.00730297", "gnorm": "0.266", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "455"}
2023-12-13 22:36:29 | INFO | train_inner | {"epoch": 7, "update": 6.898, "loss": "4.981", "nll_loss": "3.676", "ppl": "12.78", "wps": "57596.5", "ups": "16.21", "wpb": "3552.2", "bsz": "129.8", "num_updates": "7600", "lr": "0.00725476", "gnorm": "0.282", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "461"}
2023-12-13 22:36:35 | INFO | train_inner | {"epoch": 7, "update": 6.989, "loss": "4.984", "nll_loss": "3.68", "ppl": "12.82", "wps": "58852", "ups": "16.05", "wpb": "3666.6", "bsz": "123.9", "num_updates": "7700", "lr": "0.0072075", "gnorm": "0.263", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "467"}
2023-12-13 22:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:36:37 | INFO | valid | {"epoch": 7, "valid_loss": "4.718", "valid_nll_loss": "3.391", "valid_ppl": "10.49", "valid_wps": "125014", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "7712", "valid_best_loss": "4.718"}
2023-12-13 22:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7712 updates
2023-12-13 22:36:37 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint7.pt
2023-12-13 22:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint7.pt
2023-12-13 22:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint7.pt (epoch 7 @ 7712 updates, score 4.718) (writing took 0.21317989844828844 seconds)
2023-12-13 22:36:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-12-13 22:36:38 | INFO | train | {"epoch": 7, "train_loss": "4.912", "train_nll_loss": "3.595", "train_ppl": "12.08", "train_wps": "59203", "train_ups": "16.52", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "7712", "train_lr": "0.00720189", "train_gnorm": "0.271", "train_loss_scale": "32", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "470"}
2023-12-13 22:36:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:36:38 | INFO | fairseq.trainer | begin training epoch 8
2023-12-13 22:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:36:43 | INFO | train_inner | {"epoch": 8, "update": 7.08, "loss": "4.731", "nll_loss": "3.387", "ppl": "10.46", "wps": "47175.8", "ups": "13.22", "wpb": "3567.8", "bsz": "155.3", "num_updates": "7800", "lr": "0.00716115", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "475"}
2023-12-13 22:36:49 | INFO | train_inner | {"epoch": 8, "update": 7.171, "loss": "4.817", "nll_loss": "3.483", "ppl": "11.18", "wps": "59253.9", "ups": "16.55", "wpb": "3581.3", "bsz": "142.6", "num_updates": "7900", "lr": "0.00711568", "gnorm": "0.278", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "481"}
2023-12-13 22:36:55 | INFO | train_inner | {"epoch": 8, "update": 7.261, "loss": "4.852", "nll_loss": "3.53", "ppl": "11.55", "wps": "59406.3", "ups": "16.53", "wpb": "3594.8", "bsz": "137.9", "num_updates": "8000", "lr": "0.00707107", "gnorm": "0.262", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "487"}
2023-12-13 22:37:01 | INFO | train_inner | {"epoch": 8, "update": 7.352, "loss": "4.808", "nll_loss": "3.475", "ppl": "11.12", "wps": "63153.1", "ups": "17.52", "wpb": "3604.8", "bsz": "147.6", "num_updates": "8100", "lr": "0.00702728", "gnorm": "0.27", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "493"}
2023-12-13 22:37:07 | INFO | train_inner | {"epoch": 8, "update": 7.443, "loss": "4.869", "nll_loss": "3.545", "ppl": "11.68", "wps": "55897.9", "ups": "15.91", "wpb": "3512.8", "bsz": "148.2", "num_updates": "8200", "lr": "0.0069843", "gnorm": "0.3", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "499"}
2023-12-13 22:37:13 | INFO | train_inner | {"epoch": 8, "update": 7.534, "loss": "4.893", "nll_loss": "3.578", "ppl": "11.94", "wps": "59143", "ups": "16.45", "wpb": "3594.2", "bsz": "136.2", "num_updates": "8300", "lr": "0.0069421", "gnorm": "0.257", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "505"}
2023-12-13 22:37:19 | INFO | train_inner | {"epoch": 8, "update": 7.624, "loss": "4.783", "nll_loss": "3.452", "ppl": "10.94", "wps": "65587", "ups": "18.01", "wpb": "3642", "bsz": "156.9", "num_updates": "8400", "lr": "0.00690066", "gnorm": "0.251", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "511"}
2023-12-13 22:37:25 | INFO | train_inner | {"epoch": 8, "update": 7.715, "loss": "4.807", "nll_loss": "3.476", "ppl": "11.12", "wps": "57297.5", "ups": "16.21", "wpb": "3535.1", "bsz": "148.9", "num_updates": "8500", "lr": "0.00685994", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "517"}
2023-12-13 22:37:31 | INFO | train_inner | {"epoch": 8, "update": 7.806, "loss": "4.887", "nll_loss": "3.572", "ppl": "11.89", "wps": "58804.1", "ups": "16.6", "wpb": "3543.2", "bsz": "131.4", "num_updates": "8600", "lr": "0.00681994", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "523"}
2023-12-13 22:37:37 | INFO | train_inner | {"epoch": 8, "update": 7.897, "loss": "4.846", "nll_loss": "3.525", "ppl": "11.51", "wps": "62286.6", "ups": "17.09", "wpb": "3645.6", "bsz": "143.9", "num_updates": "8700", "lr": "0.00678064", "gnorm": "0.275", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "529"}
2023-12-13 22:37:42 | INFO | train_inner | {"epoch": 8, "update": 7.987, "loss": "4.779", "nll_loss": "3.449", "ppl": "10.92", "wps": "64675.3", "ups": "17.86", "wpb": "3620.3", "bsz": "150.5", "num_updates": "8800", "lr": "0.006742", "gnorm": "0.247", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "534"}
2023-12-13 22:37:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:37:45 | INFO | valid | {"epoch": 8, "valid_loss": "4.661", "valid_nll_loss": "3.336", "valid_ppl": "10.1", "valid_wps": "125676", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "8814", "valid_best_loss": "4.661"}
2023-12-13 22:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8814 updates
2023-12-13 22:37:45 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint8.pt
2023-12-13 22:37:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint8.pt
2023-12-13 22:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint8.pt (epoch 8 @ 8814 updates, score 4.661) (writing took 0.21517923288047314 seconds)
2023-12-13 22:37:45 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-12-13 22:37:45 | INFO | train | {"epoch": 8, "train_loss": "4.823", "train_nll_loss": "3.496", "train_ppl": "11.28", "train_wps": "58797.5", "train_ups": "16.41", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "8814", "train_lr": "0.00673664", "train_gnorm": "0.267", "train_loss_scale": "32", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "537"}
2023-12-13 22:37:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:37:45 | INFO | fairseq.trainer | begin training epoch 9
2023-12-13 22:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:37:50 | INFO | train_inner | {"epoch": 9, "update": 8.078, "loss": "4.713", "nll_loss": "3.368", "ppl": "10.33", "wps": "44497.6", "ups": "12.61", "wpb": "3527.4", "bsz": "141.9", "num_updates": "8900", "lr": "0.00670402", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "542"}
2023-12-13 22:37:56 | INFO | train_inner | {"epoch": 9, "update": 8.169, "loss": "4.718", "nll_loss": "3.375", "ppl": "10.37", "wps": "60415.3", "ups": "16.82", "wpb": "3592.4", "bsz": "148.3", "num_updates": "9000", "lr": "0.00666667", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "548"}
2023-12-13 22:38:02 | INFO | train_inner | {"epoch": 9, "update": 8.26, "loss": "4.717", "nll_loss": "3.373", "ppl": "10.36", "wps": "59440.8", "ups": "16.62", "wpb": "3576.5", "bsz": "145.6", "num_updates": "9100", "lr": "0.00662994", "gnorm": "0.254", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "554"}
2023-12-13 22:38:09 | INFO | train_inner | {"epoch": 9, "update": 8.35, "loss": "4.782", "nll_loss": "3.449", "ppl": "10.92", "wps": "56197.4", "ups": "15.72", "wpb": "3575.6", "bsz": "142.7", "num_updates": "9200", "lr": "0.0065938", "gnorm": "0.287", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "561"}
2023-12-13 22:38:14 | INFO | train_inner | {"epoch": 9, "update": 8.441, "loss": "4.734", "nll_loss": "3.397", "ppl": "10.54", "wps": "67313", "ups": "18.6", "wpb": "3618.4", "bsz": "155.9", "num_updates": "9300", "lr": "0.00655826", "gnorm": "0.256", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "566"}
2023-12-13 22:38:20 | INFO | train_inner | {"epoch": 9, "update": 8.532, "loss": "4.821", "nll_loss": "3.496", "ppl": "11.28", "wps": "56660.2", "ups": "16.16", "wpb": "3506.9", "bsz": "130.8", "num_updates": "9400", "lr": "0.00652328", "gnorm": "0.272", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "572"}
2023-12-13 22:38:26 | INFO | train_inner | {"epoch": 9, "update": 8.623, "loss": "4.747", "nll_loss": "3.411", "ppl": "10.64", "wps": "63868.1", "ups": "17.65", "wpb": "3618.1", "bsz": "153.6", "num_updates": "9500", "lr": "0.00648886", "gnorm": "0.271", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "578"}
2023-12-13 22:38:31 | INFO | train_inner | {"epoch": 9, "update": 8.713, "loss": "4.759", "nll_loss": "3.426", "ppl": "10.75", "wps": "64844.5", "ups": "18.11", "wpb": "3581.6", "bsz": "145", "num_updates": "9600", "lr": "0.00645497", "gnorm": "0.257", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "583"}
2023-12-13 22:38:37 | INFO | train_inner | {"epoch": 9, "update": 8.804, "loss": "4.732", "nll_loss": "3.396", "ppl": "10.53", "wps": "60688.1", "ups": "16.81", "wpb": "3609.7", "bsz": "152.9", "num_updates": "9700", "lr": "0.00642161", "gnorm": "0.267", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "589"}
2023-12-13 22:38:43 | INFO | train_inner | {"epoch": 9, "update": 8.895, "loss": "4.828", "nll_loss": "3.506", "ppl": "11.36", "wps": "57576.2", "ups": "16.06", "wpb": "3584.1", "bsz": "137.8", "num_updates": "9800", "lr": "0.00638877", "gnorm": "0.279", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "596"}
2023-12-13 22:38:49 | INFO | train_inner | {"epoch": 9, "update": 8.985, "loss": "4.78", "nll_loss": "3.452", "ppl": "10.94", "wps": "59969.8", "ups": "16.72", "wpb": "3586.4", "bsz": "139.8", "num_updates": "9900", "lr": "0.00635642", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "602"}
2023-12-13 22:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:38:52 | INFO | valid | {"epoch": 9, "valid_loss": "4.62", "valid_nll_loss": "3.288", "valid_ppl": "9.77", "valid_wps": "124998", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "9916", "valid_best_loss": "4.62"}
2023-12-13 22:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9916 updates
2023-12-13 22:38:52 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint9.pt
2023-12-13 22:38:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint9.pt
2023-12-13 22:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint9.pt (epoch 9 @ 9916 updates, score 4.62) (writing took 0.22740365099161863 seconds)
2023-12-13 22:38:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-12-13 22:38:52 | INFO | train | {"epoch": 9, "train_loss": "4.755", "train_nll_loss": "3.42", "train_ppl": "10.71", "train_wps": "58841.7", "train_ups": "16.42", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "9916", "train_lr": "0.00635129", "train_gnorm": "0.268", "train_loss_scale": "32", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "604"}
2023-12-13 22:38:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:38:52 | INFO | fairseq.trainer | begin training epoch 10
2023-12-13 22:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:38:57 | INFO | train_inner | {"epoch": 10, "update": 9.076, "loss": "4.647", "nll_loss": "3.295", "ppl": "9.82", "wps": "44545.7", "ups": "12.42", "wpb": "3586", "bsz": "151.4", "num_updates": "10000", "lr": "0.00632456", "gnorm": "0.276", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "610"}
2023-12-13 22:39:03 | INFO | train_inner | {"epoch": 10, "update": 9.167, "loss": "4.647", "nll_loss": "3.297", "ppl": "9.83", "wps": "64940.5", "ups": "18.04", "wpb": "3599.2", "bsz": "151.4", "num_updates": "10100", "lr": "0.00629317", "gnorm": "0.26", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "615"}
2023-12-13 22:39:09 | INFO | train_inner | {"epoch": 10, "update": 9.258, "loss": "4.603", "nll_loss": "3.245", "ppl": "9.48", "wps": "65935.3", "ups": "18.24", "wpb": "3614.7", "bsz": "165.4", "num_updates": "10200", "lr": "0.00626224", "gnorm": "0.266", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "621"}
2023-12-13 22:39:15 | INFO | train_inner | {"epoch": 10, "update": 9.348, "loss": "4.762", "nll_loss": "3.427", "ppl": "10.75", "wps": "55766.6", "ups": "15.76", "wpb": "3537.6", "bsz": "128.9", "num_updates": "10300", "lr": "0.00623177", "gnorm": "0.278", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "627"}
2023-12-13 22:39:21 | INFO | train_inner | {"epoch": 10, "update": 9.439, "loss": "4.728", "nll_loss": "3.39", "ppl": "10.48", "wps": "59306.2", "ups": "16.82", "wpb": "3526.3", "bsz": "142.1", "num_updates": "10400", "lr": "0.00620174", "gnorm": "0.279", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "633"}
2023-12-13 22:39:27 | INFO | train_inner | {"epoch": 10, "update": 9.53, "loss": "4.699", "nll_loss": "3.357", "ppl": "10.25", "wps": "60215.5", "ups": "16.65", "wpb": "3617.2", "bsz": "149", "num_updates": "10500", "lr": "0.00617213", "gnorm": "0.265", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "639"}
2023-12-13 22:39:32 | INFO | train_inner | {"epoch": 10, "update": 9.621, "loss": "4.694", "nll_loss": "3.355", "ppl": "10.23", "wps": "63881.9", "ups": "17.6", "wpb": "3629.6", "bsz": "145.9", "num_updates": "10600", "lr": "0.00614295", "gnorm": "0.25", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "645"}
2023-12-13 22:39:38 | INFO | train_inner | {"epoch": 10, "update": 9.711, "loss": "4.723", "nll_loss": "3.388", "ppl": "10.47", "wps": "63977", "ups": "17.93", "wpb": "3567.4", "bsz": "151.6", "num_updates": "10700", "lr": "0.00611418", "gnorm": "0.277", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "650"}
2023-12-13 22:39:44 | INFO | train_inner | {"epoch": 10, "update": 9.802, "loss": "4.759", "nll_loss": "3.428", "ppl": "10.76", "wps": "59973.3", "ups": "16.64", "wpb": "3603.6", "bsz": "133.7", "num_updates": "10800", "lr": "0.00608581", "gnorm": "0.273", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "656"}
2023-12-13 22:39:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-12-13 22:39:51 | INFO | train_inner | {"epoch": 10, "update": 9.894, "loss": "4.778", "nll_loss": "3.449", "ppl": "10.92", "wps": "54209.9", "ups": "15.19", "wpb": "3568.2", "bsz": "138", "num_updates": "10900", "lr": "0.00605783", "gnorm": "0.328", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "663"}
2023-12-13 22:39:57 | INFO | train_inner | {"epoch": 10, "update": 9.985, "loss": "4.751", "nll_loss": "3.42", "ppl": "10.7", "wps": "60103.8", "ups": "16.81", "wpb": "3575.2", "bsz": "146.9", "num_updates": "11000", "lr": "0.00603023", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "669"}
2023-12-13 22:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:39:59 | INFO | valid | {"epoch": 10, "valid_loss": "4.569", "valid_nll_loss": "3.231", "valid_ppl": "9.39", "valid_wps": "126464", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "11017", "valid_best_loss": "4.569"}
2023-12-13 22:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11017 updates
2023-12-13 22:39:59 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint10.pt
2023-12-13 22:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint10.pt
2023-12-13 22:39:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint10.pt (epoch 10 @ 11017 updates, score 4.569) (writing took 0.23448346741497517 seconds)
2023-12-13 22:39:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-12-13 22:39:59 | INFO | train | {"epoch": 10, "train_loss": "4.708", "train_nll_loss": "3.368", "train_ppl": "10.33", "train_wps": "58778.2", "train_ups": "16.4", "train_wpb": "3584.3", "train_bsz": "145.5", "train_num_updates": "11017", "train_lr": "0.00602557", "train_gnorm": "0.276", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "671"}
2023-12-13 22:39:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:39:59 | INFO | fairseq.trainer | begin training epoch 11
2023-12-13 22:39:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:40:04 | INFO | train_inner | {"epoch": 11, "update": 10.075, "loss": "4.61", "nll_loss": "3.254", "ppl": "9.54", "wps": "45990", "ups": "12.88", "wpb": "3571.4", "bsz": "143.6", "num_updates": "11100", "lr": "0.006003", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "676"}
2023-12-13 22:40:11 | INFO | train_inner | {"epoch": 11, "update": 10.166, "loss": "4.617", "nll_loss": "3.26", "ppl": "9.58", "wps": "54144", "ups": "15.19", "wpb": "3565.5", "bsz": "143.2", "num_updates": "11200", "lr": "0.00597614", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "683"}
2023-12-13 22:40:17 | INFO | train_inner | {"epoch": 11, "update": 10.257, "loss": "4.681", "nll_loss": "3.337", "ppl": "10.1", "wps": "55580.7", "ups": "15.65", "wpb": "3551.2", "bsz": "132.4", "num_updates": "11300", "lr": "0.00594964", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "689"}
2023-12-13 22:40:23 | INFO | train_inner | {"epoch": 11, "update": 10.348, "loss": "4.644", "nll_loss": "3.297", "ppl": "9.83", "wps": "62018.7", "ups": "16.93", "wpb": "3664", "bsz": "147.2", "num_updates": "11400", "lr": "0.00592349", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "695"}
2023-12-13 22:40:29 | INFO | train_inner | {"epoch": 11, "update": 10.438, "loss": "4.622", "nll_loss": "3.27", "ppl": "9.64", "wps": "59047.5", "ups": "16.34", "wpb": "3613.1", "bsz": "147.9", "num_updates": "11500", "lr": "0.00589768", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "701"}
2023-12-13 22:40:35 | INFO | train_inner | {"epoch": 11, "update": 10.529, "loss": "4.637", "nll_loss": "3.289", "ppl": "9.78", "wps": "64496.7", "ups": "17.87", "wpb": "3608.7", "bsz": "156.4", "num_updates": "11600", "lr": "0.0058722", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "707"}
2023-12-13 22:40:41 | INFO | train_inner | {"epoch": 11, "update": 10.62, "loss": "4.7", "nll_loss": "3.362", "ppl": "10.28", "wps": "62748.7", "ups": "17.56", "wpb": "3572.4", "bsz": "144.9", "num_updates": "11700", "lr": "0.00584705", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "713"}
2023-12-13 22:40:46 | INFO | train_inner | {"epoch": 11, "update": 10.711, "loss": "4.671", "nll_loss": "3.331", "ppl": "10.06", "wps": "65175.1", "ups": "18.01", "wpb": "3618.1", "bsz": "154.2", "num_updates": "11800", "lr": "0.00582223", "gnorm": "0.27", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "718"}
2023-12-13 22:40:52 | INFO | train_inner | {"epoch": 11, "update": 10.801, "loss": "4.663", "nll_loss": "3.321", "ppl": "9.99", "wps": "66314.3", "ups": "18.38", "wpb": "3608.9", "bsz": "151.4", "num_updates": "11900", "lr": "0.00579771", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "724"}
2023-12-13 22:40:57 | INFO | train_inner | {"epoch": 11, "update": 10.892, "loss": "4.702", "nll_loss": "3.366", "ppl": "10.31", "wps": "61511.7", "ups": "17.34", "wpb": "3547.2", "bsz": "146.9", "num_updates": "12000", "lr": "0.0057735", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "730"}
2023-12-13 22:41:03 | INFO | train_inner | {"epoch": 11, "update": 10.983, "loss": "4.715", "nll_loss": "3.379", "ppl": "10.41", "wps": "59556.9", "ups": "16.77", "wpb": "3551.8", "bsz": "139.5", "num_updates": "12100", "lr": "0.0057496", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "735"}
2023-12-13 22:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:41:06 | INFO | valid | {"epoch": 11, "valid_loss": "4.561", "valid_nll_loss": "3.221", "valid_ppl": "9.32", "valid_wps": "124126", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "12119", "valid_best_loss": "4.561"}
2023-12-13 22:41:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12119 updates
2023-12-13 22:41:06 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint11.pt
2023-12-13 22:41:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint11.pt
2023-12-13 22:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint11.pt (epoch 11 @ 12119 updates, score 4.561) (writing took 0.22212726157158613 seconds)
2023-12-13 22:41:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-12-13 22:41:06 | INFO | train | {"epoch": 11, "train_loss": "4.661", "train_nll_loss": "3.316", "train_ppl": "9.96", "train_wps": "58829", "train_ups": "16.42", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "12119", "train_lr": "0.00574509", "train_gnorm": "0.273", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "738"}
2023-12-13 22:41:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:41:06 | INFO | fairseq.trainer | begin training epoch 12
2023-12-13 22:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:41:12 | INFO | train_inner | {"epoch": 12, "update": 11.074, "loss": "4.595", "nll_loss": "3.236", "ppl": "9.42", "wps": "42244.7", "ups": "11.84", "wpb": "3566.8", "bsz": "125.7", "num_updates": "12200", "lr": "0.00572598", "gnorm": "0.272", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "744"}
2023-12-13 22:41:18 | INFO | train_inner | {"epoch": 12, "update": 11.164, "loss": "4.589", "nll_loss": "3.231", "ppl": "9.39", "wps": "59389.5", "ups": "16.39", "wpb": "3623.6", "bsz": "142.6", "num_updates": "12300", "lr": "0.00570266", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "750"}
2023-12-13 22:41:24 | INFO | train_inner | {"epoch": 12, "update": 11.255, "loss": "4.691", "nll_loss": "3.346", "ppl": "10.17", "wps": "55471.4", "ups": "15.48", "wpb": "3583.7", "bsz": "139.4", "num_updates": "12400", "lr": "0.00567962", "gnorm": "0.341", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "757"}
2023-12-13 22:41:30 | INFO | train_inner | {"epoch": 12, "update": 11.346, "loss": "4.612", "nll_loss": "3.26", "ppl": "9.58", "wps": "63516.5", "ups": "17.54", "wpb": "3620.9", "bsz": "144.8", "num_updates": "12500", "lr": "0.00565685", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "762"}
2023-12-13 22:41:36 | INFO | train_inner | {"epoch": 12, "update": 11.436, "loss": "4.604", "nll_loss": "3.25", "ppl": "9.51", "wps": "62349.8", "ups": "17.62", "wpb": "3538.1", "bsz": "160", "num_updates": "12600", "lr": "0.00563436", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "768"}
2023-12-13 22:41:42 | INFO | train_inner | {"epoch": 12, "update": 11.527, "loss": "4.647", "nll_loss": "3.302", "ppl": "9.86", "wps": "59580.7", "ups": "16.47", "wpb": "3616.7", "bsz": "134.6", "num_updates": "12700", "lr": "0.00561214", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "774"}
2023-12-13 22:41:48 | INFO | train_inner | {"epoch": 12, "update": 11.618, "loss": "4.646", "nll_loss": "3.3", "ppl": "9.85", "wps": "61861.2", "ups": "17.19", "wpb": "3599.6", "bsz": "147.5", "num_updates": "12800", "lr": "0.00559017", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "780"}
2023-12-13 22:41:53 | INFO | train_inner | {"epoch": 12, "update": 11.709, "loss": "4.599", "nll_loss": "3.246", "ppl": "9.49", "wps": "62767", "ups": "17.56", "wpb": "3575", "bsz": "149.1", "num_updates": "12900", "lr": "0.00556846", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "785"}
2023-12-13 22:41:59 | INFO | train_inner | {"epoch": 12, "update": 11.799, "loss": "4.675", "nll_loss": "3.337", "ppl": "10.1", "wps": "58942.8", "ups": "16.74", "wpb": "3521.2", "bsz": "144.3", "num_updates": "13000", "lr": "0.005547", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "791"}
2023-12-13 22:42:05 | INFO | train_inner | {"epoch": 12, "update": 11.89, "loss": "4.646", "nll_loss": "3.302", "ppl": "9.86", "wps": "62356.3", "ups": "17.59", "wpb": "3545.2", "bsz": "145.4", "num_updates": "13100", "lr": "0.00552579", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "797"}
2023-12-13 22:42:11 | INFO | train_inner | {"epoch": 12, "update": 11.981, "loss": "4.675", "nll_loss": "3.335", "ppl": "10.09", "wps": "63593.5", "ups": "17.71", "wpb": "3590.2", "bsz": "158.2", "num_updates": "13200", "lr": "0.00550482", "gnorm": "0.337", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "803"}
2023-12-13 22:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:42:13 | INFO | valid | {"epoch": 12, "valid_loss": "4.548", "valid_nll_loss": "3.214", "valid_ppl": "9.28", "valid_wps": "126504", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "13221", "valid_best_loss": "4.548"}
2023-12-13 22:42:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13221 updates
2023-12-13 22:42:13 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint12.pt
2023-12-13 22:42:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint12.pt
2023-12-13 22:42:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint12.pt (epoch 12 @ 13221 updates, score 4.548) (writing took 0.218208990059793 seconds)
2023-12-13 22:42:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-12-13 22:42:13 | INFO | train | {"epoch": 12, "train_loss": "4.632", "train_nll_loss": "3.283", "train_ppl": "9.73", "train_wps": "58761.8", "train_ups": "16.4", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "13221", "train_lr": "0.00550045", "train_gnorm": "0.293", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "806"}
2023-12-13 22:42:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:42:14 | INFO | fairseq.trainer | begin training epoch 13
2023-12-13 22:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:42:18 | INFO | train_inner | {"epoch": 13, "update": 12.072, "loss": "4.539", "nll_loss": "3.176", "ppl": "9.04", "wps": "47219.4", "ups": "13.17", "wpb": "3584.4", "bsz": "141.2", "num_updates": "13300", "lr": "0.00548408", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "810"}
2023-12-13 22:42:24 | INFO | train_inner | {"epoch": 13, "update": 12.162, "loss": "4.546", "nll_loss": "3.183", "ppl": "9.08", "wps": "59938.6", "ups": "16.95", "wpb": "3536.3", "bsz": "147", "num_updates": "13400", "lr": "0.00546358", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "816"}
2023-12-13 22:42:30 | INFO | train_inner | {"epoch": 13, "update": 12.253, "loss": "4.547", "nll_loss": "3.185", "ppl": "9.1", "wps": "62553", "ups": "17.47", "wpb": "3580.2", "bsz": "157.3", "num_updates": "13500", "lr": "0.00544331", "gnorm": "0.379", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "822"}
2023-12-13 22:42:35 | INFO | train_inner | {"epoch": 13, "update": 12.344, "loss": "4.486", "nll_loss": "3.119", "ppl": "8.69", "wps": "74409.1", "ups": "20.44", "wpb": "3640", "bsz": "174.1", "num_updates": "13600", "lr": "0.00542326", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "827"}
2023-12-13 22:42:41 | INFO | train_inner | {"epoch": 13, "update": 12.435, "loss": "4.64", "nll_loss": "3.295", "ppl": "9.82", "wps": "62483.4", "ups": "17.35", "wpb": "3600.9", "bsz": "130.3", "num_updates": "13700", "lr": "0.00540343", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "833"}
2023-12-13 22:42:46 | INFO | train_inner | {"epoch": 13, "update": 12.525, "loss": "4.575", "nll_loss": "3.219", "ppl": "9.31", "wps": "61265.4", "ups": "17.03", "wpb": "3596.6", "bsz": "145.2", "num_updates": "13800", "lr": "0.00538382", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "839"}
2023-12-13 22:42:53 | INFO | train_inner | {"epoch": 13, "update": 12.616, "loss": "4.661", "nll_loss": "3.317", "ppl": "9.97", "wps": "57099.7", "ups": "15.99", "wpb": "3571.9", "bsz": "129.3", "num_updates": "13900", "lr": "0.00536442", "gnorm": "0.322", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "845"}
2023-12-13 22:42:59 | INFO | train_inner | {"epoch": 13, "update": 12.707, "loss": "4.63", "nll_loss": "3.285", "ppl": "9.75", "wps": "61111.5", "ups": "17.02", "wpb": "3590.9", "bsz": "145", "num_updates": "14000", "lr": "0.00534522", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "851"}
2023-12-13 22:43:05 | INFO | train_inner | {"epoch": 13, "update": 12.798, "loss": "4.684", "nll_loss": "3.344", "ppl": "10.16", "wps": "54038.6", "ups": "15.03", "wpb": "3594.7", "bsz": "132.1", "num_updates": "14100", "lr": "0.00532624", "gnorm": "0.31", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "857"}
2023-12-13 22:43:11 | INFO | train_inner | {"epoch": 13, "update": 12.888, "loss": "4.572", "nll_loss": "3.219", "ppl": "9.31", "wps": "66202.7", "ups": "18.42", "wpb": "3593.9", "bsz": "161.3", "num_updates": "14200", "lr": "0.00530745", "gnorm": "0.269", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "863"}
2023-12-13 22:43:16 | INFO | train_inner | {"epoch": 13, "update": 12.979, "loss": "4.6", "nll_loss": "3.252", "ppl": "9.53", "wps": "63062", "ups": "17.52", "wpb": "3599.2", "bsz": "145.7", "num_updates": "14300", "lr": "0.00528886", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "868"}
2023-12-13 22:43:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:43:20 | INFO | valid | {"epoch": 13, "valid_loss": "4.516", "valid_nll_loss": "3.176", "valid_ppl": "9.04", "valid_wps": "122036", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "14323", "valid_best_loss": "4.516"}
2023-12-13 22:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14323 updates
2023-12-13 22:43:20 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint13.pt
2023-12-13 22:43:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint13.pt
2023-12-13 22:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint13.pt (epoch 13 @ 14323 updates, score 4.516) (writing took 0.22153599467128515 seconds)
2023-12-13 22:43:20 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-12-13 22:43:20 | INFO | train | {"epoch": 13, "train_loss": "4.593", "train_nll_loss": "3.241", "train_ppl": "9.45", "train_wps": "59580.6", "train_ups": "16.63", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "14323", "train_lr": "0.00528461", "train_gnorm": "0.29", "train_loss_scale": "16", "train_train_wall": "63", "train_gb_free": "39", "train_wall": "872"}
2023-12-13 22:43:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:43:20 | INFO | fairseq.trainer | begin training epoch 14
2023-12-13 22:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:43:24 | INFO | train_inner | {"epoch": 14, "update": 13.07, "loss": "4.57", "nll_loss": "3.212", "ppl": "9.26", "wps": "44040", "ups": "12.36", "wpb": "3562.1", "bsz": "135.5", "num_updates": "14400", "lr": "0.00527046", "gnorm": "0.327", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "877"}
2023-12-13 22:43:30 | INFO | train_inner | {"epoch": 14, "update": 13.161, "loss": "4.491", "nll_loss": "3.125", "ppl": "8.72", "wps": "65387", "ups": "18.29", "wpb": "3574.6", "bsz": "157.1", "num_updates": "14500", "lr": "0.00525226", "gnorm": "0.264", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "882"}
2023-12-13 22:43:36 | INFO | train_inner | {"epoch": 14, "update": 13.251, "loss": "4.478", "nll_loss": "3.108", "ppl": "8.62", "wps": "58675.1", "ups": "16.63", "wpb": "3528.5", "bsz": "162.6", "num_updates": "14600", "lr": "0.00523424", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "888"}
2023-12-13 22:43:43 | INFO | train_inner | {"epoch": 14, "update": 13.342, "loss": "4.594", "nll_loss": "3.24", "ppl": "9.45", "wps": "53533.4", "ups": "15.13", "wpb": "3537.3", "bsz": "128.6", "num_updates": "14700", "lr": "0.00521641", "gnorm": "0.296", "loss_scale": "16", "train_wall": "7", "gb_free": "39", "wall": "895"}
2023-12-13 22:43:48 | INFO | train_inner | {"epoch": 14, "update": 13.433, "loss": "4.588", "nll_loss": "3.236", "ppl": "9.42", "wps": "61062.8", "ups": "16.97", "wpb": "3597.2", "bsz": "140.2", "num_updates": "14800", "lr": "0.00519875", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "901"}
2023-12-13 22:43:54 | INFO | train_inner | {"epoch": 14, "update": 13.524, "loss": "4.536", "nll_loss": "3.178", "ppl": "9.05", "wps": "64045.2", "ups": "17.78", "wpb": "3603.1", "bsz": "155.7", "num_updates": "14900", "lr": "0.00518128", "gnorm": "0.256", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "906"}
2023-12-13 22:44:00 | INFO | train_inner | {"epoch": 14, "update": 13.614, "loss": "4.592", "nll_loss": "3.241", "ppl": "9.45", "wps": "59827.1", "ups": "16.59", "wpb": "3606.7", "bsz": "142.2", "num_updates": "15000", "lr": "0.00516398", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "912"}
2023-12-13 22:44:06 | INFO | train_inner | {"epoch": 14, "update": 13.705, "loss": "4.595", "nll_loss": "3.245", "ppl": "9.48", "wps": "58436.5", "ups": "16.45", "wpb": "3552.4", "bsz": "141", "num_updates": "15100", "lr": "0.00514685", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "918"}
2023-12-13 22:44:12 | INFO | train_inner | {"epoch": 14, "update": 13.796, "loss": "4.55", "nll_loss": "3.192", "ppl": "9.14", "wps": "56980.9", "ups": "16.14", "wpb": "3529.5", "bsz": "146.2", "num_updates": "15200", "lr": "0.00512989", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "924"}
2023-12-13 22:44:18 | INFO | train_inner | {"epoch": 14, "update": 13.887, "loss": "4.596", "nll_loss": "3.248", "ppl": "9.5", "wps": "65954.5", "ups": "18.21", "wpb": "3622.1", "bsz": "139.8", "num_updates": "15300", "lr": "0.0051131", "gnorm": "0.258", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "930"}
2023-12-13 22:44:24 | INFO | train_inner | {"epoch": 14, "update": 13.977, "loss": "4.599", "nll_loss": "3.25", "ppl": "9.51", "wps": "62719.9", "ups": "17.41", "wpb": "3602.1", "bsz": "143", "num_updates": "15400", "lr": "0.00509647", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "936"}
2023-12-13 22:44:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:44:26 | INFO | valid | {"epoch": 14, "valid_loss": "4.469", "valid_nll_loss": "3.122", "valid_ppl": "8.71", "valid_wps": "124934", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "15425", "valid_best_loss": "4.469"}
2023-12-13 22:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15425 updates
2023-12-13 22:44:26 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint14.pt
2023-12-13 22:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint14.pt
2023-12-13 22:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint14.pt (epoch 14 @ 15425 updates, score 4.469) (writing took 0.225859634578228 seconds)
2023-12-13 22:44:27 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-12-13 22:44:27 | INFO | train | {"epoch": 14, "train_loss": "4.557", "train_nll_loss": "3.201", "train_ppl": "9.19", "train_wps": "59057.6", "train_ups": "16.48", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "15425", "train_lr": "0.00509234", "train_gnorm": "0.275", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "939"}
2023-12-13 22:44:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:44:27 | INFO | fairseq.trainer | begin training epoch 15
2023-12-13 22:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:44:31 | INFO | train_inner | {"epoch": 15, "update": 14.068, "loss": "4.46", "nll_loss": "3.088", "ppl": "8.5", "wps": "49557.2", "ups": "13.58", "wpb": "3650.3", "bsz": "142.6", "num_updates": "15500", "lr": "0.00508001", "gnorm": "0.252", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "943"}
2023-12-13 22:44:37 | INFO | train_inner | {"epoch": 15, "update": 14.159, "loss": "4.411", "nll_loss": "3.034", "ppl": "8.19", "wps": "62905.2", "ups": "17.71", "wpb": "3551.7", "bsz": "168.1", "num_updates": "15600", "lr": "0.0050637", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "949"}
2023-12-13 22:44:42 | INFO | train_inner | {"epoch": 15, "update": 14.25, "loss": "4.509", "nll_loss": "3.145", "ppl": "8.84", "wps": "65606.7", "ups": "18.04", "wpb": "3637.2", "bsz": "138.6", "num_updates": "15700", "lr": "0.00504754", "gnorm": "0.264", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "954"}
2023-12-13 22:44:49 | INFO | train_inner | {"epoch": 15, "update": 14.34, "loss": "4.52", "nll_loss": "3.157", "ppl": "8.92", "wps": "54276", "ups": "15.18", "wpb": "3574.6", "bsz": "144.6", "num_updates": "15800", "lr": "0.00503155", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "961"}
2023-12-13 22:44:55 | INFO | train_inner | {"epoch": 15, "update": 14.431, "loss": "4.541", "nll_loss": "3.182", "ppl": "9.08", "wps": "61022.3", "ups": "17.06", "wpb": "3576.6", "bsz": "139.7", "num_updates": "15900", "lr": "0.0050157", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "967"}
2023-12-13 22:45:00 | INFO | train_inner | {"epoch": 15, "update": 14.522, "loss": "4.504", "nll_loss": "3.142", "ppl": "8.82", "wps": "66724.7", "ups": "18.39", "wpb": "3629", "bsz": "157.9", "num_updates": "16000", "lr": "0.005", "gnorm": "0.307", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "972"}
2023-12-13 22:45:06 | INFO | train_inner | {"epoch": 15, "update": 14.613, "loss": "4.566", "nll_loss": "3.211", "ppl": "9.26", "wps": "59450.9", "ups": "16.87", "wpb": "3524.9", "bsz": "138.6", "num_updates": "16100", "lr": "0.00498445", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "978"}
2023-12-13 22:45:12 | INFO | train_inner | {"epoch": 15, "update": 14.703, "loss": "4.542", "nll_loss": "3.185", "ppl": "9.1", "wps": "57705.4", "ups": "16.12", "wpb": "3580.8", "bsz": "139.5", "num_updates": "16200", "lr": "0.00496904", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "984"}
2023-12-13 22:45:18 | INFO | train_inner | {"epoch": 15, "update": 14.794, "loss": "4.577", "nll_loss": "3.225", "ppl": "9.35", "wps": "57576", "ups": "15.84", "wpb": "3636", "bsz": "141", "num_updates": "16300", "lr": "0.00495377", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "991"}
2023-12-13 22:45:24 | INFO | train_inner | {"epoch": 15, "update": 14.885, "loss": "4.548", "nll_loss": "3.193", "ppl": "9.15", "wps": "63389.9", "ups": "17.92", "wpb": "3536.5", "bsz": "145.7", "num_updates": "16400", "lr": "0.00493865", "gnorm": "0.268", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "996"}
2023-12-13 22:45:30 | INFO | train_inner | {"epoch": 15, "update": 14.975, "loss": "4.578", "nll_loss": "3.228", "ppl": "9.37", "wps": "59869", "ups": "16.69", "wpb": "3587.4", "bsz": "145", "num_updates": "16500", "lr": "0.00492366", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1002"}
2023-12-13 22:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:45:33 | INFO | valid | {"epoch": 15, "valid_loss": "4.483", "valid_nll_loss": "3.143", "valid_ppl": "8.83", "valid_wps": "126740", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "16527", "valid_best_loss": "4.469"}
2023-12-13 22:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16527 updates
2023-12-13 22:45:33 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint15.pt
2023-12-13 22:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint15.pt
2023-12-13 22:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint15.pt (epoch 15 @ 16527 updates, score 4.483) (writing took 0.15305074770003557 seconds)
2023-12-13 22:45:34 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-12-13 22:45:34 | INFO | train | {"epoch": 15, "train_loss": "4.524", "train_nll_loss": "3.163", "train_ppl": "8.96", "train_wps": "58954.2", "train_ups": "16.45", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "16527", "train_lr": "0.00491964", "train_gnorm": "0.276", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1006"}
2023-12-13 22:45:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:45:34 | INFO | fairseq.trainer | begin training epoch 16
2023-12-13 22:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:45:38 | INFO | train_inner | {"epoch": 16, "update": 15.066, "loss": "4.541", "nll_loss": "3.181", "ppl": "9.07", "wps": "41914", "ups": "11.86", "wpb": "3532.8", "bsz": "131.6", "num_updates": "16600", "lr": "0.00490881", "gnorm": "0.32", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "1011"}
2023-12-13 22:45:45 | INFO | train_inner | {"epoch": 16, "update": 15.157, "loss": "4.441", "nll_loss": "3.066", "ppl": "8.38", "wps": "59721.1", "ups": "16.39", "wpb": "3644.8", "bsz": "143.8", "num_updates": "16700", "lr": "0.00489409", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1017"}
2023-12-13 22:45:50 | INFO | train_inner | {"epoch": 16, "update": 15.248, "loss": "4.486", "nll_loss": "3.118", "ppl": "8.68", "wps": "60225", "ups": "16.9", "wpb": "3563.7", "bsz": "133", "num_updates": "16800", "lr": "0.0048795", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1023"}
2023-12-13 22:45:56 | INFO | train_inner | {"epoch": 16, "update": 15.338, "loss": "4.509", "nll_loss": "3.147", "ppl": "8.86", "wps": "62176.2", "ups": "17.68", "wpb": "3515.8", "bsz": "138", "num_updates": "16900", "lr": "0.00486504", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1028"}
2023-12-13 22:46:01 | INFO | train_inner | {"epoch": 16, "update": 15.429, "loss": "4.432", "nll_loss": "3.059", "ppl": "8.33", "wps": "68140.3", "ups": "18.83", "wpb": "3619.5", "bsz": "162.1", "num_updates": "17000", "lr": "0.00485071", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1034"}
2023-12-13 22:46:07 | INFO | train_inner | {"epoch": 16, "update": 15.52, "loss": "4.539", "nll_loss": "3.182", "ppl": "9.08", "wps": "59520.5", "ups": "16.63", "wpb": "3578.4", "bsz": "141.8", "num_updates": "17100", "lr": "0.00483651", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1040"}
2023-12-13 22:46:13 | INFO | train_inner | {"epoch": 16, "update": 15.611, "loss": "4.461", "nll_loss": "3.092", "ppl": "8.53", "wps": "63034", "ups": "17.49", "wpb": "3603.7", "bsz": "158.9", "num_updates": "17200", "lr": "0.00482243", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1045"}
2023-12-13 22:46:19 | INFO | train_inner | {"epoch": 16, "update": 15.701, "loss": "4.509", "nll_loss": "3.147", "ppl": "8.86", "wps": "58439.8", "ups": "16.38", "wpb": "3567.7", "bsz": "147.3", "num_updates": "17300", "lr": "0.00480847", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1051"}
2023-12-13 22:46:25 | INFO | train_inner | {"epoch": 16, "update": 15.792, "loss": "4.469", "nll_loss": "3.101", "ppl": "8.58", "wps": "62141.6", "ups": "17.27", "wpb": "3598.2", "bsz": "157.5", "num_updates": "17400", "lr": "0.00479463", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1057"}
2023-12-13 22:46:31 | INFO | train_inner | {"epoch": 16, "update": 15.883, "loss": "4.515", "nll_loss": "3.158", "ppl": "8.92", "wps": "61152.8", "ups": "17.32", "wpb": "3530.6", "bsz": "151.2", "num_updates": "17500", "lr": "0.00478091", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1063"}
2023-12-13 22:46:37 | INFO | train_inner | {"epoch": 16, "update": 15.974, "loss": "4.572", "nll_loss": "3.221", "ppl": "9.33", "wps": "57820.1", "ups": "15.94", "wpb": "3627.8", "bsz": "138.2", "num_updates": "17600", "lr": "0.00476731", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1069"}
2023-12-13 22:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:46:40 | INFO | valid | {"epoch": 16, "valid_loss": "4.444", "valid_nll_loss": "3.097", "valid_ppl": "8.55", "valid_wps": "123333", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "17629", "valid_best_loss": "4.444"}
2023-12-13 22:46:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17629 updates
2023-12-13 22:46:40 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint16.pt
2023-12-13 22:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint16.pt
2023-12-13 22:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint16.pt (epoch 16 @ 17629 updates, score 4.444) (writing took 0.22504643816500902 seconds)
2023-12-13 22:46:40 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-12-13 22:46:40 | INFO | train | {"epoch": 16, "train_loss": "4.497", "train_nll_loss": "3.133", "train_ppl": "8.77", "train_wps": "59056.5", "train_ups": "16.48", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "17629", "train_lr": "0.00476339", "train_gnorm": "0.276", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1073"}
2023-12-13 22:46:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:46:41 | INFO | fairseq.trainer | begin training epoch 17
2023-12-13 22:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:46:45 | INFO | train_inner | {"epoch": 17, "update": 16.064, "loss": "4.447", "nll_loss": "3.074", "ppl": "8.42", "wps": "45165.3", "ups": "12.52", "wpb": "3606.2", "bsz": "131.8", "num_updates": "17700", "lr": "0.00475383", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1077"}
2023-12-13 22:46:51 | INFO | train_inner | {"epoch": 17, "update": 16.155, "loss": "4.402", "nll_loss": "3.02", "ppl": "8.11", "wps": "62753.1", "ups": "17.25", "wpb": "3638.4", "bsz": "138", "num_updates": "17800", "lr": "0.00474045", "gnorm": "0.251", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1083"}
2023-12-13 22:46:57 | INFO | train_inner | {"epoch": 17, "update": 16.246, "loss": "4.463", "nll_loss": "3.093", "ppl": "8.53", "wps": "57173.4", "ups": "16.02", "wpb": "3569.1", "bsz": "138.5", "num_updates": "17900", "lr": "0.00472719", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1089"}
2023-12-13 22:47:03 | INFO | train_inner | {"epoch": 17, "update": 16.337, "loss": "4.446", "nll_loss": "3.075", "ppl": "8.43", "wps": "61006.7", "ups": "17.05", "wpb": "3577.5", "bsz": "146.2", "num_updates": "18000", "lr": "0.00471405", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1095"}
2023-12-13 22:47:08 | INFO | train_inner | {"epoch": 17, "update": 16.427, "loss": "4.475", "nll_loss": "3.107", "ppl": "8.62", "wps": "66086", "ups": "18.44", "wpb": "3582.9", "bsz": "150.3", "num_updates": "18100", "lr": "0.004701", "gnorm": "0.286", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1101"}
2023-12-13 22:47:14 | INFO | train_inner | {"epoch": 17, "update": 16.518, "loss": "4.458", "nll_loss": "3.091", "ppl": "8.52", "wps": "60899.6", "ups": "17.19", "wpb": "3543.4", "bsz": "155", "num_updates": "18200", "lr": "0.00468807", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1106"}
2023-12-13 22:47:20 | INFO | train_inner | {"epoch": 17, "update": 16.609, "loss": "4.509", "nll_loss": "3.149", "ppl": "8.87", "wps": "58487", "ups": "16.36", "wpb": "3575.7", "bsz": "142.5", "num_updates": "18300", "lr": "0.00467525", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1112"}
2023-12-13 22:47:26 | INFO | train_inner | {"epoch": 17, "update": 16.7, "loss": "4.429", "nll_loss": "3.056", "ppl": "8.32", "wps": "64900.2", "ups": "17.83", "wpb": "3639.4", "bsz": "162.5", "num_updates": "18400", "lr": "0.00466252", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1118"}
2023-12-13 22:47:32 | INFO | train_inner | {"epoch": 17, "update": 16.79, "loss": "4.522", "nll_loss": "3.165", "ppl": "8.97", "wps": "62285.8", "ups": "17.46", "wpb": "3567.6", "bsz": "138.2", "num_updates": "18500", "lr": "0.00464991", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1124"}
2023-12-13 22:47:37 | INFO | train_inner | {"epoch": 17, "update": 16.881, "loss": "4.5", "nll_loss": "3.14", "ppl": "8.82", "wps": "63272.7", "ups": "17.63", "wpb": "3588.9", "bsz": "149.1", "num_updates": "18600", "lr": "0.00463739", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1129"}
2023-12-13 22:47:44 | INFO | train_inner | {"epoch": 17, "update": 16.972, "loss": "4.538", "nll_loss": "3.182", "ppl": "9.08", "wps": "56508.5", "ups": "15.93", "wpb": "3546.8", "bsz": "140.5", "num_updates": "18700", "lr": "0.00462497", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1136"}
2023-12-13 22:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:47:47 | INFO | valid | {"epoch": 17, "valid_loss": "4.431", "valid_nll_loss": "3.081", "valid_ppl": "8.46", "valid_wps": "125288", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "18731", "valid_best_loss": "4.431"}
2023-12-13 22:47:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18731 updates
2023-12-13 22:47:47 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint17.pt
2023-12-13 22:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint17.pt
2023-12-13 22:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint17.pt (epoch 17 @ 18731 updates, score 4.431) (writing took 0.22618875559419394 seconds)
2023-12-13 22:47:47 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-12-13 22:47:47 | INFO | train | {"epoch": 17, "train_loss": "4.47", "train_nll_loss": "3.103", "train_ppl": "8.59", "train_wps": "59329.2", "train_ups": "16.56", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "18731", "train_lr": "0.00462114", "train_gnorm": "0.274", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1139"}
2023-12-13 22:47:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:47:47 | INFO | fairseq.trainer | begin training epoch 18
2023-12-13 22:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:47:51 | INFO | train_inner | {"epoch": 18, "update": 17.063, "loss": "4.346", "nll_loss": "2.96", "ppl": "7.78", "wps": "47964.7", "ups": "13.24", "wpb": "3621.4", "bsz": "165", "num_updates": "18800", "lr": "0.00461266", "gnorm": "0.257", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1143"}
2023-12-13 22:47:57 | INFO | train_inner | {"epoch": 18, "update": 17.153, "loss": "4.374", "nll_loss": "2.99", "ppl": "7.94", "wps": "59322.9", "ups": "16.67", "wpb": "3557.8", "bsz": "139.6", "num_updates": "18900", "lr": "0.00460044", "gnorm": "0.265", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1149"}
2023-12-13 22:48:03 | INFO | train_inner | {"epoch": 18, "update": 17.244, "loss": "4.423", "nll_loss": "3.048", "ppl": "8.27", "wps": "60890.3", "ups": "16.93", "wpb": "3595.8", "bsz": "147.8", "num_updates": "19000", "lr": "0.00458831", "gnorm": "0.417", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1155"}
2023-12-13 22:48:08 | INFO | train_inner | {"epoch": 18, "update": 17.335, "loss": "4.383", "nll_loss": "3.003", "ppl": "8.02", "wps": "66342.7", "ups": "18.64", "wpb": "3558.2", "bsz": "155.8", "num_updates": "19100", "lr": "0.00457629", "gnorm": "0.284", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1161"}
2023-12-13 22:48:14 | INFO | train_inner | {"epoch": 18, "update": 17.426, "loss": "4.473", "nll_loss": "3.104", "ppl": "8.6", "wps": "58143.7", "ups": "16.61", "wpb": "3500.5", "bsz": "131.3", "num_updates": "19200", "lr": "0.00456435", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1167"}
2023-12-13 22:48:20 | INFO | train_inner | {"epoch": 18, "update": 17.516, "loss": "4.385", "nll_loss": "3.006", "ppl": "8.03", "wps": "67852.3", "ups": "18.63", "wpb": "3642", "bsz": "160.2", "num_updates": "19300", "lr": "0.00455251", "gnorm": "0.262", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1172"}
2023-12-13 22:48:26 | INFO | train_inner | {"epoch": 18, "update": 17.607, "loss": "4.557", "nll_loss": "3.205", "ppl": "9.22", "wps": "57096.1", "ups": "15.88", "wpb": "3596.1", "bsz": "128.4", "num_updates": "19400", "lr": "0.00454077", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1178"}
2023-12-13 22:48:32 | INFO | train_inner | {"epoch": 18, "update": 17.698, "loss": "4.467", "nll_loss": "3.101", "ppl": "8.58", "wps": "62171.3", "ups": "17.12", "wpb": "3630.9", "bsz": "143.8", "num_updates": "19500", "lr": "0.00452911", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1184"}
2023-12-13 22:48:38 | INFO | train_inner | {"epoch": 18, "update": 17.789, "loss": "4.492", "nll_loss": "3.13", "ppl": "8.75", "wps": "56625.5", "ups": "15.91", "wpb": "3558.1", "bsz": "138.6", "num_updates": "19600", "lr": "0.00451754", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1190"}
2023-12-13 22:48:44 | INFO | train_inner | {"epoch": 18, "update": 17.879, "loss": "4.506", "nll_loss": "3.148", "ppl": "8.86", "wps": "62921.6", "ups": "17.65", "wpb": "3564.7", "bsz": "150.2", "num_updates": "19700", "lr": "0.00450606", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1196"}
2023-12-13 22:48:50 | INFO | train_inner | {"epoch": 18, "update": 17.97, "loss": "4.501", "nll_loss": "3.142", "ppl": "8.83", "wps": "57779.3", "ups": "16.09", "wpb": "3590.5", "bsz": "145.4", "num_updates": "19800", "lr": "0.00449467", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1202"}
2023-12-13 22:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:48:53 | INFO | valid | {"epoch": 18, "valid_loss": "4.412", "valid_nll_loss": "3.073", "valid_ppl": "8.41", "valid_wps": "128786", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "19833", "valid_best_loss": "4.412"}
2023-12-13 22:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19833 updates
2023-12-13 22:48:53 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint18.pt
2023-12-13 22:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint18.pt
2023-12-13 22:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint18.pt (epoch 18 @ 19833 updates, score 4.412) (writing took 0.21872484497725964 seconds)
2023-12-13 22:48:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-12-13 22:48:54 | INFO | train | {"epoch": 18, "train_loss": "4.446", "train_nll_loss": "3.076", "train_ppl": "8.44", "train_wps": "59325.3", "train_ups": "16.55", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "19833", "train_lr": "0.00449092", "train_gnorm": "0.285", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1206"}
2023-12-13 22:48:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:48:54 | INFO | fairseq.trainer | begin training epoch 19
2023-12-13 22:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:48:58 | INFO | train_inner | {"epoch": 19, "update": 18.061, "loss": "4.383", "nll_loss": "3.006", "ppl": "8.03", "wps": "49340.7", "ups": "13.62", "wpb": "3623.9", "bsz": "149.4", "num_updates": "19900", "lr": "0.00448336", "gnorm": "0.249", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1210"}
2023-12-13 22:49:04 | INFO | train_inner | {"epoch": 19, "update": 18.152, "loss": "4.41", "nll_loss": "3.031", "ppl": "8.18", "wps": "55651.6", "ups": "15.67", "wpb": "3552.4", "bsz": "126.3", "num_updates": "20000", "lr": "0.00447214", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1216"}
2023-12-13 22:49:10 | INFO | train_inner | {"epoch": 19, "update": 18.242, "loss": "4.356", "nll_loss": "2.971", "ppl": "7.84", "wps": "60637.9", "ups": "16.94", "wpb": "3578.8", "bsz": "152.8", "num_updates": "20100", "lr": "0.004461", "gnorm": "0.278", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1222"}
2023-12-13 22:49:16 | INFO | train_inner | {"epoch": 19, "update": 18.333, "loss": "4.405", "nll_loss": "3.027", "ppl": "8.15", "wps": "55669.6", "ups": "15.73", "wpb": "3540.1", "bsz": "147.7", "num_updates": "20200", "lr": "0.00444994", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1228"}
2023-12-13 22:49:21 | INFO | train_inner | {"epoch": 19, "update": 18.424, "loss": "4.389", "nll_loss": "3.012", "ppl": "8.07", "wps": "69905.6", "ups": "19.45", "wpb": "3594.4", "bsz": "160.7", "num_updates": "20300", "lr": "0.00443897", "gnorm": "0.261", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1233"}
2023-12-13 22:49:27 | INFO | train_inner | {"epoch": 19, "update": 18.515, "loss": "4.443", "nll_loss": "3.073", "ppl": "8.42", "wps": "63632.4", "ups": "17.6", "wpb": "3615.2", "bsz": "139.1", "num_updates": "20400", "lr": "0.00442807", "gnorm": "0.257", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1239"}
2023-12-13 22:49:32 | INFO | train_inner | {"epoch": 19, "update": 18.605, "loss": "4.405", "nll_loss": "3.029", "ppl": "8.16", "wps": "72469.5", "ups": "20.01", "wpb": "3622.4", "bsz": "161.4", "num_updates": "20500", "lr": "0.00441726", "gnorm": "0.297", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1244"}
2023-12-13 22:49:38 | INFO | train_inner | {"epoch": 19, "update": 18.696, "loss": "4.491", "nll_loss": "3.13", "ppl": "8.75", "wps": "57299.7", "ups": "16.16", "wpb": "3546.6", "bsz": "136.1", "num_updates": "20600", "lr": "0.00440653", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1250"}
2023-12-13 22:49:45 | INFO | train_inner | {"epoch": 19, "update": 18.787, "loss": "4.5", "nll_loss": "3.137", "ppl": "8.8", "wps": "55216.7", "ups": "15.64", "wpb": "3531.1", "bsz": "142.2", "num_updates": "20700", "lr": "0.00439587", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1257"}
2023-12-13 22:49:50 | INFO | train_inner | {"epoch": 19, "update": 18.877, "loss": "4.475", "nll_loss": "3.113", "ppl": "8.65", "wps": "60451.3", "ups": "17.01", "wpb": "3554.3", "bsz": "141.2", "num_updates": "20800", "lr": "0.00438529", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1263"}
2023-12-13 22:49:56 | INFO | train_inner | {"epoch": 19, "update": 18.968, "loss": "4.453", "nll_loss": "3.087", "ppl": "8.5", "wps": "62761", "ups": "17.19", "wpb": "3650.4", "bsz": "144.8", "num_updates": "20900", "lr": "0.00437479", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1268"}
2023-12-13 22:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:50:00 | INFO | valid | {"epoch": 19, "valid_loss": "4.403", "valid_nll_loss": "3.047", "valid_ppl": "8.27", "valid_wps": "123966", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "20935", "valid_best_loss": "4.403"}
2023-12-13 22:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20935 updates
2023-12-13 22:50:00 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint19.pt
2023-12-13 22:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint19.pt
2023-12-13 22:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint19.pt (epoch 19 @ 20935 updates, score 4.403) (writing took 0.2251207660883665 seconds)
2023-12-13 22:50:00 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-12-13 22:50:00 | INFO | train | {"epoch": 19, "train_loss": "4.426", "train_nll_loss": "3.054", "train_ppl": "8.3", "train_wps": "59327.1", "train_ups": "16.56", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "20935", "train_lr": "0.00437113", "train_gnorm": "0.275", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1272"}
2023-12-13 22:50:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:50:00 | INFO | fairseq.trainer | begin training epoch 20
2023-12-13 22:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:50:04 | INFO | train_inner | {"epoch": 20, "update": 19.059, "loss": "4.332", "nll_loss": "2.944", "ppl": "7.7", "wps": "47874.2", "ups": "13.22", "wpb": "3620.8", "bsz": "147", "num_updates": "21000", "lr": "0.00436436", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1276"}
2023-12-13 22:50:10 | INFO | train_inner | {"epoch": 20, "update": 19.15, "loss": "4.391", "nll_loss": "3.011", "ppl": "8.06", "wps": "59113.6", "ups": "16.38", "wpb": "3608.9", "bsz": "139.1", "num_updates": "21100", "lr": "0.004354", "gnorm": "0.315", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1282"}
2023-12-13 22:50:16 | INFO | train_inner | {"epoch": 20, "update": 19.24, "loss": "4.348", "nll_loss": "2.963", "ppl": "7.8", "wps": "61933.3", "ups": "17.32", "wpb": "3575.8", "bsz": "150.2", "num_updates": "21200", "lr": "0.00434372", "gnorm": "0.273", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1288"}
2023-12-13 22:50:22 | INFO | train_inner | {"epoch": 20, "update": 19.331, "loss": "4.386", "nll_loss": "3.007", "ppl": "8.04", "wps": "59635.7", "ups": "16.58", "wpb": "3595.9", "bsz": "141.3", "num_updates": "21300", "lr": "0.00433351", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1294"}
2023-12-13 22:50:28 | INFO | train_inner | {"epoch": 20, "update": 19.422, "loss": "4.367", "nll_loss": "2.986", "ppl": "7.92", "wps": "59714.6", "ups": "16.65", "wpb": "3586.1", "bsz": "146.5", "num_updates": "21400", "lr": "0.00432338", "gnorm": "0.254", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1300"}
2023-12-13 22:50:33 | INFO | train_inner | {"epoch": 20, "update": 19.513, "loss": "4.419", "nll_loss": "3.047", "ppl": "8.27", "wps": "62403.9", "ups": "17.61", "wpb": "3542.9", "bsz": "150.2", "num_updates": "21500", "lr": "0.00431331", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1306"}
2023-12-13 22:50:39 | INFO | train_inner | {"epoch": 20, "update": 19.603, "loss": "4.425", "nll_loss": "3.055", "ppl": "8.31", "wps": "58713.3", "ups": "16.51", "wpb": "3556.5", "bsz": "150.2", "num_updates": "21600", "lr": "0.00430331", "gnorm": "0.301", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1312"}
2023-12-13 22:50:45 | INFO | train_inner | {"epoch": 20, "update": 19.694, "loss": "4.451", "nll_loss": "3.085", "ppl": "8.48", "wps": "60163.6", "ups": "16.89", "wpb": "3561.7", "bsz": "145.9", "num_updates": "21700", "lr": "0.00429339", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1317"}
2023-12-13 22:50:52 | INFO | train_inner | {"epoch": 20, "update": 19.785, "loss": "4.478", "nll_loss": "3.114", "ppl": "8.66", "wps": "56643.8", "ups": "15.78", "wpb": "3590.5", "bsz": "129.4", "num_updates": "21800", "lr": "0.00428353", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1324"}
2023-12-13 22:50:57 | INFO | train_inner | {"epoch": 20, "update": 19.876, "loss": "4.396", "nll_loss": "3.023", "ppl": "8.13", "wps": "66149.7", "ups": "18.59", "wpb": "3559.1", "bsz": "156.8", "num_updates": "21900", "lr": "0.00427374", "gnorm": "0.273", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1329"}
2023-12-13 22:51:03 | INFO | train_inner | {"epoch": 20, "update": 19.966, "loss": "4.423", "nll_loss": "3.053", "ppl": "8.3", "wps": "62899.6", "ups": "17.28", "wpb": "3639.6", "bsz": "145.2", "num_updates": "22000", "lr": "0.00426401", "gnorm": "0.255", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1335"}
2023-12-13 22:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:51:07 | INFO | valid | {"epoch": 20, "valid_loss": "4.383", "valid_nll_loss": "3.041", "valid_ppl": "8.23", "valid_wps": "125320", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "22037", "valid_best_loss": "4.383"}
2023-12-13 22:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 22037 updates
2023-12-13 22:51:07 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint20.pt
2023-12-13 22:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint20.pt
2023-12-13 22:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint20.pt (epoch 20 @ 22037 updates, score 4.383) (writing took 0.2245926670730114 seconds)
2023-12-13 22:51:07 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-12-13 22:51:07 | INFO | train | {"epoch": 20, "train_loss": "4.402", "train_nll_loss": "3.027", "train_ppl": "8.15", "train_wps": "59069.1", "train_ups": "16.48", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "22037", "train_lr": "0.00426043", "train_gnorm": "0.275", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "1339"}
2023-12-13 22:51:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:51:07 | INFO | fairseq.trainer | begin training epoch 21
2023-12-13 22:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:51:11 | INFO | train_inner | {"epoch": 21, "update": 20.057, "loss": "4.346", "nll_loss": "2.961", "ppl": "7.79", "wps": "44112.8", "ups": "12.25", "wpb": "3599.7", "bsz": "139", "num_updates": "22100", "lr": "0.00425436", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1343"}
2023-12-13 22:51:17 | INFO | train_inner | {"epoch": 21, "update": 20.148, "loss": "4.349", "nll_loss": "2.963", "ppl": "7.8", "wps": "57299.3", "ups": "16.14", "wpb": "3550", "bsz": "134.4", "num_updates": "22200", "lr": "0.00424476", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1349"}
2023-12-13 22:51:23 | INFO | train_inner | {"epoch": 21, "update": 20.239, "loss": "4.292", "nll_loss": "2.899", "ppl": "7.46", "wps": "64245.6", "ups": "17.91", "wpb": "3587", "bsz": "158.8", "num_updates": "22300", "lr": "0.00423524", "gnorm": "0.259", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1355"}
2023-12-13 22:51:29 | INFO | train_inner | {"epoch": 21, "update": 20.329, "loss": "4.409", "nll_loss": "3.035", "ppl": "8.2", "wps": "58084.2", "ups": "16.39", "wpb": "3543.9", "bsz": "137.4", "num_updates": "22400", "lr": "0.00422577", "gnorm": "0.301", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1361"}
2023-12-13 22:51:35 | INFO | train_inner | {"epoch": 21, "update": 20.42, "loss": "4.37", "nll_loss": "2.989", "ppl": "7.94", "wps": "63338.2", "ups": "17.56", "wpb": "3606.2", "bsz": "145.9", "num_updates": "22500", "lr": "0.00421637", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1367"}
2023-12-13 22:51:40 | INFO | train_inner | {"epoch": 21, "update": 20.511, "loss": "4.342", "nll_loss": "2.958", "ppl": "7.77", "wps": "64397.6", "ups": "17.71", "wpb": "3636", "bsz": "151.4", "num_updates": "22600", "lr": "0.00420703", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1372"}
2023-12-13 22:51:46 | INFO | train_inner | {"epoch": 21, "update": 20.602, "loss": "4.362", "nll_loss": "2.983", "ppl": "7.91", "wps": "65032.8", "ups": "18.34", "wpb": "3545.5", "bsz": "159.8", "num_updates": "22700", "lr": "0.00419775", "gnorm": "0.273", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1378"}
2023-12-13 22:51:51 | INFO | train_inner | {"epoch": 21, "update": 20.692, "loss": "4.422", "nll_loss": "3.052", "ppl": "8.29", "wps": "63930.8", "ups": "17.93", "wpb": "3564.8", "bsz": "143.5", "num_updates": "22800", "lr": "0.00418854", "gnorm": "0.269", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1383"}
2023-12-13 22:51:57 | INFO | train_inner | {"epoch": 21, "update": 20.783, "loss": "4.385", "nll_loss": "3.01", "ppl": "8.05", "wps": "58810", "ups": "16.23", "wpb": "3624.2", "bsz": "158.5", "num_updates": "22900", "lr": "0.00417938", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1390"}
2023-12-13 22:52:04 | INFO | train_inner | {"epoch": 21, "update": 20.874, "loss": "4.489", "nll_loss": "3.13", "ppl": "8.75", "wps": "56187.3", "ups": "15.76", "wpb": "3566.1", "bsz": "134.5", "num_updates": "23000", "lr": "0.00417029", "gnorm": "0.282", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1396"}
2023-12-13 22:52:10 | INFO | train_inner | {"epoch": 21, "update": 20.965, "loss": "4.449", "nll_loss": "3.084", "ppl": "8.48", "wps": "59552.7", "ups": "16.44", "wpb": "3621.8", "bsz": "135.1", "num_updates": "23100", "lr": "0.00416125", "gnorm": "0.264", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1402"}
2023-12-13 22:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:52:14 | INFO | valid | {"epoch": 21, "valid_loss": "4.397", "valid_nll_loss": "3.049", "valid_ppl": "8.28", "valid_wps": "121854", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "23139", "valid_best_loss": "4.383"}
2023-12-13 22:52:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 23139 updates
2023-12-13 22:52:14 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint21.pt
2023-12-13 22:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint21.pt
2023-12-13 22:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint21.pt (epoch 21 @ 23139 updates, score 4.397) (writing took 0.15236741118133068 seconds)
2023-12-13 22:52:14 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-12-13 22:52:14 | INFO | train | {"epoch": 21, "train_loss": "4.383", "train_nll_loss": "3.005", "train_ppl": "8.03", "train_wps": "58826.2", "train_ups": "16.42", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "23139", "train_lr": "0.00415774", "train_gnorm": "0.274", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1406"}
2023-12-13 22:52:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:52:14 | INFO | fairseq.trainer | begin training epoch 22
2023-12-13 22:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:52:18 | INFO | train_inner | {"epoch": 22, "update": 21.055, "loss": "4.325", "nll_loss": "2.935", "ppl": "7.65", "wps": "44680.7", "ups": "12.58", "wpb": "3550.8", "bsz": "132", "num_updates": "23200", "lr": "0.00415227", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1410"}
2023-12-13 22:52:24 | INFO | train_inner | {"epoch": 22, "update": 21.146, "loss": "4.302", "nll_loss": "2.91", "ppl": "7.52", "wps": "62345.3", "ups": "17.34", "wpb": "3595.1", "bsz": "145.3", "num_updates": "23300", "lr": "0.00414335", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1416"}
2023-12-13 22:52:30 | INFO | train_inner | {"epoch": 22, "update": 21.237, "loss": "4.357", "nll_loss": "2.974", "ppl": "7.86", "wps": "58451.5", "ups": "16.51", "wpb": "3541.3", "bsz": "136.7", "num_updates": "23400", "lr": "0.00413449", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1422"}
2023-12-13 22:52:35 | INFO | train_inner | {"epoch": 22, "update": 21.328, "loss": "4.33", "nll_loss": "2.944", "ppl": "7.7", "wps": "62843.4", "ups": "17.33", "wpb": "3625.3", "bsz": "156.2", "num_updates": "23500", "lr": "0.00412568", "gnorm": "0.263", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1428"}
2023-12-13 22:52:41 | INFO | train_inner | {"epoch": 22, "update": 21.418, "loss": "4.324", "nll_loss": "2.937", "ppl": "7.66", "wps": "62408", "ups": "17.32", "wpb": "3602.6", "bsz": "150.5", "num_updates": "23600", "lr": "0.00411693", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1433"}
2023-12-13 22:52:47 | INFO | train_inner | {"epoch": 22, "update": 21.509, "loss": "4.373", "nll_loss": "2.995", "ppl": "7.97", "wps": "59893.6", "ups": "16.62", "wpb": "3604.4", "bsz": "147.8", "num_updates": "23700", "lr": "0.00410824", "gnorm": "0.274", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1439"}
2023-12-13 22:52:54 | INFO | train_inner | {"epoch": 22, "update": 21.6, "loss": "4.391", "nll_loss": "3.015", "ppl": "8.08", "wps": "55865.2", "ups": "15.84", "wpb": "3525.9", "bsz": "133.9", "num_updates": "23800", "lr": "0.0040996", "gnorm": "0.267", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1446"}
2023-12-13 22:53:00 | INFO | train_inner | {"epoch": 22, "update": 21.691, "loss": "4.401", "nll_loss": "3.027", "ppl": "8.15", "wps": "57705.4", "ups": "16.05", "wpb": "3594.9", "bsz": "147.4", "num_updates": "23900", "lr": "0.00409101", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1452"}
2023-12-13 22:53:06 | INFO | train_inner | {"epoch": 22, "update": 21.781, "loss": "4.414", "nll_loss": "3.044", "ppl": "8.25", "wps": "59837.5", "ups": "16.58", "wpb": "3608.4", "bsz": "139.2", "num_updates": "24000", "lr": "0.00408248", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1458"}
2023-12-13 22:53:11 | INFO | train_inner | {"epoch": 22, "update": 21.872, "loss": "4.384", "nll_loss": "3.012", "ppl": "8.07", "wps": "62984.2", "ups": "17.6", "wpb": "3578.6", "bsz": "159.4", "num_updates": "24100", "lr": "0.004074", "gnorm": "0.269", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1464"}
2023-12-13 22:53:17 | INFO | train_inner | {"epoch": 22, "update": 21.963, "loss": "4.409", "nll_loss": "3.038", "ppl": "8.21", "wps": "63064.1", "ups": "17.66", "wpb": "3571.3", "bsz": "144.1", "num_updates": "24200", "lr": "0.00406558", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1469"}
2023-12-13 22:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:53:21 | INFO | valid | {"epoch": 22, "valid_loss": "4.381", "valid_nll_loss": "3.034", "valid_ppl": "8.19", "valid_wps": "124658", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "24241", "valid_best_loss": "4.381"}
2023-12-13 22:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 24241 updates
2023-12-13 22:53:21 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint22.pt
2023-12-13 22:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint22.pt
2023-12-13 22:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint22.pt (epoch 22 @ 24241 updates, score 4.381) (writing took 0.2219582749530673 seconds)
2023-12-13 22:53:21 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-12-13 22:53:21 | INFO | train | {"epoch": 22, "train_loss": "4.363", "train_nll_loss": "2.983", "train_ppl": "7.91", "train_wps": "58995.1", "train_ups": "16.46", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "24241", "train_lr": "0.00406214", "train_gnorm": "0.27", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1473"}
2023-12-13 22:53:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:53:21 | INFO | fairseq.trainer | begin training epoch 23
2023-12-13 22:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:53:24 | INFO | train_inner | {"epoch": 23, "update": 22.054, "loss": "4.289", "nll_loss": "2.898", "ppl": "7.45", "wps": "49544.2", "ups": "13.79", "wpb": "3593.4", "bsz": "150.7", "num_updates": "24300", "lr": "0.0040572", "gnorm": "0.261", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "1477"}
2023-12-13 22:53:30 | INFO | train_inner | {"epoch": 23, "update": 22.144, "loss": "4.243", "nll_loss": "2.844", "ppl": "7.18", "wps": "64084.8", "ups": "17.64", "wpb": "3633.9", "bsz": "158", "num_updates": "24400", "lr": "0.00404888", "gnorm": "0.259", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1482"}
2023-12-13 22:53:36 | INFO | train_inner | {"epoch": 23, "update": 22.235, "loss": "4.341", "nll_loss": "2.957", "ppl": "7.76", "wps": "61109", "ups": "17.07", "wpb": "3580.5", "bsz": "136.2", "num_updates": "24500", "lr": "0.00404061", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1488"}
2023-12-13 22:53:42 | INFO | train_inner | {"epoch": 23, "update": 22.326, "loss": "4.375", "nll_loss": "2.995", "ppl": "7.98", "wps": "58512.7", "ups": "16.48", "wpb": "3551.4", "bsz": "136.6", "num_updates": "24600", "lr": "0.00403239", "gnorm": "0.27", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1494"}
2023-12-13 22:53:48 | INFO | train_inner | {"epoch": 23, "update": 22.417, "loss": "4.342", "nll_loss": "2.958", "ppl": "7.77", "wps": "57957.7", "ups": "16.2", "wpb": "3578.5", "bsz": "135.4", "num_updates": "24700", "lr": "0.00402422", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1500"}
2023-12-13 22:53:55 | INFO | train_inner | {"epoch": 23, "update": 22.507, "loss": "4.39", "nll_loss": "3.013", "ppl": "8.07", "wps": "53528.6", "ups": "15.27", "wpb": "3506.3", "bsz": "133", "num_updates": "24800", "lr": "0.0040161", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1507"}
2023-12-13 22:54:00 | INFO | train_inner | {"epoch": 23, "update": 22.598, "loss": "4.35", "nll_loss": "2.968", "ppl": "7.82", "wps": "62879.4", "ups": "17.47", "wpb": "3599.8", "bsz": "151.3", "num_updates": "24900", "lr": "0.00400802", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1513"}
2023-12-13 22:54:06 | INFO | train_inner | {"epoch": 23, "update": 22.689, "loss": "4.332", "nll_loss": "2.95", "ppl": "7.73", "wps": "60426.1", "ups": "16.75", "wpb": "3607.6", "bsz": "157.5", "num_updates": "25000", "lr": "0.004", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1519"}
2023-12-13 22:54:12 | INFO | train_inner | {"epoch": 23, "update": 22.779, "loss": "4.343", "nll_loss": "2.963", "ppl": "7.8", "wps": "65390.8", "ups": "17.96", "wpb": "3641.6", "bsz": "152.3", "num_updates": "25100", "lr": "0.00399202", "gnorm": "0.261", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1524"}
2023-12-13 22:54:18 | INFO | train_inner | {"epoch": 23, "update": 22.87, "loss": "4.412", "nll_loss": "3.041", "ppl": "8.23", "wps": "59362.1", "ups": "16.66", "wpb": "3563.3", "bsz": "141", "num_updates": "25200", "lr": "0.0039841", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1530"}
2023-12-13 22:54:24 | INFO | train_inner | {"epoch": 23, "update": 22.961, "loss": "4.353", "nll_loss": "2.975", "ppl": "7.86", "wps": "62439.8", "ups": "17.45", "wpb": "3579.1", "bsz": "152.2", "num_updates": "25300", "lr": "0.00397621", "gnorm": "0.262", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "1536"}
2023-12-13 22:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:54:28 | INFO | valid | {"epoch": 23, "valid_loss": "4.368", "valid_nll_loss": "3.009", "valid_ppl": "8.05", "valid_wps": "124909", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "25343", "valid_best_loss": "4.368"}
2023-12-13 22:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 25343 updates
2023-12-13 22:54:28 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint23.pt
2023-12-13 22:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint23.pt
2023-12-13 22:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint23.pt (epoch 23 @ 25343 updates, score 4.368) (writing took 0.22182886581867933 seconds)
2023-12-13 22:54:28 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-12-13 22:54:28 | INFO | train | {"epoch": 23, "train_loss": "4.344", "train_nll_loss": "2.961", "train_ppl": "7.79", "train_wps": "58812.2", "train_ups": "16.41", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "25343", "train_lr": "0.00397284", "train_gnorm": "0.27", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1540"}
2023-12-13 22:54:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:54:28 | INFO | fairseq.trainer | begin training epoch 24
2023-12-13 22:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:54:32 | INFO | train_inner | {"epoch": 24, "update": 23.052, "loss": "4.302", "nll_loss": "2.914", "ppl": "7.54", "wps": "45697.1", "ups": "12.81", "wpb": "3568.5", "bsz": "139.2", "num_updates": "25400", "lr": "0.00396838", "gnorm": "0.266", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "1544"}
2023-12-13 22:54:37 | INFO | train_inner | {"epoch": 24, "update": 23.142, "loss": "4.237", "nll_loss": "2.838", "ppl": "7.15", "wps": "65662.2", "ups": "18.52", "wpb": "3544.8", "bsz": "153", "num_updates": "25500", "lr": "0.00396059", "gnorm": "0.257", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "1549"}
2023-12-13 22:54:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-12-13 22:54:43 | INFO | train_inner | {"epoch": 24, "update": 23.234, "loss": "4.289", "nll_loss": "2.896", "ppl": "7.44", "wps": "56997.2", "ups": "15.88", "wpb": "3589.4", "bsz": "137.4", "num_updates": "25600", "lr": "0.00395285", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1555"}
2023-12-13 22:54:49 | INFO | train_inner | {"epoch": 24, "update": 23.325, "loss": "4.295", "nll_loss": "2.904", "ppl": "7.49", "wps": "60284", "ups": "16.6", "wpb": "3631.2", "bsz": "148.3", "num_updates": "25700", "lr": "0.00394515", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1561"}
2023-12-13 22:54:55 | INFO | train_inner | {"epoch": 24, "update": 23.416, "loss": "4.308", "nll_loss": "2.921", "ppl": "7.57", "wps": "58624.4", "ups": "16.32", "wpb": "3592.7", "bsz": "154.1", "num_updates": "25800", "lr": "0.0039375", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1567"}
2023-12-13 22:55:01 | INFO | train_inner | {"epoch": 24, "update": 23.506, "loss": "4.349", "nll_loss": "2.968", "ppl": "7.82", "wps": "62227.4", "ups": "17.27", "wpb": "3603.5", "bsz": "139.1", "num_updates": "25900", "lr": "0.00392989", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1573"}
2023-12-13 22:55:07 | INFO | train_inner | {"epoch": 24, "update": 23.597, "loss": "4.329", "nll_loss": "2.946", "ppl": "7.7", "wps": "62205.8", "ups": "17.59", "wpb": "3535.6", "bsz": "153.5", "num_updates": "26000", "lr": "0.00392232", "gnorm": "0.267", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1579"}
2023-12-13 22:55:13 | INFO | train_inner | {"epoch": 24, "update": 23.688, "loss": "4.393", "nll_loss": "3.019", "ppl": "8.11", "wps": "60581.5", "ups": "16.67", "wpb": "3634.6", "bsz": "127.2", "num_updates": "26100", "lr": "0.0039148", "gnorm": "0.267", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1585"}
2023-12-13 22:55:19 | INFO | train_inner | {"epoch": 24, "update": 23.779, "loss": "4.393", "nll_loss": "3.019", "ppl": "8.11", "wps": "57660.5", "ups": "16.27", "wpb": "3543.7", "bsz": "129.9", "num_updates": "26200", "lr": "0.00390732", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1591"}
2023-12-13 22:55:25 | INFO | train_inner | {"epoch": 24, "update": 23.869, "loss": "4.361", "nll_loss": "2.985", "ppl": "7.92", "wps": "62320.2", "ups": "17.23", "wpb": "3616.3", "bsz": "153.6", "num_updates": "26300", "lr": "0.00389989", "gnorm": "0.268", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1597"}
2023-12-13 22:55:31 | INFO | train_inner | {"epoch": 24, "update": 23.96, "loss": "4.406", "nll_loss": "3.035", "ppl": "8.2", "wps": "58318.7", "ups": "16.41", "wpb": "3553.1", "bsz": "144.7", "num_updates": "26400", "lr": "0.00389249", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1603"}
2023-12-13 22:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:55:35 | INFO | valid | {"epoch": 24, "valid_loss": "4.368", "valid_nll_loss": "3.023", "valid_ppl": "8.13", "valid_wps": "126069", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "26444", "valid_best_loss": "4.368"}
2023-12-13 22:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 26444 updates
2023-12-13 22:55:35 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint24.pt
2023-12-13 22:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint24.pt
2023-12-13 22:55:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint24.pt (epoch 24 @ 26444 updates, score 4.368) (writing took 0.2182457773014903 seconds)
2023-12-13 22:55:35 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-12-13 22:55:35 | INFO | train | {"epoch": 24, "train_loss": "4.327", "train_nll_loss": "2.943", "train_ppl": "7.69", "train_wps": "59156.1", "train_ups": "16.5", "train_wpb": "3584.1", "train_bsz": "145.5", "train_num_updates": "26444", "train_lr": "0.00388926", "train_gnorm": "0.271", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1607"}
2023-12-13 22:55:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:55:35 | INFO | fairseq.trainer | begin training epoch 25
2023-12-13 22:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:55:39 | INFO | train_inner | {"epoch": 25, "update": 24.051, "loss": "4.256", "nll_loss": "2.861", "ppl": "7.27", "wps": "45615.9", "ups": "12.79", "wpb": "3565.9", "bsz": "153", "num_updates": "26500", "lr": "0.00388514", "gnorm": "0.271", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1611"}
2023-12-13 22:55:44 | INFO | train_inner | {"epoch": 25, "update": 24.142, "loss": "4.236", "nll_loss": "2.836", "ppl": "7.14", "wps": "63997.3", "ups": "17.9", "wpb": "3575.2", "bsz": "149", "num_updates": "26600", "lr": "0.00387783", "gnorm": "0.259", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1616"}
2023-12-13 22:55:50 | INFO | train_inner | {"epoch": 25, "update": 24.232, "loss": "4.332", "nll_loss": "2.947", "ppl": "7.71", "wps": "63816.7", "ups": "17.72", "wpb": "3600.5", "bsz": "131.7", "num_updates": "26700", "lr": "0.00387056", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1622"}
2023-12-13 22:55:56 | INFO | train_inner | {"epoch": 25, "update": 24.323, "loss": "4.33", "nll_loss": "2.945", "ppl": "7.7", "wps": "58786.5", "ups": "16.69", "wpb": "3521.3", "bsz": "139", "num_updates": "26800", "lr": "0.00386334", "gnorm": "0.284", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1628"}
2023-12-13 22:56:02 | INFO | train_inner | {"epoch": 25, "update": 24.414, "loss": "4.277", "nll_loss": "2.887", "ppl": "7.39", "wps": "60555.7", "ups": "17.17", "wpb": "3527.7", "bsz": "159.2", "num_updates": "26900", "lr": "0.00385615", "gnorm": "0.276", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1634"}
2023-12-13 22:56:08 | INFO | train_inner | {"epoch": 25, "update": 24.505, "loss": "4.269", "nll_loss": "2.878", "ppl": "7.35", "wps": "63022.7", "ups": "17.04", "wpb": "3697.9", "bsz": "166.1", "num_updates": "27000", "lr": "0.003849", "gnorm": "0.261", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1640"}
2023-12-13 22:56:14 | INFO | train_inner | {"epoch": 25, "update": 24.595, "loss": "4.329", "nll_loss": "2.945", "ppl": "7.7", "wps": "58725.6", "ups": "16.28", "wpb": "3606.3", "bsz": "141.1", "num_updates": "27100", "lr": "0.00384189", "gnorm": "0.268", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1646"}
2023-12-13 22:56:20 | INFO | train_inner | {"epoch": 25, "update": 24.686, "loss": "4.357", "nll_loss": "2.979", "ppl": "7.88", "wps": "58963.1", "ups": "16.38", "wpb": "3600.5", "bsz": "141.8", "num_updates": "27200", "lr": "0.00383482", "gnorm": "0.291", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1652"}
2023-12-13 22:56:25 | INFO | train_inner | {"epoch": 25, "update": 24.777, "loss": "4.325", "nll_loss": "2.942", "ppl": "7.68", "wps": "63050.1", "ups": "17.8", "wpb": "3541.5", "bsz": "155", "num_updates": "27300", "lr": "0.0038278", "gnorm": "0.267", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1658"}
2023-12-13 22:56:32 | INFO | train_inner | {"epoch": 25, "update": 24.868, "loss": "4.373", "nll_loss": "2.998", "ppl": "7.99", "wps": "57911", "ups": "16.01", "wpb": "3616.4", "bsz": "129.1", "num_updates": "27400", "lr": "0.0038208", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1664"}
2023-12-13 22:56:37 | INFO | train_inner | {"epoch": 25, "update": 24.958, "loss": "4.322", "nll_loss": "2.94", "ppl": "7.67", "wps": "63250.7", "ups": "17.72", "wpb": "3568.9", "bsz": "157.8", "num_updates": "27500", "lr": "0.00381385", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1669"}
2023-12-13 22:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:56:42 | INFO | valid | {"epoch": 25, "valid_loss": "4.365", "valid_nll_loss": "3", "valid_ppl": "8", "valid_wps": "123799", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "27546", "valid_best_loss": "4.365"}
2023-12-13 22:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 27546 updates
2023-12-13 22:56:42 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint25.pt
2023-12-13 22:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint25.pt
2023-12-13 22:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint25.pt (epoch 25 @ 27546 updates, score 4.365) (writing took 0.2151482282206416 seconds)
2023-12-13 22:56:42 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-12-13 22:56:42 | INFO | train | {"epoch": 25, "train_loss": "4.315", "train_nll_loss": "2.929", "train_ppl": "7.62", "train_wps": "59005.9", "train_ups": "16.47", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "27546", "train_lr": "0.00381066", "train_gnorm": "0.274", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1674"}
2023-12-13 22:56:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:56:42 | INFO | fairseq.trainer | begin training epoch 26
2023-12-13 22:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:56:45 | INFO | train_inner | {"epoch": 26, "update": 25.049, "loss": "4.303", "nll_loss": "2.916", "ppl": "7.55", "wps": "47219.1", "ups": "13.14", "wpb": "3594", "bsz": "134.6", "num_updates": "27600", "lr": "0.00380693", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1677"}
2023-12-13 22:56:51 | INFO | train_inner | {"epoch": 26, "update": 25.14, "loss": "4.229", "nll_loss": "2.828", "ppl": "7.1", "wps": "57572.1", "ups": "16.22", "wpb": "3548.9", "bsz": "142.5", "num_updates": "27700", "lr": "0.00380006", "gnorm": "0.271", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1683"}
2023-12-13 22:56:58 | INFO | train_inner | {"epoch": 26, "update": 25.23, "loss": "4.276", "nll_loss": "2.883", "ppl": "7.38", "wps": "55880.8", "ups": "15.58", "wpb": "3586.3", "bsz": "138.6", "num_updates": "27800", "lr": "0.00379322", "gnorm": "0.276", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1690"}
2023-12-13 22:57:03 | INFO | train_inner | {"epoch": 26, "update": 25.321, "loss": "4.19", "nll_loss": "2.786", "ppl": "6.9", "wps": "72589.3", "ups": "19.75", "wpb": "3675.1", "bsz": "175.7", "num_updates": "27900", "lr": "0.00378641", "gnorm": "0.251", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1695"}
2023-12-13 22:57:08 | INFO | train_inner | {"epoch": 26, "update": 25.412, "loss": "4.285", "nll_loss": "2.896", "ppl": "7.44", "wps": "63097.6", "ups": "17.32", "wpb": "3643.2", "bsz": "151.4", "num_updates": "28000", "lr": "0.00377964", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1701"}
2023-12-13 22:57:14 | INFO | train_inner | {"epoch": 26, "update": 25.503, "loss": "4.318", "nll_loss": "2.932", "ppl": "7.63", "wps": "58917.5", "ups": "16.61", "wpb": "3547", "bsz": "141", "num_updates": "28100", "lr": "0.00377291", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1707"}
2023-12-13 22:57:21 | INFO | train_inner | {"epoch": 26, "update": 25.593, "loss": "4.393", "nll_loss": "3.02", "ppl": "8.11", "wps": "54332.8", "ups": "15.53", "wpb": "3498.2", "bsz": "132.8", "num_updates": "28200", "lr": "0.00376622", "gnorm": "0.279", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1713"}
2023-12-13 22:57:27 | INFO | train_inner | {"epoch": 26, "update": 25.684, "loss": "4.332", "nll_loss": "2.95", "ppl": "7.73", "wps": "61184.9", "ups": "16.99", "wpb": "3600.7", "bsz": "142.6", "num_updates": "28300", "lr": "0.00375956", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1719"}
2023-12-13 22:57:33 | INFO | train_inner | {"epoch": 26, "update": 25.775, "loss": "4.359", "nll_loss": "2.981", "ppl": "7.9", "wps": "59187.6", "ups": "16.5", "wpb": "3587.4", "bsz": "137.9", "num_updates": "28400", "lr": "0.00375293", "gnorm": "0.3", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1725"}
2023-12-13 22:57:39 | INFO | train_inner | {"epoch": 26, "update": 25.866, "loss": "4.351", "nll_loss": "2.973", "ppl": "7.85", "wps": "61154", "ups": "17.19", "wpb": "3556.7", "bsz": "141.1", "num_updates": "28500", "lr": "0.00374634", "gnorm": "0.266", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1731"}
2023-12-13 22:57:45 | INFO | train_inner | {"epoch": 26, "update": 25.956, "loss": "4.324", "nll_loss": "2.943", "ppl": "7.69", "wps": "61002.1", "ups": "17", "wpb": "3588.2", "bsz": "147.7", "num_updates": "28600", "lr": "0.00373979", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1737"}
2023-12-13 22:57:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:57:49 | INFO | valid | {"epoch": 26, "valid_loss": "4.388", "valid_nll_loss": "3.043", "valid_ppl": "8.24", "valid_wps": "126126", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "28648", "valid_best_loss": "4.365"}
2023-12-13 22:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 28648 updates
2023-12-13 22:57:49 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint26.pt
2023-12-13 22:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint26.pt
2023-12-13 22:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint26.pt (epoch 26 @ 28648 updates, score 4.388) (writing took 0.15627514943480492 seconds)
2023-12-13 22:57:49 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-12-13 22:57:49 | INFO | train | {"epoch": 26, "train_loss": "4.301", "train_nll_loss": "2.913", "train_ppl": "7.53", "train_wps": "58928.1", "train_ups": "16.44", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "28648", "train_lr": "0.00373665", "train_gnorm": "0.275", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "1741"}
2023-12-13 22:57:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:57:49 | INFO | fairseq.trainer | begin training epoch 27
2023-12-13 22:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:57:52 | INFO | train_inner | {"epoch": 27, "update": 26.047, "loss": "4.269", "nll_loss": "2.878", "ppl": "7.35", "wps": "49842.5", "ups": "13.87", "wpb": "3593.2", "bsz": "147.3", "num_updates": "28700", "lr": "0.00373327", "gnorm": "0.267", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1744"}
2023-12-13 22:57:57 | INFO | train_inner | {"epoch": 27, "update": 26.138, "loss": "4.203", "nll_loss": "2.798", "ppl": "6.96", "wps": "67170.2", "ups": "18.52", "wpb": "3626.8", "bsz": "140.9", "num_updates": "28800", "lr": "0.00372678", "gnorm": "0.254", "loss_scale": "8", "train_wall": "5", "gb_free": "39", "wall": "1749"}
2023-12-13 22:58:03 | INFO | train_inner | {"epoch": 27, "update": 26.229, "loss": "4.267", "nll_loss": "2.872", "ppl": "7.32", "wps": "60768.9", "ups": "17.27", "wpb": "3518.4", "bsz": "135.5", "num_updates": "28900", "lr": "0.00372033", "gnorm": "0.277", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1755"}
2023-12-13 22:58:09 | INFO | train_inner | {"epoch": 27, "update": 26.319, "loss": "4.271", "nll_loss": "2.878", "ppl": "7.35", "wps": "56396.9", "ups": "15.95", "wpb": "3536.4", "bsz": "148.4", "num_updates": "29000", "lr": "0.00371391", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1761"}
2023-12-13 22:58:15 | INFO | train_inner | {"epoch": 27, "update": 26.41, "loss": "4.236", "nll_loss": "2.839", "ppl": "7.16", "wps": "65204.1", "ups": "18.07", "wpb": "3608.3", "bsz": "160.4", "num_updates": "29100", "lr": "0.00370752", "gnorm": "0.266", "loss_scale": "8", "train_wall": "5", "gb_free": "39", "wall": "1767"}
2023-12-13 22:58:21 | INFO | train_inner | {"epoch": 27, "update": 26.501, "loss": "4.355", "nll_loss": "2.975", "ppl": "7.86", "wps": "58406.5", "ups": "16.3", "wpb": "3584.3", "bsz": "143", "num_updates": "29200", "lr": "0.00370117", "gnorm": "0.289", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1773"}
2023-12-13 22:58:27 | INFO | train_inner | {"epoch": 27, "update": 26.592, "loss": "4.312", "nll_loss": "2.927", "ppl": "7.61", "wps": "64243.4", "ups": "17.68", "wpb": "3633.8", "bsz": "143.6", "num_updates": "29300", "lr": "0.00369484", "gnorm": "0.267", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1779"}
2023-12-13 22:58:32 | INFO | train_inner | {"epoch": 27, "update": 26.682, "loss": "4.278", "nll_loss": "2.889", "ppl": "7.41", "wps": "62994.4", "ups": "17.68", "wpb": "3563.8", "bsz": "155.8", "num_updates": "29400", "lr": "0.00368856", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1784"}
2023-12-13 22:58:38 | INFO | train_inner | {"epoch": 27, "update": 26.773, "loss": "4.287", "nll_loss": "2.901", "ppl": "7.47", "wps": "59383.6", "ups": "16.64", "wpb": "3569.2", "bsz": "160.7", "num_updates": "29500", "lr": "0.0036823", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1790"}
2023-12-13 22:58:44 | INFO | train_inner | {"epoch": 27, "update": 26.864, "loss": "4.316", "nll_loss": "2.933", "ppl": "7.64", "wps": "62331.6", "ups": "17.3", "wpb": "3602.6", "bsz": "144.5", "num_updates": "29600", "lr": "0.00367607", "gnorm": "0.277", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1796"}
2023-12-13 22:58:51 | INFO | train_inner | {"epoch": 27, "update": 26.955, "loss": "4.36", "nll_loss": "2.982", "ppl": "7.9", "wps": "53080.6", "ups": "14.83", "wpb": "3578.1", "bsz": "128.8", "num_updates": "29700", "lr": "0.00366988", "gnorm": "0.28", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "1803"}
2023-12-13 22:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 22:58:55 | INFO | valid | {"epoch": 27, "valid_loss": "4.336", "valid_nll_loss": "2.979", "valid_ppl": "7.88", "valid_wps": "125250", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "29750", "valid_best_loss": "4.336"}
2023-12-13 22:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 29750 updates
2023-12-13 22:58:55 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint27.pt
2023-12-13 22:58:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint27.pt
2023-12-13 22:58:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint27.pt (epoch 27 @ 29750 updates, score 4.336) (writing took 0.22834895458072424 seconds)
2023-12-13 22:58:56 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-12-13 22:58:56 | INFO | train | {"epoch": 27, "train_loss": "4.288", "train_nll_loss": "2.899", "train_ppl": "7.46", "train_wps": "59108.9", "train_ups": "16.49", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "29750", "train_lr": "0.00366679", "train_gnorm": "0.275", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1808"}
2023-12-13 22:58:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 22:58:56 | INFO | fairseq.trainer | begin training epoch 28
2023-12-13 22:58:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 22:58:59 | INFO | train_inner | {"epoch": 28, "update": 27.045, "loss": "4.245", "nll_loss": "2.85", "ppl": "7.21", "wps": "42607.6", "ups": "12", "wpb": "3550.9", "bsz": "136.4", "num_updates": "29800", "lr": "0.00366372", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1811"}
2023-12-13 22:59:05 | INFO | train_inner | {"epoch": 28, "update": 27.136, "loss": "4.22", "nll_loss": "2.817", "ppl": "7.05", "wps": "55959.4", "ups": "15.8", "wpb": "3542.8", "bsz": "137.2", "num_updates": "29900", "lr": "0.00365758", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1817"}
2023-12-13 22:59:11 | INFO | train_inner | {"epoch": 28, "update": 27.227, "loss": "4.192", "nll_loss": "2.786", "ppl": "6.9", "wps": "65178.8", "ups": "18.14", "wpb": "3592.2", "bsz": "155.7", "num_updates": "30000", "lr": "0.00365148", "gnorm": "0.273", "loss_scale": "8", "train_wall": "5", "gb_free": "39", "wall": "1823"}
2023-12-13 22:59:17 | INFO | train_inner | {"epoch": 28, "update": 27.318, "loss": "4.254", "nll_loss": "2.859", "ppl": "7.25", "wps": "55016.3", "ups": "15.42", "wpb": "3567.4", "bsz": "136.4", "num_updates": "30100", "lr": "0.00364541", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1829"}
2023-12-13 22:59:23 | INFO | train_inner | {"epoch": 28, "update": 27.408, "loss": "4.205", "nll_loss": "2.802", "ppl": "6.97", "wps": "69324.7", "ups": "19.17", "wpb": "3616.2", "bsz": "156.5", "num_updates": "30200", "lr": "0.00363937", "gnorm": "0.26", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1835"}
2023-12-13 22:59:28 | INFO | train_inner | {"epoch": 28, "update": 27.499, "loss": "4.32", "nll_loss": "2.935", "ppl": "7.65", "wps": "61004.6", "ups": "17", "wpb": "3589.1", "bsz": "141.4", "num_updates": "30300", "lr": "0.00363336", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1841"}
2023-12-13 22:59:34 | INFO | train_inner | {"epoch": 28, "update": 27.59, "loss": "4.312", "nll_loss": "2.928", "ppl": "7.61", "wps": "61200", "ups": "16.96", "wpb": "3609.4", "bsz": "147", "num_updates": "30400", "lr": "0.00362738", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1846"}
2023-12-13 22:59:41 | INFO | train_inner | {"epoch": 28, "update": 27.681, "loss": "4.346", "nll_loss": "2.967", "ppl": "7.82", "wps": "57303.3", "ups": "16.1", "wpb": "3558.1", "bsz": "138.1", "num_updates": "30500", "lr": "0.00362143", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1853"}
2023-12-13 22:59:46 | INFO | train_inner | {"epoch": 28, "update": 27.771, "loss": "4.303", "nll_loss": "2.918", "ppl": "7.56", "wps": "63558.1", "ups": "17.78", "wpb": "3573.8", "bsz": "145.2", "num_updates": "30600", "lr": "0.00361551", "gnorm": "0.264", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1858"}
2023-12-13 22:59:52 | INFO | train_inner | {"epoch": 28, "update": 27.862, "loss": "4.281", "nll_loss": "2.893", "ppl": "7.43", "wps": "63425.6", "ups": "17.46", "wpb": "3632.6", "bsz": "150.6", "num_updates": "30700", "lr": "0.00360961", "gnorm": "0.267", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1864"}
2023-12-13 22:59:58 | INFO | train_inner | {"epoch": 28, "update": 27.953, "loss": "4.309", "nll_loss": "2.926", "ppl": "7.6", "wps": "57480", "ups": "16.1", "wpb": "3569.6", "bsz": "147.7", "num_updates": "30800", "lr": "0.00360375", "gnorm": "0.324", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1870"}
2023-12-13 23:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:00:03 | INFO | valid | {"epoch": 28, "valid_loss": "4.336", "valid_nll_loss": "2.98", "valid_ppl": "7.89", "valid_wps": "127165", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "30852", "valid_best_loss": "4.336"}
2023-12-13 23:00:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 30852 updates
2023-12-13 23:00:03 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint28.pt
2023-12-13 23:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint28.pt
2023-12-13 23:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint28.pt (epoch 28 @ 30852 updates, score 4.336) (writing took 0.21799031272530556 seconds)
2023-12-13 23:00:03 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-12-13 23:00:03 | INFO | train | {"epoch": 28, "train_loss": "4.273", "train_nll_loss": "2.882", "train_ppl": "7.37", "train_wps": "58863.5", "train_ups": "16.43", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "30852", "train_lr": "0.00360071", "train_gnorm": "0.279", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1875"}
2023-12-13 23:00:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:00:03 | INFO | fairseq.trainer | begin training epoch 29
2023-12-13 23:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:00:06 | INFO | train_inner | {"epoch": 29, "update": 28.044, "loss": "4.291", "nll_loss": "2.904", "ppl": "7.48", "wps": "45718", "ups": "12.86", "wpb": "3555.9", "bsz": "145.3", "num_updates": "30900", "lr": "0.00359791", "gnorm": "0.291", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1878"}
2023-12-13 23:00:11 | INFO | train_inner | {"epoch": 29, "update": 28.134, "loss": "4.145", "nll_loss": "2.733", "ppl": "6.65", "wps": "70034.4", "ups": "19.16", "wpb": "3654.6", "bsz": "147.8", "num_updates": "31000", "lr": "0.00359211", "gnorm": "0.255", "loss_scale": "8", "train_wall": "5", "gb_free": "39", "wall": "1883"}
2023-12-13 23:00:17 | INFO | train_inner | {"epoch": 29, "update": 28.225, "loss": "4.212", "nll_loss": "2.811", "ppl": "7.02", "wps": "58868.9", "ups": "16.46", "wpb": "3576.9", "bsz": "145.5", "num_updates": "31100", "lr": "0.00358633", "gnorm": "0.281", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1889"}
2023-12-13 23:00:24 | INFO | train_inner | {"epoch": 29, "update": 28.316, "loss": "4.259", "nll_loss": "2.863", "ppl": "7.28", "wps": "55897.4", "ups": "15.72", "wpb": "3555.8", "bsz": "136", "num_updates": "31200", "lr": "0.00358057", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1896"}
2023-12-13 23:00:30 | INFO | train_inner | {"epoch": 29, "update": 28.407, "loss": "4.255", "nll_loss": "2.86", "ppl": "7.26", "wps": "60795.6", "ups": "16.81", "wpb": "3616.7", "bsz": "137.5", "num_updates": "31300", "lr": "0.00357485", "gnorm": "0.274", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1902"}
2023-12-13 23:00:36 | INFO | train_inner | {"epoch": 29, "update": 28.497, "loss": "4.276", "nll_loss": "2.886", "ppl": "7.39", "wps": "54535.6", "ups": "15.33", "wpb": "3558.5", "bsz": "146.5", "num_updates": "31400", "lr": "0.00356915", "gnorm": "0.297", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1908"}
2023-12-13 23:00:42 | INFO | train_inner | {"epoch": 29, "update": 28.588, "loss": "4.269", "nll_loss": "2.878", "ppl": "7.35", "wps": "63754.3", "ups": "17.62", "wpb": "3617.3", "bsz": "147.8", "num_updates": "31500", "lr": "0.00356348", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1914"}
2023-12-13 23:00:47 | INFO | train_inner | {"epoch": 29, "update": 28.679, "loss": "4.247", "nll_loss": "2.855", "ppl": "7.23", "wps": "65502.3", "ups": "18.16", "wpb": "3607.3", "bsz": "157.7", "num_updates": "31600", "lr": "0.00355784", "gnorm": "0.273", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1919"}
2023-12-13 23:00:53 | INFO | train_inner | {"epoch": 29, "update": 28.77, "loss": "4.31", "nll_loss": "2.926", "ppl": "7.6", "wps": "59604.7", "ups": "16.79", "wpb": "3549.7", "bsz": "137.3", "num_updates": "31700", "lr": "0.00355222", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1925"}
2023-12-13 23:00:59 | INFO | train_inner | {"epoch": 29, "update": 28.86, "loss": "4.294", "nll_loss": "2.909", "ppl": "7.51", "wps": "67830.7", "ups": "18.74", "wpb": "3619.1", "bsz": "151.7", "num_updates": "31800", "lr": "0.00354663", "gnorm": "0.267", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1931"}
2023-12-13 23:01:04 | INFO | train_inner | {"epoch": 29, "update": 28.951, "loss": "4.297", "nll_loss": "2.915", "ppl": "7.54", "wps": "61845.6", "ups": "17.4", "wpb": "3554", "bsz": "162.2", "num_updates": "31900", "lr": "0.00354107", "gnorm": "0.276", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1936"}
2023-12-13 23:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:01:09 | INFO | valid | {"epoch": 29, "valid_loss": "4.336", "valid_nll_loss": "2.967", "valid_ppl": "7.82", "valid_wps": "124329", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "31954", "valid_best_loss": "4.336"}
2023-12-13 23:01:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 31954 updates
2023-12-13 23:01:09 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint29.pt
2023-12-13 23:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint29.pt
2023-12-13 23:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint29.pt (epoch 29 @ 31954 updates, score 4.336) (writing took 0.20796302519738674 seconds)
2023-12-13 23:01:10 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-12-13 23:01:10 | INFO | train | {"epoch": 29, "train_loss": "4.259", "train_nll_loss": "2.867", "train_ppl": "7.29", "train_wps": "59142.1", "train_ups": "16.5", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "31954", "train_lr": "0.00353808", "train_gnorm": "0.275", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "1942"}
2023-12-13 23:01:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:01:10 | INFO | fairseq.trainer | begin training epoch 30
2023-12-13 23:01:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:01:12 | INFO | train_inner | {"epoch": 30, "update": 29.042, "loss": "4.288", "nll_loss": "2.9", "ppl": "7.46", "wps": "43566.6", "ups": "12.3", "wpb": "3540.7", "bsz": "130", "num_updates": "32000", "lr": "0.00353553", "gnorm": "0.276", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1945"}
2023-12-13 23:01:19 | INFO | train_inner | {"epoch": 30, "update": 29.132, "loss": "4.177", "nll_loss": "2.768", "ppl": "6.81", "wps": "58608", "ups": "16.34", "wpb": "3586.4", "bsz": "134.8", "num_updates": "32100", "lr": "0.00353002", "gnorm": "0.264", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1951"}
2023-12-13 23:01:25 | INFO | train_inner | {"epoch": 30, "update": 29.223, "loss": "4.24", "nll_loss": "2.841", "ppl": "7.17", "wps": "58809.1", "ups": "16.59", "wpb": "3543.9", "bsz": "137.5", "num_updates": "32200", "lr": "0.00352454", "gnorm": "0.286", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1957"}
2023-12-13 23:01:30 | INFO | train_inner | {"epoch": 30, "update": 29.314, "loss": "4.226", "nll_loss": "2.829", "ppl": "7.11", "wps": "66602.9", "ups": "18.19", "wpb": "3661.4", "bsz": "150.5", "num_updates": "32300", "lr": "0.00351908", "gnorm": "0.262", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1962"}
2023-12-13 23:01:36 | INFO | train_inner | {"epoch": 30, "update": 29.405, "loss": "4.206", "nll_loss": "2.804", "ppl": "6.99", "wps": "57908", "ups": "16.49", "wpb": "3512", "bsz": "155.6", "num_updates": "32400", "lr": "0.00351364", "gnorm": "0.308", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1968"}
2023-12-13 23:01:43 | INFO | train_inner | {"epoch": 30, "update": 29.495, "loss": "4.256", "nll_loss": "2.865", "ppl": "7.28", "wps": "55039.5", "ups": "15.41", "wpb": "3571.5", "bsz": "146.9", "num_updates": "32500", "lr": "0.00350823", "gnorm": "0.307", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1975"}
2023-12-13 23:01:48 | INFO | train_inner | {"epoch": 30, "update": 29.586, "loss": "4.294", "nll_loss": "2.907", "ppl": "7.5", "wps": "61982.6", "ups": "17.2", "wpb": "3603.5", "bsz": "142.9", "num_updates": "32600", "lr": "0.00350285", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "1981"}
2023-12-13 23:01:55 | INFO | train_inner | {"epoch": 30, "update": 29.677, "loss": "4.311", "nll_loss": "2.927", "ppl": "7.61", "wps": "57845.3", "ups": "16.24", "wpb": "3561.6", "bsz": "136.1", "num_updates": "32700", "lr": "0.00349749", "gnorm": "0.286", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1987"}
2023-12-13 23:02:00 | INFO | train_inner | {"epoch": 30, "update": 29.768, "loss": "4.208", "nll_loss": "2.811", "ppl": "7.02", "wps": "70788.6", "ups": "19.45", "wpb": "3640.1", "bsz": "171.8", "num_updates": "32800", "lr": "0.00349215", "gnorm": "0.273", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "1992"}
2023-12-13 23:02:06 | INFO | train_inner | {"epoch": 30, "update": 29.858, "loss": "4.253", "nll_loss": "2.86", "ppl": "7.26", "wps": "61798.7", "ups": "17.14", "wpb": "3606.2", "bsz": "150.8", "num_updates": "32900", "lr": "0.00348684", "gnorm": "0.277", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "1998"}
2023-12-13 23:02:11 | INFO | train_inner | {"epoch": 30, "update": 29.949, "loss": "4.314", "nll_loss": "2.932", "ppl": "7.63", "wps": "62034.5", "ups": "17.15", "wpb": "3618", "bsz": "136.4", "num_updates": "33000", "lr": "0.00348155", "gnorm": "0.269", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2003"}
2023-12-13 23:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:02:17 | INFO | valid | {"epoch": 30, "valid_loss": "4.334", "valid_nll_loss": "2.99", "valid_ppl": "7.94", "valid_wps": "125309", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "33056", "valid_best_loss": "4.334"}
2023-12-13 23:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 33056 updates
2023-12-13 23:02:17 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint30.pt
2023-12-13 23:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint30.pt
2023-12-13 23:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint30.pt (epoch 30 @ 33056 updates, score 4.334) (writing took 0.22535734716802835 seconds)
2023-12-13 23:02:17 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-12-13 23:02:17 | INFO | train | {"epoch": 30, "train_loss": "4.251", "train_nll_loss": "2.858", "train_ppl": "7.25", "train_wps": "58701.7", "train_ups": "16.38", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "33056", "train_lr": "0.0034786", "train_gnorm": "0.281", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "2009"}
2023-12-13 23:02:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:02:17 | INFO | fairseq.trainer | begin training epoch 31
2023-12-13 23:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:02:19 | INFO | train_inner | {"epoch": 31, "update": 30.04, "loss": "4.238", "nll_loss": "2.843", "ppl": "7.17", "wps": "44748.9", "ups": "12.64", "wpb": "3539.8", "bsz": "144.3", "num_updates": "33100", "lr": "0.00347629", "gnorm": "0.274", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2011"}
2023-12-13 23:02:25 | INFO | train_inner | {"epoch": 31, "update": 30.131, "loss": "4.137", "nll_loss": "2.724", "ppl": "6.61", "wps": "57882.6", "ups": "16.35", "wpb": "3539.3", "bsz": "149.9", "num_updates": "33200", "lr": "0.00347105", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2018"}
2023-12-13 23:02:32 | INFO | train_inner | {"epoch": 31, "update": 30.221, "loss": "4.244", "nll_loss": "2.846", "ppl": "7.19", "wps": "58519.4", "ups": "16.26", "wpb": "3598.9", "bsz": "136.6", "num_updates": "33300", "lr": "0.00346583", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2024"}
2023-12-13 23:02:37 | INFO | train_inner | {"epoch": 31, "update": 30.312, "loss": "4.186", "nll_loss": "2.784", "ppl": "6.89", "wps": "69038.5", "ups": "19.12", "wpb": "3611.5", "bsz": "153.5", "num_updates": "33400", "lr": "0.00346064", "gnorm": "0.276", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "2029"}
2023-12-13 23:02:42 | INFO | train_inner | {"epoch": 31, "update": 30.403, "loss": "4.225", "nll_loss": "2.827", "ppl": "7.09", "wps": "65208.4", "ups": "18.12", "wpb": "3598.1", "bsz": "149.9", "num_updates": "33500", "lr": "0.00345547", "gnorm": "0.281", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "2034"}
2023-12-13 23:02:49 | INFO | train_inner | {"epoch": 31, "update": 30.494, "loss": "4.318", "nll_loss": "2.932", "ppl": "7.63", "wps": "53781.4", "ups": "15.2", "wpb": "3538.8", "bsz": "123", "num_updates": "33600", "lr": "0.00345033", "gnorm": "0.35", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2041"}
2023-12-13 23:02:55 | INFO | train_inner | {"epoch": 31, "update": 30.584, "loss": "4.28", "nll_loss": "2.892", "ppl": "7.42", "wps": "54276.9", "ups": "15.15", "wpb": "3582", "bsz": "141.1", "num_updates": "33700", "lr": "0.0034452", "gnorm": "0.288", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "2048"}
2023-12-13 23:03:02 | INFO | train_inner | {"epoch": 31, "update": 30.675, "loss": "4.26", "nll_loss": "2.869", "ppl": "7.3", "wps": "53894.5", "ups": "15.45", "wpb": "3487.9", "bsz": "144.2", "num_updates": "33800", "lr": "0.0034401", "gnorm": "0.279", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2054"}
2023-12-13 23:03:07 | INFO | train_inner | {"epoch": 31, "update": 30.766, "loss": "4.256", "nll_loss": "2.865", "ppl": "7.29", "wps": "68657.9", "ups": "18.76", "wpb": "3659.8", "bsz": "152.4", "num_updates": "33900", "lr": "0.00343503", "gnorm": "0.271", "loss_scale": "8", "train_wall": "5", "gb_free": "39", "wall": "2059"}
2023-12-13 23:03:13 | INFO | train_inner | {"epoch": 31, "update": 30.857, "loss": "4.266", "nll_loss": "2.878", "ppl": "7.35", "wps": "62286.1", "ups": "17.53", "wpb": "3553.8", "bsz": "150", "num_updates": "34000", "lr": "0.00342997", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2065"}
2023-12-13 23:03:19 | INFO | train_inner | {"epoch": 31, "update": 30.947, "loss": "4.305", "nll_loss": "2.922", "ppl": "7.58", "wps": "63411.8", "ups": "17.39", "wpb": "3646.9", "bsz": "143", "num_updates": "34100", "lr": "0.00342494", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2071"}
2023-12-13 23:03:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:03:24 | INFO | valid | {"epoch": 31, "valid_loss": "4.328", "valid_nll_loss": "2.979", "valid_ppl": "7.88", "valid_wps": "124224", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "34158", "valid_best_loss": "4.328"}
2023-12-13 23:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 34158 updates
2023-12-13 23:03:24 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint31.pt
2023-12-13 23:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint31.pt
2023-12-13 23:03:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint31.pt (epoch 31 @ 34158 updates, score 4.328) (writing took 0.2177293822169304 seconds)
2023-12-13 23:03:24 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-12-13 23:03:24 | INFO | train | {"epoch": 31, "train_loss": "4.241", "train_nll_loss": "2.847", "train_ppl": "7.19", "train_wps": "59002.6", "train_ups": "16.46", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "34158", "train_lr": "0.00342203", "train_gnorm": "0.284", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "2076"}
2023-12-13 23:03:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:03:24 | INFO | fairseq.trainer | begin training epoch 32
2023-12-13 23:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:03:26 | INFO | train_inner | {"epoch": 32, "update": 31.038, "loss": "4.19", "nll_loss": "2.79", "ppl": "6.91", "wps": "47576.6", "ups": "13.32", "wpb": "3571.5", "bsz": "149.7", "num_updates": "34200", "lr": "0.00341993", "gnorm": "0.28", "loss_scale": "8", "train_wall": "6", "gb_free": "39.1", "wall": "2078"}
2023-12-13 23:03:32 | INFO | train_inner | {"epoch": 32, "update": 31.129, "loss": "4.142", "nll_loss": "2.729", "ppl": "6.63", "wps": "61439.8", "ups": "17.16", "wpb": "3580.6", "bsz": "153.7", "num_updates": "34300", "lr": "0.00341494", "gnorm": "0.297", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2084"}
2023-12-13 23:03:38 | INFO | train_inner | {"epoch": 32, "update": 31.22, "loss": "4.213", "nll_loss": "2.814", "ppl": "7.03", "wps": "59782.9", "ups": "16.81", "wpb": "3556", "bsz": "146.4", "num_updates": "34400", "lr": "0.00340997", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2090"}
2023-12-13 23:03:44 | INFO | train_inner | {"epoch": 32, "update": 31.31, "loss": "4.207", "nll_loss": "2.805", "ppl": "6.99", "wps": "57267.5", "ups": "15.95", "wpb": "3591.3", "bsz": "141.3", "num_updates": "34500", "lr": "0.00340503", "gnorm": "0.274", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2096"}
2023-12-13 23:03:50 | INFO | train_inner | {"epoch": 32, "update": 31.401, "loss": "4.212", "nll_loss": "2.813", "ppl": "7.03", "wps": "61382.8", "ups": "17.03", "wpb": "3604.3", "bsz": "155.6", "num_updates": "34600", "lr": "0.0034001", "gnorm": "0.287", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2102"}
2023-12-13 23:03:56 | INFO | train_inner | {"epoch": 32, "update": 31.492, "loss": "4.2", "nll_loss": "2.8", "ppl": "6.96", "wps": "62752.1", "ups": "17.2", "wpb": "3647.5", "bsz": "148.1", "num_updates": "34700", "lr": "0.0033952", "gnorm": "0.265", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2108"}
2023-12-13 23:04:02 | INFO | train_inner | {"epoch": 32, "update": 31.583, "loss": "4.224", "nll_loss": "2.829", "ppl": "7.11", "wps": "65774.8", "ups": "18.03", "wpb": "3648.3", "bsz": "154.5", "num_updates": "34800", "lr": "0.00339032", "gnorm": "0.276", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "2114"}
2023-12-13 23:04:08 | INFO | train_inner | {"epoch": 32, "update": 31.673, "loss": "4.238", "nll_loss": "2.844", "ppl": "7.18", "wps": "59822.5", "ups": "16.64", "wpb": "3594.6", "bsz": "147.5", "num_updates": "34900", "lr": "0.00338546", "gnorm": "0.28", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2120"}
2023-12-13 23:04:14 | INFO | train_inner | {"epoch": 32, "update": 31.764, "loss": "4.313", "nll_loss": "2.929", "ppl": "7.62", "wps": "51529.2", "ups": "14.53", "wpb": "3547.3", "bsz": "124.3", "num_updates": "35000", "lr": "0.00338062", "gnorm": "0.29", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "2127"}
2023-12-13 23:04:21 | INFO | train_inner | {"epoch": 32, "update": 31.855, "loss": "4.305", "nll_loss": "2.92", "ppl": "7.57", "wps": "56988.5", "ups": "16.16", "wpb": "3526.1", "bsz": "134.6", "num_updates": "35100", "lr": "0.0033758", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2133"}
2023-12-13 23:04:27 | INFO | train_inner | {"epoch": 32, "update": 31.946, "loss": "4.321", "nll_loss": "2.941", "ppl": "7.68", "wps": "56679", "ups": "15.92", "wpb": "3559.2", "bsz": "140", "num_updates": "35200", "lr": "0.003371", "gnorm": "0.291", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2139"}
2023-12-13 23:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:04:32 | INFO | valid | {"epoch": 32, "valid_loss": "4.325", "valid_nll_loss": "2.964", "valid_ppl": "7.81", "valid_wps": "125759", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "35260", "valid_best_loss": "4.325"}
2023-12-13 23:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 35260 updates
2023-12-13 23:04:32 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint32.pt
2023-12-13 23:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint32.pt
2023-12-13 23:04:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint32.pt (epoch 32 @ 35260 updates, score 4.325) (writing took 0.2223287085071206 seconds)
2023-12-13 23:04:32 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-12-13 23:04:32 | INFO | train | {"epoch": 32, "train_loss": "4.232", "train_nll_loss": "2.837", "train_ppl": "7.14", "train_wps": "57813.1", "train_ups": "16.13", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "35260", "train_lr": "0.00336813", "train_gnorm": "0.282", "train_loss_scale": "8", "train_train_wall": "65", "train_gb_free": "39", "train_wall": "2144"}
2023-12-13 23:04:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:04:32 | INFO | fairseq.trainer | begin training epoch 33
2023-12-13 23:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:04:35 | INFO | train_inner | {"epoch": 33, "update": 32.036, "loss": "4.178", "nll_loss": "2.773", "ppl": "6.84", "wps": "45993.9", "ups": "12.91", "wpb": "3562.1", "bsz": "159.4", "num_updates": "35300", "lr": "0.00336622", "gnorm": "0.286", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2147"}
2023-12-13 23:04:40 | INFO | train_inner | {"epoch": 33, "update": 32.127, "loss": "4.137", "nll_loss": "2.726", "ppl": "6.62", "wps": "61263.5", "ups": "17.21", "wpb": "3559.3", "bsz": "146.8", "num_updates": "35400", "lr": "0.00336146", "gnorm": "0.269", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2153"}
2023-12-13 23:04:47 | INFO | train_inner | {"epoch": 33, "update": 32.218, "loss": "4.232", "nll_loss": "2.833", "ppl": "7.13", "wps": "58250.5", "ups": "16.31", "wpb": "3571.4", "bsz": "128.6", "num_updates": "35500", "lr": "0.00335673", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2159"}
2023-12-13 23:04:52 | INFO | train_inner | {"epoch": 33, "update": 32.309, "loss": "4.118", "nll_loss": "2.704", "ppl": "6.52", "wps": "65426.7", "ups": "17.99", "wpb": "3636.3", "bsz": "168.6", "num_updates": "35600", "lr": "0.00335201", "gnorm": "0.278", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "2164"}
2023-12-13 23:04:58 | INFO | train_inner | {"epoch": 33, "update": 32.399, "loss": "4.204", "nll_loss": "2.803", "ppl": "6.98", "wps": "63543.2", "ups": "17.6", "wpb": "3610.8", "bsz": "146.8", "num_updates": "35700", "lr": "0.00334731", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2170"}
2023-12-13 23:05:03 | INFO | train_inner | {"epoch": 33, "update": 32.49, "loss": "4.196", "nll_loss": "2.795", "ppl": "6.94", "wps": "63606.1", "ups": "17.83", "wpb": "3567.6", "bsz": "157.8", "num_updates": "35800", "lr": "0.00334263", "gnorm": "0.283", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2176"}
2023-12-13 23:05:10 | INFO | train_inner | {"epoch": 33, "update": 32.581, "loss": "4.265", "nll_loss": "2.874", "ppl": "7.33", "wps": "58296.1", "ups": "16.28", "wpb": "3580.6", "bsz": "136.4", "num_updates": "35900", "lr": "0.00333797", "gnorm": "0.29", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2182"}
2023-12-13 23:05:16 | INFO | train_inner | {"epoch": 33, "update": 32.672, "loss": "4.236", "nll_loss": "2.842", "ppl": "7.17", "wps": "60966.8", "ups": "16.82", "wpb": "3625.1", "bsz": "145", "num_updates": "36000", "lr": "0.00333333", "gnorm": "0.271", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2188"}
2023-12-13 23:05:22 | INFO | train_inner | {"epoch": 33, "update": 32.762, "loss": "4.268", "nll_loss": "2.878", "ppl": "7.35", "wps": "56850.4", "ups": "15.85", "wpb": "3585.9", "bsz": "137.9", "num_updates": "36100", "lr": "0.00332871", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2194"}
2023-12-13 23:05:28 | INFO | train_inner | {"epoch": 33, "update": 32.853, "loss": "4.266", "nll_loss": "2.878", "ppl": "7.35", "wps": "59791.4", "ups": "16.83", "wpb": "3553", "bsz": "152.9", "num_updates": "36200", "lr": "0.00332411", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2200"}
2023-12-13 23:05:34 | INFO | train_inner | {"epoch": 33, "update": 32.944, "loss": "4.271", "nll_loss": "2.883", "ppl": "7.38", "wps": "60400.8", "ups": "16.65", "wpb": "3626.7", "bsz": "137.2", "num_updates": "36300", "lr": "0.00331953", "gnorm": "0.275", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2206"}
2023-12-13 23:05:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:05:39 | INFO | valid | {"epoch": 33, "valid_loss": "4.33", "valid_nll_loss": "2.985", "valid_ppl": "7.92", "valid_wps": "118879", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "36362", "valid_best_loss": "4.325"}
2023-12-13 23:05:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 36362 updates
2023-12-13 23:05:39 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint33.pt
2023-12-13 23:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint33.pt
2023-12-13 23:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint33.pt (epoch 33 @ 36362 updates, score 4.33) (writing took 0.17291596066206694 seconds)
2023-12-13 23:05:39 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-12-13 23:05:39 | INFO | train | {"epoch": 33, "train_loss": "4.219", "train_nll_loss": "2.821", "train_ppl": "7.07", "train_wps": "58935", "train_ups": "16.45", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "36362", "train_lr": "0.0033167", "train_gnorm": "0.281", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "2211"}
2023-12-13 23:05:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:05:39 | INFO | fairseq.trainer | begin training epoch 34
2023-12-13 23:05:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:05:42 | INFO | train_inner | {"epoch": 34, "update": 33.034, "loss": "4.216", "nll_loss": "2.817", "ppl": "7.05", "wps": "45011.1", "ups": "12.77", "wpb": "3525.7", "bsz": "138.7", "num_updates": "36400", "lr": "0.00331497", "gnorm": "0.278", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2214"}
2023-12-13 23:05:48 | INFO | train_inner | {"epoch": 34, "update": 33.125, "loss": "4.089", "nll_loss": "2.67", "ppl": "6.36", "wps": "58456.8", "ups": "16.41", "wpb": "3563", "bsz": "152.8", "num_updates": "36500", "lr": "0.00331042", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2220"}
2023-12-13 23:05:54 | INFO | train_inner | {"epoch": 34, "update": 33.216, "loss": "4.169", "nll_loss": "2.76", "ppl": "6.78", "wps": "59931.6", "ups": "16.75", "wpb": "3578.5", "bsz": "134.2", "num_updates": "36600", "lr": "0.0033059", "gnorm": "0.283", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2226"}
2023-12-13 23:06:00 | INFO | train_inner | {"epoch": 34, "update": 33.307, "loss": "4.183", "nll_loss": "2.779", "ppl": "6.87", "wps": "57934.2", "ups": "16.25", "wpb": "3565.7", "bsz": "147.8", "num_updates": "36700", "lr": "0.00330139", "gnorm": "0.293", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2232"}
2023-12-13 23:06:06 | INFO | train_inner | {"epoch": 34, "update": 33.397, "loss": "4.215", "nll_loss": "2.815", "ppl": "7.04", "wps": "54909.5", "ups": "15.16", "wpb": "3621.1", "bsz": "132.6", "num_updates": "36800", "lr": "0.0032969", "gnorm": "0.279", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2239"}
2023-12-13 23:06:12 | INFO | train_inner | {"epoch": 34, "update": 33.488, "loss": "4.194", "nll_loss": "2.793", "ppl": "6.93", "wps": "60936.7", "ups": "17.09", "wpb": "3566.2", "bsz": "150.6", "num_updates": "36900", "lr": "0.00329243", "gnorm": "0.281", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2244"}
2023-12-13 23:06:18 | INFO | train_inner | {"epoch": 34, "update": 33.579, "loss": "4.216", "nll_loss": "2.817", "ppl": "7.05", "wps": "58441.7", "ups": "16.33", "wpb": "3579.3", "bsz": "139.4", "num_updates": "37000", "lr": "0.00328798", "gnorm": "0.278", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2251"}
2023-12-13 23:06:24 | INFO | train_inner | {"epoch": 34, "update": 33.67, "loss": "4.252", "nll_loss": "2.86", "ppl": "7.26", "wps": "60529.4", "ups": "16.77", "wpb": "3609.1", "bsz": "141.8", "num_updates": "37100", "lr": "0.00328355", "gnorm": "0.281", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2256"}
2023-12-13 23:06:31 | INFO | train_inner | {"epoch": 34, "update": 33.76, "loss": "4.26", "nll_loss": "2.869", "ppl": "7.3", "wps": "50671.7", "ups": "14.38", "wpb": "3524.5", "bsz": "139", "num_updates": "37200", "lr": "0.00327913", "gnorm": "0.295", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "2263"}
2023-12-13 23:06:37 | INFO | train_inner | {"epoch": 34, "update": 33.851, "loss": "4.284", "nll_loss": "2.898", "ppl": "7.46", "wps": "58363.3", "ups": "16.51", "wpb": "3534.4", "bsz": "142.8", "num_updates": "37300", "lr": "0.00327473", "gnorm": "0.276", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2269"}
2023-12-13 23:06:43 | INFO | train_inner | {"epoch": 34, "update": 33.942, "loss": "4.237", "nll_loss": "2.847", "ppl": "7.2", "wps": "61084.8", "ups": "16.79", "wpb": "3638.4", "bsz": "169", "num_updates": "37400", "lr": "0.00327035", "gnorm": "0.298", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2275"}
2023-12-13 23:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:06:49 | INFO | valid | {"epoch": 34, "valid_loss": "4.319", "valid_nll_loss": "2.964", "valid_ppl": "7.8", "valid_wps": "125215", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "37464", "valid_best_loss": "4.319"}
2023-12-13 23:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 37464 updates
2023-12-13 23:06:49 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint34.pt
2023-12-13 23:06:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint34.pt
2023-12-13 23:06:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint34.pt (epoch 34 @ 37464 updates, score 4.319) (writing took 0.20134104695171118 seconds)
2023-12-13 23:06:49 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-12-13 23:06:49 | INFO | train | {"epoch": 34, "train_loss": "4.209", "train_nll_loss": "2.81", "train_ppl": "7.01", "train_wps": "56660.5", "train_ups": "15.81", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "37464", "train_lr": "0.00326756", "train_gnorm": "0.284", "train_loss_scale": "8", "train_train_wall": "67", "train_gb_free": "39", "train_wall": "2281"}
2023-12-13 23:06:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:06:49 | INFO | fairseq.trainer | begin training epoch 35
2023-12-13 23:06:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:06:51 | INFO | train_inner | {"epoch": 35, "update": 34.033, "loss": "4.182", "nll_loss": "2.781", "ppl": "6.87", "wps": "47561.5", "ups": "13.04", "wpb": "3646.6", "bsz": "154.4", "num_updates": "37500", "lr": "0.00326599", "gnorm": "0.284", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2283"}
2023-12-13 23:06:57 | INFO | train_inner | {"epoch": 35, "update": 34.123, "loss": "4.086", "nll_loss": "2.667", "ppl": "6.35", "wps": "58233.5", "ups": "16.21", "wpb": "3591.6", "bsz": "156.2", "num_updates": "37600", "lr": "0.00326164", "gnorm": "0.266", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2289"}
2023-12-13 23:07:03 | INFO | train_inner | {"epoch": 35, "update": 34.214, "loss": "4.143", "nll_loss": "2.733", "ppl": "6.65", "wps": "57767.8", "ups": "16.02", "wpb": "3605.2", "bsz": "144.3", "num_updates": "37700", "lr": "0.00325731", "gnorm": "0.307", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2296"}
2023-12-13 23:07:09 | INFO | train_inner | {"epoch": 35, "update": 34.305, "loss": "4.159", "nll_loss": "2.753", "ppl": "6.74", "wps": "60652.7", "ups": "17.04", "wpb": "3559.1", "bsz": "154.6", "num_updates": "37800", "lr": "0.003253", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2301"}
2023-12-13 23:07:15 | INFO | train_inner | {"epoch": 35, "update": 34.396, "loss": "4.204", "nll_loss": "2.805", "ppl": "6.99", "wps": "62070", "ups": "17.36", "wpb": "3575.9", "bsz": "142", "num_updates": "37900", "lr": "0.00324871", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2307"}
2023-12-13 23:07:21 | INFO | train_inner | {"epoch": 35, "update": 34.486, "loss": "4.207", "nll_loss": "2.808", "ppl": "7", "wps": "60505.3", "ups": "17.1", "wpb": "3538.8", "bsz": "140.5", "num_updates": "38000", "lr": "0.00324443", "gnorm": "0.289", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2313"}
2023-12-13 23:07:27 | INFO | train_inner | {"epoch": 35, "update": 34.577, "loss": "4.244", "nll_loss": "2.852", "ppl": "7.22", "wps": "60881.9", "ups": "16.66", "wpb": "3654.7", "bsz": "141.8", "num_updates": "38100", "lr": "0.00324017", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2319"}
2023-12-13 23:07:33 | INFO | train_inner | {"epoch": 35, "update": 34.668, "loss": "4.23", "nll_loss": "2.835", "ppl": "7.13", "wps": "56978.2", "ups": "15.93", "wpb": "3576.9", "bsz": "145.5", "num_updates": "38200", "lr": "0.00323592", "gnorm": "0.296", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2325"}
2023-12-13 23:07:40 | INFO | train_inner | {"epoch": 35, "update": 34.759, "loss": "4.246", "nll_loss": "2.854", "ppl": "7.23", "wps": "55899.6", "ups": "15.75", "wpb": "3549.6", "bsz": "137.4", "num_updates": "38300", "lr": "0.0032317", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2332"}
2023-12-13 23:07:45 | INFO | train_inner | {"epoch": 35, "update": 34.849, "loss": "4.227", "nll_loss": "2.833", "ppl": "7.12", "wps": "60706", "ups": "17.16", "wpb": "3537.2", "bsz": "147.2", "num_updates": "38400", "lr": "0.00322749", "gnorm": "0.294", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2337"}
2023-12-13 23:07:52 | INFO | train_inner | {"epoch": 35, "update": 34.94, "loss": "4.281", "nll_loss": "2.896", "ppl": "7.45", "wps": "56561", "ups": "15.72", "wpb": "3598.7", "bsz": "138.7", "num_updates": "38500", "lr": "0.00322329", "gnorm": "0.281", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2344"}
2023-12-13 23:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:07:57 | INFO | valid | {"epoch": 35, "valid_loss": "4.303", "valid_nll_loss": "2.943", "valid_ppl": "7.69", "valid_wps": "124132", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "38566", "valid_best_loss": "4.303"}
2023-12-13 23:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 38566 updates
2023-12-13 23:07:57 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint35.pt
2023-12-13 23:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint35.pt
2023-12-13 23:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint35.pt (epoch 35 @ 38566 updates, score 4.303) (writing took 0.2124762637540698 seconds)
2023-12-13 23:07:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-12-13 23:07:58 | INFO | train | {"epoch": 35, "train_loss": "4.2", "train_nll_loss": "2.801", "train_ppl": "6.97", "train_wps": "57332.7", "train_ups": "16", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "38566", "train_lr": "0.00322053", "train_gnorm": "0.283", "train_loss_scale": "8", "train_train_wall": "66", "train_gb_free": "39", "train_wall": "2350"}
2023-12-13 23:07:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:07:58 | INFO | fairseq.trainer | begin training epoch 36
2023-12-13 23:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:08:00 | INFO | train_inner | {"epoch": 36, "update": 35.031, "loss": "4.169", "nll_loss": "2.766", "ppl": "6.8", "wps": "45203.6", "ups": "12.39", "wpb": "3649.6", "bsz": "152.6", "num_updates": "38600", "lr": "0.00321911", "gnorm": "0.278", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2352"}
2023-12-13 23:08:06 | INFO | train_inner | {"epoch": 36, "update": 35.122, "loss": "4.133", "nll_loss": "2.72", "ppl": "6.59", "wps": "59668", "ups": "16.83", "wpb": "3545.3", "bsz": "140.8", "num_updates": "38700", "lr": "0.00321495", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2358"}
2023-12-13 23:08:12 | INFO | train_inner | {"epoch": 36, "update": 35.212, "loss": "4.173", "nll_loss": "2.765", "ppl": "6.8", "wps": "56422.6", "ups": "15.74", "wpb": "3584.5", "bsz": "131.6", "num_updates": "38800", "lr": "0.00321081", "gnorm": "0.286", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2364"}
2023-12-13 23:08:18 | INFO | train_inner | {"epoch": 36, "update": 35.303, "loss": "4.193", "nll_loss": "2.79", "ppl": "6.92", "wps": "55777.2", "ups": "15.62", "wpb": "3571.5", "bsz": "129.8", "num_updates": "38900", "lr": "0.00320668", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2371"}
2023-12-13 23:08:25 | INFO | train_inner | {"epoch": 36, "update": 35.394, "loss": "4.18", "nll_loss": "2.777", "ppl": "6.85", "wps": "55889.2", "ups": "15.56", "wpb": "3592", "bsz": "145.7", "num_updates": "39000", "lr": "0.00320256", "gnorm": "0.306", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2377"}
2023-12-13 23:08:31 | INFO | train_inner | {"epoch": 36, "update": 35.485, "loss": "4.214", "nll_loss": "2.816", "ppl": "7.04", "wps": "60931.3", "ups": "17.2", "wpb": "3542.8", "bsz": "140.2", "num_updates": "39100", "lr": "0.00319847", "gnorm": "0.277", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2383"}
2023-12-13 23:08:37 | INFO | train_inner | {"epoch": 36, "update": 35.575, "loss": "4.197", "nll_loss": "2.796", "ppl": "6.94", "wps": "59566", "ups": "16.53", "wpb": "3603.1", "bsz": "147.8", "num_updates": "39200", "lr": "0.00319438", "gnorm": "0.283", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2389"}
2023-12-13 23:08:43 | INFO | train_inner | {"epoch": 36, "update": 35.666, "loss": "4.215", "nll_loss": "2.82", "ppl": "7.06", "wps": "60781.8", "ups": "16.79", "wpb": "3619.5", "bsz": "147.8", "num_updates": "39300", "lr": "0.00319032", "gnorm": "0.279", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2395"}
2023-12-13 23:08:48 | INFO | train_inner | {"epoch": 36, "update": 35.757, "loss": "4.157", "nll_loss": "2.753", "ppl": "6.74", "wps": "63262.4", "ups": "17.36", "wpb": "3644.3", "bsz": "175.4", "num_updates": "39400", "lr": "0.00318626", "gnorm": "0.27", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2401"}
2023-12-13 23:08:55 | INFO | train_inner | {"epoch": 36, "update": 35.848, "loss": "4.282", "nll_loss": "2.894", "ppl": "7.43", "wps": "53009.8", "ups": "15.14", "wpb": "3501.3", "bsz": "125.9", "num_updates": "39500", "lr": "0.00318223", "gnorm": "0.3", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "2407"}
2023-12-13 23:09:01 | INFO | train_inner | {"epoch": 36, "update": 35.938, "loss": "4.212", "nll_loss": "2.817", "ppl": "7.05", "wps": "59332", "ups": "16.46", "wpb": "3605.5", "bsz": "153.4", "num_updates": "39600", "lr": "0.00317821", "gnorm": "0.291", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2413"}
2023-12-13 23:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:09:07 | INFO | valid | {"epoch": 36, "valid_loss": "4.308", "valid_nll_loss": "2.954", "valid_ppl": "7.75", "valid_wps": "124266", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "39668", "valid_best_loss": "4.303"}
2023-12-13 23:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 39668 updates
2023-12-13 23:09:07 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint36.pt
2023-12-13 23:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint36.pt
2023-12-13 23:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint36.pt (epoch 36 @ 39668 updates, score 4.308) (writing took 0.15382910333573818 seconds)
2023-12-13 23:09:07 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-12-13 23:09:07 | INFO | train | {"epoch": 36, "train_loss": "4.192", "train_nll_loss": "2.791", "train_ppl": "6.92", "train_wps": "56992.5", "train_ups": "15.9", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "39668", "train_lr": "0.00317548", "train_gnorm": "0.286", "train_loss_scale": "8", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2419"}
2023-12-13 23:09:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:09:07 | INFO | fairseq.trainer | begin training epoch 37
2023-12-13 23:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:09:09 | INFO | train_inner | {"epoch": 37, "update": 36.029, "loss": "4.198", "nll_loss": "2.799", "ppl": "6.96", "wps": "45850.6", "ups": "12.88", "wpb": "3560.1", "bsz": "154.9", "num_updates": "39700", "lr": "0.0031742", "gnorm": "0.292", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2421"}
2023-12-13 23:09:15 | INFO | train_inner | {"epoch": 37, "update": 36.12, "loss": "4.134", "nll_loss": "2.721", "ppl": "6.59", "wps": "57891.6", "ups": "16.1", "wpb": "3596.5", "bsz": "137.4", "num_updates": "39800", "lr": "0.00317021", "gnorm": "0.277", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2427"}
2023-12-13 23:09:21 | INFO | train_inner | {"epoch": 37, "update": 36.211, "loss": "4.138", "nll_loss": "2.726", "ppl": "6.62", "wps": "58947.5", "ups": "16.51", "wpb": "3570.5", "bsz": "142.9", "num_updates": "39900", "lr": "0.00316624", "gnorm": "0.285", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2433"}
2023-12-13 23:09:27 | INFO | train_inner | {"epoch": 37, "update": 36.301, "loss": "4.173", "nll_loss": "2.769", "ppl": "6.82", "wps": "60323.4", "ups": "17.02", "wpb": "3543.8", "bsz": "144.6", "num_updates": "40000", "lr": "0.00316228", "gnorm": "0.289", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2439"}
2023-12-13 23:09:33 | INFO | train_inner | {"epoch": 37, "update": 36.392, "loss": "4.126", "nll_loss": "2.716", "ppl": "6.57", "wps": "59768.8", "ups": "16.55", "wpb": "3612.1", "bsz": "158.2", "num_updates": "40100", "lr": "0.00315833", "gnorm": "0.292", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2445"}
2023-12-13 23:09:39 | INFO | train_inner | {"epoch": 37, "update": 36.483, "loss": "4.148", "nll_loss": "2.74", "ppl": "6.68", "wps": "60903", "ups": "16.77", "wpb": "3631.2", "bsz": "152.8", "num_updates": "40200", "lr": "0.0031544", "gnorm": "0.273", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2451"}
2023-12-13 23:09:45 | INFO | train_inner | {"epoch": 37, "update": 36.574, "loss": "4.179", "nll_loss": "2.777", "ppl": "6.86", "wps": "60662", "ups": "16.81", "wpb": "3609.7", "bsz": "159.5", "num_updates": "40300", "lr": "0.00315049", "gnorm": "0.286", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2457"}
2023-12-13 23:09:51 | INFO | train_inner | {"epoch": 37, "update": 36.664, "loss": "4.217", "nll_loss": "2.82", "ppl": "7.06", "wps": "57163.8", "ups": "16", "wpb": "3572.3", "bsz": "137.1", "num_updates": "40400", "lr": "0.00314658", "gnorm": "0.281", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2463"}
2023-12-13 23:09:57 | INFO | train_inner | {"epoch": 37, "update": 36.755, "loss": "4.192", "nll_loss": "2.794", "ppl": "6.94", "wps": "62029.9", "ups": "17.31", "wpb": "3583", "bsz": "155.8", "num_updates": "40500", "lr": "0.0031427", "gnorm": "0.278", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2469"}
2023-12-13 23:10:04 | INFO | train_inner | {"epoch": 37, "update": 36.846, "loss": "4.307", "nll_loss": "2.924", "ppl": "7.59", "wps": "50025", "ups": "13.97", "wpb": "3580.3", "bsz": "119.8", "num_updates": "40600", "lr": "0.00313882", "gnorm": "0.301", "loss_scale": "8", "train_wall": "7", "gb_free": "38.9", "wall": "2476"}
2023-12-13 23:10:10 | INFO | train_inner | {"epoch": 37, "update": 36.936, "loss": "4.204", "nll_loss": "2.806", "ppl": "6.99", "wps": "59970.2", "ups": "16.82", "wpb": "3565.6", "bsz": "148.6", "num_updates": "40700", "lr": "0.00313497", "gnorm": "0.282", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2482"}
2023-12-13 23:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:10:16 | INFO | valid | {"epoch": 37, "valid_loss": "4.31", "valid_nll_loss": "2.938", "valid_ppl": "7.66", "valid_wps": "123411", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "40770", "valid_best_loss": "4.303"}
2023-12-13 23:10:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 40770 updates
2023-12-13 23:10:16 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint37.pt
2023-12-13 23:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint37.pt
2023-12-13 23:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint37.pt (epoch 37 @ 40770 updates, score 4.31) (writing took 0.14947552885860205 seconds)
2023-12-13 23:10:16 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-12-13 23:10:16 | INFO | train | {"epoch": 37, "train_loss": "4.182", "train_nll_loss": "2.78", "train_ppl": "6.87", "train_wps": "57149.4", "train_ups": "15.95", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "40770", "train_lr": "0.00313227", "train_gnorm": "0.284", "train_loss_scale": "8", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2488"}
2023-12-13 23:10:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:10:16 | INFO | fairseq.trainer | begin training epoch 38
2023-12-13 23:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:10:18 | INFO | train_inner | {"epoch": 38, "update": 37.027, "loss": "4.16", "nll_loss": "2.755", "ppl": "6.75", "wps": "46347.2", "ups": "12.9", "wpb": "3593.5", "bsz": "144.2", "num_updates": "40800", "lr": "0.00313112", "gnorm": "0.272", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2490"}
2023-12-13 23:10:24 | INFO | train_inner | {"epoch": 38, "update": 37.118, "loss": "4.098", "nll_loss": "2.68", "ppl": "6.41", "wps": "55821.6", "ups": "15.65", "wpb": "3567.2", "bsz": "135", "num_updates": "40900", "lr": "0.00312729", "gnorm": "0.293", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2496"}
2023-12-13 23:10:30 | INFO | train_inner | {"epoch": 38, "update": 37.209, "loss": "4.153", "nll_loss": "2.745", "ppl": "6.7", "wps": "57339.8", "ups": "16.17", "wpb": "3546.2", "bsz": "134.7", "num_updates": "41000", "lr": "0.00312348", "gnorm": "0.289", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2503"}
2023-12-13 23:10:37 | INFO | train_inner | {"epoch": 38, "update": 37.299, "loss": "4.177", "nll_loss": "2.771", "ppl": "6.82", "wps": "58391.2", "ups": "16.36", "wpb": "3569.9", "bsz": "131.4", "num_updates": "41100", "lr": "0.00311967", "gnorm": "0.289", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2509"}
2023-12-13 23:10:43 | INFO | train_inner | {"epoch": 38, "update": 37.39, "loss": "4.142", "nll_loss": "2.734", "ppl": "6.65", "wps": "61010.1", "ups": "16.98", "wpb": "3593.1", "bsz": "147.9", "num_updates": "41200", "lr": "0.00311588", "gnorm": "0.278", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2515"}
2023-12-13 23:10:48 | INFO | train_inner | {"epoch": 38, "update": 37.481, "loss": "4.155", "nll_loss": "2.75", "ppl": "6.73", "wps": "62566.8", "ups": "17.36", "wpb": "3603.2", "bsz": "164.2", "num_updates": "41300", "lr": "0.00311211", "gnorm": "0.274", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2520"}
2023-12-13 23:10:54 | INFO | train_inner | {"epoch": 38, "update": 37.572, "loss": "4.155", "nll_loss": "2.75", "ppl": "6.73", "wps": "65260.6", "ups": "18.16", "wpb": "3594.5", "bsz": "159.8", "num_updates": "41400", "lr": "0.00310835", "gnorm": "0.277", "loss_scale": "8", "train_wall": "5", "gb_free": "38.9", "wall": "2526"}
2023-12-13 23:11:00 | INFO | train_inner | {"epoch": 38, "update": 37.662, "loss": "4.18", "nll_loss": "2.778", "ppl": "6.86", "wps": "57698.8", "ups": "16.02", "wpb": "3602.6", "bsz": "141.1", "num_updates": "41500", "lr": "0.0031046", "gnorm": "0.288", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2532"}
2023-12-13 23:11:06 | INFO | train_inner | {"epoch": 38, "update": 37.753, "loss": "4.203", "nll_loss": "2.807", "ppl": "7", "wps": "57984.7", "ups": "16.24", "wpb": "3569.8", "bsz": "162.5", "num_updates": "41600", "lr": "0.00310087", "gnorm": "0.303", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2538"}
2023-12-13 23:11:13 | INFO | train_inner | {"epoch": 38, "update": 37.844, "loss": "4.249", "nll_loss": "2.859", "ppl": "7.26", "wps": "55482.1", "ups": "15.48", "wpb": "3584.3", "bsz": "143.3", "num_updates": "41700", "lr": "0.00309715", "gnorm": "0.313", "loss_scale": "8", "train_wall": "6", "gb_free": "39", "wall": "2545"}
2023-12-13 23:11:19 | INFO | train_inner | {"epoch": 38, "update": 37.935, "loss": "4.249", "nll_loss": "2.859", "ppl": "7.25", "wps": "55909.5", "ups": "15.5", "wpb": "3607.4", "bsz": "133.6", "num_updates": "41800", "lr": "0.00309344", "gnorm": "0.287", "loss_scale": "8", "train_wall": "6", "gb_free": "38.9", "wall": "2551"}
2023-12-13 23:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:11:25 | INFO | valid | {"epoch": 38, "valid_loss": "4.3", "valid_nll_loss": "2.936", "valid_ppl": "7.65", "valid_wps": "125359", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "41872", "valid_best_loss": "4.3"}
2023-12-13 23:11:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 41872 updates
2023-12-13 23:11:25 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint38.pt
2023-12-13 23:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint38.pt
2023-12-13 23:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint38.pt (epoch 38 @ 41872 updates, score 4.3) (writing took 0.1976447431370616 seconds)
2023-12-13 23:11:25 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-12-13 23:11:25 | INFO | train | {"epoch": 38, "train_loss": "4.176", "train_nll_loss": "2.772", "train_ppl": "6.83", "train_wps": "57131.6", "train_ups": "15.94", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "41872", "train_lr": "0.00309078", "train_gnorm": "0.289", "train_loss_scale": "8", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2557"}
2023-12-13 23:11:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:11:25 | INFO | fairseq.trainer | begin training epoch 39
2023-12-13 23:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:11:27 | INFO | train_inner | {"epoch": 39, "update": 38.025, "loss": "4.174", "nll_loss": "2.771", "ppl": "6.82", "wps": "44722.8", "ups": "12.58", "wpb": "3555.7", "bsz": "146.3", "num_updates": "41900", "lr": "0.00308975", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2559"}
2023-12-13 23:11:33 | INFO | train_inner | {"epoch": 39, "update": 38.116, "loss": "4.064", "nll_loss": "2.642", "ppl": "6.24", "wps": "60508.8", "ups": "16.94", "wpb": "3572.4", "bsz": "145.3", "num_updates": "42000", "lr": "0.00308607", "gnorm": "0.272", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2565"}
2023-12-13 23:11:39 | INFO | train_inner | {"epoch": 39, "update": 38.207, "loss": "4.133", "nll_loss": "2.721", "ppl": "6.6", "wps": "59681.6", "ups": "16.69", "wpb": "3575.2", "bsz": "141.8", "num_updates": "42100", "lr": "0.0030824", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2571"}
2023-12-13 23:11:45 | INFO | train_inner | {"epoch": 39, "update": 38.298, "loss": "4.173", "nll_loss": "2.769", "ppl": "6.82", "wps": "56474", "ups": "15.95", "wpb": "3540.8", "bsz": "149.4", "num_updates": "42200", "lr": "0.00307875", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2577"}
2023-12-13 23:11:51 | INFO | train_inner | {"epoch": 39, "update": 38.388, "loss": "4.133", "nll_loss": "2.724", "ppl": "6.61", "wps": "60153.1", "ups": "16.64", "wpb": "3615.9", "bsz": "154.5", "num_updates": "42300", "lr": "0.0030751", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2583"}
2023-12-13 23:11:58 | INFO | train_inner | {"epoch": 39, "update": 38.479, "loss": "4.176", "nll_loss": "2.773", "ppl": "6.83", "wps": "55711.7", "ups": "15.62", "wpb": "3567.7", "bsz": "136.3", "num_updates": "42400", "lr": "0.00307148", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2590"}
2023-12-13 23:12:03 | INFO | train_inner | {"epoch": 39, "update": 38.57, "loss": "4.145", "nll_loss": "2.738", "ppl": "6.67", "wps": "62615.7", "ups": "17.29", "wpb": "3621.3", "bsz": "149", "num_updates": "42500", "lr": "0.00306786", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2596"}
2023-12-13 23:12:10 | INFO | train_inner | {"epoch": 39, "update": 38.661, "loss": "4.192", "nll_loss": "2.793", "ppl": "6.93", "wps": "56739.7", "ups": "16.01", "wpb": "3543.4", "bsz": "146.4", "num_updates": "42600", "lr": "0.00306426", "gnorm": "0.32", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2602"}
2023-12-13 23:12:16 | INFO | train_inner | {"epoch": 39, "update": 38.751, "loss": "4.221", "nll_loss": "2.826", "ppl": "7.09", "wps": "59919.1", "ups": "16.53", "wpb": "3625.7", "bsz": "146.2", "num_updates": "42700", "lr": "0.00306067", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2608"}
2023-12-13 23:12:22 | INFO | train_inner | {"epoch": 39, "update": 38.842, "loss": "4.2", "nll_loss": "2.803", "ppl": "6.98", "wps": "58667", "ups": "16.43", "wpb": "3571.8", "bsz": "150.2", "num_updates": "42800", "lr": "0.00305709", "gnorm": "0.295", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2614"}
2023-12-13 23:12:28 | INFO | train_inner | {"epoch": 39, "update": 38.933, "loss": "4.235", "nll_loss": "2.842", "ppl": "7.17", "wps": "57622.7", "ups": "16.21", "wpb": "3554.5", "bsz": "134.4", "num_updates": "42900", "lr": "0.00305352", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2620"}
2023-12-13 23:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:12:34 | INFO | valid | {"epoch": 39, "valid_loss": "4.283", "valid_nll_loss": "2.924", "valid_ppl": "7.59", "valid_wps": "122654", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "42974", "valid_best_loss": "4.283"}
2023-12-13 23:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 42974 updates
2023-12-13 23:12:34 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint39.pt
2023-12-13 23:12:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint39.pt
2023-12-13 23:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint39.pt (epoch 39 @ 42974 updates, score 4.283) (writing took 0.22281789500266314 seconds)
2023-12-13 23:12:34 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-12-13 23:12:34 | INFO | train | {"epoch": 39, "train_loss": "4.167", "train_nll_loss": "2.763", "train_ppl": "6.79", "train_wps": "57211.3", "train_ups": "15.96", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "42974", "train_lr": "0.00305089", "train_gnorm": "0.289", "train_loss_scale": "16", "train_train_wall": "66", "train_gb_free": "39", "train_wall": "2626"}
2023-12-13 23:12:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:12:34 | INFO | fairseq.trainer | begin training epoch 40
2023-12-13 23:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:12:36 | INFO | train_inner | {"epoch": 40, "update": 39.024, "loss": "4.189", "nll_loss": "2.789", "ppl": "6.91", "wps": "45345.6", "ups": "12.51", "wpb": "3625.7", "bsz": "135.4", "num_updates": "43000", "lr": "0.00304997", "gnorm": "0.271", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2628"}
2023-12-13 23:12:42 | INFO | train_inner | {"epoch": 40, "update": 39.114, "loss": "4.068", "nll_loss": "2.648", "ppl": "6.27", "wps": "57123.9", "ups": "15.75", "wpb": "3627.8", "bsz": "148.7", "num_updates": "43100", "lr": "0.00304643", "gnorm": "0.276", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2634"}
2023-12-13 23:12:48 | INFO | train_inner | {"epoch": 40, "update": 39.205, "loss": "4.08", "nll_loss": "2.663", "ppl": "6.33", "wps": "59072.7", "ups": "16.67", "wpb": "3543.1", "bsz": "157", "num_updates": "43200", "lr": "0.0030429", "gnorm": "0.287", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2640"}
2023-12-13 23:12:54 | INFO | train_inner | {"epoch": 40, "update": 39.296, "loss": "4.125", "nll_loss": "2.714", "ppl": "6.56", "wps": "59140.4", "ups": "16.48", "wpb": "3589.3", "bsz": "146.2", "num_updates": "43300", "lr": "0.00303939", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2646"}
2023-12-13 23:13:01 | INFO | train_inner | {"epoch": 40, "update": 39.387, "loss": "4.123", "nll_loss": "2.712", "ppl": "6.55", "wps": "56390.6", "ups": "15.87", "wpb": "3552.4", "bsz": "142.1", "num_updates": "43400", "lr": "0.00303588", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2653"}
2023-12-13 23:13:06 | INFO | train_inner | {"epoch": 40, "update": 39.477, "loss": "4.133", "nll_loss": "2.724", "ppl": "6.61", "wps": "64841", "ups": "17.65", "wpb": "3673.9", "bsz": "159.4", "num_updates": "43500", "lr": "0.00303239", "gnorm": "0.281", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2658"}
2023-12-13 23:13:13 | INFO | train_inner | {"epoch": 40, "update": 39.568, "loss": "4.25", "nll_loss": "2.857", "ppl": "7.25", "wps": "50869.1", "ups": "14.24", "wpb": "3571.6", "bsz": "115.7", "num_updates": "43600", "lr": "0.00302891", "gnorm": "0.299", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2665"}
2023-12-13 23:13:19 | INFO | train_inner | {"epoch": 40, "update": 39.659, "loss": "4.17", "nll_loss": "2.767", "ppl": "6.81", "wps": "59992.9", "ups": "17.01", "wpb": "3527.9", "bsz": "143.7", "num_updates": "43700", "lr": "0.00302545", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2671"}
2023-12-13 23:13:25 | INFO | train_inner | {"epoch": 40, "update": 39.75, "loss": "4.14", "nll_loss": "2.734", "ppl": "6.65", "wps": "66875.6", "ups": "18.71", "wpb": "3574.2", "bsz": "162.8", "num_updates": "43800", "lr": "0.00302199", "gnorm": "0.288", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2677"}
2023-12-13 23:13:30 | INFO | train_inner | {"epoch": 40, "update": 39.84, "loss": "4.171", "nll_loss": "2.771", "ppl": "6.83", "wps": "61724.4", "ups": "17.18", "wpb": "3592.1", "bsz": "163.4", "num_updates": "43900", "lr": "0.00301855", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2683"}
2023-12-13 23:13:37 | INFO | train_inner | {"epoch": 40, "update": 39.931, "loss": "4.255", "nll_loss": "2.866", "ppl": "7.29", "wps": "57972.9", "ups": "16.23", "wpb": "3571.1", "bsz": "133.9", "num_updates": "44000", "lr": "0.00301511", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2689"}
2023-12-13 23:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:13:43 | INFO | valid | {"epoch": 40, "valid_loss": "4.298", "valid_nll_loss": "2.931", "valid_ppl": "7.62", "valid_wps": "124884", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "44076", "valid_best_loss": "4.283"}
2023-12-13 23:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 44076 updates
2023-12-13 23:13:43 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint40.pt
2023-12-13 23:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint40.pt
2023-12-13 23:13:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint40.pt (epoch 40 @ 44076 updates, score 4.298) (writing took 0.15281032118946314 seconds)
2023-12-13 23:13:43 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-12-13 23:13:43 | INFO | train | {"epoch": 40, "train_loss": "4.158", "train_nll_loss": "2.753", "train_ppl": "6.74", "train_wps": "57422.1", "train_ups": "16.02", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "44076", "train_lr": "0.00301251", "train_gnorm": "0.288", "train_loss_scale": "16", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2695"}
2023-12-13 23:13:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:13:43 | INFO | fairseq.trainer | begin training epoch 41
2023-12-13 23:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:13:45 | INFO | train_inner | {"epoch": 41, "update": 40.022, "loss": "4.227", "nll_loss": "2.832", "ppl": "7.12", "wps": "45234.7", "ups": "12.53", "wpb": "3610.7", "bsz": "130.6", "num_updates": "44100", "lr": "0.00301169", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2697"}
2023-12-13 23:13:51 | INFO | train_inner | {"epoch": 41, "update": 40.113, "loss": "4.075", "nll_loss": "2.655", "ppl": "6.3", "wps": "58001.4", "ups": "16.31", "wpb": "3555.8", "bsz": "140", "num_updates": "44200", "lr": "0.00300828", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2703"}
2023-12-13 23:13:56 | INFO | train_inner | {"epoch": 41, "update": 40.203, "loss": "4.06", "nll_loss": "2.638", "ppl": "6.22", "wps": "62990.4", "ups": "17.54", "wpb": "3591.4", "bsz": "150.2", "num_updates": "44300", "lr": "0.00300489", "gnorm": "0.279", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2708"}
2023-12-13 23:14:03 | INFO | train_inner | {"epoch": 41, "update": 40.294, "loss": "4.123", "nll_loss": "2.71", "ppl": "6.54", "wps": "54156.6", "ups": "15.58", "wpb": "3476.5", "bsz": "130.9", "num_updates": "44400", "lr": "0.0030015", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2715"}
2023-12-13 23:14:09 | INFO | train_inner | {"epoch": 41, "update": 40.385, "loss": "4.15", "nll_loss": "2.742", "ppl": "6.69", "wps": "62508.8", "ups": "17.24", "wpb": "3625.1", "bsz": "148.1", "num_updates": "44500", "lr": "0.00299813", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2721"}
2023-12-13 23:14:15 | INFO | train_inner | {"epoch": 41, "update": 40.475, "loss": "4.105", "nll_loss": "2.691", "ppl": "6.46", "wps": "58084.6", "ups": "16.23", "wpb": "3578", "bsz": "159.9", "num_updates": "44600", "lr": "0.00299476", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2727"}
2023-12-13 23:14:21 | INFO | train_inner | {"epoch": 41, "update": 40.566, "loss": "4.166", "nll_loss": "2.764", "ppl": "6.79", "wps": "59834.7", "ups": "16.64", "wpb": "3596.1", "bsz": "148", "num_updates": "44700", "lr": "0.00299141", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2733"}
2023-12-13 23:14:27 | INFO | train_inner | {"epoch": 41, "update": 40.657, "loss": "4.153", "nll_loss": "2.747", "ppl": "6.71", "wps": "57674.4", "ups": "16.07", "wpb": "3588.9", "bsz": "145.4", "num_updates": "44800", "lr": "0.00298807", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2739"}
2023-12-13 23:14:33 | INFO | train_inner | {"epoch": 41, "update": 40.748, "loss": "4.159", "nll_loss": "2.756", "ppl": "6.76", "wps": "63262.3", "ups": "17.42", "wpb": "3631.5", "bsz": "152.2", "num_updates": "44900", "lr": "0.00298474", "gnorm": "0.275", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2745"}
2023-12-13 23:14:39 | INFO | train_inner | {"epoch": 41, "update": 40.838, "loss": "4.192", "nll_loss": "2.794", "ppl": "6.93", "wps": "58706.8", "ups": "16.19", "wpb": "3627.1", "bsz": "144.7", "num_updates": "45000", "lr": "0.00298142", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2751"}
2023-12-13 23:14:45 | INFO | train_inner | {"epoch": 41, "update": 40.929, "loss": "4.226", "nll_loss": "2.834", "ppl": "7.13", "wps": "58392.9", "ups": "16.31", "wpb": "3580.5", "bsz": "148.9", "num_updates": "45100", "lr": "0.00297812", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2757"}
2023-12-13 23:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:14:52 | INFO | valid | {"epoch": 41, "valid_loss": "4.298", "valid_nll_loss": "2.926", "valid_ppl": "7.6", "valid_wps": "124177", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "45178", "valid_best_loss": "4.283"}
2023-12-13 23:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 45178 updates
2023-12-13 23:14:52 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint41.pt
2023-12-13 23:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint41.pt
2023-12-13 23:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint41.pt (epoch 41 @ 45178 updates, score 4.298) (writing took 0.1587907262146473 seconds)
2023-12-13 23:14:52 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-12-13 23:14:52 | INFO | train | {"epoch": 41, "train_loss": "4.15", "train_nll_loss": "2.743", "train_ppl": "6.7", "train_wps": "57286.4", "train_ups": "15.99", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "45178", "train_lr": "0.00297554", "train_gnorm": "0.289", "train_loss_scale": "16", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2764"}
2023-12-13 23:14:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:14:52 | INFO | fairseq.trainer | begin training epoch 42
2023-12-13 23:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:14:53 | INFO | train_inner | {"epoch": 42, "update": 41.02, "loss": "4.219", "nll_loss": "2.824", "ppl": "7.08", "wps": "43326.3", "ups": "12.09", "wpb": "3583", "bsz": "133.6", "num_updates": "45200", "lr": "0.00297482", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2765"}
2023-12-13 23:14:59 | INFO | train_inner | {"epoch": 42, "update": 41.111, "loss": "4.073", "nll_loss": "2.653", "ppl": "6.29", "wps": "58415", "ups": "16.45", "wpb": "3551", "bsz": "140.4", "num_updates": "45300", "lr": "0.00297154", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2771"}
2023-12-13 23:15:05 | INFO | train_inner | {"epoch": 42, "update": 41.201, "loss": "4.072", "nll_loss": "2.652", "ppl": "6.28", "wps": "62206.4", "ups": "17.43", "wpb": "3569.3", "bsz": "153.5", "num_updates": "45400", "lr": "0.00296826", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2777"}
2023-12-13 23:15:11 | INFO | train_inner | {"epoch": 42, "update": 41.292, "loss": "4.109", "nll_loss": "2.693", "ppl": "6.47", "wps": "56748.9", "ups": "16.14", "wpb": "3515.1", "bsz": "133.1", "num_updates": "45500", "lr": "0.002965", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "2783"}
2023-12-13 23:15:17 | INFO | train_inner | {"epoch": 42, "update": 41.383, "loss": "4.175", "nll_loss": "2.772", "ppl": "6.83", "wps": "59621.9", "ups": "16.4", "wpb": "3634.9", "bsz": "142.8", "num_updates": "45600", "lr": "0.00296174", "gnorm": "0.34", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2790"}
2023-12-13 23:15:24 | INFO | train_inner | {"epoch": 42, "update": 41.474, "loss": "4.135", "nll_loss": "2.726", "ppl": "6.62", "wps": "56993.2", "ups": "15.76", "wpb": "3616.6", "bsz": "144.6", "num_updates": "45700", "lr": "0.0029585", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2796"}
2023-12-13 23:15:30 | INFO | train_inner | {"epoch": 42, "update": 41.564, "loss": "4.184", "nll_loss": "2.784", "ppl": "6.89", "wps": "53426.3", "ups": "15.17", "wpb": "3521.9", "bsz": "135", "num_updates": "45800", "lr": "0.00295527", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2802"}
2023-12-13 23:15:37 | INFO | train_inner | {"epoch": 42, "update": 41.655, "loss": "4.126", "nll_loss": "2.718", "ppl": "6.58", "wps": "58032.1", "ups": "16.27", "wpb": "3567.5", "bsz": "162.6", "num_updates": "45900", "lr": "0.00295205", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2809"}
2023-12-13 23:15:42 | INFO | train_inner | {"epoch": 42, "update": 41.746, "loss": "4.138", "nll_loss": "2.733", "ppl": "6.65", "wps": "60947.4", "ups": "17.12", "wpb": "3560.3", "bsz": "159.2", "num_updates": "46000", "lr": "0.00294884", "gnorm": "0.277", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2814"}
2023-12-13 23:15:48 | INFO | train_inner | {"epoch": 42, "update": 41.837, "loss": "4.165", "nll_loss": "2.762", "ppl": "6.79", "wps": "63869", "ups": "17.47", "wpb": "3656.1", "bsz": "150.3", "num_updates": "46100", "lr": "0.00294564", "gnorm": "0.327", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2820"}
2023-12-13 23:15:55 | INFO | train_inner | {"epoch": 42, "update": 41.927, "loss": "4.253", "nll_loss": "2.863", "ppl": "7.28", "wps": "53535.7", "ups": "14.88", "wpb": "3598.3", "bsz": "131.7", "num_updates": "46200", "lr": "0.00294245", "gnorm": "0.312", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2827"}
2023-12-13 23:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:16:01 | INFO | valid | {"epoch": 42, "valid_loss": "4.3", "valid_nll_loss": "2.942", "valid_ppl": "7.68", "valid_wps": "121907", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "46280", "valid_best_loss": "4.283"}
2023-12-13 23:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 46280 updates
2023-12-13 23:16:01 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint42.pt
2023-12-13 23:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint42.pt
2023-12-13 23:16:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint42.pt (epoch 42 @ 46280 updates, score 4.3) (writing took 0.16591618303209543 seconds)
2023-12-13 23:16:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-12-13 23:16:01 | INFO | train | {"epoch": 42, "train_loss": "4.146", "train_nll_loss": "2.739", "train_ppl": "6.68", "train_wps": "56905.4", "train_ups": "15.88", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "46280", "train_lr": "0.00293991", "train_gnorm": "0.298", "train_loss_scale": "16", "train_train_wall": "67", "train_gb_free": "38.9", "train_wall": "2833"}
2023-12-13 23:16:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:16:01 | INFO | fairseq.trainer | begin training epoch 43
2023-12-13 23:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:16:03 | INFO | train_inner | {"epoch": 43, "update": 42.018, "loss": "4.19", "nll_loss": "2.792", "ppl": "6.93", "wps": "45386.8", "ups": "12.56", "wpb": "3614.8", "bsz": "141.9", "num_updates": "46300", "lr": "0.00293927", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2835"}
2023-12-13 23:16:09 | INFO | train_inner | {"epoch": 43, "update": 42.109, "loss": "4.08", "nll_loss": "2.66", "ppl": "6.32", "wps": "55068.6", "ups": "15.59", "wpb": "3531.3", "bsz": "134.8", "num_updates": "46400", "lr": "0.0029361", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2841"}
2023-12-13 23:16:15 | INFO | train_inner | {"epoch": 43, "update": 42.2, "loss": "4.066", "nll_loss": "2.645", "ppl": "6.26", "wps": "63566.8", "ups": "17.64", "wpb": "3603", "bsz": "155.7", "num_updates": "46500", "lr": "0.00293294", "gnorm": "0.286", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2847"}
2023-12-13 23:16:21 | INFO | train_inner | {"epoch": 43, "update": 42.29, "loss": "4.126", "nll_loss": "2.714", "ppl": "6.56", "wps": "56777.2", "ups": "15.97", "wpb": "3554.9", "bsz": "130.7", "num_updates": "46600", "lr": "0.00292979", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2853"}
2023-12-13 23:16:28 | INFO | train_inner | {"epoch": 43, "update": 42.381, "loss": "4.128", "nll_loss": "2.718", "ppl": "6.58", "wps": "54493.8", "ups": "15.1", "wpb": "3607.8", "bsz": "147", "num_updates": "46700", "lr": "0.00292666", "gnorm": "0.29", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2860"}
2023-12-13 23:16:34 | INFO | train_inner | {"epoch": 43, "update": 42.472, "loss": "4.142", "nll_loss": "2.735", "ppl": "6.66", "wps": "59486.8", "ups": "16.65", "wpb": "3572.9", "bsz": "144.5", "num_updates": "46800", "lr": "0.00292353", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2866"}
2023-12-13 23:16:40 | INFO | train_inner | {"epoch": 43, "update": 42.563, "loss": "4.139", "nll_loss": "2.731", "ppl": "6.64", "wps": "57336.9", "ups": "15.87", "wpb": "3612.4", "bsz": "152.3", "num_updates": "46900", "lr": "0.00292041", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2872"}
2023-12-13 23:16:46 | INFO | train_inner | {"epoch": 43, "update": 42.653, "loss": "4.162", "nll_loss": "2.76", "ppl": "6.77", "wps": "60654.4", "ups": "17.1", "wpb": "3546.2", "bsz": "145.9", "num_updates": "47000", "lr": "0.0029173", "gnorm": "0.362", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2878"}
2023-12-13 23:16:52 | INFO | train_inner | {"epoch": 43, "update": 42.744, "loss": "4.161", "nll_loss": "2.758", "ppl": "6.76", "wps": "62665.6", "ups": "17.75", "wpb": "3530", "bsz": "154.3", "num_updates": "47100", "lr": "0.0029142", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2884"}
2023-12-13 23:16:57 | INFO | train_inner | {"epoch": 43, "update": 42.835, "loss": "4.188", "nll_loss": "2.79", "ppl": "6.92", "wps": "60474.3", "ups": "16.77", "wpb": "3606.2", "bsz": "142.8", "num_updates": "47200", "lr": "0.00291111", "gnorm": "0.317", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2890"}
2023-12-13 23:17:04 | INFO | train_inner | {"epoch": 43, "update": 42.926, "loss": "4.255", "nll_loss": "2.865", "ppl": "7.29", "wps": "52583.6", "ups": "14.67", "wpb": "3583.8", "bsz": "124.6", "num_updates": "47300", "lr": "0.00290803", "gnorm": "0.292", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2896"}
2023-12-13 23:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:17:10 | INFO | valid | {"epoch": 43, "valid_loss": "4.288", "valid_nll_loss": "2.929", "valid_ppl": "7.61", "valid_wps": "124405", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "47382", "valid_best_loss": "4.283"}
2023-12-13 23:17:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 47382 updates
2023-12-13 23:17:10 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint43.pt
2023-12-13 23:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint43.pt
2023-12-13 23:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint43.pt (epoch 43 @ 47382 updates, score 4.288) (writing took 0.15131535567343235 seconds)
2023-12-13 23:17:10 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-12-13 23:17:10 | INFO | train | {"epoch": 43, "train_loss": "4.141", "train_nll_loss": "2.734", "train_ppl": "6.65", "train_wps": "57158.2", "train_ups": "15.95", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "47382", "train_lr": "0.00290552", "train_gnorm": "0.3", "train_loss_scale": "16", "train_train_wall": "66", "train_gb_free": "38.9", "train_wall": "2903"}
2023-12-13 23:17:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:17:10 | INFO | fairseq.trainer | begin training epoch 44
2023-12-13 23:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:17:12 | INFO | train_inner | {"epoch": 44, "update": 43.016, "loss": "4.116", "nll_loss": "2.708", "ppl": "6.53", "wps": "50448.3", "ups": "13.74", "wpb": "3671.9", "bsz": "168.2", "num_updates": "47400", "lr": "0.00290496", "gnorm": "0.28", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2904"}
2023-12-13 23:17:18 | INFO | train_inner | {"epoch": 44, "update": 43.107, "loss": "4.018", "nll_loss": "2.588", "ppl": "6.01", "wps": "58157.7", "ups": "16.24", "wpb": "3582.1", "bsz": "141.7", "num_updates": "47500", "lr": "0.00290191", "gnorm": "0.28", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2910"}
2023-12-13 23:17:24 | INFO | train_inner | {"epoch": 44, "update": 43.198, "loss": "4.084", "nll_loss": "2.666", "ppl": "6.35", "wps": "58595.2", "ups": "16.44", "wpb": "3563.9", "bsz": "146.6", "num_updates": "47600", "lr": "0.00289886", "gnorm": "0.308", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2916"}
2023-12-13 23:17:29 | INFO | train_inner | {"epoch": 44, "update": 43.289, "loss": "4.028", "nll_loss": "2.603", "ppl": "6.08", "wps": "68667.8", "ups": "18.66", "wpb": "3680.4", "bsz": "164.9", "num_updates": "47700", "lr": "0.00289581", "gnorm": "0.271", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2921"}
2023-12-13 23:17:35 | INFO | train_inner | {"epoch": 44, "update": 43.379, "loss": "4.134", "nll_loss": "2.726", "ppl": "6.61", "wps": "65554.6", "ups": "18.03", "wpb": "3635.2", "bsz": "141.5", "num_updates": "47800", "lr": "0.00289278", "gnorm": "0.289", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2927"}
2023-12-13 23:17:41 | INFO | train_inner | {"epoch": 44, "update": 43.47, "loss": "4.143", "nll_loss": "2.736", "ppl": "6.66", "wps": "60177.3", "ups": "16.81", "wpb": "3578.9", "bsz": "142.2", "num_updates": "47900", "lr": "0.00288976", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2933"}
2023-12-13 23:17:47 | INFO | train_inner | {"epoch": 44, "update": 43.561, "loss": "4.208", "nll_loss": "2.809", "ppl": "7.01", "wps": "53245.9", "ups": "15.14", "wpb": "3517.8", "bsz": "126.6", "num_updates": "48000", "lr": "0.00288675", "gnorm": "0.337", "loss_scale": "16", "train_wall": "7", "gb_free": "39", "wall": "2939"}
2023-12-13 23:17:53 | INFO | train_inner | {"epoch": 44, "update": 43.652, "loss": "4.179", "nll_loss": "2.778", "ppl": "6.86", "wps": "65964.3", "ups": "18.07", "wpb": "3649.6", "bsz": "142.9", "num_updates": "48100", "lr": "0.00288375", "gnorm": "0.29", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2945"}
2023-12-13 23:17:58 | INFO | train_inner | {"epoch": 44, "update": 43.742, "loss": "4.102", "nll_loss": "2.692", "ppl": "6.46", "wps": "69969.1", "ups": "19.48", "wpb": "3591.9", "bsz": "168.2", "num_updates": "48200", "lr": "0.00288076", "gnorm": "0.28", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "2950"}
2023-12-13 23:18:04 | INFO | train_inner | {"epoch": 44, "update": 43.833, "loss": "4.197", "nll_loss": "2.8", "ppl": "6.96", "wps": "58882.4", "ups": "16.47", "wpb": "3576.1", "bsz": "142.7", "num_updates": "48300", "lr": "0.00287777", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2956"}
2023-12-13 23:18:11 | INFO | train_inner | {"epoch": 44, "update": 43.924, "loss": "4.207", "nll_loss": "2.811", "ppl": "7.02", "wps": "51914.8", "ups": "14.94", "wpb": "3475", "bsz": "139.1", "num_updates": "48400", "lr": "0.0028748", "gnorm": "0.304", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2963"}
2023-12-13 23:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:18:17 | INFO | valid | {"epoch": 44, "valid_loss": "4.313", "valid_nll_loss": "2.932", "valid_ppl": "7.63", "valid_wps": "122569", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "48484", "valid_best_loss": "4.283"}
2023-12-13 23:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 48484 updates
2023-12-13 23:18:17 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint44.pt
2023-12-13 23:18:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint44.pt
2023-12-13 23:18:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint44.pt (epoch 44 @ 48484 updates, score 4.313) (writing took 0.16512399818748236 seconds)
2023-12-13 23:18:17 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-12-13 23:18:17 | INFO | train | {"epoch": 44, "train_loss": "4.132", "train_nll_loss": "2.724", "train_ppl": "6.61", "train_wps": "59267.4", "train_ups": "16.54", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "48484", "train_lr": "0.00287231", "train_gnorm": "0.295", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "2969"}
2023-12-13 23:18:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:18:17 | INFO | fairseq.trainer | begin training epoch 45
2023-12-13 23:18:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:18:18 | INFO | train_inner | {"epoch": 45, "update": 44.015, "loss": "4.135", "nll_loss": "2.729", "ppl": "6.63", "wps": "47803", "ups": "13.47", "wpb": "3548.5", "bsz": "146.6", "num_updates": "48500", "lr": "0.00287183", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2970"}
2023-12-13 23:18:24 | INFO | train_inner | {"epoch": 45, "update": 44.105, "loss": "4.01", "nll_loss": "2.581", "ppl": "5.98", "wps": "64391.3", "ups": "17.73", "wpb": "3632.1", "bsz": "147.2", "num_updates": "48600", "lr": "0.00286888", "gnorm": "0.268", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2976"}
2023-12-13 23:18:29 | INFO | train_inner | {"epoch": 45, "update": 44.196, "loss": "4.043", "nll_loss": "2.621", "ppl": "6.15", "wps": "63632.3", "ups": "17.78", "wpb": "3578.5", "bsz": "161.9", "num_updates": "48700", "lr": "0.00286593", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2982"}
2023-12-13 23:18:36 | INFO | train_inner | {"epoch": 45, "update": 44.287, "loss": "4.08", "nll_loss": "2.661", "ppl": "6.32", "wps": "57148.9", "ups": "16", "wpb": "3572.1", "bsz": "137.8", "num_updates": "48800", "lr": "0.00286299", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "2988"}
2023-12-13 23:18:42 | INFO | train_inner | {"epoch": 45, "update": 44.377, "loss": "4.199", "nll_loss": "2.799", "ppl": "6.96", "wps": "53425.8", "ups": "15", "wpb": "3561.3", "bsz": "122.3", "num_updates": "48900", "lr": "0.00286006", "gnorm": "0.312", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "2994"}
2023-12-13 23:18:49 | INFO | train_inner | {"epoch": 45, "update": 44.468, "loss": "4.1", "nll_loss": "2.686", "ppl": "6.43", "wps": "56090.1", "ups": "15.94", "wpb": "3519.3", "bsz": "142.4", "num_updates": "49000", "lr": "0.00285714", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3001"}
2023-12-13 23:18:55 | INFO | train_inner | {"epoch": 45, "update": 44.559, "loss": "4.158", "nll_loss": "2.753", "ppl": "6.74", "wps": "60978.3", "ups": "16.86", "wpb": "3615.8", "bsz": "140.6", "num_updates": "49100", "lr": "0.00285423", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3007"}
2023-12-13 23:19:00 | INFO | train_inner | {"epoch": 45, "update": 44.65, "loss": "4.138", "nll_loss": "2.732", "ppl": "6.65", "wps": "63317.1", "ups": "17.73", "wpb": "3571.1", "bsz": "157", "num_updates": "49200", "lr": "0.00285133", "gnorm": "0.291", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3012"}
2023-12-13 23:19:06 | INFO | train_inner | {"epoch": 45, "update": 44.74, "loss": "4.138", "nll_loss": "2.733", "ppl": "6.65", "wps": "65521.2", "ups": "18.06", "wpb": "3628.6", "bsz": "158.6", "num_updates": "49300", "lr": "0.00284844", "gnorm": "0.298", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3018"}
2023-12-13 23:19:11 | INFO | train_inner | {"epoch": 45, "update": 44.831, "loss": "4.111", "nll_loss": "2.701", "ppl": "6.5", "wps": "66869.4", "ups": "18.49", "wpb": "3616.1", "bsz": "158.2", "num_updates": "49400", "lr": "0.00284555", "gnorm": "0.279", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3023"}
2023-12-13 23:19:17 | INFO | train_inner | {"epoch": 45, "update": 44.922, "loss": "4.217", "nll_loss": "2.823", "ppl": "7.08", "wps": "57763.4", "ups": "16.25", "wpb": "3554.2", "bsz": "139.4", "num_updates": "49500", "lr": "0.00284268", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3029"}
2023-12-13 23:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:19:24 | INFO | valid | {"epoch": 45, "valid_loss": "4.306", "valid_nll_loss": "2.952", "valid_ppl": "7.74", "valid_wps": "121054", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "49586", "valid_best_loss": "4.283"}
2023-12-13 23:19:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 49586 updates
2023-12-13 23:19:24 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint45.pt
2023-12-13 23:19:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint45.pt
2023-12-13 23:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint45.pt (epoch 45 @ 49586 updates, score 4.306) (writing took 0.1653512679040432 seconds)
2023-12-13 23:19:24 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-12-13 23:19:24 | INFO | train | {"epoch": 45, "train_loss": "4.125", "train_nll_loss": "2.715", "train_ppl": "6.57", "train_wps": "58608.9", "train_ups": "16.35", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "49586", "train_lr": "0.00284021", "train_gnorm": "0.294", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "3037"}
2023-12-13 23:19:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:19:24 | INFO | fairseq.trainer | begin training epoch 46
2023-12-13 23:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:19:25 | INFO | train_inner | {"epoch": 46, "update": 45.013, "loss": "4.189", "nll_loss": "2.791", "ppl": "6.92", "wps": "44168.9", "ups": "12.34", "wpb": "3578.3", "bsz": "131.6", "num_updates": "49600", "lr": "0.00283981", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3037"}
2023-12-13 23:19:31 | INFO | train_inner | {"epoch": 46, "update": 45.103, "loss": "4.075", "nll_loss": "2.656", "ppl": "6.3", "wps": "59737.5", "ups": "17.11", "wpb": "3490.8", "bsz": "143.4", "num_updates": "49700", "lr": "0.00283695", "gnorm": "0.338", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3043"}
2023-12-13 23:19:37 | INFO | train_inner | {"epoch": 46, "update": 45.194, "loss": "4.067", "nll_loss": "2.647", "ppl": "6.26", "wps": "59076.6", "ups": "16.75", "wpb": "3527.8", "bsz": "144.4", "num_updates": "49800", "lr": "0.0028341", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3049"}
2023-12-13 23:19:44 | INFO | train_inner | {"epoch": 46, "update": 45.285, "loss": "4.102", "nll_loss": "2.686", "ppl": "6.44", "wps": "55060.8", "ups": "15.28", "wpb": "3603.6", "bsz": "133.4", "num_updates": "49900", "lr": "0.00283126", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3056"}
2023-12-13 23:19:49 | INFO | train_inner | {"epoch": 46, "update": 45.376, "loss": "4.053", "nll_loss": "2.634", "ppl": "6.21", "wps": "64110.4", "ups": "17.79", "wpb": "3603.6", "bsz": "160.2", "num_updates": "50000", "lr": "0.00282843", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3061"}
2023-12-13 23:19:55 | INFO | train_inner | {"epoch": 46, "update": 45.466, "loss": "4.105", "nll_loss": "2.691", "ppl": "6.46", "wps": "64720.4", "ups": "17.9", "wpb": "3616.3", "bsz": "149.1", "num_updates": "50100", "lr": "0.0028256", "gnorm": "0.292", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3067"}
2023-12-13 23:20:01 | INFO | train_inner | {"epoch": 46, "update": 45.557, "loss": "4.133", "nll_loss": "2.725", "ppl": "6.61", "wps": "56881.3", "ups": "15.81", "wpb": "3597.4", "bsz": "144.2", "num_updates": "50200", "lr": "0.00282279", "gnorm": "0.306", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3073"}
2023-12-13 23:20:07 | INFO | train_inner | {"epoch": 46, "update": 45.648, "loss": "4.146", "nll_loss": "2.741", "ppl": "6.69", "wps": "60239.7", "ups": "16.64", "wpb": "3620.2", "bsz": "152.7", "num_updates": "50300", "lr": "0.00281998", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3079"}
2023-12-13 23:20:13 | INFO | train_inner | {"epoch": 46, "update": 45.739, "loss": "4.094", "nll_loss": "2.682", "ppl": "6.42", "wps": "66962", "ups": "18.43", "wpb": "3632.7", "bsz": "153.9", "num_updates": "50400", "lr": "0.00281718", "gnorm": "0.286", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3085"}
2023-12-13 23:20:19 | INFO | train_inner | {"epoch": 46, "update": 45.829, "loss": "4.156", "nll_loss": "2.752", "ppl": "6.73", "wps": "60444.5", "ups": "16.73", "wpb": "3613.5", "bsz": "140.9", "num_updates": "50500", "lr": "0.00281439", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3091"}
2023-12-13 23:20:24 | INFO | train_inner | {"epoch": 46, "update": 45.92, "loss": "4.224", "nll_loss": "2.832", "ppl": "7.12", "wps": "62116.7", "ups": "17.46", "wpb": "3556.9", "bsz": "136.9", "num_updates": "50600", "lr": "0.00281161", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3097"}
2023-12-13 23:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:20:31 | INFO | valid | {"epoch": 46, "valid_loss": "4.312", "valid_nll_loss": "2.945", "valid_ppl": "7.7", "valid_wps": "121817", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "50688", "valid_best_loss": "4.283"}
2023-12-13 23:20:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 50688 updates
2023-12-13 23:20:31 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint46.pt
2023-12-13 23:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint46.pt
2023-12-13 23:20:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint46.pt (epoch 46 @ 50688 updates, score 4.312) (writing took 0.19197453279048204 seconds)
2023-12-13 23:20:32 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-12-13 23:20:32 | INFO | train | {"epoch": 46, "train_loss": "4.121", "train_nll_loss": "2.711", "train_ppl": "6.55", "train_wps": "58708", "train_ups": "16.38", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "50688", "train_lr": "0.00280917", "train_gnorm": "0.306", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "3104"}
2023-12-13 23:20:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:20:32 | INFO | fairseq.trainer | begin training epoch 47
2023-12-13 23:20:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:20:33 | INFO | train_inner | {"epoch": 47, "update": 46.011, "loss": "4.17", "nll_loss": "2.77", "ppl": "6.82", "wps": "43621.9", "ups": "12.27", "wpb": "3554.8", "bsz": "144.2", "num_updates": "50700", "lr": "0.00280883", "gnorm": "0.367", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3105"}
2023-12-13 23:20:38 | INFO | train_inner | {"epoch": 47, "update": 46.102, "loss": "4.012", "nll_loss": "2.583", "ppl": "5.99", "wps": "60736.6", "ups": "16.82", "wpb": "3611.1", "bsz": "142.2", "num_updates": "50800", "lr": "0.00280607", "gnorm": "0.283", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3111"}
2023-12-13 23:20:45 | INFO | train_inner | {"epoch": 47, "update": 46.192, "loss": "4.07", "nll_loss": "2.651", "ppl": "6.28", "wps": "59024.7", "ups": "16.58", "wpb": "3559.4", "bsz": "145", "num_updates": "50900", "lr": "0.00280331", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3117"}
2023-12-13 23:20:50 | INFO | train_inner | {"epoch": 47, "update": 46.283, "loss": "4.07", "nll_loss": "2.65", "ppl": "6.28", "wps": "63227.3", "ups": "17.75", "wpb": "3562.7", "bsz": "149.7", "num_updates": "51000", "lr": "0.00280056", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3122"}
2023-12-13 23:20:56 | INFO | train_inner | {"epoch": 47, "update": 46.374, "loss": "4.093", "nll_loss": "2.677", "ppl": "6.4", "wps": "59225.5", "ups": "16.7", "wpb": "3546.1", "bsz": "146.2", "num_updates": "51100", "lr": "0.00279782", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3128"}
2023-12-13 23:21:03 | INFO | train_inner | {"epoch": 47, "update": 46.465, "loss": "4.156", "nll_loss": "2.751", "ppl": "6.73", "wps": "52112.4", "ups": "14.54", "wpb": "3583.6", "bsz": "128", "num_updates": "51200", "lr": "0.00279508", "gnorm": "0.305", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "3135"}
2023-12-13 23:21:08 | INFO | train_inner | {"epoch": 47, "update": 46.555, "loss": "4.062", "nll_loss": "2.644", "ppl": "6.25", "wps": "66959.9", "ups": "18.58", "wpb": "3604.3", "bsz": "165.5", "num_updates": "51300", "lr": "0.00279236", "gnorm": "0.283", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3141"}
2023-12-13 23:21:14 | INFO | train_inner | {"epoch": 47, "update": 46.646, "loss": "4.136", "nll_loss": "2.729", "ppl": "6.63", "wps": "65265.4", "ups": "18.02", "wpb": "3622.1", "bsz": "151.8", "num_updates": "51400", "lr": "0.00278964", "gnorm": "0.329", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3146"}
2023-12-13 23:21:20 | INFO | train_inner | {"epoch": 47, "update": 46.737, "loss": "4.13", "nll_loss": "2.724", "ppl": "6.61", "wps": "60884.6", "ups": "16.91", "wpb": "3599.8", "bsz": "152.3", "num_updates": "51500", "lr": "0.00278693", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3152"}
2023-12-13 23:21:26 | INFO | train_inner | {"epoch": 47, "update": 46.828, "loss": "4.214", "nll_loss": "2.817", "ppl": "7.04", "wps": "55609.5", "ups": "15.62", "wpb": "3561.3", "bsz": "122.6", "num_updates": "51600", "lr": "0.00278423", "gnorm": "0.336", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3158"}
2023-12-13 23:21:33 | INFO | train_inner | {"epoch": 47, "update": 46.918, "loss": "4.156", "nll_loss": "2.755", "ppl": "6.75", "wps": "57257.8", "ups": "16.05", "wpb": "3568.2", "bsz": "147.8", "num_updates": "51700", "lr": "0.00278154", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3165"}
2023-12-13 23:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:21:39 | INFO | valid | {"epoch": 47, "valid_loss": "4.308", "valid_nll_loss": "2.927", "valid_ppl": "7.61", "valid_wps": "122412", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "51790", "valid_best_loss": "4.283"}
2023-12-13 23:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 51790 updates
2023-12-13 23:21:39 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint47.pt
2023-12-13 23:21:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint47.pt
2023-12-13 23:21:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint47.pt (epoch 47 @ 51790 updates, score 4.308) (writing took 0.15886305924504995 seconds)
2023-12-13 23:21:40 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-12-13 23:21:40 | INFO | train | {"epoch": 47, "train_loss": "4.112", "train_nll_loss": "2.701", "train_ppl": "6.5", "train_wps": "58141.8", "train_ups": "16.22", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "51790", "train_lr": "0.00277912", "train_gnorm": "0.3", "train_loss_scale": "16", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "3172"}
2023-12-13 23:21:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:21:40 | INFO | fairseq.trainer | begin training epoch 48
2023-12-13 23:21:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:21:40 | INFO | train_inner | {"epoch": 48, "update": 47.009, "loss": "4.129", "nll_loss": "2.724", "ppl": "6.61", "wps": "46928.7", "ups": "13.05", "wpb": "3595.8", "bsz": "153.1", "num_updates": "51800", "lr": "0.00277885", "gnorm": "0.284", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3172"}
2023-12-13 23:21:47 | INFO | train_inner | {"epoch": 48, "update": 47.1, "loss": "4.042", "nll_loss": "2.617", "ppl": "6.13", "wps": "54165", "ups": "15.26", "wpb": "3548.3", "bsz": "135.4", "num_updates": "51900", "lr": "0.00277617", "gnorm": "0.312", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3179"}
2023-12-13 23:21:53 | INFO | train_inner | {"epoch": 48, "update": 47.191, "loss": "4.006", "nll_loss": "2.578", "ppl": "5.97", "wps": "62273.2", "ups": "17.25", "wpb": "3609", "bsz": "160.4", "num_updates": "52000", "lr": "0.0027735", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3185"}
2023-12-13 23:21:59 | INFO | train_inner | {"epoch": 48, "update": 47.281, "loss": "4.085", "nll_loss": "2.667", "ppl": "6.35", "wps": "59109.9", "ups": "16.29", "wpb": "3629.3", "bsz": "133.5", "num_updates": "52100", "lr": "0.00277084", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3191"}
2023-12-13 23:22:05 | INFO | train_inner | {"epoch": 48, "update": 47.372, "loss": "4.121", "nll_loss": "2.71", "ppl": "6.54", "wps": "56466.1", "ups": "16.11", "wpb": "3504.6", "bsz": "130.2", "num_updates": "52200", "lr": "0.00276818", "gnorm": "0.308", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3197"}
2023-12-13 23:22:11 | INFO | train_inner | {"epoch": 48, "update": 47.463, "loss": "4.148", "nll_loss": "2.742", "ppl": "6.69", "wps": "58192.8", "ups": "16.37", "wpb": "3554.8", "bsz": "134", "num_updates": "52300", "lr": "0.00276553", "gnorm": "0.309", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3203"}
2023-12-13 23:22:17 | INFO | train_inner | {"epoch": 48, "update": 47.554, "loss": "4.139", "nll_loss": "2.73", "ppl": "6.64", "wps": "57582.9", "ups": "16.03", "wpb": "3591.8", "bsz": "134.7", "num_updates": "52400", "lr": "0.00276289", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3209"}
2023-12-13 23:22:23 | INFO | train_inner | {"epoch": 48, "update": 47.644, "loss": "4.111", "nll_loss": "2.7", "ppl": "6.5", "wps": "59942.8", "ups": "16.75", "wpb": "3577.7", "bsz": "143.7", "num_updates": "52500", "lr": "0.00276026", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3215"}
2023-12-13 23:22:29 | INFO | train_inner | {"epoch": 48, "update": 47.735, "loss": "4.137", "nll_loss": "2.731", "ppl": "6.64", "wps": "58769.4", "ups": "16.42", "wpb": "3579.7", "bsz": "156.1", "num_updates": "52600", "lr": "0.00275764", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3221"}
2023-12-13 23:22:35 | INFO | train_inner | {"epoch": 48, "update": 47.826, "loss": "4.18", "nll_loss": "2.781", "ppl": "6.87", "wps": "59149.3", "ups": "16.18", "wpb": "3655.1", "bsz": "138.2", "num_updates": "52700", "lr": "0.00275502", "gnorm": "0.299", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3228"}
2023-12-13 23:22:41 | INFO | train_inner | {"epoch": 48, "update": 47.917, "loss": "4.1", "nll_loss": "2.691", "ppl": "6.46", "wps": "68237.2", "ups": "18.79", "wpb": "3631.8", "bsz": "168", "num_updates": "52800", "lr": "0.00275241", "gnorm": "0.282", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3233"}
2023-12-13 23:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:22:47 | INFO | valid | {"epoch": 48, "valid_loss": "4.291", "valid_nll_loss": "2.931", "valid_ppl": "7.62", "valid_wps": "122002", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "52892", "valid_best_loss": "4.283"}
2023-12-13 23:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 52892 updates
2023-12-13 23:22:47 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint48.pt
2023-12-13 23:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint48.pt
2023-12-13 23:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint48.pt (epoch 48 @ 52892 updates, score 4.291) (writing took 0.15205908007919788 seconds)
2023-12-13 23:22:48 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-12-13 23:22:48 | INFO | train | {"epoch": 48, "train_loss": "4.106", "train_nll_loss": "2.694", "train_ppl": "6.47", "train_wps": "58073.9", "train_ups": "16.21", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "52892", "train_lr": "0.00275001", "train_gnorm": "0.299", "train_loss_scale": "16", "train_train_wall": "65", "train_gb_free": "39", "train_wall": "3240"}
2023-12-13 23:22:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:22:48 | INFO | fairseq.trainer | begin training epoch 49
2023-12-13 23:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:22:48 | INFO | train_inner | {"epoch": 49, "update": 48.007, "loss": "4.115", "nll_loss": "2.709", "ppl": "6.54", "wps": "48006.4", "ups": "13.56", "wpb": "3540.8", "bsz": "159.9", "num_updates": "52900", "lr": "0.00274981", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3240"}
2023-12-13 23:22:54 | INFO | train_inner | {"epoch": 49, "update": 48.098, "loss": "3.921", "nll_loss": "2.481", "ppl": "5.58", "wps": "59307.8", "ups": "16.78", "wpb": "3535.3", "bsz": "169.3", "num_updates": "53000", "lr": "0.00274721", "gnorm": "0.285", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3246"}
2023-12-13 23:23:00 | INFO | train_inner | {"epoch": 49, "update": 48.189, "loss": "4.056", "nll_loss": "2.634", "ppl": "6.21", "wps": "61175.1", "ups": "16.94", "wpb": "3611.1", "bsz": "144.3", "num_updates": "53100", "lr": "0.00274462", "gnorm": "0.3", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3252"}
2023-12-13 23:23:06 | INFO | train_inner | {"epoch": 49, "update": 48.279, "loss": "4.082", "nll_loss": "2.666", "ppl": "6.34", "wps": "60192.5", "ups": "16.72", "wpb": "3600.6", "bsz": "138.6", "num_updates": "53200", "lr": "0.00274204", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3258"}
2023-12-13 23:23:12 | INFO | train_inner | {"epoch": 49, "update": 48.37, "loss": "4.074", "nll_loss": "2.655", "ppl": "6.3", "wps": "57554.2", "ups": "16.12", "wpb": "3571.2", "bsz": "142.1", "num_updates": "53300", "lr": "0.00273947", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3264"}
2023-12-13 23:23:18 | INFO | train_inner | {"epoch": 49, "update": 48.461, "loss": "4.139", "nll_loss": "2.732", "ppl": "6.64", "wps": "59001.1", "ups": "16.74", "wpb": "3524.7", "bsz": "135", "num_updates": "53400", "lr": "0.0027369", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3270"}
2023-12-13 23:23:24 | INFO | train_inner | {"epoch": 49, "update": 48.552, "loss": "4.13", "nll_loss": "2.723", "ppl": "6.6", "wps": "64438", "ups": "17.91", "wpb": "3597.4", "bsz": "145.8", "num_updates": "53500", "lr": "0.00273434", "gnorm": "0.305", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3276"}
2023-12-13 23:23:30 | INFO | train_inner | {"epoch": 49, "update": 48.642, "loss": "4.141", "nll_loss": "2.734", "ppl": "6.65", "wps": "54829.9", "ups": "15.51", "wpb": "3534.7", "bsz": "135", "num_updates": "53600", "lr": "0.00273179", "gnorm": "0.311", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3282"}
2023-12-13 23:23:36 | INFO | train_inner | {"epoch": 49, "update": 48.733, "loss": "4.145", "nll_loss": "2.74", "ppl": "6.68", "wps": "59707", "ups": "16.45", "wpb": "3629.2", "bsz": "133.6", "num_updates": "53700", "lr": "0.00272925", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3288"}
2023-12-13 23:23:42 | INFO | train_inner | {"epoch": 49, "update": 48.824, "loss": "4.103", "nll_loss": "2.691", "ppl": "6.46", "wps": "65218", "ups": "18.1", "wpb": "3602.5", "bsz": "165.7", "num_updates": "53800", "lr": "0.00272671", "gnorm": "0.321", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3294"}
2023-12-13 23:23:47 | INFO | train_inner | {"epoch": 49, "update": 48.915, "loss": "4.167", "nll_loss": "2.768", "ppl": "6.81", "wps": "64849", "ups": "18.01", "wpb": "3600.5", "bsz": "144", "num_updates": "53900", "lr": "0.00272418", "gnorm": "0.293", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3299"}
2023-12-13 23:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:23:54 | INFO | valid | {"epoch": 49, "valid_loss": "4.296", "valid_nll_loss": "2.916", "valid_ppl": "7.55", "valid_wps": "123465", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "53994", "valid_best_loss": "4.283"}
2023-12-13 23:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 53994 updates
2023-12-13 23:23:54 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint49.pt
2023-12-13 23:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint49.pt
2023-12-13 23:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint49.pt (epoch 49 @ 53994 updates, score 4.296) (writing took 0.1566969221457839 seconds)
2023-12-13 23:23:55 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-12-13 23:23:55 | INFO | train | {"epoch": 49, "train_loss": "4.102", "train_nll_loss": "2.69", "train_ppl": "6.45", "train_wps": "58918.1", "train_ups": "16.44", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "53994", "train_lr": "0.00272181", "train_gnorm": "0.302", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "3307"}
2023-12-13 23:23:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:23:55 | INFO | fairseq.trainer | begin training epoch 50
2023-12-13 23:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:23:55 | INFO | train_inner | {"epoch": 50, "update": 49.005, "loss": "4.157", "nll_loss": "2.755", "ppl": "6.75", "wps": "47232", "ups": "13", "wpb": "3634", "bsz": "146.5", "num_updates": "54000", "lr": "0.00272166", "gnorm": "0.321", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3307"}
2023-12-13 23:24:01 | INFO | train_inner | {"epoch": 50, "update": 49.096, "loss": "3.957", "nll_loss": "2.521", "ppl": "5.74", "wps": "64722", "ups": "18.07", "wpb": "3580.9", "bsz": "162", "num_updates": "54100", "lr": "0.00271914", "gnorm": "0.283", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3313"}
2023-12-13 23:24:06 | INFO | train_inner | {"epoch": 50, "update": 49.187, "loss": "3.987", "nll_loss": "2.556", "ppl": "5.88", "wps": "69123.7", "ups": "18.99", "wpb": "3640.4", "bsz": "155.8", "num_updates": "54200", "lr": "0.00271663", "gnorm": "0.279", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3318"}
2023-12-13 23:24:12 | INFO | train_inner | {"epoch": 50, "update": 49.278, "loss": "4.081", "nll_loss": "2.663", "ppl": "6.33", "wps": "59556.1", "ups": "16.48", "wpb": "3613.7", "bsz": "136.8", "num_updates": "54300", "lr": "0.00271413", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3324"}
2023-12-13 23:24:18 | INFO | train_inner | {"epoch": 50, "update": 49.368, "loss": "4.06", "nll_loss": "2.64", "ppl": "6.23", "wps": "59292.1", "ups": "16.42", "wpb": "3611.5", "bsz": "144", "num_updates": "54400", "lr": "0.00271163", "gnorm": "0.289", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3330"}
2023-12-13 23:24:24 | INFO | train_inner | {"epoch": 50, "update": 49.459, "loss": "4.101", "nll_loss": "2.688", "ppl": "6.45", "wps": "61091.7", "ups": "17.24", "wpb": "3543.1", "bsz": "150.1", "num_updates": "54500", "lr": "0.00270914", "gnorm": "0.302", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3336"}
2023-12-13 23:24:30 | INFO | train_inner | {"epoch": 50, "update": 49.55, "loss": "4.112", "nll_loss": "2.702", "ppl": "6.51", "wps": "55847.2", "ups": "15.49", "wpb": "3605.6", "bsz": "139", "num_updates": "54600", "lr": "0.00270666", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3342"}
2023-12-13 23:24:37 | INFO | train_inner | {"epoch": 50, "update": 49.641, "loss": "4.169", "nll_loss": "2.765", "ppl": "6.8", "wps": "48959.2", "ups": "14.08", "wpb": "3476.9", "bsz": "119.8", "num_updates": "54700", "lr": "0.00270418", "gnorm": "0.326", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "3349"}
2023-12-13 23:24:43 | INFO | train_inner | {"epoch": 50, "update": 49.731, "loss": "4.144", "nll_loss": "2.74", "ppl": "6.68", "wps": "59821.5", "ups": "16.91", "wpb": "3537.5", "bsz": "146.8", "num_updates": "54800", "lr": "0.00270172", "gnorm": "0.3", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3355"}
2023-12-13 23:24:49 | INFO | train_inner | {"epoch": 50, "update": 49.822, "loss": "4.083", "nll_loss": "2.671", "ppl": "6.37", "wps": "63069.7", "ups": "17.41", "wpb": "3623.3", "bsz": "165", "num_updates": "54900", "lr": "0.00269925", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3361"}
2023-12-13 23:24:55 | INFO | train_inner | {"epoch": 50, "update": 49.913, "loss": "4.179", "nll_loss": "2.78", "ppl": "6.87", "wps": "55409.5", "ups": "15.56", "wpb": "3561.1", "bsz": "137", "num_updates": "55000", "lr": "0.0026968", "gnorm": "0.31", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3368"}
2023-12-13 23:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:25:03 | INFO | valid | {"epoch": 50, "valid_loss": "4.289", "valid_nll_loss": "2.933", "valid_ppl": "7.64", "valid_wps": "124770", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "55096", "valid_best_loss": "4.283"}
2023-12-13 23:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 55096 updates
2023-12-13 23:25:03 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint50.pt
2023-12-13 23:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint50.pt
2023-12-13 23:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint50.pt (epoch 50 @ 55096 updates, score 4.289) (writing took 0.1487559573724866 seconds)
2023-12-13 23:25:03 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-12-13 23:25:03 | INFO | train | {"epoch": 50, "train_loss": "4.092", "train_nll_loss": "2.678", "train_ppl": "6.4", "train_wps": "57877.7", "train_ups": "16.15", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "55096", "train_lr": "0.00269445", "train_gnorm": "0.296", "train_loss_scale": "16", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "3375"}
2023-12-13 23:25:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:25:03 | INFO | fairseq.trainer | begin training epoch 51
2023-12-13 23:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:25:03 | INFO | train_inner | {"epoch": 51, "update": 50.004, "loss": "4.144", "nll_loss": "2.741", "ppl": "6.68", "wps": "46901.6", "ups": "12.99", "wpb": "3609.6", "bsz": "143.8", "num_updates": "55100", "lr": "0.00269435", "gnorm": "0.297", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3375"}
2023-12-13 23:25:10 | INFO | train_inner | {"epoch": 51, "update": 50.094, "loss": "4.006", "nll_loss": "2.574", "ppl": "5.95", "wps": "53133.6", "ups": "14.9", "wpb": "3565.1", "bsz": "127.2", "num_updates": "55200", "lr": "0.00269191", "gnorm": "0.284", "loss_scale": "16", "train_wall": "7", "gb_free": "38.9", "wall": "3382"}
2023-12-13 23:25:16 | INFO | train_inner | {"epoch": 51, "update": 50.185, "loss": "4.007", "nll_loss": "2.577", "ppl": "5.97", "wps": "61718.7", "ups": "17.16", "wpb": "3596.4", "bsz": "143", "num_updates": "55300", "lr": "0.00268947", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3388"}
2023-12-13 23:25:22 | INFO | train_inner | {"epoch": 51, "update": 50.276, "loss": "4.125", "nll_loss": "2.714", "ppl": "6.56", "wps": "56847.7", "ups": "15.98", "wpb": "3556.5", "bsz": "128.5", "num_updates": "55400", "lr": "0.00268705", "gnorm": "0.318", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3394"}
2023-12-13 23:25:27 | INFO | train_inner | {"epoch": 51, "update": 50.367, "loss": "4.04", "nll_loss": "2.618", "ppl": "6.14", "wps": "67418.9", "ups": "18.7", "wpb": "3604.4", "bsz": "156.2", "num_updates": "55500", "lr": "0.00268462", "gnorm": "0.289", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3399"}
2023-12-13 23:25:33 | INFO | train_inner | {"epoch": 51, "update": 50.457, "loss": "4.051", "nll_loss": "2.631", "ppl": "6.2", "wps": "65552.1", "ups": "18.04", "wpb": "3633.3", "bsz": "155.2", "num_updates": "55600", "lr": "0.00268221", "gnorm": "0.309", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3405"}
2023-12-13 23:25:38 | INFO | train_inner | {"epoch": 51, "update": 50.548, "loss": "4.035", "nll_loss": "2.616", "ppl": "6.13", "wps": "66066.4", "ups": "18.36", "wpb": "3597.7", "bsz": "175.4", "num_updates": "55700", "lr": "0.0026798", "gnorm": "0.299", "loss_scale": "16", "train_wall": "5", "gb_free": "39", "wall": "3410"}
2023-12-13 23:25:44 | INFO | train_inner | {"epoch": 51, "update": 50.639, "loss": "4.111", "nll_loss": "2.702", "ppl": "6.51", "wps": "63165.9", "ups": "17.79", "wpb": "3550.2", "bsz": "156.1", "num_updates": "55800", "lr": "0.0026774", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3416"}
2023-12-13 23:25:50 | INFO | train_inner | {"epoch": 51, "update": 50.73, "loss": "4.134", "nll_loss": "2.727", "ppl": "6.62", "wps": "56052.6", "ups": "15.7", "wpb": "3570.8", "bsz": "132.6", "num_updates": "55900", "lr": "0.002675", "gnorm": "0.323", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3422"}
2023-12-13 23:25:56 | INFO | train_inner | {"epoch": 51, "update": 50.82, "loss": "4.158", "nll_loss": "2.755", "ppl": "6.75", "wps": "57781.5", "ups": "16.16", "wpb": "3575.9", "bsz": "135", "num_updates": "56000", "lr": "0.00267261", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3429"}
2023-12-13 23:26:02 | INFO | train_inner | {"epoch": 51, "update": 50.911, "loss": "4.17", "nll_loss": "2.77", "ppl": "6.82", "wps": "61548.2", "ups": "17.11", "wpb": "3597.4", "bsz": "141.3", "num_updates": "56100", "lr": "0.00267023", "gnorm": "0.302", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3434"}
2023-12-13 23:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:26:10 | INFO | valid | {"epoch": 51, "valid_loss": "4.303", "valid_nll_loss": "2.926", "valid_ppl": "7.6", "valid_wps": "123349", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "56198", "valid_best_loss": "4.283"}
2023-12-13 23:26:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 56198 updates
2023-12-13 23:26:10 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint51.pt
2023-12-13 23:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint51.pt
2023-12-13 23:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint51.pt (epoch 51 @ 56198 updates, score 4.303) (writing took 0.16802636068314314 seconds)
2023-12-13 23:26:10 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-12-13 23:26:10 | INFO | train | {"epoch": 51, "train_loss": "4.086", "train_nll_loss": "2.671", "train_ppl": "6.37", "train_wps": "58879", "train_ups": "16.43", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "56198", "train_lr": "0.0026679", "train_gnorm": "0.301", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "3442"}
2023-12-13 23:26:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:26:10 | INFO | fairseq.trainer | begin training epoch 52
2023-12-13 23:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:26:10 | INFO | train_inner | {"epoch": 52, "update": 51.002, "loss": "4.122", "nll_loss": "2.714", "ppl": "6.56", "wps": "45135", "ups": "12.63", "wpb": "3572.5", "bsz": "144.8", "num_updates": "56200", "lr": "0.00266785", "gnorm": "0.296", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3442"}
2023-12-13 23:26:16 | INFO | train_inner | {"epoch": 52, "update": 51.093, "loss": "3.982", "nll_loss": "2.55", "ppl": "5.86", "wps": "58327.7", "ups": "16.37", "wpb": "3562.2", "bsz": "149.1", "num_updates": "56300", "lr": "0.00266548", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3448"}
2023-12-13 23:26:22 | INFO | train_inner | {"epoch": 52, "update": 51.183, "loss": "4.013", "nll_loss": "2.586", "ppl": "6", "wps": "62874.3", "ups": "17.64", "wpb": "3565", "bsz": "152.2", "num_updates": "56400", "lr": "0.00266312", "gnorm": "0.298", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3454"}
2023-12-13 23:26:28 | INFO | train_inner | {"epoch": 52, "update": 51.274, "loss": "4.066", "nll_loss": "2.646", "ppl": "6.26", "wps": "57424.1", "ups": "16.01", "wpb": "3585.9", "bsz": "135.4", "num_updates": "56500", "lr": "0.00266076", "gnorm": "0.309", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3460"}
2023-12-13 23:26:34 | INFO | train_inner | {"epoch": 52, "update": 51.365, "loss": "4.086", "nll_loss": "2.671", "ppl": "6.37", "wps": "62840.8", "ups": "17.38", "wpb": "3615", "bsz": "141.6", "num_updates": "56600", "lr": "0.00265841", "gnorm": "0.301", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3466"}
2023-12-13 23:26:40 | INFO | train_inner | {"epoch": 52, "update": 51.456, "loss": "4.086", "nll_loss": "2.672", "ppl": "6.37", "wps": "62152.1", "ups": "17.24", "wpb": "3604.2", "bsz": "149.2", "num_updates": "56700", "lr": "0.00265606", "gnorm": "0.293", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3472"}
2023-12-13 23:26:46 | INFO | train_inner | {"epoch": 52, "update": 51.546, "loss": "4.048", "nll_loss": "2.629", "ppl": "6.18", "wps": "59793", "ups": "16.7", "wpb": "3581.2", "bsz": "160.6", "num_updates": "56800", "lr": "0.00265372", "gnorm": "0.32", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3478"}
2023-12-13 23:26:52 | INFO | train_inner | {"epoch": 52, "update": 51.637, "loss": "4.136", "nll_loss": "2.73", "ppl": "6.63", "wps": "60060.8", "ups": "16.67", "wpb": "3603.6", "bsz": "140.2", "num_updates": "56900", "lr": "0.00265139", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3484"}
2023-12-13 23:26:58 | INFO | train_inner | {"epoch": 52, "update": 51.728, "loss": "4.084", "nll_loss": "2.672", "ppl": "6.37", "wps": "60578.2", "ups": "16.97", "wpb": "3569.8", "bsz": "146.9", "num_updates": "57000", "lr": "0.00264906", "gnorm": "0.292", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3490"}
2023-12-13 23:27:04 | INFO | train_inner | {"epoch": 52, "update": 51.819, "loss": "4.181", "nll_loss": "2.782", "ppl": "6.88", "wps": "57517.6", "ups": "16.17", "wpb": "3556.2", "bsz": "132.2", "num_updates": "57100", "lr": "0.00264674", "gnorm": "0.303", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3496"}
2023-12-13 23:27:10 | INFO | train_inner | {"epoch": 52, "update": 51.909, "loss": "4.088", "nll_loss": "2.675", "ppl": "6.39", "wps": "63837.6", "ups": "17.71", "wpb": "3603.9", "bsz": "152.9", "num_updates": "57200", "lr": "0.00264443", "gnorm": "0.304", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3502"}
2023-12-13 23:27:16 | INFO | train_inner | {"epoch": 52, "update": 52.0, "loss": "4.141", "nll_loss": "2.736", "ppl": "6.66", "wps": "59292.2", "ups": "16.61", "wpb": "3570", "bsz": "141", "num_updates": "57300", "lr": "0.00264212", "gnorm": "0.307", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3508"}
2023-12-13 23:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:27:17 | INFO | valid | {"epoch": 52, "valid_loss": "4.286", "valid_nll_loss": "2.91", "valid_ppl": "7.52", "valid_wps": "123722", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "57300", "valid_best_loss": "4.283"}
2023-12-13 23:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 57300 updates
2023-12-13 23:27:17 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint52.pt
2023-12-13 23:27:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint52.pt
2023-12-13 23:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint52.pt (epoch 52 @ 57300 updates, score 4.286) (writing took 0.15485578775405884 seconds)
2023-12-13 23:27:17 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-12-13 23:27:17 | INFO | train | {"epoch": 52, "train_loss": "4.083", "train_nll_loss": "2.669", "train_ppl": "6.36", "train_wps": "58713.6", "train_ups": "16.38", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "57300", "train_lr": "0.00264212", "train_gnorm": "0.303", "train_loss_scale": "16", "train_train_wall": "64", "train_gb_free": "39", "train_wall": "3509"}
2023-12-13 23:27:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:27:17 | INFO | fairseq.trainer | begin training epoch 53
2023-12-13 23:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:27:23 | INFO | train_inner | {"epoch": 53, "update": 52.091, "loss": "3.998", "nll_loss": "2.568", "ppl": "5.93", "wps": "45021.6", "ups": "12.66", "wpb": "3556.6", "bsz": "138", "num_updates": "57400", "lr": "0.00263982", "gnorm": "0.29", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3516"}
2023-12-13 23:27:29 | INFO | train_inner | {"epoch": 53, "update": 52.181, "loss": "3.983", "nll_loss": "2.552", "ppl": "5.86", "wps": "62955.7", "ups": "17.63", "wpb": "3571.2", "bsz": "156.1", "num_updates": "57500", "lr": "0.00263752", "gnorm": "0.288", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3521"}
2023-12-13 23:27:35 | INFO | train_inner | {"epoch": 53, "update": 52.272, "loss": "3.987", "nll_loss": "2.557", "ppl": "5.89", "wps": "64862.7", "ups": "18.35", "wpb": "3534.3", "bsz": "164.6", "num_updates": "57600", "lr": "0.00263523", "gnorm": "0.295", "loss_scale": "16", "train_wall": "5", "gb_free": "38.9", "wall": "3527"}
2023-12-13 23:27:41 | INFO | train_inner | {"epoch": 53, "update": 52.363, "loss": "4.059", "nll_loss": "2.639", "ppl": "6.23", "wps": "58620.9", "ups": "16.33", "wpb": "3590.4", "bsz": "132.9", "num_updates": "57700", "lr": "0.00263295", "gnorm": "0.294", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3533"}
2023-12-13 23:27:47 | INFO | train_inner | {"epoch": 53, "update": 52.454, "loss": "4.122", "nll_loss": "2.71", "ppl": "6.55", "wps": "56140.3", "ups": "16", "wpb": "3509.1", "bsz": "134.4", "num_updates": "57800", "lr": "0.00263067", "gnorm": "0.319", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3539"}
2023-12-13 23:27:54 | INFO | train_inner | {"epoch": 53, "update": 52.544, "loss": "4.127", "nll_loss": "2.718", "ppl": "6.58", "wps": "54173.1", "ups": "15.14", "wpb": "3577.1", "bsz": "134.5", "num_updates": "57900", "lr": "0.0026284", "gnorm": "0.315", "loss_scale": "16", "train_wall": "7", "gb_free": "39", "wall": "3546"}
2023-12-13 23:28:00 | INFO | train_inner | {"epoch": 53, "update": 52.635, "loss": "4.047", "nll_loss": "2.626", "ppl": "6.17", "wps": "59663.7", "ups": "16.41", "wpb": "3634.8", "bsz": "146.3", "num_updates": "58000", "lr": "0.00262613", "gnorm": "0.295", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3552"}
2023-12-13 23:28:06 | INFO | train_inner | {"epoch": 53, "update": 52.726, "loss": "4.13", "nll_loss": "2.724", "ppl": "6.61", "wps": "60787.5", "ups": "16.75", "wpb": "3628.5", "bsz": "147.4", "num_updates": "58100", "lr": "0.00262387", "gnorm": "0.312", "loss_scale": "16", "train_wall": "6", "gb_free": "38.9", "wall": "3558"}
2023-12-13 23:28:12 | INFO | train_inner | {"epoch": 53, "update": 52.817, "loss": "4.145", "nll_loss": "2.741", "ppl": "6.69", "wps": "59137.6", "ups": "16.44", "wpb": "3597.3", "bsz": "140.9", "num_updates": "58200", "lr": "0.00262161", "gnorm": "0.315", "loss_scale": "16", "train_wall": "6", "gb_free": "39", "wall": "3564"}
2023-12-13 23:28:17 | INFO | train_inner | {"epoch": 53, "update": 52.907, "loss": "4.128", "nll_loss": "2.722", "ppl": "6.6", "wps": "63270.3", "ups": "17.65", "wpb": "3584.2", "bsz": "145.4", "num_updates": "58300", "lr": "0.00261936", "gnorm": "0.302", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3569"}
2023-12-13 23:28:23 | INFO | train_inner | {"epoch": 53, "update": 52.998, "loss": "4.097", "nll_loss": "2.687", "ppl": "6.44", "wps": "65274.4", "ups": "17.96", "wpb": "3634.3", "bsz": "160.4", "num_updates": "58400", "lr": "0.00261712", "gnorm": "0.304", "loss_scale": "32", "train_wall": "5", "gb_free": "39", "wall": "3575"}
2023-12-13 23:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:28:25 | INFO | valid | {"epoch": 53, "valid_loss": "4.28", "valid_nll_loss": "2.922", "valid_ppl": "7.58", "valid_wps": "124882", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "58402", "valid_best_loss": "4.28"}
2023-12-13 23:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 58402 updates
2023-12-13 23:28:25 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint53.pt
2023-12-13 23:28:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint53.pt
2023-12-13 23:28:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint53.pt (epoch 53 @ 58402 updates, score 4.28) (writing took 0.21832163631916046 seconds)
2023-12-13 23:28:25 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-12-13 23:28:25 | INFO | train | {"epoch": 53, "train_loss": "4.076", "train_nll_loss": "2.66", "train_ppl": "6.32", "train_wps": "58416.5", "train_ups": "16.3", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "58402", "train_lr": "0.00261707", "train_gnorm": "0.303", "train_loss_scale": "32", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "3577"}
2023-12-13 23:28:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:28:25 | INFO | fairseq.trainer | begin training epoch 54
2023-12-13 23:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:28:31 | INFO | train_inner | {"epoch": 54, "update": 53.089, "loss": "4.005", "nll_loss": "2.576", "ppl": "5.96", "wps": "43077.3", "ups": "12.13", "wpb": "3552.1", "bsz": "135.8", "num_updates": "58500", "lr": "0.00261488", "gnorm": "0.292", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3583"}
2023-12-13 23:28:37 | INFO | train_inner | {"epoch": 54, "update": 53.18, "loss": "3.997", "nll_loss": "2.568", "ppl": "5.93", "wps": "61671.5", "ups": "17.16", "wpb": "3593.9", "bsz": "146.2", "num_updates": "58600", "lr": "0.00261265", "gnorm": "0.289", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3589"}
2023-12-13 23:28:42 | INFO | train_inner | {"epoch": 54, "update": 53.27, "loss": "3.993", "nll_loss": "2.565", "ppl": "5.92", "wps": "65095.7", "ups": "18.15", "wpb": "3587.2", "bsz": "166.4", "num_updates": "58700", "lr": "0.00261042", "gnorm": "0.302", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3595"}
2023-12-13 23:28:49 | INFO | train_inner | {"epoch": 54, "update": 53.361, "loss": "4.116", "nll_loss": "2.706", "ppl": "6.52", "wps": "55577.8", "ups": "15.5", "wpb": "3585.1", "bsz": "141.4", "num_updates": "58800", "lr": "0.0026082", "gnorm": "0.32", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3601"}
2023-12-13 23:28:55 | INFO | train_inner | {"epoch": 54, "update": 53.452, "loss": "4.077", "nll_loss": "2.659", "ppl": "6.31", "wps": "56104.3", "ups": "16.03", "wpb": "3499.2", "bsz": "130.6", "num_updates": "58900", "lr": "0.00260599", "gnorm": "0.387", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3607"}
2023-12-13 23:29:01 | INFO | train_inner | {"epoch": 54, "update": 53.543, "loss": "4.067", "nll_loss": "2.651", "ppl": "6.28", "wps": "65539.2", "ups": "17.93", "wpb": "3654.6", "bsz": "150.1", "num_updates": "59000", "lr": "0.00260378", "gnorm": "0.321", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3613"}
2023-12-13 23:29:07 | INFO | train_inner | {"epoch": 54, "update": 53.633, "loss": "4.075", "nll_loss": "2.66", "ppl": "6.32", "wps": "61287.6", "ups": "17.11", "wpb": "3581.7", "bsz": "147.9", "num_updates": "59100", "lr": "0.00260157", "gnorm": "0.309", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3619"}
2023-12-13 23:29:13 | INFO | train_inner | {"epoch": 54, "update": 53.724, "loss": "4.089", "nll_loss": "2.676", "ppl": "6.39", "wps": "56691.7", "ups": "15.94", "wpb": "3557.1", "bsz": "138.9", "num_updates": "59200", "lr": "0.00259938", "gnorm": "0.3", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3625"}
2023-12-13 23:29:18 | INFO | train_inner | {"epoch": 54, "update": 53.815, "loss": "4.097", "nll_loss": "2.687", "ppl": "6.44", "wps": "67549.8", "ups": "18.52", "wpb": "3648.3", "bsz": "155", "num_updates": "59300", "lr": "0.00259718", "gnorm": "0.297", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3630"}
2023-12-13 23:29:25 | INFO | train_inner | {"epoch": 54, "update": 53.906, "loss": "4.133", "nll_loss": "2.727", "ppl": "6.62", "wps": "56544.6", "ups": "15.75", "wpb": "3591.1", "bsz": "144.8", "num_updates": "59400", "lr": "0.002595", "gnorm": "0.304", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3637"}
2023-12-13 23:29:31 | INFO | train_inner | {"epoch": 54, "update": 53.996, "loss": "4.148", "nll_loss": "2.744", "ppl": "6.7", "wps": "56154.5", "ups": "15.77", "wpb": "3561.4", "bsz": "140.7", "num_updates": "59500", "lr": "0.00259281", "gnorm": "0.314", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3643"}
2023-12-13 23:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:29:33 | INFO | valid | {"epoch": 54, "valid_loss": "4.283", "valid_nll_loss": "2.916", "valid_ppl": "7.55", "valid_wps": "123707", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "59504", "valid_best_loss": "4.28"}
2023-12-13 23:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 59504 updates
2023-12-13 23:29:33 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint54.pt
2023-12-13 23:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint54.pt
2023-12-13 23:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint54.pt (epoch 54 @ 59504 updates, score 4.283) (writing took 0.15584409795701504 seconds)
2023-12-13 23:29:33 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-12-13 23:29:33 | INFO | train | {"epoch": 54, "train_loss": "4.073", "train_nll_loss": "2.657", "train_ppl": "6.31", "train_wps": "58034.6", "train_ups": "16.19", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "59504", "train_lr": "0.00259273", "train_gnorm": "0.312", "train_loss_scale": "32", "train_train_wall": "65", "train_gb_free": "38.9", "train_wall": "3645"}
2023-12-13 23:29:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1102
2023-12-13 23:29:33 | INFO | fairseq.trainer | begin training epoch 55
2023-12-13 23:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-12-13 23:29:39 | INFO | train_inner | {"epoch": 55, "update": 54.087, "loss": "3.988", "nll_loss": "2.559", "ppl": "5.89", "wps": "46829.1", "ups": "13.06", "wpb": "3585.9", "bsz": "149.8", "num_updates": "59600", "lr": "0.00259064", "gnorm": "0.295", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3651"}
2023-12-13 23:29:45 | INFO | train_inner | {"epoch": 55, "update": 54.178, "loss": "3.991", "nll_loss": "2.56", "ppl": "5.9", "wps": "59207.2", "ups": "16.58", "wpb": "3570.1", "bsz": "139.5", "num_updates": "59700", "lr": "0.00258847", "gnorm": "0.3", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3657"}
2023-12-13 23:29:51 | INFO | train_inner | {"epoch": 55, "update": 54.269, "loss": "4.064", "nll_loss": "2.642", "ppl": "6.24", "wps": "55839.6", "ups": "15.82", "wpb": "3530.7", "bsz": "125.8", "num_updates": "59800", "lr": "0.0025863", "gnorm": "0.313", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3663"}
2023-12-13 23:29:57 | INFO | train_inner | {"epoch": 55, "update": 54.359, "loss": "4.047", "nll_loss": "2.626", "ppl": "6.17", "wps": "61575.1", "ups": "16.92", "wpb": "3638.2", "bsz": "141.1", "num_updates": "59900", "lr": "0.00258414", "gnorm": "0.294", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3669"}
2023-12-13 23:30:03 | INFO | train_inner | {"epoch": 55, "update": 54.45, "loss": "4.051", "nll_loss": "2.631", "ppl": "6.2", "wps": "63210.8", "ups": "17.22", "wpb": "3671.5", "bsz": "150.1", "num_updates": "60000", "lr": "0.00258199", "gnorm": "0.304", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3675"}
2023-12-13 23:30:08 | INFO | train_inner | {"epoch": 55, "update": 54.541, "loss": "4.063", "nll_loss": "2.646", "ppl": "6.26", "wps": "64993.5", "ups": "17.98", "wpb": "3614", "bsz": "154.8", "num_updates": "60100", "lr": "0.00257984", "gnorm": "0.301", "loss_scale": "32", "train_wall": "5", "gb_free": "38.9", "wall": "3680"}
2023-12-13 23:30:14 | INFO | train_inner | {"epoch": 55, "update": 54.632, "loss": "4.086", "nll_loss": "2.674", "ppl": "6.38", "wps": "60405.9", "ups": "17.27", "wpb": "3498.4", "bsz": "150", "num_updates": "60200", "lr": "0.0025777", "gnorm": "0.315", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3686"}
2023-12-13 23:30:20 | INFO | train_inner | {"epoch": 55, "update": 54.722, "loss": "4.106", "nll_loss": "2.694", "ppl": "6.47", "wps": "55535", "ups": "15.68", "wpb": "3542.3", "bsz": "136.2", "num_updates": "60300", "lr": "0.00257556", "gnorm": "0.319", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3693"}
2023-12-13 23:30:27 | INFO | train_inner | {"epoch": 55, "update": 54.813, "loss": "4.128", "nll_loss": "2.722", "ppl": "6.6", "wps": "55980.7", "ups": "15.57", "wpb": "3596", "bsz": "144.3", "num_updates": "60400", "lr": "0.00257343", "gnorm": "0.343", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3699"}
2023-12-13 23:30:33 | INFO | train_inner | {"epoch": 55, "update": 54.904, "loss": "4.118", "nll_loss": "2.712", "ppl": "6.55", "wps": "63390.2", "ups": "17.49", "wpb": "3625", "bsz": "151.9", "num_updates": "60500", "lr": "0.0025713", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "39", "wall": "3705"}
2023-12-13 23:30:38 | INFO | train_inner | {"epoch": 55, "update": 54.995, "loss": "4.12", "nll_loss": "2.715", "ppl": "6.56", "wps": "62967.6", "ups": "17.74", "wpb": "3550", "bsz": "153.3", "num_updates": "60600", "lr": "0.00256917", "gnorm": "0.299", "loss_scale": "32", "train_wall": "6", "gb_free": "38.9", "wall": "3710"}
2023-12-13 23:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-12-13 23:30:40 | INFO | valid | {"epoch": 55, "valid_loss": "4.296", "valid_nll_loss": "2.912", "valid_ppl": "7.53", "valid_wps": "124168", "valid_wpb": "2835.3", "valid_bsz": "115.6", "valid_num_updates": "60606", "valid_best_loss": "4.28"}
2023-12-13 23:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 60606 updates
2023-12-13 23:30:40 | INFO | fairseq.trainer | Saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint55.pt
2023-12-13 23:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/jprado/experiments/nlp_experiments/checkpoint_d0_1e-0_84903/checkpoint55.pt
2023-12-13 23:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoint_d0_1e-0_84903/checkpoint55.pt (epoch 55 @ 60606 updates, score 4.296) (writing took 0.15138181019574404 seconds)
2023-12-13 23:30:40 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2023-12-13 23:30:40 | INFO | train | {"epoch": 55, "train_loss": "4.068", "train_nll_loss": "2.651", "train_ppl": "6.28", "train_wps": "58696.4", "train_ups": "16.38", "train_wpb": "3583.6", "train_bsz": "145.4", "train_num_updates": "60606", "train_lr": "0.00256905", "train_gnorm": "0.307", "train_loss_scale": "32", "train_train_wall": "64", "train_gb_free": "38.9", "train_wall": "3712"}
2023-12-13 23:30:40 | INFO | fairseq_cli.train | done training in 3712.2 seconds
